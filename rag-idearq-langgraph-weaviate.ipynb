{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __RAG - Orquestación con LangGraph__\n",
    "\n",
    "Autora: Elena Aguayo Jara\n",
    "\n",
    "Fecha: 19-09-2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:98;} </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "import os\n",
    "import pprint\n",
    "import logging\n",
    "import time\n",
    "import json\n",
    "import itertools\n",
    "import pathlib\n",
    "import torch\n",
    "import pandas as pd\n",
    "import ragas\n",
    "from ragas import evaluate\n",
    "from dotenv import load_dotenv\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_weaviate import WeaviateVectorStore\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.documents import Document\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "from pydantic import BaseModel, Field, ValidationError\n",
    "from langchain_ollama import OllamaLLM\n",
    "import weaviate\n",
    "from langchain.embeddings.base import Embeddings\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "from sentence_transformers import CrossEncoder, SentenceTransformer\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any, Optional, TypedDict\n",
    "from datetime import datetime, timezone\n",
    "from langsmith import Client\n",
    "from langsmith.evaluation import evaluate as ls_evaluate, LangChainStringEvaluator\n",
    "from ragas.metrics import (\n",
    "    ContextRecall,\n",
    "    Faithfulness,\n",
    "    ContextPrecision,\n",
    "    ResponseRelevancy,\n",
    "    AnswerCorrectness,\n",
    "    AnswerSimilarity,\n",
    "    SemanticSimilarity\n",
    ")\n",
    "from datasets import Dataset\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "load_dotenv(override=True)\n",
    "\n",
    "from IPython.display import display, HTML, Image\n",
    "display(HTML(\"<style>.container { width:98;} </style>\"))\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# Para el aviso de Triton, pesos y otros transformers \n",
    "logging.getLogger(\"xformers\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith configurado: True\n",
      "Proyecto: RAG-IDEArq\n"
     ]
    }
   ],
   "source": [
    "WEAVIATE_URL = os.getenv('WEAVIATE_URL', 'http://localhost:8080')\n",
    "LANGSMITH_API_KEY = os.getenv('LANGSMITH_API_KEY')\n",
    "LANGSMITH_PROJECT = os.getenv('LANGSMITH_PROJECT', 'RAG-IDEArq')\n",
    "LANGSMITH_TRACING = os.getenv('LANGSMITH_TRACING', 'true')\n",
    "MISTRAL_API_KEY = os.getenv(\"MISTRAL_API_KEY\")\n",
    "# Configurar LangSmith\n",
    "if LANGSMITH_API_KEY:\n",
    "    os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "    os.environ[\"LANGCHAIN_API_KEY\"] = LANGSMITH_API_KEY\n",
    "    os.environ[\"LANGCHAIN_PROJECT\"] = LANGSMITH_PROJECT\n",
    "\n",
    "\n",
    "RESULTS_DIR = pathlib.Path('./results')\n",
    "RESULTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f'LangSmith configurado: {LANGSMITH_API_KEY is not None}')\n",
    "print(f'Proyecto: {LANGSMITH_PROJECT}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memoria GPU limpiada\n"
     ]
    }
   ],
   "source": [
    "# Limpiar memoria GPU si está disponible\n",
    "import gc\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    print(f'Memoria GPU limpiada')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Configuración de modelos__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activamos los modelos SLM con Ollama:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ollama run hf.co/unsloth/Qwen3-4B-Instruct-2507-GGUF:Q8_0 \n",
    "# ollama run hf.co/MaziyarPanahi/Phi-3.5-mini-instruct-GGUF:Q6_K \n",
    "# ollama run hf.co/bartowski/Llama-3.2-3B-Instruct-GGUF:Q8_0\n",
    "# corremos los modelos localmente en una terminal diferente cada uno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo para embeddings: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:530: DeprecationWarning: the load_module() method is deprecated and slated for removal in Python 3.15; use exec_module() instead\n",
      "Some weights of the model checkpoint at Alibaba-NLP/gte-multilingual-base were not used when initializing NewModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing NewModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing NewModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Usando dispositivo para embeddings: {device}')\n",
    "# embedding gte\n",
    "model_kwargs = {\n",
    "    'device': device,\n",
    "    'trust_remote_code': True\n",
    "}\n",
    "\n",
    "'''Wrapper personalizado para el modelo de embeddings E5 Instruct.\n",
    "   Añade prefijos específicos (\"passage:\" para documentos, \"query:\" para consultas) \n",
    "   Métodos:\n",
    "    - embed_documents(): Procesa listas de documentos\n",
    "    - embed_query(): Procesa una consulta individual\n",
    "'''\n",
    "\n",
    "class E5InstructEmbeddings(Embeddings):\n",
    "    def __init__(self, model_name=\"intfloat/multilingual-e5-large-instruct\", device=None):\n",
    "        \"\"\"Inicializa el modelo de embeddings E5 Instruct con prefijos específicos para documentos y queries.\"\"\"\n",
    "        if device is None:\n",
    "            device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        \n",
    "        self.device = device\n",
    "        self.model = SentenceTransformer(model_name, device=device)\n",
    "    \n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        \"\"\"Para documentos - añadir prefix 'passage:'\"\"\"\n",
    "        prefixed_texts = [f\"passage: {text}\" for text in texts]\n",
    "        return self.model.encode(prefixed_texts, device=self.device).tolist()\n",
    "    \n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        \"\"\"Para queries - añadir prefix 'query:'\"\"\"\n",
    "        prefixed_text = f\"query: {text}\"\n",
    "        return self.model.encode([prefixed_text], device=self.device)[0].tolist()\n",
    "\n",
    "LLM = {\n",
    "    'Qwen3-4B-instruct-2507': OllamaLLM(model=\"hf.co/unsloth/Qwen3-4B-Instruct-2507-GGUF:Q8_0\", temperatura = 0.5),\n",
    "    'Llama-3.2-3B-instruct': OllamaLLM(model=\"hf.co/bartowski/Llama-3.2-3B-Instruct-GGUF:Q8_0\", temperatura = 0.5),\n",
    "    'Phi-3.5-mini-instruct': OllamaLLM(model=\"hf.co/MaziyarPanahi/Phi-3.5-mini-instruct-GGUF:Q6_K\", temperatura = 0.5)\n",
    "}\n",
    "\n",
    "EMBEDDING_MODELS = {\n",
    "    \"all-MiniLM-L6-v2\": HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "        model_kwargs={\"device\": device}),\n",
    "    \"e5-large-instruct\": E5InstructEmbeddings(\n",
    "        model_name=\"intfloat/multilingual-e5-large-instruct\",\n",
    "        device=device),\n",
    "    \"gte-multilingual-base\": HuggingFaceEmbeddings(\n",
    "        model_name=\"Alibaba-NLP/gte-multilingual-base\",\n",
    "        model_kwargs=model_kwargs)\n",
    "}\n",
    "\n",
    "# Cliente Weaviate\n",
    "client = weaviate.connect_to_local(\n",
    "    host=\"localhost\",\n",
    "    port=8080,\n",
    "    grpc_port=50051\n",
    ")\n",
    "\n",
    "# Mapear embeddings a las clases de Weaviate\n",
    "WEAVIATE_CLASSES = {\n",
    "    'all-MiniLM-L6-v2': 'IdearqAllMiniLM',\n",
    "    'e5-large-instruct': 'IdearqE5',\n",
    "    'gte-multilingual-base': 'IdearqGTE'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Aplicamos los tres tipos de prompts__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPTS = {\n",
    "'prompt_zero_shot': \"\"\"Eres un asistente experto en arqueología, historia y datos geoespaciales. Responde la pregunta usando los contextos proporcionados, que pueden estar en español, inglés, francés, catalán o portugués.\n",
    "Sintetiza información de todos los contextos relevantes independientemente de su idioma. Si encuentras información relevante en cualquier idioma, úsala para construir tu respuesta en el mismo idioma en el que se realiza la pregunta.\n",
    "\n",
    "Contexto: {context}\n",
    "\n",
    "Pregunta: {question}\n",
    "\n",
    "Instrucciones:\n",
    "- Si encuentras información parcial en el contexto, intégrala en la respuesta aunque no sea completa.\n",
    "- Si no hay absolutamente nada relevante, responde claramente: \"No hay información suficiente en el contexto\".\n",
    "- No inventes ni alucines información fuera del contexto.\n",
    "- Cuando sea posible, cita explícitamente los puntos clave del contexto (ej. autores, años, títulos de publicaciones, yacimientos, cronologías).\n",
    "- Responde siempre de forma clara, estructurada y útil para un investigador.\n",
    "\n",
    "Respuesta:\"\"\",\n",
    "\n",
    "    'prompt_one_shot': \"\"\"Eres un asistente experto en arqueología, historia y datos geoespaciales. Responde la pregunta usando los contextos proporcionados, que pueden estar en español, inglés, francés, catalán o portugués.\n",
    "Sintetiza información de todos los contextos relevantes independientemente de su idioma. Si encuentras información relevante en cualquier idioma, úsala para construir tu respuesta en el mismo idioma en el que se realiza la pregunta.\n",
    "\n",
    "Contexto: {context}\n",
    "\n",
    "Pregunta: {question}\n",
    "\n",
    "Instrucciones:\n",
    "- Si encuentras información parcial en el contexto, intégrala en la respuesta aunque no sea completa.\n",
    "- Si no hay absolutamente nada relevante, responde claramente: \"No hay información suficiente en el contexto\".\n",
    "- No inventes ni alucines información fuera del contexto.\n",
    "- Cuando sea posible, cita explícitamente los puntos clave del contexto (ej. autores, años, títulos de publicaciones, yacimientos, cronologías).\n",
    "- Responde siempre de forma clara, estructurada y útil para un investigador.\n",
    "\n",
    "Ejemplo:\n",
    "Q: ¿Cuál es la utilidad de los análisis de isótopos de estroncio en Arqueología?\n",
    "A: El tema del desplazamiento, la movilidad y la migración ha sido altamente destacado como uno de los cinco grandes retos de la investigación arqueológica contemporánea. El uso del análisis de isótopos de estroncio es hoy en día uno de los métodos más eficaces para afrontar este reto, ofreciendo un enfoque sistemático, cuantitativo y comparable a la movilidad de las poblaciones humanas y animales del pasado (Larsen 2018).\n",
    "\n",
    "Respuesta:\"\"\",\n",
    "\n",
    "    'prompt_few_shot': \"\"\"Eres un asistente experto en arqueología, historia y datos geoespaciales. Responde la pregunta usando los contextos proporcionados, que pueden estar en español, inglés, francés, catalán o portugués.\n",
    "Sintetiza información de todos los contextos relevantes independientemente de su idioma. Si encuentras información relevante en cualquier idioma, úsala para construir tu respuesta en el mismo idioma en el que se realiza la pregunta.\n",
    "Contexto: {context}\n",
    "\n",
    "Pregunta: {question}\n",
    "\n",
    "Instrucciones:\n",
    "- Si encuentras información parcial en el contexto, intégrala en la respuesta aunque no sea completa.\n",
    "- Si no hay absolutamente nada relevante, responde claramente: \"No hay información suficiente en el contexto\".\n",
    "- No inventes ni alucines información fuera del contexto.\n",
    "- Cuando sea posible, cita explícitamente los puntos clave del contexto (ej. autores, años, títulos de publicaciones, yacimientos, cronologías).\n",
    "- Responde siempre de forma clara, estructurada y útil para un investigador.\n",
    "\n",
    "Ejemplos:\n",
    "Q: ¿Cuál es la utilidad de los análisis de isótopos de estroncio en Arqueología?\n",
    "A: El tema del desplazamiento, la movilidad y la migración ha sido altamente destacado como uno de los cinco grandes retos de la investigación arqueológica contemporánea. El uso del análisis de isótopos de estroncio es hoy en día uno de los métodos más eficaces para afrontar este reto, ofreciendo un enfoque sistemático, cuantitativo y comparable a la movilidad de las poblaciones humanas y animales del pasado (Larsen 2018).\n",
    "\n",
    "Q: ¿Cuáles son las características de la distribución geográfica de la muestra disponible de análisis de isótopos de estroncio en la Península Ibérica?\n",
    "A: La distribución de la muestra es variable y discontinua, con concentraciones asociadas a focos de investigación específicos (p. ej., Lisboa, valle del Ebro). La cobertura es irregular tanto geográfica como cronológicamente, lo que dificulta los estudios a escala ibérica para la mayoría de los periodos, a excepción de la Edad del Cobre (764 muestras). La escasez de datos es crítica en algunas épocas, como el Mesolítico, que cuenta con una única muestra. \n",
    "\n",
    "Respuesta:\"\"\"\n",
    "}\n",
    "\n",
    "selected_template = PROMPTS['prompt_few_shot']\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(selected_template)\n",
    "\n",
    "example_messages = prompt_template.invoke(\n",
    "    {\"context\": \"Contexto de ejemplo.\", \"question\": \"Pregunta de ejemplo.\"}\n",
    ").to_messages()\n",
    "\n",
    "# Results dir\n",
    "RESULTS_DIR = pathlib.Path('./results')\n",
    "RESULTS_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Definimos el grafo__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estado del grafo con TypedDict\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    llm_name: str\n",
    "    embedding_name: str\n",
    "    prompt_name: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "    metadata: Dict[str, Any]\n",
    "\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "@dataclass\n",
    "class RunResultComplete:\n",
    "    llm: str\n",
    "    embedding: str\n",
    "    prompt: str\n",
    "    question: str\n",
    "    answer: Optional[str]\n",
    "    contexts: List[str]\n",
    "    ground_truth: Optional[str]\n",
    "    docs: List[Dict[str, Any]]\n",
    "    latency: float\n",
    "    metadata: Dict[str, Any]\n",
    "    # Métricas RAGAS con LLM\n",
    "    context_recall: Optional[float] = None\n",
    "    faithfulness: Optional[float] = None\n",
    "    context_precision: Optional[float] = None  \n",
    "    # Métricas RAGAS sin LLM\n",
    "    answer_correctness: Optional[float] = None  \n",
    "  \n",
    "def retrieve(state: State):\n",
    "    # Obtener el modelo de embedding correspondiente\n",
    "    embedding_model = EMBEDDING_MODELS[state[\"embedding_name\"]]     \n",
    "    class_name = WEAVIATE_CLASSES[state[\"embedding_name\"]]   \n",
    "\n",
    "    vector_store = WeaviateVectorStore(\n",
    "        client=client,\n",
    "        index_name=class_name,\n",
    "        text_key=\"content\",\n",
    "        embedding=embedding_model,\n",
    "        attributes=[\"filename\", \"title\", \"source\", \"chunk_index\", \"doc_index\"]\n",
    "    )\n",
    "\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"], k = 10)\n",
    "    #print(f\"Recuperados {len(retrieved_docs)} docs para {state['embedding_name']}\")\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "def generate(state: State):\n",
    "    print(\"    -> Entrando en el nodo 'generate'...\")\n",
    "    try:\n",
    "        # 1. Preparamos el contexto y el prompt\n",
    "        docs_content = \"\\\\n\\\\n---\\\\n\\\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "        template = PROMPTS[state[\"prompt_name\"]]\n",
    "        prompt = ChatPromptTemplate.from_template(template)\n",
    "        \n",
    "        # 2. Seleccionamos el LLM\n",
    "        current_llm = LLM[state[\"llm_name\"]]\n",
    "        \n",
    "        # --- INICIO DE DEPURACIÓN ---\n",
    "        print(f\"       - LLM a usar: {state['llm_name']}\")\n",
    "        print(f\"       - Prompt a usar: {state['prompt_name']}\")\n",
    "        # Imprimimos solo los primeros 300 caracteres del contexto para no llenar la pantalla\n",
    "        print(f\"       - Contexto para el prompt (primeros 300 chars):\\\\n'{docs_content[:300]}...'\")\n",
    "        # --- FIN DE DEPURACIÓN ---\n",
    "\n",
    "        # 3. Invocamos el LLM\n",
    "        messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "        response = current_llm.invoke(messages)\n",
    "        \n",
    "        print(\"    -> El LLM ha devuelto una respuesta.\")\n",
    "        \n",
    "        latency = 0 \n",
    "        metadata = { \"latency\": latency }\n",
    "\n",
    "        return {\"answer\": response, \"metadata\": metadata}\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"    -> ERROR DENTRO DEL NODO 'generate': {e}\")\n",
    "        return {\"answer\": \"\", \"metadata\": {\"error\": str(e)}}\n",
    "\n",
    "def extract_sources_from_docs(docs: List[Document]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Extraer metadatos de fuentes de los documentos\"\"\"\n",
    "    sources = []\n",
    "    for doc in docs:\n",
    "        metadata = doc.metadata\n",
    "        source_info = {\n",
    "            'filename': metadata.get('filename', 'Unknown'),\n",
    "            'title': metadata.get('title', metadata.get('doc_title', 'Sin título')),\n",
    "            'page_content_preview': doc.page_content[:200] + \"...\"\n",
    "        }\n",
    "        sources.append(source_info)\n",
    "    return sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGoAAADqCAIAAADF80cYAAAQAElEQVR4nOydB1wUZ/rH35ndpeyydBDpIkXFgrHFEokCSgpnj9hOo7FgL+g/xpSz5Dyjnl40nnqJ8eKJJrFENMaYxBawoCIGe6QXAenLwrJl9v/M7rosuDuzy4iOMF/98JmZ931nZ37zvGXeMg9frVYjjubCRxwM4ORjBCcfIzj5GMHJxwhOPkYwlS/rVt3DNEl1uby2RkUoEYJWEKb5C+0hDLYQhpN7iEBqjPyHcE04QUaDcNggIxCac+FqRJBJGtLyNEGalhUZDY6rMd0PayJr02IYgXBcrdKFYDxCrcIbLhFTa86A6Q/gAszGFhc58P262IW+aocYgDWv3Zd6pjo9uaKmWglXLhDgAlsM52luRqUGgRrEMpBP93u45kcJtUZHckMvH5yBUJFx1bgaI7RpNbdOIN22WiuEJjKOEWTaRqfSBfExQtlwU+RDQggZ3CXOwwm1WiEjFHICftFGJOjQRThkvBuyHIvlS/2t+tqvpXCpbl7WvSNd/Tpbo5eZmnJ10rGSvIxalZzw72oX/dd2FiW3TL7/rs2WSYnO/RwGj3JBrYu7V2ou/vgYjHHm6gDzizQL5NsR/9DN22bcYm/Uejn3femdK1UDYlzDwh3MiW+ufNuXPhwyziO0P6OC9mUBDGXSyg4OLjzamGbJtyM+Y+bajgJb1HbY9X5m7wjnXlGO1NFwRMfOFZlD3/FoU9oBs/8RkPJLWfVjGtuike+bdTnuPjad+opQ26PvcNeEzVnUcajku/5rpVSiGr3AE7VJekU4iOz4R7YXUMShlO9MRbd+NJm/dTN6gXdhZh1FBJPy3TwvUSmJQaOdURtG5IALxTwKAzQp340L5e5ez7u+iIqKKigosDRVRkbG22+/jVqGHoOdSvLqTYWalE9aqegz/Lm+Wjx69KiiogJZzp07d1CL0SvCEV5Fcu/VGg01/nry8IYUx3HfTi3yPgstzQMHDpw4cSInJ6dDhw6vvvpqXFzcjRs35syZA6EjRowIDw/fvHkz2NShQ4euXr1aWFgYEBAwcuTIsWPHas8QERHx3nvvnTlzBlJNmTJl3759cLB3795LliyZNGkSetbYiHi3kqt9OwmfDjIuX+ZtKb/FugIOHjy4Z8+exYsXDxw48Ny5c1988YVIJHr33Xe3bt0KB48dO+bl5QXRQEEQbtWqVRiGZWdnb9iwoX379pAEggQCwdGjR/v27Qsi9urVCyKcPn0angdqGcRO/MrHcqNBxuWrLlPYCOlfWZpHampqly5dtKXVqFGj+vTpU1trJGusX79eKpV6epLNJrCsxMTEixcvauUDvRwcHOLj49FzQewkKMgwXv8al09erxJYtZR8PXr02LZt25o1a3r27Dl48GBvb+N9EJDHwU6Tk5Mhj2uPaK1SCzwA9LywscOVcsJokHH5CBWB07/ONZOJEydCbj1//vzq1av5fD7UtgsXLnRza9RbSRDEokWL5HL5/PnzwfTEYvGMGTMMI1hZWaHnBXTNYibUMC6flTW/vk6FWupq8FEaMjMzU1JSdu/eXVNTs2XLFsM49+7du3379o4dO6CA0x6RSCTu7u7oRVAnAWPCjAYZV9XeWSCvN26uzIEyHmpV2ID6NDY2dsKECffv328Sp7KyEv7q9crUgF4QUBPwbYwXZcbl8wkRympbyvpOnTq1fPnyCxcuVFVVJSUlQfsDSkM47u/vD39/+eWXW7dugbKQr6FFUl1dDdXuxo0boX0DDUOjJ/T19S0tLYVKXF9KPluqKuROLgKjQcblC+0vhtqttNB4bc2QDz/8ENRZunQpNN/Wrl0LrTxoncBxqENiYmJ27twJFYuHh8e6devS09OHDh0Krbl58+ZBow9k1Tf9DBk0aFBYWBhUxD///DNqAeprVZ17i40Gmewu/eqjLOia/8vs9qhtc+9azW8HiuZtDjQaarJ+DQyzy3sgRW2eSydK7U3kXEQxTB4+xu32paq0c1VhrxsfNCkqKoKC32iQnZ0dVKZGgyDbwisHahn2ajAaBGWRqXwGbSOjZYKWWolyxppAU6FUYx1nvi3NSJfMXNfBaKhSqSwpKTEaJJPJbGxsjAZBhdBy7Q+JBqNBUAXZ29sbDYLj8LyNBiWszyUINHmVLzIBzVDRrpWZfp2E0VM9UNuj4KEscVdB3MaOFHFo3i1mrw/ISJfW17TFCbzHdxcOiKGZuUH/ahY1od3etVmojfH133J8goU9BttTRzNrnLe8WJHwWe78TR0RhtoC/16RET6mXZd+9HMCzJ1lkHW77sevCnq85vRaq5vdYkju3bof9xb6hYjenG5WcW/JFCEV2vVhppU1PmxyO6/AVjhsfuCzPOgW7f+2W1i4vZlJLJ6gdvKroux7UuhMDQqze22UK3r5uXG++lZyZXWZ3MXTJnaZZROgmjk98uSeooKHtdArY23LE9nzBTaYUMwn4Fwqg3mJeMOURd0RDGl/Tb/RAN4whdJwm5zrqHoyKxLTzzTVndnghBgi56rqJrfqG8m66ae4dh6mLhVPwFPKCGm1srZGVS9TQW+ei6fVuDhvZHkXYjPl0yItJ1J+LS8trIdHB5etVCBC1XhaZ+Nza+bWamofMujJthYDyTTpdEFqtRLDmr4aacTBdKfUnZA8m2ZSLxnUcAZyeir25KDuKfD5GI+cn8tz8hB0G+DkHdz8YR1G8j0Hhg8fnpCQ4OLC0vqK7TPr4dUQ3vMQW+HkYwQnHyPYLp9CoYBBccRWWC0fDFcizcgcYiuslo/lORdx8jGE1RfH8oIPcdbHEE4+RnDyMYKTjxFsl4+rOpoPZ32M4ORjBCcfI6DZzMnXfDjrYwQnHyM4+RjByccIrseFEZz1MYLH44nFYsRi2D5UVFVVhVgMu7MGnw/5F7EYTj5GcPIxgpOPEZx8jGB7w4WTr/lw1scITj5GcPIxgpOPEZx8jODkYwQnHyM4+RjByccI9svHxlVFq1evTkxM1F6YZjUVCY7jV69eRSyDjZPW4+Li/P39cQ3w2ouTn+DCTH1o7cXCRvnc3d0jIyMNj4B8I0aMQOyDpUsmJk+e7Ofnp9/18vIaOXIkYh8slQ8G2GJiYvQLYoYNG+boyMYvSLN3wc7EiRO15Z2np+fo0aMRK7Gs5r10oryqXKGoJ79N17BY/Mm6Z3LZMbnk2WC195MNzWJlMi5O+t5pWGXeaMU5ptlrcMuD5efl//nwgZend1BQEOySy8UNPirY4ORIc1qCMLJ+3dTXl7TxmyAQ4Lb2gr7DXGzNdqthrnwnvyrOeVDL55EXrajXqqZzvGSwIl6zhltt4LTpSRxD10Vka4TQLRbH8IZtMhZ5/8gwiCBPhGsW2BM4HCIaXbve85NOSoMjDXG0l9QEw7X/T+AJMJyHFDLC0c16wgqzKnqz5EtKLLtzuTpmlr+dU5v4kMsP2/OtbNH4pfQK0st39tvSjNvS8cv8UFvi+K58HFfHxvtQR6OvOv68WRPazwm1MWJme1cU0388k0Y+eQ1SylVdB5n7WZjWBE+AXzxRTh2HpsugRqIi2qr/Y0KlltXQfP+WrscFU6lb6gPEbEelUquUNKbDufhkBCefScgmKs7U+rA2WvJp3bgSNO1cWvnUbeOLh82E3voQh2m4ss8kpMdhOp8lnHwmgXafms7tAX3Zh9oqmg4irt3XXHT9lJRwVYdJyHYfj6n1td3MS7b7VDTWQ9thhb0o8zt85GBEVF/Ebmjla9n+ltVr3j/50zGjQV06d50y+T3Ebl5w1XH//p0+ffobDercuSv8Ry8O8lvGdFnv2Q9UQqYbM254UvI5yHrbvtgER8rLy9Z9uip24tsjR0d+uv6jvDydQ6YhEb0fFRVu3LQ2ZsTrsDtiVMThwwcWLZkJx6sl1YaZV6lU7tr9+bsz3nkrZvD/rVx4+XKS9viCRTNW/N98w19fuWrx3PnTKJJYhJqu6H/28llZWdXWShMTD618f82oEe+oVKoly2an3by+ZPEHe7781snRee68qQWF+RDz1Mlk+Ls8/qPjx84hjefJEyePBgaGbPzsC6FtI3+an2/77NDhhFEjxyfsPx4+OOKT1SvOX/gNjg8Jj7qemiKV6pwCyWSya9cuRw6NpkhiPmSxpWZcdagtrHxhYBVuIzZ2amREtLe3b3p6Wm5u9gcr1/brO8DZ2SVuzmJ7B8fDhxOMJrS3d1gwL753r36Gq6Dr6+t/Pn1i4oRpf4kZ42Dv8OYbIyKGRn+z7z8QFB4eSRDE70lntDHB5GH39dejKJI8W+irDqxZTb9OIaHajfRbaWBWr/Tso90FjcJ69Lr5R6rRVCHBRjxPPnhwVy6X9+ndUETCGTIzH1ZVV7m4uML270lntceTk8/1eqUvPCRTSUBWZD6Ymrbsa6mqQ+9DsqZGolAooDgzDHV0dKJOZQicAWmKuSbHK8rLwLLA1rZ/sQnsncfjXbr8+8IFKyiSyOpl1tbmfmLdHLtp8bcOMBBbW9tP1zVyQcnDLXC/6uJKerxZtnSVl1ejUVd3d9KlBsgHxdzFSxdAejLnhkdRJBEJRchsoOyjHSZr8beOjh2D6+rq4Fa9PHWD9oWPChwdLBg49vby1ZpMzzCdCVdUlMPovlBIVi9ggJBhU1Iu1tfLBg4I1x40lcTSD0vQGiB9zcvQ/ODe+vYdsGnT2uLioqqqyh+OfT8nbsqpU4kQBHfo5uYOdeWNtGsUc5hBkWlTZ0PBD7UQlGhQgcavmLv1X//QR4AK5I8/Uq9fvwKWaGaSZwX902D+1rH+062Jxw+vWbfyzp10Hx+/yMg3Ro/W+cebNHH613t3ply9eCCByjV27Pi/ghUnHNybmpoiEtmFdum+bNmH+lDIsP/c8nd4GGB9ZiZ5VtDMcSkvku/fkDvtb4Go7fHN2ozgMHHUZCqnfFyHlUnIVgtd2cZ1WJmEzJZ0Myw462MEZ30mMafHhbM+k0Dmpe3s5KyPEdxIm0lwHHHD5M2HIBDzYXIu+1JhRtXBNV1Mw1UdjODKPkZw8jGCVj4rvK0qbGXNg//UcWi6FJw9EI7hklL69TWtD5WK8KRzgk3f2yxy4F/6qQy1Me5dqYJmc1BPIXU0evn+usr3cW5dwQNWfxDkmXPtt/IBb7WjjWbuet7dKzPtxAKfznZiZ75SZSQJZrSNo9as9jURT7tpZGWtWtfcVJtIon7Sk2H4o/ptNbxs6RcFP1ngiz1JRWAmp4yCuclrUd59Semj+snL/cRu9MOBFqwmP7S1oKJEoVSqlAq10TM9PaXhaU1xXE3o10Jr5dP4DUeU19hk2XPDAmzD8+uXZxuuMseQdnm5fuNp/+j6DR6O+AKenSP/L+/62NFbnvY32b3iLzo6ev/+/Zxz7WbCuTdmBCcfI1ju7YmzPkawWj6o1giC4PEsmE/0nOG8xTCCk48RnKsnRnDWxwhOPkZw8jGCK/sYwVkfIzj5GMHJxwhOPkZw8jGCk48RnHyM4ORjBNdsZgRn+3IDTQAACgJJREFUfYzg5GME273FuLm5IRbDavlUKlVJSQliMZyvIkZw8jGCk48RnHyM4ORjBCcfI9guH7RdEIvhrI8RnHyMYLt80OmCWAxnfYzg5GMEJx8jOPkYwcnHCE4+RrBxVdGCBQuSkpKwJ5/wwXGcIAjYvX79OmIZbHQwu2jRIm9vb/wJSKOgr68vYh9slC8wMHDQoEGG2QJMLzw8HLEP9jrX9vFp+GorbI8dOxaxD5bK5+XlFRERod2Ggq93795aT9Fsg73OtWNjY7Xe3eHv+PHjESt5lg2X/Af1kip5E7+OTVZEq7UftWxc2+sXJDdKhqyH9Z95Vna2W0jXuhK324+rn24jYJrV6GrznD+Th3m4UMjzDLY19nnt5sC04XL2u8e5D2rrJOQSc40KTc9nuLabRK050iQO1ceKdCvvjfoYN6K7xs0BrvHz/TQ8HrnIX7se3doWb+dv+/YUD8RAyubLd+CzvPISOY+P2Yit7d3Fzt4WfJD7hVNdXFfxSCqrrlPIlUKxIHpye8/A5qjYHPmO7XqU/6DWWmTlG+puZf/SfyUn62pRbVWdvYvVlA8sblpaLN9/VmURaixkoA+La53m8PBSoVwmn/pxR5GdBaksk2/H8kyxq9CnO6un7TSbinxp4b2S6X/rYCs2dwWxBfLtiM9w9nHyCHZArZpbv2aNWeDb3t+sotDcHPjvFRluHVq/dkDXyA6HP89F5o2PmiXfN+tybETWbgGtXzst7gHOO1dlmhOTXr6U05XSalWHvu1Rm8G9owN0NX7/rwLamPTypf5W7ubvjNoYgQO9SnJliO7DezTynT9cBjWLawcxantAw/bg1nzqODTy/ZlWbef6Mr1OPEM8glzKSmg8a1HKp0CyWsKnqyt6CXlUnLFu0wjEADtXawzHrvxUQRGHSr5zx0rhlRa9nOQX3EWMEdgIMtNrKCJQvbEWZcsE1mYt6rmUcuRc8v66uurOwQOjI+d8unnEpHFre3YfBkHZuX+cPvtlXv4dO5FT55BBw4a8Z2NDlgb7vv0AGu2v9Ij+9sia+vpaP59ubw2f7+ej8+l5NfXEpatHHxU/bN8uMKxb5Gv9Y7UjRx+vHxb1+vT02+cyc26sWfmLUGifdPm7O/eTcvNvC/jWAf4934iMc3XxPvXb7l/PfQXx4z/qFxO9KHzgxGpJ2fGftmbn/SGXy0KCXo0Mn+7u5kd7XyIHa0mZlCIClfVJJUqBDX2PAFz64eMbeoRGrFj0ffeuEf/7jvSohJG+lVFpWd6uvQsUivr5s76cOnHDo+I//70nTqUixx5xnJ+Tl3497adFc/b+/ePzfIHVwSNrtCdMvfnzt0fXenuGfLD06BtRcRcuHjx2Uufmjc8TXL52zLN98Kyp26ythVk5aT/8uNnft/u0CZ/Fjv6kRlqecOgTiBYdMev1QVMcHTw2rb0C2qlUqp175mZkp46JeX/Z/AQ7kfPnu6eXluXT3prQSaisJ5opn7xOhQvoWzbXbpwU27kMj5hlJ3IM7fRacGA/fVDqzVNww9MmbGjn5u/hHjBuxKqCR/dv3T2vDQWjGz/qQxdnLx6P/0r34Y9Lc+AIHE+5fizAr+fomBViO+eggN5w5uQr30tqyjWJMJGtw8i3lgYH9oVUvt7d4hcciBg8LTCgV0hQv/ABk3Lzb0lrq5pcYVZuWklp9oSxqzsF97cXu8RELxQJHX+/dJD21oRCPkFQvX9QGRd0K+I8+rKvqDjD1zsUbka72z10yC9nv9RuQ8718e4iEjlqd52d2rs4e4PJ9OhKjmO4u/mDBWmDbGzItlFtXbVAYJOV+0fUkAb/iKCgWk1kZad17zoUkS7sOuuDeDxeWXlB4sktkANk9bpcVlNTLhI2ekHKzrnJ4wngPNpdKAc6dnglM/sGokPN56kpLYxKPpyHCCV9h0KdTOLo2PCpT3iwBkE1eQV3oAAyjA/FkHZDm8GboFTKVSrFqV93wn/D4xJpue6K+Q0v87fuXtibsHzo4GlvDV/g6RH04GHKf75ZaOwKa+CcTS4DymJEB0HOcaBSgEo+AR9XyuhfncFelMqGSYzVklL9tljs0sEvbPjQWYbxRSKqd2crKxtrK2GvsDe7hw41PA55/OnIV679AOd/MypOuwsP0ug5oWyxsrKdPmmz4UHtADw1smo5tF0oIlDJJ3a1qiyjn2ICNV1B4X39LliEftuzXdD1myehQtRfa1FJppsLTacu1AwgBBRn2l14NmUVBY4ORr5lC5ndydFDv5t+56zRE3q1D5bL6yCLuDrrRjshy5tjfdLKOitrKpWpwryDhEo5vXyhnQYXP846c+G/0HV4/88r2Tlp+qDBAybAKG3iT1uguVDyOOfEz9s3b58IzRHqE4I1QfVy5XoipIWC8n/frdr19TzI1E/H1GTYKw8zr0Ntfj5Z5zK5orII/rq5+EhqSm/dOQ+/G9SxT6eg/t//8CkE1Ugrk68c+tfOaSmpxxEdtRKFczsqh7RU1jfgbafUs+XQzOBRtl66dRkysN84aNzBDUDD7Y2oudt2z+DzyQYjtMvi5yec/X3f1p1TSx5nQw0zbuQqb89OiBLIj0vivoHn8ePp7WA10CR8d9JGgcDIbUAbE2qMr/fHyxV1g14dHzvmk/KKwi/3LZ44dg20QDv49th7YAW0NIcNnTl98j8vXT0CjSpoLbm5+kF787X+9GPHqnpFcE+qrnWa3uY9H2fjVtb+vaj8NMKThywJGUS7C5Xg57umL5m7T3/kJaWiQFp0/3Hcxo4UcWiKzx6DnWAUijpOVs7NLTumHDm+sbziETxb2PD36Q7ZCr3kPM6qcPO1oY5DP9ZBfq2+nb1nCFVBe/naD/CaBYWarY0Yms0xwxdCtkUvM8o61f3k3HmbA6mj0cuXkSY99b/i0Aj6N8TWxL3zuT5BNm/NoOljp2/7dAwTubS3+vMifc91qyEv/TGGqWm1Q2YOFcUu88bUREF6KWoDSCvqq4prZq8PMCeyBeO8X6/OUat5Af1a85iRtFSZnZY/b3NHM+NbNstg18pMvo1Vx1Y66lZwq6yqWDJ3k7naoWbMcdn397yaKqVniKtDeyFqLajk6OHlPOgimbnO35J0zZphdelERdr5ClyAuXg7veyDcJJSedH9kvo6pV+IMGaWxbmq+fP7Tn5VlPugliCQwJpva29t7y6yc7LFn9GszRZEhaRVckmJtKayTilTqJSEm5fNO0ubOXGa6ezSu5cl6ZeqqkoVCrm2X7Yll9noXTyZOGJslmqjGFp/2dBdKrDGRfa8jt3s+73piBjwjFcVqeqQXG7QRWg4exbXTNNVPxWE4438WOsdQKnVWBM3WLgmidrYEb3XLXXj+brQW65S63WF3mkrS6bv0cJ2V08s56WfWvti4eRjBCcfIzj5GMHJxwhOPkb8PwAAAP//bzZ9iAAAAAZJREFUAwB//Eohfx/mwQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Crear el grafo \n",
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(\"retrieve\", retrieve)\n",
    "graph_builder.add_node(\"generate\", generate)\n",
    "\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph_builder.add_edge(\"retrieve\", \"generate\")\n",
    "\n",
    "graph = graph_builder.compile()\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Configuramos la evaluación con RAGAS__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos el dataset de preguntas con el que se realiza la evaluación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from datasets import Dataset\n",
    "\n",
    "# Preguntas y ground truths\n",
    "questions = [\n",
    "    'What are the main theoretical models of Neolithic expansion in Europe?',\n",
    "    'Quais são as datas mais antigas da extração de sílex na península central?',\n",
    "    '¿Cuáles son las cronologías de las manifestaciones funerarias del Mesolítico en las distintas regiones peninsulares?',\n",
    "    'Principales yacimientos de la Segunda Edad del Hierro en la provincia de León.',\n",
    "    'Periodización del Bronce Final en el Levante de la Península Ibérica, cronología de las fases y principales ejemplos de yacimientos asignados a las mismas.',\n",
    "    'Yacimientos Calcolíticos de la Península Ibérica  en los que se han hallado objetos de marfil.',\n",
    "    'Cronología y districubión espacial del poblamiento neolítixco en la Meseta Sur.',\n",
    "    'Dataciones más antiguas para el megalitismo en la zona Sureste de la Península Ibérica.'\n",
    "    'Excavaciones de urgencia de la Junta de Andalucía en la provincia de Almería publicadas en 2001.',\n",
    "    '¿En qué año excavaron en el yacimiento de La Bastida de Totana los hermanos Siret?'\n",
    "]\n",
    "ground_truths = [\n",
    "    \"\"\"These can be divided into two main positions: the first, known as demic diffusion, emphasises the movement of Neolithic societies and, by extension, agricultural practices; the second, referred to in the literature as cultural diffusion, focuses on the importance of the transmission of the Neolithic package—technology (e.g., pottery), plants, and domesticated animals—as a trigger for the expansion of the Neolithic.\"\"\",\n",
    "    \"\"\"A única mina de sílex do Neolítico no centro de Espanha é a de Casamontero (Madrid). A série completa de datas de radiocarbono é apresentada na Fig. 3 e a sua distribuição espacial na Fig. 4 do artigo de Díaz del Río e Consuegra, 2015.\n",
    "        Infelizmente, a amostra de Sus sp. não tinha colagénio suficiente para ser datada. O teste X2 mostra que todas as datas, com a única exceção da Beta-232890, são estatisticamente idênticas. Recentemente, foi enviada outra matriz de anel para datação num fragmento de fémur de Ovis aries. O resultado, 6200+/ -40 BP (Beta-295152), é estatisticamente igual a dez das onze datas anteriores.\n",
    "       Assumindo a hipótese plausível de que elas datam diferentes eventos de mineração, há uma probabilidade de 65% de que todos os episódios de mineração tenham ocorrido entre 5327-5215 cal BC (1σ), um período de tempo de apenas cem anos. Portanto, estas datas de radiocarbono não permitem observar a evolução espácio-temporal da exploração mineira, mas indicam que o principal episódio de atividade da Casa Montero durou pouco mais de um século, quatro gerações. Esta interpretação não é apenas possível, é provável.\"\"\"\n",
    "    \"\"\"Modelo construido a partir de muestras individuales de radiocarbono de esqueletos mesolíticos encontrados en los cementerios ibéricos. La diferencia más significativa entre la región mediterránea y la región cantábrica y Portugal se observa en la aparición de cementerios durante el Mesolítico temprano. Además, al evaluar los datos de las tres zonas de la Península Ibérica, se pueden identificar los siguientes patrones cronológicos.\n",
    "        - En la región mediterránea, las fechas de El Collado muestran que los cementerios aparecieron alrededor de 9475-9300 cal BP. Este tipo de práctica funeraria continuará en otros yacimientos cercanos, como Casa Corona y Cingle del Mas Nou. A diferencia del cementerio de El Collado, que estuvo en uso durante unos 1100 años, según las fechas obtenidas, en Casa Corona y Cingle del Mas Nou, su periodo de uso es mucho más breve (8007-7583 cal BP). Además, Cingle del Mas Nou se diferencia de otros yacimientos funerarios mesolíticos de la Península Ibérica en que los restos de siete individuos (completos e incompletos) fueron depositados en una única estructura.\n",
    "        - En la fachada atlántica de Portugal, las primeras pruebas de cementerios en el estuario de Muge datan de 8409-8030 cal BP (en Cabeço de Arruda, por ejemplo). Estos están asociados a grandes concheros de más de 5 m de espesor, utilizados durante un largo periodo de tiempo. En el estuario del Sado, las fechas son ligeramente más recientes que en Muge, comenzando alrededor del 8200 cal BP (por ejemplo, en Amoreiras). Está claro que entre el 8160 y el 7970 cal BP, los grupos mesolíticos enterraban sistemáticamente a todos o algunos de sus muertos en cementerios.\n",
    "        - Por último, las fechas de los yacimientos funerarios del norte de la Península Ibérica (costa cantábrica) con dos o más individuos indican que los primeros enterramientos mesolíticos agrupados fueron un poco más recientes (entre 7981 y 6636 cal BP). En cualquier caso, cabe destacar que, a diferencia de las otras dos zonas, en la mayoría de los yacimientos solo se ha documentado un único individuo o grupos mucho más reducidos, como en Los Canes y La Braña.\"\"\"\n",
    "    \"\"\"\n",
    "        - Castro de la Edad de Hierro de Valencia de Don Juan\n",
    "        - La Muela (al otro lado de la carretera de acceso a Valencia de Don Juan)\n",
    "        - Antigua ciudad astur-romana de Lancia: otro de los grandes de oppida de la Segunda Edad del Hierro\n",
    "        - Regueras de Arriba o San Martín de Torres.\n",
    "        - En la zona cántabra, los castros laciniaegos de la Mesa en Rioscuro, que se delimita con una potente muralla de módulos, fechada seguramente en los siglos II y I a.C., y el castro de La Zamora, en sosas de Laciana.\n",
    "        - También en la zona cántabra en el municipio de Puebla de Lillo se han podido reconocer ciertas piezas metalíticas de la Segunda Edad del Hierro, recogidas en el antiguo castro de Castiltejón. \n",
    "        - El castro de Chano en la comarca de Fornela.\n",
    "        - Peña del Castro (La Ercina), ubicado a 2 km de la localidad de la Ercina \n",
    "        - El Castrelín de San Juan dse Paluezas\n",
    "        - La Corona del Castro en Borrenes\n",
    "        - La Peña del Hombre en el ayuntamiento de Priaranza\n",
    "        - Castro de Columbrianos\n",
    "        - Peña Piñera, en la Vega de Espinareda\n",
    "        - Por último, se ha señalado un conjunto de castros en altitudes considerables en las sierras del Teleno, la Valdería y el Bierzo, algunos ya conocidos en la bibliografía y en la Carta Arqueológica de León, con grandes amurallamientos, que se extienden entre afloramientos rocosos de materiales de la era Primaria; yacimientos como Portillo de Xandequín en Pozos, Peña Rayada en Cunas, Alto de San Vicente-Los Conventos en Morla de la Valdería, Yera de los Piornos-Peña del Tren en Torneros de la Valdería, Sierra del Pueblo en Torneros de la Valdería, El Pajarín-La Formosida en Boisán (Lucillo) y los bercianos localizados en Folgoso de la Ribera, Torre del Bierzo y Molinaseca. \"\"\"\n",
    "    \"\"\"Bronce tardío o reciente (c. 1550/1500-1300/1250 cal BC):\n",
    "        - Oropesa la Vella\n",
    "        - Torreló d’Onda\n",
    "        - Les Raboses\n",
    "        - Altet de Palau\n",
    "        - Cap Prim\n",
    "        - Mas del Corral\n",
    "        - Cabezo Redondo\n",
    "        - Peña de Sax\n",
    "        - El Negret\n",
    "        - Illeta del Banyets\n",
    "        - Tabayá\n",
    "\n",
    "    Bronce final I (c. 1300/1250-1000 cal BC):\n",
    "        - Costamar\n",
    "        - Oropesa la Vella\n",
    "        - El Castellet\n",
    "        - Torrelló de Boverot\n",
    "        - Pic dels Corbs III y IV\n",
    "        - Cova d’en Pardo\n",
    "        - Cova de la Pastora\n",
    "        - Cap Prim\n",
    "        - Peña de Sax\n",
    "        - El Negret\n",
    "        - Tabayá\n",
    "        - Botx-Grupitex\n",
    "\n",
    "    Bronce final II (1000-850 cal BC):\n",
    "        - Ereta del Castellar\n",
    "        - El Castellet\n",
    "        - Torrelló de Boverot\n",
    "        - Pic dels Corbs V\n",
    "        - Solana del Castell I\n",
    "        - Mola d’Agres\n",
    "        - Tabayá\n",
    "        - Caramoro\n",
    "        - Botx\n",
    "\n",
    "    Bronce final III (850-725 cal BC):\n",
    "        -Ereta del Castellar\n",
    "        - El Castellet\n",
    "        -Torrelló de Boverot\n",
    "        -Vinarragell\n",
    "        - La Vital\n",
    "        -Solana del Castell II\n",
    "        -Mola d’Agres\n",
    "        -Cova de la Sarsa\n",
    "        -Tabayá\n",
    "        -Peña Negra I\n",
    "        - Barranc del Botx\n",
    "        -Saladares Ia1/IA2\n",
    "\n",
    "    Hierro antiguo o fase Orientalizante (725-550 cal BC):\n",
    "        - Vinarragell\n",
    "        - El Molón\n",
    "        - Los Villares\n",
    "        - Solana del Castell III\n",
    "        - El Castellar\n",
    "        - El Puig\n",
    "        - Camara\n",
    "        - Tabayá\n",
    "        - Peña Negra II\n",
    "        - Casa Secà\n",
    "        - Saladares IA3\n",
    "\"\"\",\n",
    "\"\"\"Calcolítico antiguo (pre-campaniforme [bell beaker]):\n",
    "        - Zambujal\n",
    "        - Vila Nova de São Pedro\n",
    "        - Leceiaa\n",
    "        - Praia das Maçãs\n",
    "        - Palmela\n",
    "        - Alcalar\n",
    "        - Perdigões \n",
    "        - Señorío de Guzmán\n",
    "        - La Pijotilla\n",
    "        - Valencina de la Concepción\n",
    "        - Gilena\n",
    "        - Los Millares\n",
    "\n",
    "Calcolítico reciente (campaniforme [bell beaker]):\n",
    "        - Palmela\n",
    "        - Pedra do Ouro\n",
    "        - Verdelha dos Ruivos\n",
    "        - Vila Nova de São Pedro\n",
    "        - Perdigões\n",
    "        - Valencina de la Concepción\n",
    "        - Los Algarbes\n",
    "        - Cerro de la Virgen\n",
    "        - Camino de Yeseras\n",
    "        - La Pijotilla\n",
    "\"\"\",\n",
    "\"\"\"Lo dividimos en dos áreas: poblamiento neolítico en el valle medio y alto del Tajo y poblamiento neolítico de La Mancha.\n",
    "- Valle del Tajo: En la zona de la Sierra madrileña se localizan las cuevas la Cueva de La Ventana o la Cueva de la Higuera. Ambas son especialmente importantes para comprender los asentamientos en cueva, ya que disponen de dataciones radiocarbónicas asociadas a contextos de habitación. Ya en la provincia de Guadalajara destacan los yacimientos de la Cueva de la Hoz, Abrigo de Tordelrrábano  la Cueva de Jarama II, los enclaves de Sorbe II (Humanes de Mohernando), II y VII, la Cueva del Paso, el Abrigo de los Enebrales, Cueva del Reno y la Cueva del Destete.  Sin embargo, son los yacimientos de hoyos los que constituyen el principal modelo de asentamiento. Las excavaciones arqueológicas en extensión realizadas en los últimos años han puesto de manifiesto el predominio del hábitat en asentamientos al aire libre durante este periodo. Tan sólo se han documentado 8 enclaves neolíticos serranos de un total de 24 yacimientos cartografiados en la región. Los 16 yacimientos restantes se ubican en zonas bajas de los valles. A estas cifras hay que sumar tres nuevos yacimientos neolíticos: Soto del Henares, La Serna y Prado de Galápagos, recientemente publicados por C. Blasco et al.\n",
    "(2016) que amplían el listado de asentamientos de hoyos ubicados en los fondos de\n",
    "valle.\n",
    "La concentración de yacimientos neolíticos es especialmente interesante en la zona sureste de la Comunidad de Madrid, en los tramos finales de los ríos Henares, Jarama y Manzanares. La densidad de yacimientos de hoyos neolíticos en las zonas bajas de estos cursos fluviales ha aportado desde hace años datos muy interesantes para conocer los patrones de asentamiento y los modelos de\n",
    "ocupación territorial de las primeras comunidades neolíticas. \n",
    "- Poblamiento neolítico de La Mancha: El modelo de asentamiento neolítico mejor conocido en La Mancha son las ocupaciones en cuevas y abrigos. En este sentido, los yacimientos neolíticos manchegos mejor conocidos son la Cueva del Niño y el Abrigo de Molino de Vadico, en Albacete, y el Abrigo de Verdelpino, en Cuenca, a los que ya nos referimos en el capítulo anterior. En estos yacimientos se han documentado, además, ocupaciones previas, por lo que se son especialmente interesantes para estudiar el momento de adopción de los modos de vida neolíticos. \n",
    "En los últimos años se han realizado varias intervenciones arqueológicas en el contexto de las obras de construcción de grandes infraestructuras. Desde el punto de vista arqueológico, este tipo de intervenciones implican la prospección y, en su caso, excavación en zonas aleatorias afectadas por los proyectos constructivos, por lo que no se introducen sesgos relacionados con intereses científicos concretos. Por lo tanto, los hallazgos suponen una buena aproximación de la existencia o ausencia de distintos tipos de registro arqueológico. En este sentido, las obras de acceso al aeropuerto de Ciudad Real o los trabajos de la autopista que conecta Ocaña (Toledo) con La Roda (Ciudad Real), no aportaron hallazgos de asentamientos neolíticos. \n",
    "Si bien es cierto que las investigaciones sobre esta etapa de la Prehistoria en La Mancha han sido escasas y son pocos los equipos de investigación que han desarrollado líneas de investigación orientadas al conocimiento de las primeras sociedades productoras en esa región, no es menos cierto que las intervenciones arqueológicas llevadas a cabo en el contexto de obras de infraestructura en Castilla-La Mancha apoyan la idea de un poblamiento neolítico caracterizado por su escasa densidad, especialmente si se compara con otras regiones como en valle medio y alto del Tajo.\n",
    "\"\"\",\n",
    "\"\"\"Son el solar situado en la avenida Pablo Iglesias esquina A Rafaeka Jiménez, solar situado en la calle La central de Villaricos (cuevas de Almanzora) y en la calle Castillejo (Gador, Almería).\"\"\",\n",
    "\"\"\"En el año 1886.\"\"\"\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos la evaluación utilizando la API de Mistral. Es recomendable evaluar por batches para evitar sobrecargar la API con llamadas; además, se ha evaluado cada modelo de lenguaje por separado para ayudar a evitar esa sobrecarga.\n",
    "Sumado a esto, hemos definido dos prompts para las métricas `context_precision` y `context_recall` puesto que son las que lo permiten y esto guia a Mistral a realizar la mejor evaluación posible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mistral configurado para RAGAS\n"
     ]
    }
   ],
   "source": [
    "from langchain_mistralai import ChatMistralAI\n",
    "from ragas.metrics import context_precision, context_recall, faithfulness, answer_correctness\n",
    "import time\n",
    "from datasets import Dataset\n",
    "from ragas import evaluate \n",
    "import pandas as pd\n",
    "  # Configurar Mistral\n",
    "mistral_evaluator = ChatMistralAI(\n",
    "    api_key=MISTRAL_API_KEY,\n",
    "    model=\"mistral-small-latest\",\n",
    "    temperature=0.1,\n",
    "    max_retries=3,\n",
    "    timeout= 180 # Timeout para las requests HTTP\n",
    "    \n",
    ")\n",
    "\n",
    "# Prompts específicos para métricas\n",
    "context_precision.context_precision_prompt.instruction = \"\"\"\n",
    "Dada una pregunta sobre arqueología y un conjunto de contextos que pueden estar en varios idiomas (español, inglés, francés, catalán, portugués), identifica qué contextos son útiles para responder la pregunta.\n",
    "Los contextos pueden contener información técnica, fechas, yacimientos arqueológicos, cronologías, dataciones, etc. Un contexto es útil si contiene información relevante que ayude a responder la pregunta, aunque sea parcialmente, independientemente      \n",
    "del idioma en que esté escrito.     \n",
    "\n",
    "Pregunta: {question}\n",
    "Contextos: {contexts}\n",
    "\n",
    "Responde SOLO con un JSON válido en este formato exacto:\n",
    "{\"useful_contexts\": [0, 1, 2]}\n",
    "donde los números son los índices de contextos útiles.\n",
    "\"\"\"\n",
    "\n",
    "context_recall.context_recall_prompt.instruction = \"\"\"\n",
    "Dada una pregunta sobre arqueología y un conjunto de contextos que pueden estar en varios idiomas (español, inglés, francés, catalán, portugués), evalúa si el contexto contiene toda la información necesaria para responder la pregunta.\n",
    "Los contextos pueden contener información técnica, fechas, yacimientos arqueológicos, cronologías, dataciones, etc. Un contexto es útil si contiene información relevante que ayude a responder la pregunta, aunque sea parcialmente, independientemente      \n",
    "del idioma en que esté escrito.\n",
    "Responde SOLO con un JSON válido en este formato exacto:\n",
    "{\"correctness\": 0.8}\n",
    "donde el valor está entre 0.0 y 1.0\n",
    "\"\"\"  \n",
    "print(\"Mistral configurado para RAGAS\")\n",
    "\n",
    "# Función de evaluación con Mistral y las 4 métricas\n",
    "\n",
    "def evaluate_with_mistral_four_metrics(results_list, embedding_model, max_batch_size=2, delay_between_batches=90):\n",
    "    \"\"\"\n",
    "    Evaluación RAGAS con Mistral API usando las 4 métricas principales\n",
    "    \"\"\"\n",
    "    print(f\"Evaluando {len(results_list)} preguntas con 4 métricas en batches de {max_batch_size}\")\n",
    "\n",
    "    all_batch_results = []\n",
    "    total_batches = (len(results_list) + max_batch_size - 1) // max_batch_size\n",
    "\n",
    "    for batch_idx in range(0, len(results_list), max_batch_size):\n",
    "        batch_num = batch_idx // max_batch_size + 1\n",
    "        batch = results_list[batch_idx:batch_idx + max_batch_size]\n",
    "\n",
    "        print(f\"Procesando batch {batch_num}/{total_batches} ({len(batch)} preguntas)\")\n",
    "\n",
    "        # Crear dataset del batch\n",
    "        batch_dataset = Dataset.from_list(batch)\n",
    "\n",
    "        # Intentar evaluación con reintentos\n",
    "        batch_success = False\n",
    "        for attempt in range(3):\n",
    "            try:\n",
    "                print(f\"      Intento {attempt + 1}/3 para batch {batch_num}\")\n",
    "\n",
    "                # Evaluar cada métrica por separado para mayor estabilidad\n",
    "                batch_metrics = {}\n",
    "\n",
    "                metrics_to_evaluate = [\n",
    "                    ('context_precision', context_precision),\n",
    "                    ('context_recall', context_recall),\n",
    "                    ('faithfulness', faithfulness),\n",
    "                    ('answer_correctness', answer_correctness)\n",
    "                ]\n",
    "\n",
    "                for metric_name, metric_obj in metrics_to_evaluate:\n",
    "                    try:\n",
    "                        print(f\"         Evaluando {metric_name}...\")\n",
    "\n",
    "                        metric_result = evaluate(\n",
    "                            batch_dataset,\n",
    "                            llm=mistral_evaluator,\n",
    "                            embeddings=embedding_model,\n",
    "                            metrics=[metric_obj],\n",
    "                            raise_exceptions=False\n",
    "                        )\n",
    "\n",
    "                        metric_df = metric_result.to_pandas()\n",
    "\n",
    "                        if metric_name in metric_df.columns:\n",
    "                            batch_metrics[metric_name] = metric_df[metric_name]\n",
    "                            print(f\"{metric_name} completado\")\n",
    "                        else:\n",
    "                            batch_metrics[metric_name] = None\n",
    "                            print(f\"{metric_name} no encontrado en resultados\")\n",
    "\n",
    "                        # Pausa entre métricas para evitar rate limits\n",
    "                        time.sleep(25)\n",
    "\n",
    "                    except Exception as metric_error:\n",
    "                        print(f\"{metric_name} falló: {metric_error}\")\n",
    "                        batch_metrics[metric_name] = None\n",
    "                        time.sleep(30)  # Pausa más larga si hay error\n",
    "\n",
    "                # Crear DataFrame combinado del batch\n",
    "                batch_result_df = pd.DataFrame({\n",
    "                    'question': [item['question'] for item in batch],\n",
    "                    'answer': [item['answer'] for item in batch],\n",
    "                    'contexts': [item['contexts'] for item in batch],\n",
    "                    'ground_truth': [item['ground_truth'] for item in batch],\n",
    "                    'context_precision': batch_metrics.get('context_precision'),\n",
    "                    'context_recall': batch_metrics.get('context_recall'),\n",
    "                    'faithfulness': batch_metrics.get('faithfulness'),\n",
    "                    'answer_correctness': batch_metrics.get('answer_correctness')\n",
    "                })\n",
    "\n",
    "                all_batch_results.append(batch_result_df)\n",
    "                batch_success = True\n",
    "                print(f\"Batch {batch_num} completado con 4 métricas\")\n",
    "                break\n",
    "\n",
    "            except Exception as batch_error:\n",
    "                print(f\"Batch {batch_num}, intento {attempt + 1} falló: {batch_error}\")\n",
    "                if attempt < 2:\n",
    "                    wait_time = 120 * (attempt + 1)  # Espera más larga para 4 métricas\n",
    "                    print(f\"         Esperando {wait_time}s antes del siguiente intento...\")\n",
    "                    time.sleep(wait_time)\n",
    "\n",
    "        if not batch_success:\n",
    "            print(f\"Batch {batch_num} falló después de 3 intentos, creando resultados vacíos\")\n",
    "            # Crear DataFrame vacío para este batch\n",
    "            empty_batch_df = pd.DataFrame({\n",
    "                'question': [item['question'] for item in batch],\n",
    "                'answer': [item['answer'] for item in batch],\n",
    "                'contexts': [item['contexts'] for item in batch],\n",
    "                'ground_truth': [item['ground_truth'] for item in batch],\n",
    "                'context_precision': [None] * len(batch),\n",
    "                'context_recall': [None] * len(batch),\n",
    "                'faithfulness': [None] * len(batch),\n",
    "                'answer_correctness': [None] * len(batch)\n",
    "            })\n",
    "            all_batch_results.append(empty_batch_df)\n",
    "\n",
    "        # Rate limiting: pausa entre batches (más larga para 4 métricas)\n",
    "        if batch_num < total_batches:\n",
    "            print(f\"Esperando {delay_between_batches}s antes del siguiente batch...\")\n",
    "            time.sleep(delay_between_batches)\n",
    "\n",
    "    # Combinar todos los resultados\n",
    "    if all_batch_results:\n",
    "        combined_results = pd.concat(all_batch_results, ignore_index=True)\n",
    "        print(f\"Evaluación completada: {len(combined_results)} preguntas con 4 métricas\")\n",
    "        return combined_results\n",
    "    else:\n",
    "        print(f\"No se pudieron procesar resultados\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Evaluación del modelo Qwen3-4B-instruct-2507__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUANDO CON PROMPT: prompt_zero_shot\n",
      "================================================================================\n",
      "Generando respuestas con LangGraph...\n",
      "Procesando pregunta 1/9 con prompt_zero_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Published by Elsevier Inc. All rights reserved. doi:10.1016/j.yqres.2011.12.003 Contents lists available at SciVerse ScienceDirect Quaternary Research journal homepage: www.elsevier.com/locate/yqres https://doi.org/10.1016/j.yqres.2011.12.003 Published online by Cambridge University Press Introduc...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 2/9 con prompt_zero_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. A data obtida, é claramente mais recuada que os con­ textos mais antigos reportados em território hoje portu­ guês, nomeadamente Gruta da Nascente do Rio Almonda (OxA­‑9287 – 5480­‑5320 cal BC a 2 sigmas) e da Gruta do Caldeirão (OxA­‑1036 – 5480 – 5070 cal BC a 2 sigmas). Entre nós, apenas se rep...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 3/9 con prompt_zero_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 2. ENCUADRE CRONO-CULTURAL DEL HA- LLAZGO: COGOTAS I Entre las entidades arqueológicas de la Edad del Bronce peninsular, Cogotas I sobresale por su extensa cobertura geográfica, que desborda la Meseta por el Valle del Ebro y Extremadura, y por su dilatada crono- logía —c. 1800-1150 cal BC, cubrien...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 4/9 con prompt_zero_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. y NEIRA, A. (1999): “Prehistoria”, en M.A. Rabanal Alonso (coord.): La His­ toria de León, tomo I, Universidad de León y Diario de León. CELIS SÁNCHEZ, J. (1993a): “La secuencia del poblado de la Primera Edad del Hierro de los «Cuestos de la Estación», Benavente, Zamora”, en F. Romero, C. Sanz y Z...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 5/9 con prompt_zero_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Con el desarrollo de las excavaciones arqueológicas en diversos asentamientos, el aumento del número de dataciones y la realización de diversos estudios en los últimos años, las perspectivas de investigación sobre el Bronce final en el Levante comienza a variar sustancialmente, estando ya en condi...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 6/9 con prompt_zero_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. En la actualidad, El Argar sigue siendo el grupo arqueo­ lógico de la Edad del Bronce mejor conocido de la península ibérica, con un desarrollo temporal entre el 2200 y el 1550 cal BC. También se puede afirmar que fue una de las sociedades con mayor capacidad productiva y desarrollo social de la E...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Respuestas válidas generadas con prompt_zero_shot: 6\n",
      "\n",
      "EVALUANDO: prompt_zero_shot + all-MiniLM-L6-v2\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 métricas en batches de 2\n",
      "   🔄 Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\_analytics.py:77: ResourceWarning: unclosed file <_io.TextIOWrapper name='C:\\\\Users\\\\elevi\\\\AppData\\\\Local\\\\ragas\\\\ragas\\\\uuid.json' mode='r' encoding='cp1252'>\n",
      "  user_id = json.load(open(uuid_filepath))[\"userid\"]\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79e230356c8e423e8471e4b3280d93d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01850125092c47688b0de6ab08c911e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d78f4e158354411e86829dcfa53b4af7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f26b5c6063746c79f6126997101bd89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37f2e29ddcee4555afed371b1100a118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5b9887c59ef4dccb43d09bff27a57db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24ff93de7c0d4ae3aeef7a23a2664660",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ff2126fbad14b8cb81e99dbc3f6f401",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8f2fdad20cc48fcb903161090323269",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "317142ce49c44644a3715c0497b310c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aa20fb2e4644eb98a0c6e6ac4e2778f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82d9bd96119f47b38008abd51eac8df6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 métricas\n",
      "Evaluación completada: 6 preguntas con 4 métricas\n",
      "\n",
      "COMBINACIÓN: prompt_zero_shot + all-MiniLM-L6-v2\n",
      "   context_precision: 0.475\n",
      "   context_recall: 0.106\n",
      "   faithfulness: 0.903\n",
      "   answer_correctness: 0.275\n",
      "\n",
      "EVALUANDO: prompt_zero_shot + e5-large-instruct\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 métricas en batches de 2\n",
      "   🔄 Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9acd151e0ed4d539efeb493342a4ece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fdaf6b6f46a4c3ca6071fa12b7a566d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "867c3c050cff4d6aa1373000ee09d057",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86237c04fe9f49bba26bfa1a7526c57e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1c1cff51cb442fabe42623c8efd8f24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f9401722e3f47a1a69728f2f98e595a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f5f0681703e4041b21f499c8f1ddbf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eb0653bca4a46d999cdb433e2f52555",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdeb4e72cbcf4ae8b4465953f6b7bd8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "464fbdc0a8604605acdb17aaf2442c24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e884d2aab6dc4ea28f9a9320987854b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9266d7b0cca94b0585ecb6f380d97e16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 métricas\n",
      "Evaluación completada: 6 preguntas con 4 métricas\n",
      "\n",
      "COMBINACIÓN: prompt_zero_shot + e5-large-instruct\n",
      "   context_precision: 0.387\n",
      "   context_recall: 0.087\n",
      "   faithfulness: 0.880\n",
      "   answer_correctness: 0.242\n",
      "\n",
      "EVALUANDO: prompt_zero_shot + gte-multilingual-base\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 métricas en batches de 2\n",
      "   🔄 Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3884547c0f14504ac9f044de0fd51fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a38d8cabf60a4ee48c4df9351263e18d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02232aead2ff4a678f284f6660964281",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32c420ee7dfb42a4b73845da561e0153",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bbfb08cc8cb404385bf1aeef4e53750",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcf74b591187428fa07d7575b4378fe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87677fc0271143dfb956330b33fc8eba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e00228382b694ba69fb6c0f89bccab69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00568aee39ca4bc7babb4bb67e8a23fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c28f87197c454df8965e08dc3cd3ad15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3370c59e5d4f44c881246fb9786b4c5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebe5c8ffe6674093b3e1031b8c0d3d57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 métricas\n",
      "Evaluación completada: 6 preguntas con 4 métricas\n",
      "\n",
      "COMBINACIÓN: prompt_zero_shot + gte-multilingual-base\n",
      "   context_precision: 0.417\n",
      "   context_recall: 0.304\n",
      "   faithfulness: 0.844\n",
      "   answer_correctness: 0.162\n",
      "\n",
      "PAUSA ENTRE PROMPTS: 300 segundos...\n",
      "\n",
      "EVALUANDO CON PROMPT: prompt_one_shot\n",
      "================================================================================\n",
      "Generando respuestas con LangGraph...\n",
      "Procesando pregunta 1/9 con prompt_one_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Published by Elsevier Inc. All rights reserved. doi:10.1016/j.yqres.2011.12.003 Contents lists available at SciVerse ScienceDirect Quaternary Research journal homepage: www.elsevier.com/locate/yqres https://doi.org/10.1016/j.yqres.2011.12.003 Published online by Cambridge University Press Introduc...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 2/9 con prompt_one_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. A data obtida, é claramente mais recuada que os con­ textos mais antigos reportados em território hoje portu­ guês, nomeadamente Gruta da Nascente do Rio Almonda (OxA­‑9287 – 5480­‑5320 cal BC a 2 sigmas) e da Gruta do Caldeirão (OxA­‑1036 – 5480 – 5070 cal BC a 2 sigmas). Entre nós, apenas se rep...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 3/9 con prompt_one_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 2. ENCUADRE CRONO-CULTURAL DEL HA- LLAZGO: COGOTAS I Entre las entidades arqueológicas de la Edad del Bronce peninsular, Cogotas I sobresale por su extensa cobertura geográfica, que desborda la Meseta por el Valle del Ebro y Extremadura, y por su dilatada crono- logía —c. 1800-1150 cal BC, cubrien...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 4/9 con prompt_one_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. y NEIRA, A. (1999): “Prehistoria”, en M.A. Rabanal Alonso (coord.): La His­ toria de León, tomo I, Universidad de León y Diario de León. CELIS SÁNCHEZ, J. (1993a): “La secuencia del poblado de la Primera Edad del Hierro de los «Cuestos de la Estación», Benavente, Zamora”, en F. Romero, C. Sanz y Z...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 5/9 con prompt_one_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Con el desarrollo de las excavaciones arqueológicas en diversos asentamientos, el aumento del número de dataciones y la realización de diversos estudios en los últimos años, las perspectivas de investigación sobre el Bronce final en el Levante comienza a variar sustancialmente, estando ya en condi...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 6/9 con prompt_one_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. En la actualidad, El Argar sigue siendo el grupo arqueo­ lógico de la Edad del Bronce mejor conocido de la península ibérica, con un desarrollo temporal entre el 2200 y el 1550 cal BC. También se puede afirmar que fue una de las sociedades con mayor capacidad productiva y desarrollo social de la E...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Respuestas válidas generadas con prompt_one_shot: 6\n",
      "\n",
      "EVALUANDO: prompt_one_shot + all-MiniLM-L6-v2\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 métricas en batches de 2\n",
      "   🔄 Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71992f71c9b044ffab4df3760c183100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f12d1c3f8e82496293555c392116d6d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8263769784624f9193d79aba3cd7982a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60dfc596de034e849a4b665985f1c38f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94ad3204a4e747bfa8f31f2c416df482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2287ca019d9d4d5080dd83841e1ecb9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fec9f95d4ade4791b8fc3a020e509bbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df1ab209f343403db2464ad3dc5c3e56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "834659f97df04370bc257c35f15dc43f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef844210687946a5bf5e0acf73e83a2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c01455d7fa54af9b78c662b96bad715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f737aa3bcfc477ba07b57c482b14254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 métricas\n",
      "Evaluación completada: 6 preguntas con 4 métricas\n",
      "\n",
      "COMBINACIÓN: prompt_one_shot + all-MiniLM-L6-v2\n",
      "   context_precision: 0.395\n",
      "   context_recall: 0.143\n",
      "   faithfulness: 0.763\n",
      "   answer_correctness: 0.187\n",
      "\n",
      "EVALUANDO: prompt_one_shot + e5-large-instruct\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 métricas en batches de 2\n",
      "   🔄 Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0ca9aade77c493bb2585cf39105cf85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "605340e1b436486185d6603498eb509d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60b7f5f37ee64c4294bfc3f9ec6a7c67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "810198abe90048d4a12f517c7c281995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b46c598be22f4fadb9bcef688088beb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f42dc0b2fe8a4748b3ad994601f5f574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7465ed0e86784b62b26b8f88aa25a25a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "773c8d5eb75242b4ba952a6c0e432090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b49b58f60d0f4c4da92b5d84ea8b989c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "617cd9e9d74c4576bcf046748ea4f174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7441a46e71054b4d9657ce7ac01782e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a6ec2ab4a3d4cefa96b6e65aa9da0cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 métricas\n",
      "Evaluación completada: 6 preguntas con 4 métricas\n",
      "\n",
      "COMBINACIÓN: prompt_one_shot + e5-large-instruct\n",
      "   context_precision: 0.340\n",
      "   context_recall: 0.342\n",
      "   faithfulness: 0.742\n",
      "   answer_correctness: 0.287\n",
      "\n",
      "EVALUANDO: prompt_one_shot + gte-multilingual-base\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 métricas en batches de 2\n",
      "   🔄 Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eb2ee11b8e548c9a546f2a262c5c793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "244c47285ac74dc2b2a3ec08005ae2ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9cab6782e2f44e9a0cc741dffbf4f8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fbb1345f43c48ec9146d5aca6efdc68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdc7dd2e2c12415cb9991d05ef6ae295",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9e48e00b6394dc39d84797075bd8df2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6665bb639354445a30e38ed1a384f50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "796b2a0b47d740ddb5ee9d581a5c1d68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fff1f283df149fdb0c225f546d6988e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a407a915991b48be963b4b7544d78cf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46afd26c176c43d8ade3bbea48989758",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2130fbf64c743c587360aab3cc60d39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 métricas\n",
      "Evaluación completada: 6 preguntas con 4 métricas\n",
      "\n",
      "COMBINACIÓN: prompt_one_shot + gte-multilingual-base\n",
      "   context_precision: 0.315\n",
      "   context_recall: 0.092\n",
      "   faithfulness: 0.747\n",
      "   answer_correctness: 0.212\n",
      "\n",
      "PAUSA ENTRE PROMPTS: 300 segundos...\n",
      "\n",
      "EVALUANDO CON PROMPT: prompt_few_shot\n",
      "================================================================================\n",
      "Generando respuestas con LangGraph...\n",
      "Procesando pregunta 1/9 con prompt_few_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Published by Elsevier Inc. All rights reserved. doi:10.1016/j.yqres.2011.12.003 Contents lists available at SciVerse ScienceDirect Quaternary Research journal homepage: www.elsevier.com/locate/yqres https://doi.org/10.1016/j.yqres.2011.12.003 Published online by Cambridge University Press Introduc...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 2/9 con prompt_few_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. A data obtida, é claramente mais recuada que os con­ textos mais antigos reportados em território hoje portu­ guês, nomeadamente Gruta da Nascente do Rio Almonda (OxA­‑9287 – 5480­‑5320 cal BC a 2 sigmas) e da Gruta do Caldeirão (OxA­‑1036 – 5480 – 5070 cal BC a 2 sigmas). Entre nós, apenas se rep...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 3/9 con prompt_few_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 2. ENCUADRE CRONO-CULTURAL DEL HA- LLAZGO: COGOTAS I Entre las entidades arqueológicas de la Edad del Bronce peninsular, Cogotas I sobresale por su extensa cobertura geográfica, que desborda la Meseta por el Valle del Ebro y Extremadura, y por su dilatada crono- logía —c. 1800-1150 cal BC, cubrien...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 4/9 con prompt_few_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. y NEIRA, A. (1999): “Prehistoria”, en M.A. Rabanal Alonso (coord.): La His­ toria de León, tomo I, Universidad de León y Diario de León. CELIS SÁNCHEZ, J. (1993a): “La secuencia del poblado de la Primera Edad del Hierro de los «Cuestos de la Estación», Benavente, Zamora”, en F. Romero, C. Sanz y Z...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 5/9 con prompt_few_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Con el desarrollo de las excavaciones arqueológicas en diversos asentamientos, el aumento del número de dataciones y la realización de diversos estudios en los últimos años, las perspectivas de investigación sobre el Bronce final en el Levante comienza a variar sustancialmente, estando ya en condi...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 6/9 con prompt_few_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. En la actualidad, El Argar sigue siendo el grupo arqueo­ lógico de la Edad del Bronce mejor conocido de la península ibérica, con un desarrollo temporal entre el 2200 y el 1550 cal BC. También se puede afirmar que fue una de las sociedades con mayor capacidad productiva y desarrollo social de la E...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Respuestas válidas generadas con prompt_few_shot: 6\n",
      "\n",
      "EVALUANDO: prompt_few_shot + all-MiniLM-L6-v2\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 métricas en batches de 2\n",
      "   🔄 Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdc3f3ee7bb84eb4a4872d8938077213",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f696d0d910104413aafecf0f42d36686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ad575db7bb5490d9a7776dce10f3d13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dde1f843247f4a8a9f08ea052d16cd91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b1e79e46aa7445dbc9e5170fb6193a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93375959afc54f37a489c89b07e540d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cac54a94b0e94d51b5bfa1945ca5257f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f76661ec65d4441a09e09c5c12b179a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2b520861247479fb19e061bd480f852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64eefc7c712c4e88aba656bcd074a2aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e9b57ba66a941a188e3dc0395ff846c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d2bdbf4eda84d7f9041699c18f49882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 métricas\n",
      "Evaluación completada: 6 preguntas con 4 métricas\n",
      "\n",
      "COMBINACIÓN: prompt_few_shot + all-MiniLM-L6-v2\n",
      "   context_precision: 0.228\n",
      "   context_recall: 0.300\n",
      "   faithfulness: 0.657\n",
      "   answer_correctness: 0.149\n",
      "\n",
      "EVALUANDO: prompt_few_shot + e5-large-instruct\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 métricas en batches de 2\n",
      "   🔄 Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b8d32418b704dde92fde0d9a5e87aec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "970f8c209c9f4266bf0a14b800a060ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "027061b3bdfc4711970683436fd34039",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fda1d313bf34f3c8086ebb5b45439d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5dfc20e66d94c00ab502f5735b24a27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e02db97c70e4aa08e775f908b71a120",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8096e4278744a59b67d40bfcb77ae10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5516fe7c65f444968a2e926c1f47b8bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adf13c214516406888f96e3cabfdbc12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e0b66a0e0634bf2827240eb046b0abd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca9aa4dbf1d240d7af72e545f7703a50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70912dfb3d8b45788b9ef0b327e4708d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 métricas\n",
      "Evaluación completada: 6 preguntas con 4 métricas\n",
      "\n",
      "COMBINACIÓN: prompt_few_shot + e5-large-instruct\n",
      "   context_precision: 0.356\n",
      "   context_recall: 0.088\n",
      "   faithfulness: 0.587\n",
      "   answer_correctness: 0.236\n",
      "\n",
      "EVALUANDO: prompt_few_shot + gte-multilingual-base\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 métricas en batches de 2\n",
      "   🔄 Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e39128498f1d468086abfbb297745cf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff3c920881a642b298b21e00fbeb98d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bab7caab578b401390df7330cfb6dbc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "717a962c4f9e474f85fe4daead8ac8f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db512e6c4cc6460abd115be37939adf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b5bdb0a38084c70aa88a962efa263b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "752b72d797564f49aaa04f00c3725734",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a03d609fb154de7885bfb28dd178f6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7613648ebe444866a1c9eb102468de0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b9296ab59414ec39c95bb0496cc731b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f95b9629efb43eaa2d06dc3786dfd7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec0455e47eeb41fdaa2810a8a01fda57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 métricas\n",
      "Evaluación completada: 6 preguntas con 4 métricas\n",
      "\n",
      "COMBINACIÓN: prompt_few_shot + gte-multilingual-base\n",
      "   context_precision: 0.437\n",
      "   context_recall: 0.096\n",
      "   faithfulness: 0.721\n",
      "   answer_correctness: 0.181\n",
      "\"EVALUACIÓN COMPLETA\n",
      "\n",
      "TABLA DE RESULTADOS:\n",
      "====================================================================================================\n",
      "\n",
      "PROMPT: prompt_zero_shot\n",
      "all-MiniLM-L6-v2:\n",
      "      context_precision: 0.475\n",
      "      context_recall: 0.106\n",
      "      faithfulness: 0.903\n",
      "      answer_correctness: 0.275\n",
      "e5-large-instruct:\n",
      "      context_precision: 0.387\n",
      "      context_recall: 0.087\n",
      "      faithfulness: 0.880\n",
      "      answer_correctness: 0.242\n",
      "gte-multilingual-base:\n",
      "      context_precision: 0.417\n",
      "      context_recall: 0.304\n",
      "      faithfulness: 0.844\n",
      "      answer_correctness: 0.162\n",
      "\n",
      "PROMPT: prompt_one_shot\n",
      "all-MiniLM-L6-v2:\n",
      "      context_precision: 0.395\n",
      "      context_recall: 0.143\n",
      "      faithfulness: 0.763\n",
      "      answer_correctness: 0.187\n",
      "e5-large-instruct:\n",
      "      context_precision: 0.340\n",
      "      context_recall: 0.342\n",
      "      faithfulness: 0.742\n",
      "      answer_correctness: 0.287\n",
      "gte-multilingual-base:\n",
      "      context_precision: 0.315\n",
      "      context_recall: 0.092\n",
      "      faithfulness: 0.747\n",
      "      answer_correctness: 0.212\n",
      "\n",
      "PROMPT: prompt_few_shot\n",
      "all-MiniLM-L6-v2:\n",
      "      context_precision: 0.228\n",
      "      context_recall: 0.300\n",
      "      faithfulness: 0.657\n",
      "      answer_correctness: 0.149\n",
      "e5-large-instruct:\n",
      "      context_precision: 0.356\n",
      "      context_recall: 0.088\n",
      "      faithfulness: 0.587\n",
      "      answer_correctness: 0.236\n",
      "gte-multilingual-base:\n",
      "      context_precision: 0.437\n",
      "      context_recall: 0.096\n",
      "      faithfulness: 0.721\n",
      "      answer_correctness: 0.181\n"
     ]
    }
   ],
   "source": [
    "# Evaluar TODAS las combinaciones: 3 prompts × 3 embeddings = 9 combinaciones\n",
    "resultados_completos = {}\n",
    "\n",
    "prompts_list = ['prompt_zero_shot', 'prompt_one_shot', 'prompt_few_shot']\n",
    "\n",
    "for prompt_name in prompts_list:\n",
    "    print(f\"\\nEVALUANDO CON PROMPT: {prompt_name}\")\n",
    "    print(\"=\"*80)\n",
    "    # CAMBIAR EL TEMPLATE GLOBAL (esto es lo clave)\n",
    "    selected_template = PROMPTS[prompt_name]\n",
    "    prompt_template = ChatPromptTemplate.from_template(selected_template)\n",
    "\n",
    "    # Generar respuestas con este prompt específico\n",
    "    results_list_prompt = []\n",
    "\n",
    "    # Necesitas generar las respuestas con tu grafo de LangGraph primero\n",
    "    print(\"Generando respuestas con LangGraph...\")\n",
    "\n",
    "    for i, (question, ground_truth) in enumerate(zip(questions, ground_truths)):\n",
    "        print(f\"Procesando pregunta {i+1}/{len(questions)} con {prompt_name}\")\n",
    "\n",
    "\n",
    "        state = {\n",
    "            'question': question,\n",
    "            'llm_name': 'Qwen3-4B-instruct-2507',  \n",
    "            'embedding_name': 'all-MiniLM-L6-v2',  # Se cambiará en el bucle    \n",
    "            'prompt_name': prompt_name,\n",
    "            'context': [],\n",
    "            'answer': '',\n",
    "            'metadata': {}\n",
    "        }\n",
    "        try:\n",
    "        \n",
    "            final_state = graph.invoke(state)\n",
    "            answer = final_state.get('answer', '')\n",
    "            contexts = final_state.get('context', [])\n",
    "\n",
    "            if answer and answer.strip():  # Verificar que hay respuesta\n",
    "                  results_list_prompt.append({\n",
    "                      'question': question,\n",
    "                      'answer': answer,\n",
    "                      'contexts': [doc.page_content for doc in contexts] if contexts else ['Sin contexto'],\n",
    "                      'ground_truth': ground_truth\n",
    "                  })\n",
    "            else:\n",
    "                  print(f\"Pregunta {i+1} sin respuesta válida\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error en pregunta {i+1}: {e}\")\n",
    "\n",
    "    print(f\"Respuestas válidas generadas con {prompt_name}: {len(results_list_prompt)}\")\n",
    "\n",
    "    # Solo evaluar si tenemos respuestas válidas\n",
    "    if len(results_list_prompt) >= 2:\n",
    "          # EVALUAR CON LOS 3 EMBEDDINGS\n",
    "        resultados_por_embedding = {}\n",
    "\n",
    "        for embedding_name, current_embedding_model in EMBEDDING_MODELS.items():\n",
    "            print(f\"\\nEVALUANDO: {prompt_name} + {embedding_name}\")\n",
    "            print(\"-\"*60)\n",
    "\n",
    "            resultado = evaluate_with_mistral_four_metrics(\n",
    "                results_list=results_list_prompt,\n",
    "                  embedding_model=current_embedding_model,\n",
    "                  max_batch_size=2,\n",
    "                  delay_between_batches=120\n",
    "            )\n",
    "\n",
    "            resultados_por_embedding[embedding_name] = resultado\n",
    "\n",
    "              # Mostrar métricas promedio\n",
    "            print(f\"\\nCOMBINACIÓN: {prompt_name} + {embedding_name}\")\n",
    "            for metric in ['context_precision', 'context_recall', 'faithfulness', 'answer_correctness']:\n",
    "                if metric in resultado.columns:\n",
    "                    valores = resultado[metric].dropna()\n",
    "                    if len(valores) > 0:\n",
    "                        print(f\"   {metric}: {valores.mean():.3f}\")\n",
    "                    else:\n",
    "                        print(f\"   {metric}: Sin valores válidos\")\n",
    "\n",
    "            time.sleep(90)  # Pausa entre embeddings\n",
    "\n",
    "          # Guardar resultados de este prompt\n",
    "        resultados_completos[prompt_name] = resultados_por_embedding\n",
    "\n",
    "    else:\n",
    "        print(f\"No hay suficientes respuestas válidas para {prompt_name}, saltando evaluación\")\n",
    "\n",
    "    if prompt_name != prompts_list[-1]:\n",
    "        print(f\"\\nPAUSA ENTRE PROMPTS: 300 segundos...\")\n",
    "        time.sleep(300)\n",
    "\n",
    "print(\"\\\"EVALUACIÓN COMPLETA\")\n",
    "\n",
    "  # Mostrar tabla final\n",
    "print(\"\\nTABLA DE RESULTADOS:\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "for prompt_name, embeddings_results in resultados_completos.items():\n",
    "    print(f\"\\nPROMPT: {prompt_name}\")\n",
    "    for embedding_name, resultado in embeddings_results.items():\n",
    "        print(f\"{embedding_name}:\")\n",
    "        for metric in ['context_precision', 'context_recall', 'faithfulness', 'answer_correctness']:\n",
    "            if metric in resultado.columns:\n",
    "                valores = resultado[metric].dropna()\n",
    "                if len(valores) > 0:\n",
    "                    print(f\"      {metric}: {valores.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Evaluación del modelo Phi-3.5-mini-instruct__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUANDO CON PROMPT: prompt_zero_shot\n",
      "================================================================================\n",
      "Generando respuestas con LangGraph...\n",
      "Procesando pregunta 1/9 con prompt_zero_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Phi-3.5-mini-instruct\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Published by Elsevier Inc. All rights reserved. doi:10.1016/j.yqres.2011.12.003 Contents lists available at SciVerse ScienceDirect Quaternary Research journal homepage: www.elsevier.com/locate/yqres https://doi.org/10.1016/j.yqres.2011.12.003 Published online by Cambridge University Press Introduc...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 2/9 con prompt_zero_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Phi-3.5-mini-instruct\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. A data obtida, é claramente mais recuada que os con­ textos mais antigos reportados em território hoje portu­ guês, nomeadamente Gruta da Nascente do Rio Almonda (OxA­‑9287 – 5480­‑5320 cal BC a 2 sigmas) e da Gruta do Caldeirão (OxA­‑1036 – 5480 – 5070 cal BC a 2 sigmas). Entre nós, apenas se rep...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 3/9 con prompt_zero_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Phi-3.5-mini-instruct\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 2. ENCUADRE CRONO-CULTURAL DEL HA- LLAZGO: COGOTAS I Entre las entidades arqueológicas de la Edad del Bronce peninsular, Cogotas I sobresale por su extensa cobertura geográfica, que desborda la Meseta por el Valle del Ebro y Extremadura, y por su dilatada crono- logía —c. 1800-1150 cal BC, cubrien...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 4/9 con prompt_zero_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Phi-3.5-mini-instruct\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. y NEIRA, A. (1999): “Prehistoria”, en M.A. Rabanal Alonso (coord.): La His­ toria de León, tomo I, Universidad de León y Diario de León. CELIS SÁNCHEZ, J. (1993a): “La secuencia del poblado de la Primera Edad del Hierro de los «Cuestos de la Estación», Benavente, Zamora”, en F. Romero, C. Sanz y Z...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 5/9 con prompt_zero_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Phi-3.5-mini-instruct\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Con el desarrollo de las excavaciones arqueológicas en diversos asentamientos, el aumento del número de dataciones y la realización de diversos estudios en los últimos años, las perspectivas de investigación sobre el Bronce final en el Levante comienza a variar sustancialmente, estando ya en condi...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 6/9 con prompt_zero_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Phi-3.5-mini-instruct\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. En la actualidad, El Argar sigue siendo el grupo arqueo­ lógico de la Edad del Bronce mejor conocido de la península ibérica, con un desarrollo temporal entre el 2200 y el 1550 cal BC. También se puede afirmar que fue una de las sociedades con mayor capacidad productiva y desarrollo social de la E...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Respuestas válidas generadas con prompt_zero_shot: 6\n",
      "\n",
      "🔄 EVALUANDO: prompt_zero_shot + all-MiniLM-L6-v2\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 métricas en batches de 2\n",
      "   🔄 Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\_analytics.py:77: ResourceWarning: unclosed file <_io.TextIOWrapper name='C:\\\\Users\\\\elevi\\\\AppData\\\\Local\\\\ragas\\\\ragas\\\\uuid.json' mode='r' encoding='cp1252'>\n",
      "  user_id = json.load(open(uuid_filepath))[\"userid\"]\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "663e7bb4fdca4632b82976872ae69b03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fe446edf41c463c9f8be28bbfa38482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0434717ba5324f03857489e0613f3c2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db416305fb414e5abfca3a5b535743b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb018b6bce6842e78e0cf049c3de9e99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cb9740fd15240df937880930de116e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cbbe934b5f049e1ada4a753505e1782",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e050d8be21b8445995db57fa96d42a22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a62cfd3d27e49439c8823249a02e486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d37e08e4b1f34fde8ffcb2667b2ac71a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57166d98962c4aa2ad7349d19d3edd8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "612f611d366c472bb4a7ea442d6b303a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 métricas\n",
      "Evaluación completada: 6 preguntas con 4 métricas\n",
      "\n",
      "📊 COMBINACIÓN: prompt_zero_shot + all-MiniLM-L6-v2\n",
      "   context_precision: 0.404\n",
      "   context_recall: 0.106\n",
      "   faithfulness: 0.705\n",
      "   answer_correctness: 0.179\n",
      "\n",
      "🔄 EVALUANDO: prompt_zero_shot + e5-large-instruct\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 métricas en batches de 2\n",
      "   🔄 Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fc1ce17e6a04aaca42e71019b28a8ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc217258522f46aba65a673ad5dc4a2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "935cafa686ea46118f8bcfce6d7e0196",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a64708f6ffe4fc1ac5a6bcae707b8df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91991ab9c05149cfa9eabd28df0ade51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb0ed8e9a6264974a6d596024d1a2aee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "923e866116304871be75f767e69ce279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ff6cfdf8e1a4033b2b58937a603b363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d12b83d50864e5b976822add5b158f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "225a7aa032fd4dc189dac32feb138627",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55be81519e0b41a58ae7a964dd93b046",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a054ededaad4a6ca40fa4644379bdf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 métricas\n",
      "Evaluación completada: 6 preguntas con 4 métricas\n",
      "\n",
      "📊 COMBINACIÓN: prompt_zero_shot + e5-large-instruct\n",
      "   context_precision: 0.458\n",
      "   context_recall: 0.148\n",
      "   faithfulness: 0.772\n",
      "   answer_correctness: 0.266\n",
      "\n",
      "🔄 EVALUANDO: prompt_zero_shot + gte-multilingual-base\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 métricas en batches de 2\n",
      "   🔄 Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "575dafa3156448579a03c58b59084ccd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94d620b9d5424786954527ed754cbdc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b8253d98cb3459da9ec83721257f783",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b935b8e893d44feaa702b82591d810e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6a0f197a0f84d728f1aeede4eecb9a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4be0b246eb0c4597a8d6cfdfd26a0cfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "480a2eef5e5b4103b91653ee46271ac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad2e84e5e79048c1ab1ba6cdb7d7b3c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96a13f8b243846ba9c93007898d1b158",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2791b29738f14e21a257067f9b1f5d6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "535a201a013c4f17b306397a56c3e660",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a6f261c6ec14d28849c7fcee48d75e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 métricas\n",
      "Evaluación completada: 6 preguntas con 4 métricas\n",
      "\n",
      "📊 COMBINACIÓN: prompt_zero_shot + gte-multilingual-base\n",
      "   context_precision: 0.475\n",
      "   context_recall: 0.239\n",
      "   faithfulness: 0.733\n",
      "   answer_correctness: 0.148\n",
      "\n",
      "⏱️ PAUSA ENTRE PROMPTS: 300 segundos...\n",
      "\n",
      "EVALUANDO CON PROMPT: prompt_one_shot\n",
      "================================================================================\n",
      "Generando respuestas con LangGraph...\n",
      "Procesando pregunta 1/9 con prompt_one_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Phi-3.5-mini-instruct\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Published by Elsevier Inc. All rights reserved. doi:10.1016/j.yqres.2011.12.003 Contents lists available at SciVerse ScienceDirect Quaternary Research journal homepage: www.elsevier.com/locate/yqres https://doi.org/10.1016/j.yqres.2011.12.003 Published online by Cambridge University Press Introduc...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 2/9 con prompt_one_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Phi-3.5-mini-instruct\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. A data obtida, é claramente mais recuada que os con­ textos mais antigos reportados em território hoje portu­ guês, nomeadamente Gruta da Nascente do Rio Almonda (OxA­‑9287 – 5480­‑5320 cal BC a 2 sigmas) e da Gruta do Caldeirão (OxA­‑1036 – 5480 – 5070 cal BC a 2 sigmas). Entre nós, apenas se rep...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 3/9 con prompt_one_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Phi-3.5-mini-instruct\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 2. ENCUADRE CRONO-CULTURAL DEL HA- LLAZGO: COGOTAS I Entre las entidades arqueológicas de la Edad del Bronce peninsular, Cogotas I sobresale por su extensa cobertura geográfica, que desborda la Meseta por el Valle del Ebro y Extremadura, y por su dilatada crono- logía —c. 1800-1150 cal BC, cubrien...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 4/9 con prompt_one_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Phi-3.5-mini-instruct\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. y NEIRA, A. (1999): “Prehistoria”, en M.A. Rabanal Alonso (coord.): La His­ toria de León, tomo I, Universidad de León y Diario de León. CELIS SÁNCHEZ, J. (1993a): “La secuencia del poblado de la Primera Edad del Hierro de los «Cuestos de la Estación», Benavente, Zamora”, en F. Romero, C. Sanz y Z...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 5/9 con prompt_one_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Phi-3.5-mini-instruct\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Con el desarrollo de las excavaciones arqueológicas en diversos asentamientos, el aumento del número de dataciones y la realización de diversos estudios en los últimos años, las perspectivas de investigación sobre el Bronce final en el Levante comienza a variar sustancialmente, estando ya en condi...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 6/9 con prompt_one_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Phi-3.5-mini-instruct\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. En la actualidad, El Argar sigue siendo el grupo arqueo­ lógico de la Edad del Bronce mejor conocido de la península ibérica, con un desarrollo temporal entre el 2200 y el 1550 cal BC. También se puede afirmar que fue una de las sociedades con mayor capacidad productiva y desarrollo social de la E...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Respuestas válidas generadas con prompt_one_shot: 6\n",
      "\n",
      "🔄 EVALUANDO: prompt_one_shot + all-MiniLM-L6-v2\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 métricas en batches de 2\n",
      "   🔄 Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d42ddc6d6a7460fb51cf4bddcc63bb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cb10a6506d94f9988206fa7217b0793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bd7a798b050424f869936fcfc3a6399",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "482ca3db145d4ccca57f187f0e18c032",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1adf1e16b5b943539bdbc6bd92deac9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbc0114ae25d43dca8b20ed2ce98a347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ab63515dcf94e6687228d98b2b3a043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4deff40965ee48b48348d4ba9294fa55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54b789ce4e0d467da95a7e20473c35a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6602b1baa10247c5b7cc3d0a0aea9ced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77796551f8f8413eb688122eaab30e6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02b46c3ba346472093404e1e09981762",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 métricas\n",
      "Evaluación completada: 6 preguntas con 4 métricas\n",
      "\n",
      "📊 COMBINACIÓN: prompt_one_shot + all-MiniLM-L6-v2\n",
      "   context_precision: 0.429\n",
      "   context_recall: 0.282\n",
      "   faithfulness: 0.967\n",
      "   answer_correctness: 0.215\n",
      "\n",
      "🔄 EVALUANDO: prompt_one_shot + e5-large-instruct\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 métricas en batches de 2\n",
      "   🔄 Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbb14bcafa55465cb5efaa960215b064",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99dbc308b71641d7b9d9303cc31f363b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bab457f68c7e4639959151f2ca66f8ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7b8107220574f08bb0b58a75fe63428",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ed740c258414d74b422e5bc9e7542a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3d5e86e6017485cb4aec672c6db3442",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e55f7105c9348b6920ca9b11734e13f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1336b64706f54fbebe8f7a63e4709f8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab2d0529e717486da2402259c6d4f901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1342fad78b8145a083ce6148bdc6bd1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7b4c1ad8fe54f8188ed9d47c6083e0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d726dc55324742cd8a06827b46774384",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 métricas\n",
      "Evaluación completada: 6 preguntas con 4 métricas\n",
      "\n",
      "📊 COMBINACIÓN: prompt_one_shot + e5-large-instruct\n",
      "   context_precision: 0.458\n",
      "   context_recall: 0.130\n",
      "   faithfulness: 0.929\n",
      "   answer_correctness: 0.307\n",
      "\n",
      "🔄 EVALUANDO: prompt_one_shot + gte-multilingual-base\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 métricas en batches de 2\n",
      "   🔄 Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b38b5340330247948876ca9714b8d1a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc2473b2667545c89f4942fb786e1da2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43a4a25f304b4ba881721c5abfc98c10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d6f1a6c4b4c4f9f80ce35fcd493cc73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "359c4dbfcd1348aa886e67d5bb516579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f206eafd75d4fc3ae8947a3e0351c24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9420221cc3da4be69fb10da8afc51ab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68082e59e84b4d6cb5c1d87996d98d9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09f7caecd491496b9f6fe5b69160a3f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b463a87afe14694b07ed053c374ebae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b930dbdbef0f46f4a1d59dea99822d9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ce82cc31e504a1cb5a40a717a15823b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 métricas\n",
      "Evaluación completada: 6 preguntas con 4 métricas\n",
      "\n",
      "📊 COMBINACIÓN: prompt_one_shot + gte-multilingual-base\n",
      "   context_precision: 0.527\n",
      "   context_recall: 0.181\n",
      "   faithfulness: 0.888\n",
      "   answer_correctness: 0.211\n",
      "\n",
      "⏱️ PAUSA ENTRE PROMPTS: 300 segundos...\n",
      "\n",
      "EVALUANDO CON PROMPT: prompt_few_shot\n",
      "================================================================================\n",
      "Generando respuestas con LangGraph...\n",
      "Procesando pregunta 1/9 con prompt_few_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Phi-3.5-mini-instruct\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Published by Elsevier Inc. All rights reserved. doi:10.1016/j.yqres.2011.12.003 Contents lists available at SciVerse ScienceDirect Quaternary Research journal homepage: www.elsevier.com/locate/yqres https://doi.org/10.1016/j.yqres.2011.12.003 Published online by Cambridge University Press Introduc...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 2/9 con prompt_few_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Phi-3.5-mini-instruct\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. A data obtida, é claramente mais recuada que os con­ textos mais antigos reportados em território hoje portu­ guês, nomeadamente Gruta da Nascente do Rio Almonda (OxA­‑9287 – 5480­‑5320 cal BC a 2 sigmas) e da Gruta do Caldeirão (OxA­‑1036 – 5480 – 5070 cal BC a 2 sigmas). Entre nós, apenas se rep...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 3/9 con prompt_few_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Phi-3.5-mini-instruct\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 2. ENCUADRE CRONO-CULTURAL DEL HA- LLAZGO: COGOTAS I Entre las entidades arqueológicas de la Edad del Bronce peninsular, Cogotas I sobresale por su extensa cobertura geográfica, que desborda la Meseta por el Valle del Ebro y Extremadura, y por su dilatada crono- logía —c. 1800-1150 cal BC, cubrien...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 4/9 con prompt_few_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Phi-3.5-mini-instruct\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. y NEIRA, A. (1999): “Prehistoria”, en M.A. Rabanal Alonso (coord.): La His­ toria de León, tomo I, Universidad de León y Diario de León. CELIS SÁNCHEZ, J. (1993a): “La secuencia del poblado de la Primera Edad del Hierro de los «Cuestos de la Estación», Benavente, Zamora”, en F. Romero, C. Sanz y Z...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 5/9 con prompt_few_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Phi-3.5-mini-instruct\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Con el desarrollo de las excavaciones arqueológicas en diversos asentamientos, el aumento del número de dataciones y la realización de diversos estudios en los últimos años, las perspectivas de investigación sobre el Bronce final en el Levante comienza a variar sustancialmente, estando ya en condi...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 6/9 con prompt_few_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Phi-3.5-mini-instruct\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. En la actualidad, El Argar sigue siendo el grupo arqueo­ lógico de la Edad del Bronce mejor conocido de la península ibérica, con un desarrollo temporal entre el 2200 y el 1550 cal BC. También se puede afirmar que fue una de las sociedades con mayor capacidad productiva y desarrollo social de la E...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Respuestas válidas generadas con prompt_few_shot: 6\n",
      "\n",
      "🔄 EVALUANDO: prompt_few_shot + all-MiniLM-L6-v2\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 métricas en batches de 2\n",
      "   🔄 Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c8e68f59d8c425e8eb1aae8e62aee35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee539e36aef544058cb6b314f501d20c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d819adf28a5470c8594487aca9ac971",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53b8654942864d43af1444fd2b8c7248",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c7b3c9437b84492a645ffe5bfe780da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afb30791c4164820a170030485f1fe78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4db537fc8a2744a5bc0feb7f566d9d38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fa738e2a81f44e2b0b301ee9094c926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b77224b7a944e9c9cdecfd7e8c107d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "503ba870f82a4dfdb2a37ea111479702",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5815faba5e7a46fc9dbe1a4318242797",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99b23b949bcd4d0d899b36f0ff287096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 métricas\n",
      "Evaluación completada: 6 preguntas con 4 métricas\n",
      "\n",
      "📊 COMBINACIÓN: prompt_few_shot + all-MiniLM-L6-v2\n",
      "   context_precision: 0.367\n",
      "   context_recall: 0.314\n",
      "   faithfulness: 0.845\n",
      "   answer_correctness: 0.180\n",
      "\n",
      "🔄 EVALUANDO: prompt_few_shot + e5-large-instruct\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 métricas en batches de 2\n",
      "   🔄 Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb1f27103d744e6aaf3f7dd6bc372964",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c91042a772fc47d68a5d31dba053b3e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4eb298138c44318b7a4ce0a4f756be0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae8d9f09c2054ec68136ce5f6717993e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfefec6d38f0422780c7ca3030fd69fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbcb493f58f044aebda697ab232bb2c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b2f3377bfce4192ae1b82cf7d585bfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "361eac7b71124622a355bd445cb5779f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f43866a5fad46bf9e37c407b78b7b35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcc4f73cecf14710979166bfa5fcda39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b662055f6744957a46372a7da378a08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b0cabac32594f4cad40c7533e6229da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 métricas\n",
      "Evaluación completada: 6 preguntas con 4 métricas\n",
      "\n",
      "📊 COMBINACIÓN: prompt_few_shot + e5-large-instruct\n",
      "   context_precision: 0.479\n",
      "   context_recall: 0.329\n",
      "   faithfulness: 0.860\n",
      "   answer_correctness: 0.262\n",
      "\n",
      "🔄 EVALUANDO: prompt_few_shot + gte-multilingual-base\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 métricas en batches de 2\n",
      "   🔄 Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "509b7ba4df694702a9edd097d23bd245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d08e89bff4654fbe864ecb379c9b9ac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "014585d99666401486b9a7f1aa5d94bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aab5f81468964621a14562cd3f0976c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00f1934219db46458fe1033f3057d219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76991506a8f4470b8d9cc8574345bf0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f164e717c6a451e9b696663f67408f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b7593b54fa241a98dd3da9b1707d682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55979c94c11940d48e8dc21455116227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdd0941ea87241e781fbe94a2b154598",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75165e34e9084757806d844abec373c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a74f5cb7ed984d0bbf83a8512abc5992",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 métricas\n",
      "Evaluación completada: 6 preguntas con 4 métricas\n",
      "\n",
      "📊 COMBINACIÓN: prompt_few_shot + gte-multilingual-base\n",
      "   context_precision: 0.471\n",
      "   context_recall: 0.259\n",
      "   faithfulness: 0.866\n",
      "   answer_correctness: 0.158\n",
      "\"EVALUACIÓN COMPLETA\n",
      "\n",
      "TABLA DE RESULTADOS:\n",
      "====================================================================================================\n",
      "\n",
      "🎯 PROMPT: prompt_zero_shot\n",
      "   📊 all-MiniLM-L6-v2:\n",
      "      context_precision: 0.404\n",
      "      context_recall: 0.106\n",
      "      faithfulness: 0.705\n",
      "      answer_correctness: 0.179\n",
      "   📊 e5-large-instruct:\n",
      "      context_precision: 0.458\n",
      "      context_recall: 0.148\n",
      "      faithfulness: 0.772\n",
      "      answer_correctness: 0.266\n",
      "   📊 gte-multilingual-base:\n",
      "      context_precision: 0.475\n",
      "      context_recall: 0.239\n",
      "      faithfulness: 0.733\n",
      "      answer_correctness: 0.148\n",
      "\n",
      "🎯 PROMPT: prompt_one_shot\n",
      "   📊 all-MiniLM-L6-v2:\n",
      "      context_precision: 0.429\n",
      "      context_recall: 0.282\n",
      "      faithfulness: 0.967\n",
      "      answer_correctness: 0.215\n",
      "   📊 e5-large-instruct:\n",
      "      context_precision: 0.458\n",
      "      context_recall: 0.130\n",
      "      faithfulness: 0.929\n",
      "      answer_correctness: 0.307\n",
      "   📊 gte-multilingual-base:\n",
      "      context_precision: 0.527\n",
      "      context_recall: 0.181\n",
      "      faithfulness: 0.888\n",
      "      answer_correctness: 0.211\n",
      "\n",
      "🎯 PROMPT: prompt_few_shot\n",
      "   📊 all-MiniLM-L6-v2:\n",
      "      context_precision: 0.367\n",
      "      context_recall: 0.314\n",
      "      faithfulness: 0.845\n",
      "      answer_correctness: 0.180\n",
      "   📊 e5-large-instruct:\n",
      "      context_precision: 0.479\n",
      "      context_recall: 0.329\n",
      "      faithfulness: 0.860\n",
      "      answer_correctness: 0.262\n",
      "   📊 gte-multilingual-base:\n",
      "      context_precision: 0.471\n",
      "      context_recall: 0.259\n",
      "      faithfulness: 0.866\n",
      "      answer_correctness: 0.158\n"
     ]
    }
   ],
   "source": [
    "# Evaluar TODAS las combinaciones: 3 prompts × 3 embeddings = 9 combinaciones\n",
    "resultados_completos = {}\n",
    "\n",
    "prompts_list = ['prompt_zero_shot', 'prompt_one_shot', 'prompt_few_shot']\n",
    "\n",
    "for prompt_name in prompts_list:\n",
    "    print(f\"\\nEVALUANDO CON PROMPT: {prompt_name}\")\n",
    "    print(\"=\"*80)\n",
    "    selected_template = PROMPTS[prompt_name]\n",
    "    prompt_template = ChatPromptTemplate.from_template(selected_template)\n",
    "\n",
    "    # Generar respuestas con este prompt específico\n",
    "    results_list_prompt = []\n",
    "\n",
    "    # Necesitas generar las respuestas con tu grafo de LangGraph primero\n",
    "    print(\"Generando respuestas con LangGraph...\")\n",
    "\n",
    "    for i, (question, ground_truth) in enumerate(zip(questions, ground_truths)):\n",
    "        print(f\"Procesando pregunta {i+1}/{len(questions)} con {prompt_name}\")\n",
    "\n",
    "        # Aquí usas tu grafo de LangGraph para generar la respuesta\n",
    "        state = {\n",
    "            'question': question,\n",
    "            'llm_name': 'Phi-3.5-mini-instruct',  # Tu LLM de generación\n",
    "            'embedding_name': 'all-MiniLM-L6-v2',  # Se cambiará en el bucle    \n",
    "            'prompt_name': prompt_name,\n",
    "            'context': [],\n",
    "            'answer': '',\n",
    "            'metadata': {}\n",
    "        }\n",
    "        try:\n",
    "            # INVOCAR TU GRAFO (ajusta según tu código)\n",
    "            final_state = graph.invoke(state)\n",
    "            answer = final_state.get('answer', '')\n",
    "            contexts = final_state.get('context', [])\n",
    "\n",
    "            if answer and answer.strip():  # Verificar que hay respuesta\n",
    "                  results_list_prompt.append({\n",
    "                      'question': question,\n",
    "                      'answer': answer,\n",
    "                      'contexts': [doc.page_content for doc in contexts] if contexts else ['Sin contexto'],\n",
    "                      'ground_truth': ground_truth\n",
    "                  })\n",
    "            else:\n",
    "                  print(f\"Pregunta {i+1} sin respuesta válida\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error en pregunta {i+1}: {e}\")\n",
    "\n",
    "    print(f\"Respuestas válidas generadas con {prompt_name}: {len(results_list_prompt)}\")\n",
    "\n",
    "      # Solo evaluar si tenemos respuestas válidas\n",
    "    if len(results_list_prompt) >= 2:\n",
    "          # EVALUAR CON LOS 3 EMBEDDINGS\n",
    "        resultados_por_embedding = {}\n",
    "\n",
    "        for embedding_name, current_embedding_model in EMBEDDING_MODELS.items():\n",
    "            print(f\"\\nEVALUANDO: {prompt_name} + {embedding_name}\")\n",
    "            print(\"-\"*60)\n",
    "\n",
    "            resultado = evaluate_with_mistral_four_metrics(\n",
    "                results_list=results_list_prompt,\n",
    "                  embedding_model=current_embedding_model,\n",
    "                  max_batch_size=2,\n",
    "                  delay_between_batches=120\n",
    "            )\n",
    "\n",
    "            resultados_por_embedding[embedding_name] = resultado\n",
    "\n",
    "              # Mostrar métricas promedio\n",
    "            print(f\"\\nCOMBINACIÓN: {prompt_name} + {embedding_name}\")\n",
    "            for metric in ['context_precision', 'context_recall', 'faithfulness', 'answer_correctness']:\n",
    "                if metric in resultado.columns:\n",
    "                    valores = resultado[metric].dropna()\n",
    "                    if len(valores) > 0:\n",
    "                        print(f\"   {metric}: {valores.mean():.3f}\")\n",
    "                    else:\n",
    "                        print(f\"   {metric}: Sin valores válidos\")\n",
    "\n",
    "            time.sleep(90)  # Pausa entre embeddings\n",
    "\n",
    "          # Guardar resultados de este prompt\n",
    "        resultados_completos[prompt_name] = resultados_por_embedding\n",
    "\n",
    "    else:\n",
    "        print(f\"No hay suficientes respuestas válidas para {prompt_name}, saltando evaluación\")\n",
    "\n",
    "    if prompt_name != prompts_list[-1]:\n",
    "        print(f\"\\nPAUSA ENTRE PROMPTS: 300 segundos...\")\n",
    "        time.sleep(300)\n",
    "\n",
    "print(\"\\\"EVALUACIÓN COMPLETA\")\n",
    "\n",
    "  # Mostrar tabla final\n",
    "print(\"\\nTABLA DE RESULTADOS:\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "for prompt_name, embeddings_results in resultados_completos.items():\n",
    "    print(f\"\\nPROMPT: {prompt_name}\")\n",
    "    for embedding_name, resultado in embeddings_results.items():\n",
    "        print(f\"{embedding_name}:\")\n",
    "        for metric in ['context_precision', 'context_recall', 'faithfulness', 'answer_correctness']:\n",
    "            if metric in resultado.columns:\n",
    "                valores = resultado[metric].dropna()\n",
    "                if len(valores) > 0:\n",
    "                    print(f\"      {metric}: {valores.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Evaluación del modelo Llama-3.2-3B-instruct__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUANDO CON PROMPT: prompt_zero_shot\n",
      "================================================================================\n",
      "Generando respuestas con LangGraph...\n",
      "Procesando pregunta 1/9 con prompt_zero_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Llama-3.2-3B-instruct\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Published by Elsevier Inc. All rights reserved. doi:10.1016/j.yqres.2011.12.003 Contents lists available at SciVerse ScienceDirect Quaternary Research journal homepage: www.elsevier.com/locate/yqres https://doi.org/10.1016/j.yqres.2011.12.003 Published online by Cambridge University Press Introduc...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 2/9 con prompt_zero_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Llama-3.2-3B-instruct\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. A data obtida, é claramente mais recuada que os con­ textos mais antigos reportados em território hoje portu­ guês, nomeadamente Gruta da Nascente do Rio Almonda (OxA­‑9287 – 5480­‑5320 cal BC a 2 sigmas) e da Gruta do Caldeirão (OxA­‑1036 – 5480 – 5070 cal BC a 2 sigmas). Entre nós, apenas se rep...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 3/9 con prompt_zero_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Llama-3.2-3B-instruct\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 2. ENCUADRE CRONO-CULTURAL DEL HA- LLAZGO: COGOTAS I Entre las entidades arqueológicas de la Edad del Bronce peninsular, Cogotas I sobresale por su extensa cobertura geográfica, que desborda la Meseta por el Valle del Ebro y Extremadura, y por su dilatada crono- logía —c. 1800-1150 cal BC, cubrien...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 4/9 con prompt_zero_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Llama-3.2-3B-instruct\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. y NEIRA, A. (1999): “Prehistoria”, en M.A. Rabanal Alonso (coord.): La His­ toria de León, tomo I, Universidad de León y Diario de León. CELIS SÁNCHEZ, J. (1993a): “La secuencia del poblado de la Primera Edad del Hierro de los «Cuestos de la Estación», Benavente, Zamora”, en F. Romero, C. Sanz y Z...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 5/9 con prompt_zero_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Llama-3.2-3B-instruct\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Con el desarrollo de las excavaciones arqueológicas en diversos asentamientos, el aumento del número de dataciones y la realización de diversos estudios en los últimos años, las perspectivas de investigación sobre el Bronce final en el Levante comienza a variar sustancialmente, estando ya en condi...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 6/9 con prompt_zero_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Llama-3.2-3B-instruct\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. En la actualidad, El Argar sigue siendo el grupo arqueo­ lógico de la Edad del Bronce mejor conocido de la península ibérica, con un desarrollo temporal entre el 2200 y el 1550 cal BC. También se puede afirmar que fue una de las sociedades con mayor capacidad productiva y desarrollo social de la E...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Respuestas válidas generadas con prompt_zero_shot: 6\n",
      "\n",
      "EVALUANDO: prompt_zero_shot + all-MiniLM-L6-v2\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 métricas en batches de 2\n",
      "   🔄 Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39bc2025ad63498fb573b9ba9423bfa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15316af68c264e46808b936fe476bf78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d89cff9ca7114170ba656514e4a5c361",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "358ba34e49014bbaaa01fcd822e0db61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b75e79fbedde4b64a17583c6662ba919",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b698712df6f649a9a6f45ea5f0c76133",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f2c95d23e6d47b9a0ab46805ea6b30e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df6243bdba2844ae905a3a3d8a94f314",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3c71764819c4e22b20e1e3d91630c92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41137bb4d8c64713a2044ef51d4996e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4581505ba90042fa817733e229560696",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fa2e4e40ab049dd97ba1ad0868e5b35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 métricas\n",
      "Evaluación completada: 6 preguntas con 4 métricas\n",
      "\n",
      "COMBINACIÓN: prompt_zero_shot + all-MiniLM-L6-v2\n",
      "   context_precision: 0.317\n",
      "   context_recall: 0.157\n",
      "   faithfulness: 0.566\n",
      "   answer_correctness: 0.223\n",
      "\n",
      "EVALUANDO: prompt_zero_shot + e5-large-instruct\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 métricas en batches de 2\n",
      "   🔄 Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "714157d681c54c7398621b9220aab1cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2a7fd3f24de4245bd2dfec8a863336b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad8ee4deb62e47bf8257018338eba794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2783c33e5d6549e7ab2ea15bdef3dfbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc6fb0229d9447cd88031b30345d7571",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4829a72708446c89307d0783a156a77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d3f15030d074d12ab68bf485ceaebbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "971dd70a5b694e9b8a42b0f053e32180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "196edfd091594f9ea5163138594f2dce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29da80131c574b87a607623c89dbac9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f31d174ffd964a0a8fa11a4ab29b31bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d97d96cd8c7a415fa76b0da4f9b6a942",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 métricas\n",
      "Evaluación completada: 6 preguntas con 4 métricas\n",
      "\n",
      "COMBINACIÓN: prompt_zero_shot + e5-large-instruct\n",
      "   context_precision: 0.365\n",
      "   context_recall: 0.217\n",
      "   faithfulness: 0.626\n",
      "   answer_correctness: 0.350\n",
      "\n",
      "EVALUANDO: prompt_zero_shot + gte-multilingual-base\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 métricas en batches de 2\n",
      "   🔄 Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a81b969b2a04bf3bf677a1603be39a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4ec50318d1b411cbe521a6e2e56337b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb8a343815534f6fab9fe4fdc62be8d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b61c4becab04fd4a0a27c535a71aa60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53898a4b33f142d7833ad72164686d85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1507690f15a443c28c33948e5715bf43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a8a55021bcf4a41b06d5936b3460f89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f79d3293722c407080ce8fe6d3be7388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daccb81e5bee49cca4e491142ec92b23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "515afd9de0b14ef1899b413885d2a1a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0f5441fcd47433690ae32c9cb0dc1d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d83a4e8ad72e41c798914c43d603f676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 métricas\n",
      "Evaluación completada: 6 preguntas con 4 métricas\n",
      "\n",
      "COMBINACIÓN: prompt_zero_shot + gte-multilingual-base\n",
      "   context_precision: 0.390\n",
      "   context_recall: 0.129\n",
      "   faithfulness: 0.598\n",
      "   answer_correctness: 0.379\n",
      "\n",
      "PAUSA ENTRE PROMPTS: 300 segundos...\n",
      "\n",
      "EVALUANDO CON PROMPT: prompt_one_shot\n",
      "================================================================================\n",
      "Generando respuestas con LangGraph...\n",
      "Procesando pregunta 1/9 con prompt_one_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Llama-3.2-3B-instruct\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Published by Elsevier Inc. All rights reserved. doi:10.1016/j.yqres.2011.12.003 Contents lists available at SciVerse ScienceDirect Quaternary Research journal homepage: www.elsevier.com/locate/yqres https://doi.org/10.1016/j.yqres.2011.12.003 Published online by Cambridge University Press Introduc...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 2/9 con prompt_one_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Llama-3.2-3B-instruct\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. A data obtida, é claramente mais recuada que os con­ textos mais antigos reportados em território hoje portu­ guês, nomeadamente Gruta da Nascente do Rio Almonda (OxA­‑9287 – 5480­‑5320 cal BC a 2 sigmas) e da Gruta do Caldeirão (OxA­‑1036 – 5480 – 5070 cal BC a 2 sigmas). Entre nós, apenas se rep...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 3/9 con prompt_one_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Llama-3.2-3B-instruct\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 2. ENCUADRE CRONO-CULTURAL DEL HA- LLAZGO: COGOTAS I Entre las entidades arqueológicas de la Edad del Bronce peninsular, Cogotas I sobresale por su extensa cobertura geográfica, que desborda la Meseta por el Valle del Ebro y Extremadura, y por su dilatada crono- logía —c. 1800-1150 cal BC, cubrien...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 4/9 con prompt_one_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Llama-3.2-3B-instruct\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. y NEIRA, A. (1999): “Prehistoria”, en M.A. Rabanal Alonso (coord.): La His­ toria de León, tomo I, Universidad de León y Diario de León. CELIS SÁNCHEZ, J. (1993a): “La secuencia del poblado de la Primera Edad del Hierro de los «Cuestos de la Estación», Benavente, Zamora”, en F. Romero, C. Sanz y Z...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 5/9 con prompt_one_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Llama-3.2-3B-instruct\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Con el desarrollo de las excavaciones arqueológicas en diversos asentamientos, el aumento del número de dataciones y la realización de diversos estudios en los últimos años, las perspectivas de investigación sobre el Bronce final en el Levante comienza a variar sustancialmente, estando ya en condi...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 6/9 con prompt_one_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Llama-3.2-3B-instruct\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. En la actualidad, El Argar sigue siendo el grupo arqueo­ lógico de la Edad del Bronce mejor conocido de la península ibérica, con un desarrollo temporal entre el 2200 y el 1550 cal BC. También se puede afirmar que fue una de las sociedades con mayor capacidad productiva y desarrollo social de la E...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Respuestas válidas generadas con prompt_one_shot: 6\n",
      "\n",
      "EVALUANDO: prompt_one_shot + all-MiniLM-L6-v2\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 métricas en batches de 2\n",
      "   🔄 Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb383fb6507f42a1b4e11bbecec69d3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aba0e1a17ec84cfbb4aa99209d5a32dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "915c35a2ab204c07ba1f9c6e0f1949c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a9ad39ff09d43458bbe7df603ce7a84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d489d5f0dd584058a720cb4fd5e924b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "107a6a8eb8804c7ba7cbe4e86f064e0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "029baf081b7047fa9968c2054d57d798",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e22f7add65fa49aeb6f713f83787d278",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd2e8958eb9d4fbbbcce91b5fcd7c6d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1f8f33bb6b14868ac9e7765f347ce09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bbb805c818e451f8676e73b84a05834",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e042018fa7647eda0acd35cef9ce4e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 métricas\n",
      "Evaluación completada: 6 preguntas con 4 métricas\n",
      "\n",
      "COMBINACIÓN: prompt_one_shot + all-MiniLM-L6-v2\n",
      "   context_precision: 0.478\n",
      "   context_recall: 0.273\n",
      "   faithfulness: 0.754\n",
      "   answer_correctness: 0.218\n",
      "\n",
      "EVALUANDO: prompt_one_shot + e5-large-instruct\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 métricas en batches de 2\n",
      "   🔄 Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f708d9d6181e4de1b7f15fdd77bb2a33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fb6864ee3fa457a8b45909e5901a2e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "652fbadd50a146fd944f135b342884f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd4f469eb2984a9d89b4a590852a4e34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edf89a19651d4c42bb511111c8d08fa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e02294f4aae42b5b937a8bef72dd8bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b44db4a9d433485e848f53e10a26ca54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85f6c1738c6946ba911fd2a130434e13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9384942366734acdac5812fb287bd189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a2d49bac80d423699bec407bb4be33c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57fd992e307f45ccbe4681e56c22b61e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b33f816fafc84c71b40d6141ccedee6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 métricas\n",
      "Evaluación completada: 6 preguntas con 4 métricas\n",
      "\n",
      "COMBINACIÓN: prompt_one_shot + e5-large-instruct\n",
      "   context_precision: 0.450\n",
      "   context_recall: 0.323\n",
      "   faithfulness: 0.733\n",
      "   answer_correctness: 0.353\n",
      "\n",
      "EVALUANDO: prompt_one_shot + gte-multilingual-base\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 métricas en batches de 2\n",
      "   🔄 Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a909a6359b342df84217ae431976124",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a496ef569db04126bcbbeab8167782d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3d4c429365140828c89332c8c3deba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af74ae2ef749474ca1db5bf58df84e16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5919125796fc4010b8ac3ad84509225e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee500f96c6c9422c98674a633fd30983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "Exception raised in Job[0]: OutputParserException(Invalid json output: ```json\\n{\\n    \"classifications\": [\\n        {\\n            \"statement\": \"Las primeras manifestaciones funerarias datadas se sitúan en la primera mitad del V milenio con una estimación probabilística para su inicio de entre el 4975-4785 cal BC (68% de probabilidad) y entre el 4740-4570 cal BC (68% de probabilidad).\",\\n            \"reason\": \"El contexto menciona explícitamente las cronologías de las primeras manifestaciones funerarias en la península ibérica, incluyendo fechas específicas del V milenio cal BC.\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"Las manifestaciones funerarias del Mesolítico en las distintas regiones peninsulares.\\n            \"reason\": \"El contexto no proporciona información específica sobre el Mesolítico, ya que se centra en el Neolítico, Calcolítico y Edad del Bronce.\\n            \"attributed\": 0\\n        },\\n        {\\n            \"statement\": \"Las dataciones radiocarbónicas de asentamientos neolíticos se sitúan a finales del VI milenio y en la primera mitad del V milenio cal BC.\\n            \"reason\": \"El contexto menciona fechas radiocarbónicas de asentamientos neolíticos, aunque no se especifica su relación directa con manifestaciones funerarias.\\n            \"attributed\": 0.5\\n        }\\n    ]\\n}\\n```\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69f98bc79019472895b4145006ab336e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a90e8c5fa7ca40b98ba91ddae795db22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "965b806ff4174d789deb3349f59fe14a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a0f6727983246dd924cd1dbb2e93053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45d6820f1f694e64b5771a7c82a728da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8223633604b4b7f8ec2108c5cb8b709",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 métricas\n",
      "Evaluación completada: 6 preguntas con 4 métricas\n",
      "\n",
      "COMBINACIÓN: prompt_one_shot + gte-multilingual-base\n",
      "   context_precision: 0.479\n",
      "   context_recall: 0.105\n",
      "   faithfulness: 0.746\n",
      "   answer_correctness: 0.246\n",
      "\n",
      "PAUSA ENTRE PROMPTS: 300 segundos...\n",
      "\n",
      "EVALUANDO CON PROMPT: prompt_few_shot\n",
      "================================================================================\n",
      "Generando respuestas con LangGraph...\n",
      "Procesando pregunta 1/9 con prompt_few_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Llama-3.2-3B-instruct\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Published by Elsevier Inc. All rights reserved. doi:10.1016/j.yqres.2011.12.003 Contents lists available at SciVerse ScienceDirect Quaternary Research journal homepage: www.elsevier.com/locate/yqres https://doi.org/10.1016/j.yqres.2011.12.003 Published online by Cambridge University Press Introduc...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 2/9 con prompt_few_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Llama-3.2-3B-instruct\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. A data obtida, é claramente mais recuada que os con­ textos mais antigos reportados em território hoje portu­ guês, nomeadamente Gruta da Nascente do Rio Almonda (OxA­‑9287 – 5480­‑5320 cal BC a 2 sigmas) e da Gruta do Caldeirão (OxA­‑1036 – 5480 – 5070 cal BC a 2 sigmas). Entre nós, apenas se rep...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 3/9 con prompt_few_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Llama-3.2-3B-instruct\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 2. ENCUADRE CRONO-CULTURAL DEL HA- LLAZGO: COGOTAS I Entre las entidades arqueológicas de la Edad del Bronce peninsular, Cogotas I sobresale por su extensa cobertura geográfica, que desborda la Meseta por el Valle del Ebro y Extremadura, y por su dilatada crono- logía —c. 1800-1150 cal BC, cubrien...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 4/9 con prompt_few_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Llama-3.2-3B-instruct\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. y NEIRA, A. (1999): “Prehistoria”, en M.A. Rabanal Alonso (coord.): La His­ toria de León, tomo I, Universidad de León y Diario de León. CELIS SÁNCHEZ, J. (1993a): “La secuencia del poblado de la Primera Edad del Hierro de los «Cuestos de la Estación», Benavente, Zamora”, en F. Romero, C. Sanz y Z...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 5/9 con prompt_few_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Llama-3.2-3B-instruct\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Con el desarrollo de las excavaciones arqueológicas en diversos asentamientos, el aumento del número de dataciones y la realización de diversos estudios en los últimos años, las perspectivas de investigación sobre el Bronce final en el Levante comienza a variar sustancialmente, estando ya en condi...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 6/9 con prompt_few_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Llama-3.2-3B-instruct\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. En la actualidad, El Argar sigue siendo el grupo arqueo­ lógico de la Edad del Bronce mejor conocido de la península ibérica, con un desarrollo temporal entre el 2200 y el 1550 cal BC. También se puede afirmar que fue una de las sociedades con mayor capacidad productiva y desarrollo social de la E...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Respuestas válidas generadas con prompt_few_shot: 6\n",
      "\n",
      "EVALUANDO: prompt_few_shot + all-MiniLM-L6-v2\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 métricas en batches de 2\n",
      "   🔄 Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25903638dd1f4d90b7f5ca2b2524f834",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69dc88d315b2481da99ba42280e316e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6891c162ac5e472396675007d8055435",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67fdab0b9b6f4a0abe292ecc95610764",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e27195b9863483397653f90f69c639d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb8a2226432745bb975cc55534012f96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7ac28ac444a442fa9999bdd8074e990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eab138e0272f41119df95bd396b2fbca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c86f20e755b446196cdfd99d87168c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "febf16cfc41043a5986f024267f68f37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4649337582224404ac4a5c5c734449cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93bd17f6e7804a2a9fd33834fa9d48b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 métricas\n",
      "Evaluación completada: 6 preguntas con 4 métricas\n",
      "\n",
      "COMBINACIÓN: prompt_few_shot + all-MiniLM-L6-v2\n",
      "   context_precision: 0.427\n",
      "   context_recall: 0.254\n",
      "   faithfulness: 0.763\n",
      "   answer_correctness: 0.322\n",
      "\n",
      "EVALUANDO: prompt_few_shot + e5-large-instruct\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 métricas en batches de 2\n",
      "   🔄 Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1affaa86e0144365888e15467c43c280",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cf1945bdb874d59b886518aca13f866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6fb726a162c42b29776d71bbb0a0081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ccf6edd1ba4490183ffcc80d4111f85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15060a6392a348098d7de0c64e7e04c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8846a1cb86114a2dae181d16a05ad05c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7276bd789046418eb2cf4f227f9e3b1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09ad349f74524fc898cad791413ac7ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c92a5ae5edf94339a7d80a6ad02179bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daaf8fd62d75414084c7d1186be394b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a97581f02a41423990714856bf48afe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "473f7586930f48ec85bb60cafac79320",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 métricas\n",
      "Evaluación completada: 6 preguntas con 4 métricas\n",
      "\n",
      "COMBINACIÓN: prompt_few_shot + e5-large-instruct\n",
      "   context_precision: 0.420\n",
      "   context_recall: 0.187\n",
      "   faithfulness: 0.745\n",
      "   answer_correctness: 0.472\n",
      "\n",
      "EVALUANDO: prompt_few_shot + gte-multilingual-base\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 métricas en batches de 2\n",
      "   🔄 Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17b942307d4f474886063d9858ac0916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20008a6b98d04250b3fb0a5ba4ecd150",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2335b71c1a624050bbe76ec932b476b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44977d7ff766468791b25ebf64571a41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b51ba5af0415418cb0b5798fb3b3980b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34dc1b58a9534bd7a359b823450c8be8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e45d07e1c5564c6fae2c545503b4d3cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f3942fd460544e4aa60f5c08f732cd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58b44e595d7146a89c3754fabf32106e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42be9723305149d58b5f8dd45e2210fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "969edb4545914b129b9451afff54b090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b20a25f2d73e4e68913e4113732325f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 métricas\n",
      "Evaluación completada: 6 preguntas con 4 métricas\n",
      "\n",
      "COMBINACIÓN: prompt_few_shot + gte-multilingual-base\n",
      "   context_precision: 0.248\n",
      "   context_recall: 0.300\n",
      "   faithfulness: 0.782\n",
      "   answer_correctness: 0.233\n",
      "\"EVALUACIÓN COMPLETA\n",
      "\n",
      "TABLA DE RESULTADOS:\n",
      "====================================================================================================\n",
      "\n",
      "PROMPT: prompt_zero_shot\n",
      "all-MiniLM-L6-v2:\n",
      "      context_precision: 0.317\n",
      "      context_recall: 0.157\n",
      "      faithfulness: 0.566\n",
      "      answer_correctness: 0.223\n",
      "e5-large-instruct:\n",
      "      context_precision: 0.365\n",
      "      context_recall: 0.217\n",
      "      faithfulness: 0.626\n",
      "      answer_correctness: 0.350\n",
      "gte-multilingual-base:\n",
      "      context_precision: 0.390\n",
      "      context_recall: 0.129\n",
      "      faithfulness: 0.598\n",
      "      answer_correctness: 0.379\n",
      "\n",
      "PROMPT: prompt_one_shot\n",
      "all-MiniLM-L6-v2:\n",
      "      context_precision: 0.478\n",
      "      context_recall: 0.273\n",
      "      faithfulness: 0.754\n",
      "      answer_correctness: 0.218\n",
      "e5-large-instruct:\n",
      "      context_precision: 0.450\n",
      "      context_recall: 0.323\n",
      "      faithfulness: 0.733\n",
      "      answer_correctness: 0.353\n",
      "gte-multilingual-base:\n",
      "      context_precision: 0.479\n",
      "      context_recall: 0.105\n",
      "      faithfulness: 0.746\n",
      "      answer_correctness: 0.246\n",
      "\n",
      "PROMPT: prompt_few_shot\n",
      "all-MiniLM-L6-v2:\n",
      "      context_precision: 0.427\n",
      "      context_recall: 0.254\n",
      "      faithfulness: 0.763\n",
      "      answer_correctness: 0.322\n",
      "e5-large-instruct:\n",
      "      context_precision: 0.420\n",
      "      context_recall: 0.187\n",
      "      faithfulness: 0.745\n",
      "      answer_correctness: 0.472\n",
      "gte-multilingual-base:\n",
      "      context_precision: 0.248\n",
      "      context_recall: 0.300\n",
      "      faithfulness: 0.782\n",
      "      answer_correctness: 0.233\n"
     ]
    }
   ],
   "source": [
    "# Evaluar TODAS las combinaciones: 3 prompts × 3 embeddings = 9 combinaciones\n",
    "resultados_completos = {}\n",
    "\n",
    "prompts_list = ['prompt_zero_shot', 'prompt_one_shot', 'prompt_few_shot']\n",
    "\n",
    "for prompt_name in prompts_list:\n",
    "    print(f\"\\nEVALUANDO CON PROMPT: {prompt_name}\")\n",
    "    print(\"=\"*80)\n",
    "    # CAMBIAR EL TEMPLATE GLOBAL (esto es lo clave)\n",
    "    selected_template = PROMPTS[prompt_name]\n",
    "    prompt_template = ChatPromptTemplate.from_template(selected_template)\n",
    "\n",
    "    # Generar respuestas con este prompt específico\n",
    "    results_list_prompt = []\n",
    "\n",
    "    # Necesitas generar las respuestas con tu grafo de LangGraph primero\n",
    "    print(\"Generando respuestas con LangGraph...\")\n",
    "\n",
    "    for i, (question, ground_truth) in enumerate(zip(questions, ground_truths)):\n",
    "        print(f\"Procesando pregunta {i+1}/{len(questions)} con {prompt_name}\")\n",
    "\n",
    "        # Aquí usas tu grafo de LangGraph para generar la respuesta\n",
    "        state = {\n",
    "            'question': question,\n",
    "            'llm_name': 'Llama-3.2-3B-instruct',  # Tu LLM de generación\n",
    "            'embedding_name': 'all-MiniLM-L6-v2',  # Se cambiará en el bucle    \n",
    "            'prompt_name': prompt_name,\n",
    "            'context': [],\n",
    "            'answer': '',\n",
    "            'metadata': {}\n",
    "        }\n",
    "        try:\n",
    "            # INVOCAR TU GRAFO (ajusta según tu código)\n",
    "            final_state = graph.invoke(state)\n",
    "            answer = final_state.get('answer', '')\n",
    "            contexts = final_state.get('context', [])\n",
    "\n",
    "            if answer and answer.strip():  # Verificar que hay respuesta\n",
    "                  results_list_prompt.append({\n",
    "                      'question': question,\n",
    "                      'answer': answer,\n",
    "                      'contexts': [doc.page_content for doc in contexts] if contexts else ['Sin contexto'],\n",
    "                      'ground_truth': ground_truth\n",
    "                  })\n",
    "            else:\n",
    "                  print(f\"Pregunta {i+1} sin respuesta válida\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error en pregunta {i+1}: {e}\")\n",
    "\n",
    "    print(f\"Respuestas válidas generadas con {prompt_name}: {len(results_list_prompt)}\")\n",
    "\n",
    "      # Solo evaluar si tenemos respuestas válidas\n",
    "    if len(results_list_prompt) >= 2:\n",
    "          # EVALUAR CON LOS 3 EMBEDDINGS\n",
    "        resultados_por_embedding = {}\n",
    "\n",
    "        for embedding_name, current_embedding_model in EMBEDDING_MODELS.items():\n",
    "            print(f\"\\nEVALUANDO: {prompt_name} + {embedding_name}\")\n",
    "            print(\"-\"*60)\n",
    "\n",
    "            resultado = evaluate_with_mistral_four_metrics(\n",
    "                results_list=results_list_prompt,\n",
    "                  embedding_model=current_embedding_model,\n",
    "                  max_batch_size=2,\n",
    "                  delay_between_batches=120\n",
    "            )\n",
    "\n",
    "            resultados_por_embedding[embedding_name] = resultado\n",
    "\n",
    "              # Mostrar métricas promedio\n",
    "            print(f\"\\nCOMBINACIÓN: {prompt_name} + {embedding_name}\")\n",
    "            for metric in ['context_precision', 'context_recall', 'faithfulness', 'answer_correctness']:\n",
    "                if metric in resultado.columns:\n",
    "                    valores = resultado[metric].dropna()\n",
    "                    if len(valores) > 0:\n",
    "                        print(f\"   {metric}: {valores.mean():.3f}\")\n",
    "                    else:\n",
    "                        print(f\"   {metric}: Sin valores válidos\")\n",
    "\n",
    "            time.sleep(90)  # Pausa entre embeddings\n",
    "\n",
    "          # Guardar resultados de este prompt\n",
    "        resultados_completos[prompt_name] = resultados_por_embedding\n",
    "\n",
    "    else:\n",
    "        print(f\"No hay suficientes respuestas válidas para {prompt_name}, saltando evaluación\")\n",
    "\n",
    "    if prompt_name != prompts_list[-1]:\n",
    "        print(f\"\\nPAUSA ENTRE PROMPTS: 300 segundos...\")\n",
    "        time.sleep(300)\n",
    "\n",
    "print(\"\\\"EVALUACIÓN COMPLETA\")\n",
    "\n",
    "  # Mostrar tabla final\n",
    "print(\"\\nTABLA DE RESULTADOS:\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "for prompt_name, embeddings_results in resultados_completos.items():\n",
    "    print(f\"\\nPROMPT: {prompt_name}\")\n",
    "    for embedding_name, resultado in embeddings_results.items():\n",
    "        print(f\"{embedding_name}:\")\n",
    "        for metric in ['context_precision', 'context_recall', 'faithfulness', 'answer_correctness']:\n",
    "            if metric in resultado.columns:\n",
    "                valores = resultado[metric].dropna()\n",
    "                if len(valores) > 0:\n",
    "                    print(f\"      {metric}: {valores.mean():.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
