{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:98;} </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "import os\n",
    "import pprint\n",
    "import logging\n",
    "import time\n",
    "import json\n",
    "import itertools\n",
    "import pathlib\n",
    "import torch\n",
    "import pandas as pd\n",
    "import ragas\n",
    "from ragas import evaluate\n",
    "from dotenv import load_dotenv\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_weaviate import WeaviateVectorStore\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.documents import Document\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "from pydantic import BaseModel, Field, ValidationError\n",
    "from langchain_ollama import OllamaLLM\n",
    "import weaviate\n",
    "from langchain.embeddings.base import Embeddings\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "from sentence_transformers import CrossEncoder, SentenceTransformer\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any, Optional, TypedDict\n",
    "from datetime import datetime, timezone\n",
    "from langsmith import Client\n",
    "from langsmith.evaluation import evaluate as ls_evaluate, LangChainStringEvaluator\n",
    "from ragas.metrics import (\n",
    "    ContextRecall,\n",
    "    Faithfulness,\n",
    "    ContextPrecision,\n",
    "    ResponseRelevancy,\n",
    "    AnswerCorrectness,\n",
    "    AnswerSimilarity,\n",
    "    SemanticSimilarity\n",
    ")\n",
    "from datasets import Dataset\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "load_dotenv(override=True)\n",
    "\n",
    "from IPython.display import display, HTML, Image\n",
    "display(HTML(\"<style>.container { width:98;} </style>\"))\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# Para el aviso de Triton, pesos y otros transformers \n",
    "logging.getLogger(\"xformers\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith configurado: True\n",
      "Proyecto: RAG-IDEArq\n"
     ]
    }
   ],
   "source": [
    "WEAVIATE_URL = os.getenv('WEAVIATE_URL', 'http://localhost:8080')\n",
    "LANGSMITH_API_KEY = os.getenv('LANGSMITH_API_KEY')\n",
    "LANGSMITH_PROJECT = os.getenv('LANGSMITH_PROJECT', 'RAG-IDEArq')\n",
    "LANGSMITH_TRACING = os.getenv('LANGSMITH_TRACING', 'true')\n",
    "MISTRAL_API_KEY = os.getenv(\"MISTRAL_API_KEY\")\n",
    "# Configurar LangSmith\n",
    "if LANGSMITH_API_KEY:\n",
    "    os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "    os.environ[\"LANGCHAIN_API_KEY\"] = LANGSMITH_API_KEY\n",
    "    os.environ[\"LANGCHAIN_PROJECT\"] = LANGSMITH_PROJECT\n",
    "\n",
    "\n",
    "RESULTS_DIR = pathlib.Path('./results')\n",
    "RESULTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f'LangSmith configurado: {LANGSMITH_API_KEY is not None}')\n",
    "print(f'Proyecto: {LANGSMITH_PROJECT}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memoria GPU limpiada\n"
     ]
    }
   ],
   "source": [
    "# Limpiar memoria GPU si est√° disponible\n",
    "import gc\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    print(f'Memoria GPU limpiada')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuraci√≥n de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activamos los modelos LLM con Ollama:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ollama run hf.co/unsloth/Qwen3-4B-Instruct-2507-GGUF:Q8_0 \n",
    "# ollama run hf.co/MaziyarPanahi/Phi-3.5-mini-instruct-GGUF:Q6_K \n",
    "# ollama run hf.co/bartowski/Llama-3.2-3B-Instruct-GGUF:Q8_0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo para embeddings: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:530: DeprecationWarning: the load_module() method is deprecated and slated for removal in Python 3.15; use exec_module() instead\n",
      "Some weights of the model checkpoint at Alibaba-NLP/gte-multilingual-base were not used when initializing NewModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing NewModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing NewModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Usando dispositivo para embeddings: {device}')\n",
    "# embedding gte\n",
    "model_kwargs = {\n",
    "    'device': device,\n",
    "    'trust_remote_code': True\n",
    "}\n",
    "\n",
    "'''Wrapper personalizado para el modelo de embeddings E5 Instruct.\n",
    "   A√±ade prefijos espec√≠ficos (\"passage:\" para documentos, \"query:\" para consultas) \n",
    "   M√©todos:\n",
    "    - embed_documents(): Procesa listas de documentos\n",
    "    - embed_query(): Procesa una consulta individual\n",
    "'''\n",
    "\n",
    "class E5InstructEmbeddings(Embeddings):\n",
    "    def __init__(self, model_name=\"intfloat/multilingual-e5-large-instruct\", device=None):\n",
    "        \"\"\"Inicializa el modelo de embeddings E5 Instruct con prefijos espec√≠ficos para documentos y queries.\"\"\"\n",
    "        if device is None:\n",
    "            device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        \n",
    "        self.device = device\n",
    "        self.model = SentenceTransformer(model_name, device=device)\n",
    "    \n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        \"\"\"Para documentos - a√±adir prefix 'passage:'\"\"\"\n",
    "        prefixed_texts = [f\"passage: {text}\" for text in texts]\n",
    "        return self.model.encode(prefixed_texts, device=self.device).tolist()\n",
    "    \n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        \"\"\"Para queries - a√±adir prefix 'query:'\"\"\"\n",
    "        prefixed_text = f\"query: {text}\"\n",
    "        return self.model.encode([prefixed_text], device=self.device)[0].tolist()\n",
    "\n",
    "LLM = {\n",
    "    'Qwen3-4B-instruct-2507': OllamaLLM(model=\"hf.co/unsloth/Qwen3-4B-Instruct-2507-GGUF:Q8_0\", temperatura = 0.5),\n",
    "    'Llama-3.2-3B-instruct': OllamaLLM(model=\"hf.co/bartowski/Llama-3.2-3B-Instruct-GGUF:Q8_0\", temperatura = 0.5),\n",
    "    'Phi-3.5-mini-instruct': OllamaLLM(model=\"hf.co/MaziyarPanahi/Phi-3.5-mini-instruct-GGUF:Q6_K\", temperatura = 0.5)\n",
    "}\n",
    "\n",
    "EMBEDDING_MODELS = {\n",
    "    \"all-MiniLM-L6-v2\": HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "        model_kwargs={\"device\": device}),\n",
    "    \"e5-large-instruct\": E5InstructEmbeddings(\n",
    "        model_name=\"intfloat/multilingual-e5-large-instruct\",\n",
    "        device=device),\n",
    "    \"gte-multilingual-base\": HuggingFaceEmbeddings(\n",
    "        model_name=\"Alibaba-NLP/gte-multilingual-base\",\n",
    "        model_kwargs=model_kwargs)\n",
    "}\n",
    "\n",
    "# Cliente Weaviate\n",
    "client = weaviate.connect_to_local(\n",
    "    host=\"localhost\",\n",
    "    port=8080,\n",
    "    grpc_port=50051\n",
    ")\n",
    "\n",
    "# Mapear embeddings a las clases de Weaviate\n",
    "WEAVIATE_CLASSES = {\n",
    "    'all-MiniLM-L6-v2': 'IdearqAllMiniLM',\n",
    "    'e5-large-instruct': 'IdearqE5',\n",
    "    'gte-multilingual-base': 'IdearqGTE'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPTS = {\n",
    "'prompt_zero_shot': \"\"\"Eres un asistente experto en arqueolog√≠a, historia y datos geoespaciales. Responde la pregunta usando los contextos proporcionados, que pueden estar en espa√±ol, ingl√©s, franc√©s, catal√°n o portugu√©s.\n",
    "Sintetiza informaci√≥n de todos los contextos relevantes independientemente de su idioma. Si encuentras informaci√≥n relevante en cualquier idioma, √∫sala para construir tu respuesta en el mismo idioma en el que se realiza la pregunta.\n",
    "\n",
    "Contexto: {context}\n",
    "\n",
    "Pregunta: {question}\n",
    "\n",
    "Instrucciones:\n",
    "- Si encuentras informaci√≥n parcial en el contexto, int√©grala en la respuesta aunque no sea completa.\n",
    "- Si no hay absolutamente nada relevante, responde claramente: \"No hay informaci√≥n suficiente en el contexto\".\n",
    "- No inventes ni alucines informaci√≥n fuera del contexto.\n",
    "- Cuando sea posible, cita expl√≠citamente los puntos clave del contexto (ej. autores, a√±os, t√≠tulos de publicaciones, yacimientos, cronolog√≠as).\n",
    "- Responde siempre de forma clara, estructurada y √∫til para un investigador.\n",
    "\n",
    "Respuesta:\"\"\",\n",
    "\n",
    "    'prompt_one_shot': \"\"\"Eres un asistente experto en arqueolog√≠a, historia y datos geoespaciales. Responde la pregunta usando los contextos proporcionados, que pueden estar en espa√±ol, ingl√©s, franc√©s, catal√°n o portugu√©s.\n",
    "Sintetiza informaci√≥n de todos los contextos relevantes independientemente de su idioma. Si encuentras informaci√≥n relevante en cualquier idioma, √∫sala para construir tu respuesta en el mismo idioma en el que se realiza la pregunta.\n",
    "\n",
    "Contexto: {context}\n",
    "\n",
    "Pregunta: {question}\n",
    "\n",
    "Instrucciones:\n",
    "- Si encuentras informaci√≥n parcial en el contexto, int√©grala en la respuesta aunque no sea completa.\n",
    "- Si no hay absolutamente nada relevante, responde claramente: \"No hay informaci√≥n suficiente en el contexto\".\n",
    "- No inventes ni alucines informaci√≥n fuera del contexto.\n",
    "- Cuando sea posible, cita expl√≠citamente los puntos clave del contexto (ej. autores, a√±os, t√≠tulos de publicaciones, yacimientos, cronolog√≠as).\n",
    "- Responde siempre de forma clara, estructurada y √∫til para un investigador.\n",
    "\n",
    "Ejemplo:\n",
    "Q: ¬øCu√°l es la utilidad de los an√°lisis de is√≥topos de estroncio en Arqueolog√≠a?\n",
    "A: El tema del desplazamiento, la movilidad y la migraci√≥n ha sido altamente destacado como uno de los cinco grandes retos de la investigaci√≥n arqueol√≥gica contempor√°nea. El uso del an√°lisis de is√≥topos de estroncio es hoy en d√≠a uno de los m√©todos m√°s eficaces para afrontar este reto, ofreciendo un enfoque sistem√°tico, cuantitativo y comparable a la movilidad de las poblaciones humanas y animales del pasado (Larsen 2018).\n",
    "\n",
    "Respuesta:\"\"\",\n",
    "\n",
    "    'prompt_few_shot': \"\"\"Eres un asistente experto en arqueolog√≠a, historia y datos geoespaciales. Responde la pregunta usando los contextos proporcionados, que pueden estar en espa√±ol, ingl√©s, franc√©s, catal√°n o portugu√©s.\n",
    "Sintetiza informaci√≥n de todos los contextos relevantes independientemente de su idioma. Si encuentras informaci√≥n relevante en cualquier idioma, √∫sala para construir tu respuesta en el mismo idioma en el que se realiza la pregunta.\n",
    "Contexto: {context}\n",
    "\n",
    "Pregunta: {question}\n",
    "\n",
    "Instrucciones:\n",
    "- Si encuentras informaci√≥n parcial en el contexto, int√©grala en la respuesta aunque no sea completa.\n",
    "- Si no hay absolutamente nada relevante, responde claramente: \"No hay informaci√≥n suficiente en el contexto\".\n",
    "- No inventes ni alucines informaci√≥n fuera del contexto.\n",
    "- Cuando sea posible, cita expl√≠citamente los puntos clave del contexto (ej. autores, a√±os, t√≠tulos de publicaciones, yacimientos, cronolog√≠as).\n",
    "- Responde siempre de forma clara, estructurada y √∫til para un investigador.\n",
    "\n",
    "Ejemplos:\n",
    "Q: ¬øCu√°l es la utilidad de los an√°lisis de is√≥topos de estroncio en Arqueolog√≠a?\n",
    "A: El tema del desplazamiento, la movilidad y la migraci√≥n ha sido altamente destacado como uno de los cinco grandes retos de la investigaci√≥n arqueol√≥gica contempor√°nea. El uso del an√°lisis de is√≥topos de estroncio es hoy en d√≠a uno de los m√©todos m√°s eficaces para afrontar este reto, ofreciendo un enfoque sistem√°tico, cuantitativo y comparable a la movilidad de las poblaciones humanas y animales del pasado (Larsen 2018).\n",
    "\n",
    "Q: ¬øCu√°les son las caracter√≠sticas de la distribuci√≥n geogr√°fica de la muestra disponible de an√°lisis de is√≥topos de estroncio en la Pen√≠nsula Ib√©rica?\n",
    "A: La distribuci√≥n de la muestra es variable y discontinua, con concentraciones asociadas a focos de investigaci√≥n espec√≠ficos (p. ej., Lisboa, valle del Ebro). La cobertura es irregular tanto geogr√°fica como cronol√≥gicamente, lo que dificulta los estudios a escala ib√©rica para la mayor√≠a de los periodos, a excepci√≥n de la Edad del Cobre (764 muestras). La escasez de datos es cr√≠tica en algunas √©pocas, como el Mesol√≠tico, que cuenta con una √∫nica muestra. \n",
    "\n",
    "Respuesta:\"\"\"\n",
    "}\n",
    "\n",
    "selected_template = PROMPTS['prompt_few_shot']\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(selected_template)\n",
    "\n",
    "example_messages = prompt_template.invoke(\n",
    "    {\"context\": \"Contexto de ejemplo.\", \"question\": \"Pregunta de ejemplo.\"}\n",
    ").to_messages()\n",
    "\n",
    "# Results dir\n",
    "RESULTS_DIR = pathlib.Path('./results')\n",
    "RESULTS_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos el grafo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estado del grafo con TypedDict\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    llm_name: str\n",
    "    embedding_name: str\n",
    "    prompt_name: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "    metadata: Dict[str, Any]\n",
    "\n",
    "# Clase para almacenar resultados con todas las m√©tricas\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "@dataclass\n",
    "class RunResultComplete:\n",
    "    llm: str\n",
    "    embedding: str\n",
    "    prompt: str\n",
    "    question: str\n",
    "    answer: Optional[str]\n",
    "    contexts: List[str]\n",
    "    ground_truth: Optional[str]\n",
    "    docs: List[Dict[str, Any]]\n",
    "    latency: float\n",
    "    metadata: Dict[str, Any]\n",
    "    \n",
    "    # M√©tricas RAGAS con LLM\n",
    "    context_recall: Optional[float] = None\n",
    "    faithfulness: Optional[float] = None\n",
    "    context_precision: Optional[float] = None  \n",
    "    response_relevancy: Optional[float] = None\n",
    "    \n",
    "    # M√©tricas RAGAS sin LLM\n",
    "    answer_correctness: Optional[float] = None  \n",
    "    semantic_similarity: Optional[float] = None\n",
    "    exact_match: Optional[float] = None  \n",
    "    \n",
    "    # M√©tricas LangSmith con LLM\n",
    "    ls_correctness: Optional[float] = None\n",
    "    ls_helpfulness: Optional[float] = None\n",
    "    ls_relevance: Optional[float] = None\n",
    "    \n",
    "    # M√©tricas LangSmith sin LLM\n",
    "    ls_string_distance: Optional[float] = None\n",
    "    ls_regex_match: Optional[float] = None\n",
    "\n",
    "def retrieve(state: State):\n",
    "    # Obtener el modelo de embedding correspondiente\n",
    "    embedding_model = EMBEDDING_MODELS[state[\"embedding_name\"]]     \n",
    "    class_name = WEAVIATE_CLASSES[state[\"embedding_name\"]]   \n",
    "\n",
    "    vector_store = WeaviateVectorStore(\n",
    "        client=client,\n",
    "        index_name=class_name,\n",
    "        text_key=\"content\",\n",
    "        embedding=embedding_model,\n",
    "        attributes=[\"filename\", \"title\", \"source\", \"chunk_index\", \"doc_index\"]\n",
    "    )\n",
    "\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"], k = 10)\n",
    "    #print(f\"Recuperados {len(retrieved_docs)} docs para {state['embedding_name']}\")\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "def generate(state: State):\n",
    "    print(\"    -> Entrando en el nodo 'generate'...\")\n",
    "    try:\n",
    "        # 1. Preparamos el contexto y el prompt\n",
    "        docs_content = \"\\\\n\\\\n---\\\\n\\\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "        template = PROMPTS[state[\"prompt_name\"]]\n",
    "        prompt = ChatPromptTemplate.from_template(template)\n",
    "        \n",
    "        # 2. Seleccionamos el LLM\n",
    "        current_llm = LLM[state[\"llm_name\"]]\n",
    "        \n",
    "        # --- INICIO DE DEPURACI√ìN ---\n",
    "        print(f\"       - LLM a usar: {state['llm_name']}\")\n",
    "        print(f\"       - Prompt a usar: {state['prompt_name']}\")\n",
    "        # Imprimimos solo los primeros 300 caracteres del contexto para no llenar la pantalla\n",
    "        print(f\"       - Contexto para el prompt (primeros 300 chars):\\\\n'{docs_content[:300]}...'\")\n",
    "        # --- FIN DE DEPURACI√ìN ---\n",
    "\n",
    "        # 3. Invocamos el LLM\n",
    "        messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "        response = current_llm.invoke(messages)\n",
    "        \n",
    "        print(\"    -> El LLM ha devuelto una respuesta.\")\n",
    "        \n",
    "        latency = 0 \n",
    "        metadata = { \"latency\": latency }\n",
    "\n",
    "        return {\"answer\": response, \"metadata\": metadata}\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"    -> ERROR DENTRO DEL NODO 'generate': {e}\")\n",
    "        return {\"answer\": \"\", \"metadata\": {\"error\": str(e)}}\n",
    "\n",
    "def extract_sources_from_docs(docs: List[Document]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Extraer metadatos de fuentes de los documentos\"\"\"\n",
    "    sources = []\n",
    "    for doc in docs:\n",
    "        metadata = doc.metadata\n",
    "        source_info = {\n",
    "            'filename': metadata.get('filename', 'Unknown'),\n",
    "            'title': metadata.get('title', metadata.get('doc_title', 'Sin t√≠tulo')),\n",
    "            'page_content_preview': doc.page_content[:200] + \"...\"\n",
    "        }\n",
    "        sources.append(source_info)\n",
    "    return sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Crear el grafo \n",
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(\"retrieve\", retrieve)\n",
    "graph_builder.add_node(\"generate\", generate)\n",
    "\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph_builder.add_edge(\"retrieve\", \"generate\")\n",
    "\n",
    "graph = graph_builder.compile()\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurar la evaluaci√≥n con RAGAS y LangSmith"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from datasets import Dataset\n",
    "\n",
    "# Preguntas y ground truths\n",
    "questions = [\n",
    "    'What are the main theoretical models of Neolithic expansion in Europe?',\n",
    "    'Quais s√£o as datas mais antigas da extra√ß√£o de s√≠lex na pen√≠nsula central?',\n",
    "    '¬øCu√°les son las cronolog√≠as de las manifestaciones funerarias del Mesol√≠tico en las distintas regiones peninsulares?',\n",
    "    'Principales yacimientos de la Segunda Edad del Hierro en la provincia de Le√≥n.',\n",
    "    'Periodizaci√≥n del Bronce Final en el Levante de la Pen√≠nsula Ib√©rica, cronolog√≠a de las fases y principales ejemplos de yacimientos asignados a las mismas.',\n",
    "    'Yacimientos Calcol√≠ticos de la Pen√≠nsula Ib√©rica  en los que se han hallado objetos de marfil.',\n",
    "    'Cronolog√≠a y districubi√≥n espacial del poblamiento neol√≠tixco en la Meseta Sur.',\n",
    "    'Dataciones m√°s antiguas para el megalitismo en la zona Sureste de la Pen√≠nsula Ib√©rica.'\n",
    "    'Excavaciones de urgencia de la Junta de Andaluc√≠a en la provincia de Almer√≠a publicadas en 2001.',\n",
    "    '¬øEn qu√© a√±o excavaron en el yacimiento de La Bastida de Totana los hermanos Siret?'\n",
    "]\n",
    "ground_truths = [\n",
    "    \"\"\"These can be divided into two main positions: the first, known as demic diffusion, emphasises the movement of Neolithic societies and, by extension, agricultural practices; the second, referred to in the literature as cultural diffusion, focuses on the importance of the transmission of the Neolithic package‚Äîtechnology (e.g., pottery), plants, and domesticated animals‚Äîas a trigger for the expansion of the Neolithic.\"\"\",\n",
    "    \"\"\"A √∫nica mina de s√≠lex do Neol√≠tico no centro de Espanha √© a de Casamontero (Madrid). A s√©rie completa de datas de radiocarbono √© apresentada na Fig. 3 e a sua distribui√ß√£o espacial na Fig. 4 do artigo de D√≠az del R√≠o e Consuegra, 2015.\n",
    "        Infelizmente, a amostra de Sus sp. n√£o tinha colag√©nio suficiente para ser datada. O teste X2 mostra que todas as datas, com a √∫nica exce√ß√£o da Beta-232890, s√£o estatisticamente id√™nticas. Recentemente, foi enviada outra matriz de anel para data√ß√£o num fragmento de f√©mur de Ovis aries. O resultado, 6200+/ -40 BP (Beta-295152), √© estatisticamente igual a dez das onze datas anteriores.\n",
    "       Assumindo a hip√≥tese plaus√≠vel de que elas datam diferentes eventos de minera√ß√£o, h√° uma probabilidade de 65% de que todos os epis√≥dios de minera√ß√£o tenham ocorrido entre 5327-5215 cal BC (1œÉ), um per√≠odo de tempo de apenas cem anos. Portanto, estas datas de radiocarbono n√£o permitem observar a evolu√ß√£o esp√°cio-temporal da explora√ß√£o mineira, mas indicam que o principal epis√≥dio de atividade da Casa Montero durou pouco mais de um s√©culo, quatro gera√ß√µes. Esta interpreta√ß√£o n√£o √© apenas poss√≠vel, √© prov√°vel.\"\"\"\n",
    "    \"\"\"Modelo construido a partir de muestras individuales de radiocarbono de esqueletos mesol√≠ticos encontrados en los cementerios ib√©ricos. La diferencia m√°s significativa entre la regi√≥n mediterr√°nea y la regi√≥n cant√°brica y Portugal se observa en la aparici√≥n de cementerios durante el Mesol√≠tico temprano. Adem√°s, al evaluar los datos de las tres zonas de la Pen√≠nsula Ib√©rica, se pueden identificar los siguientes patrones cronol√≥gicos.\n",
    "        - En la regi√≥n mediterr√°nea, las fechas de El Collado muestran que los cementerios aparecieron alrededor de 9475-9300 cal BP. Este tipo de pr√°ctica funeraria continuar√° en otros yacimientos cercanos, como Casa Corona y Cingle del Mas Nou. A diferencia del cementerio de El Collado, que estuvo en uso durante unos 1100 a√±os, seg√∫n las fechas obtenidas, en Casa Corona y Cingle del Mas Nou, su periodo de uso es mucho m√°s breve (8007-7583 cal BP). Adem√°s, Cingle del Mas Nou se diferencia de otros yacimientos funerarios mesol√≠ticos de la Pen√≠nsula Ib√©rica en que los restos de siete individuos (completos e incompletos) fueron depositados en una √∫nica estructura.\n",
    "        - En la fachada atl√°ntica de Portugal, las primeras pruebas de cementerios en el estuario de Muge datan de 8409-8030 cal BP (en Cabe√ßo de Arruda, por ejemplo). Estos est√°n asociados a grandes concheros de m√°s de 5 m de espesor, utilizados durante un largo periodo de tiempo. En el estuario del Sado, las fechas son ligeramente m√°s recientes que en Muge, comenzando alrededor del 8200 cal BP (por ejemplo, en Amoreiras). Est√° claro que entre el 8160 y el 7970 cal BP, los grupos mesol√≠ticos enterraban sistem√°ticamente a todos o algunos de sus muertos en cementerios.\n",
    "        - Por √∫ltimo, las fechas de los yacimientos funerarios del norte de la Pen√≠nsula Ib√©rica (costa cant√°brica) con dos o m√°s individuos indican que los primeros enterramientos mesol√≠ticos agrupados fueron un poco m√°s recientes (entre 7981 y 6636 cal BP). En cualquier caso, cabe destacar que, a diferencia de las otras dos zonas, en la mayor√≠a de los yacimientos solo se ha documentado un √∫nico individuo o grupos mucho m√°s reducidos, como en Los Canes y La Bra√±a.\"\"\"\n",
    "    \"\"\"\n",
    "        - Castro de la Edad de Hierro de Valencia de Don Juan\n",
    "        - La Muela (al otro lado de la carretera de acceso a Valencia de Don Juan)\n",
    "        - Antigua ciudad astur-romana de Lancia: otro de los grandes de oppida de la Segunda Edad del Hierro\n",
    "        - Regueras de Arriba o San Mart√≠n de Torres.\n",
    "        - En la zona c√°ntabra, los castros laciniaegos de la Mesa en Rioscuro, que se delimita con una potente muralla de m√≥dulos, fechada seguramente en los siglos II y I a.C., y el castro de La Zamora, en sosas de Laciana.\n",
    "        - Tambi√©n en la zona c√°ntabra en el municipio de Puebla de Lillo se han podido reconocer ciertas piezas metal√≠ticas de la Segunda Edad del Hierro, recogidas en el antiguo castro de Castiltej√≥n. \n",
    "        - El castro de Chano en la comarca de Fornela.\n",
    "        - Pe√±a del Castro (La Ercina), ubicado a 2 km de la localidad de la Ercina \n",
    "        - El Castrel√≠n de San Juan dse Paluezas\n",
    "        - La Corona del Castro en Borrenes\n",
    "        - La Pe√±a del Hombre en el ayuntamiento de Priaranza\n",
    "        - Castro de Columbrianos\n",
    "        - Pe√±a Pi√±era, en la Vega de Espinareda\n",
    "        - Por √∫ltimo, se ha se√±alado un conjunto de castros en altitudes considerables en las sierras del Teleno, la Valder√≠a y el Bierzo, algunos ya conocidos en la bibliograf√≠a y en la Carta Arqueol√≥gica de Le√≥n, con grandes amurallamientos, que se extienden entre afloramientos rocosos de materiales de la era Primaria; yacimientos como Portillo de Xandequ√≠n en Pozos, Pe√±a Rayada en Cunas, Alto de San Vicente-Los Conventos en Morla de la Valder√≠a, Yera de los Piornos-Pe√±a del Tren en Torneros de la Valder√≠a, Sierra del Pueblo en Torneros de la Valder√≠a, El Pajar√≠n-La Formosida en Bois√°n (Lucillo) y los bercianos localizados en Folgoso de la Ribera, Torre del Bierzo y Molinaseca. \"\"\"\n",
    "    \"\"\"Bronce tard√≠o o reciente (c. 1550/1500-1300/1250 cal BC):\n",
    "        - Oropesa la Vella\n",
    "        - Torrel√≥ d‚ÄôOnda\n",
    "        - Les Raboses\n",
    "        - Altet de Palau\n",
    "        - Cap Prim\n",
    "        - Mas del Corral\n",
    "        - Cabezo Redondo\n",
    "        - Pe√±a de Sax\n",
    "        - El Negret\n",
    "        - Illeta del Banyets\n",
    "        - Tabay√°\n",
    "\n",
    "    Bronce final I (c. 1300/1250-1000 cal BC):\n",
    "        - Costamar\n",
    "        - Oropesa la Vella\n",
    "        - El Castellet\n",
    "        - Torrell√≥ de Boverot\n",
    "        - Pic dels Corbs III y IV\n",
    "        - Cova d‚Äôen Pardo\n",
    "        - Cova de la Pastora\n",
    "        - Cap Prim\n",
    "        - Pe√±a de Sax\n",
    "        - El Negret\n",
    "        - Tabay√°\n",
    "        - Botx-Grupitex\n",
    "\n",
    "    Bronce final II (1000-850 cal BC):\n",
    "        - Ereta del Castellar\n",
    "        - El Castellet\n",
    "        - Torrell√≥ de Boverot\n",
    "        - Pic dels Corbs V\n",
    "        - Solana del Castell I\n",
    "        - Mola d‚ÄôAgres\n",
    "        - Tabay√°\n",
    "        - Caramoro\n",
    "        - Botx\n",
    "\n",
    "    Bronce final III (850-725 cal BC):\n",
    "        -Ereta del Castellar\n",
    "        - El Castellet\n",
    "        -Torrell√≥ de Boverot\n",
    "        -Vinarragell\n",
    "        - La Vital\n",
    "        -Solana del Castell II\n",
    "        -Mola d‚ÄôAgres\n",
    "        -Cova de la Sarsa\n",
    "        -Tabay√°\n",
    "        -Pe√±a Negra I\n",
    "        - Barranc del Botx\n",
    "        -Saladares Ia1/IA2\n",
    "\n",
    "    Hierro antiguo o fase Orientalizante (725-550 cal BC):\n",
    "        - Vinarragell\n",
    "        - El Mol√≥n\n",
    "        - Los Villares\n",
    "        - Solana del Castell III\n",
    "        - El Castellar\n",
    "        - El Puig\n",
    "        - Camara\n",
    "        - Tabay√°\n",
    "        - Pe√±a Negra II\n",
    "        - Casa Sec√†\n",
    "        - Saladares IA3\n",
    "\"\"\",\n",
    "\"\"\"Calcol√≠tico antiguo (pre-campaniforme [bell beaker]):\n",
    "        - Zambujal\n",
    "        - Vila Nova de S√£o Pedro\n",
    "        - Leceiaa\n",
    "        - Praia das Ma√ß√£s\n",
    "        - Palmela\n",
    "        - Alcalar\n",
    "        - Perdig√µes \n",
    "        - Se√±or√≠o de Guzm√°n\n",
    "        - La Pijotilla\n",
    "        - Valencina de la Concepci√≥n\n",
    "        - Gilena\n",
    "        - Los Millares\n",
    "\n",
    "Calcol√≠tico reciente (campaniforme [bell beaker]):\n",
    "        - Palmela\n",
    "        - Pedra do Ouro\n",
    "        - Verdelha dos Ruivos\n",
    "        - Vila Nova de S√£o Pedro\n",
    "        - Perdig√µes\n",
    "        - Valencina de la Concepci√≥n\n",
    "        - Los Algarbes\n",
    "        - Cerro de la Virgen\n",
    "        - Camino de Yeseras\n",
    "        - La Pijotilla\n",
    "\"\"\",\n",
    "\"\"\"Lo dividimos en dos √°reas: poblamiento neol√≠tico en el valle medio y alto del Tajo y poblamiento neol√≠tico de La Mancha.\n",
    "- Valle del Tajo: En la zona de la Sierra madrile√±a se localizan las cuevas la Cueva de La Ventana o la Cueva de la Higuera. Ambas son especialmente importantes para comprender los asentamientos en cueva, ya que disponen de dataciones radiocarb√≥nicas asociadas a contextos de habitaci√≥n. Ya en la provincia de Guadalajara destacan los yacimientos de la Cueva de la Hoz, Abrigo de Tordelrr√°bano  la Cueva de Jarama II, los enclaves de Sorbe II (Humanes de Mohernando), II y VII, la Cueva del Paso, el Abrigo de los Enebrales, Cueva del Reno y la Cueva del Destete.  Sin embargo, son los yacimientos de hoyos los que constituyen el principal modelo de asentamiento. Las excavaciones arqueol√≥gicas en extensi√≥n realizadas en los √∫ltimos a√±os han puesto de manifiesto el predominio del h√°bitat en asentamientos al aire libre durante este periodo. Tan s√≥lo se han documentado 8 enclaves neol√≠ticos serranos de un total de 24 yacimientos cartografiados en la regi√≥n. Los 16 yacimientos restantes se ubican en zonas bajas de los valles. A estas cifras hay que sumar tres nuevos yacimientos neol√≠ticos: Soto del Henares, La Serna y Prado de Gal√°pagos, recientemente publicados por C. Blasco et al.\n",
    "(2016) que ampl√≠an el listado de asentamientos de hoyos ubicados en los fondos de\n",
    "valle.\n",
    "La concentraci√≥n de yacimientos neol√≠ticos es especialmente interesante en la zona sureste de la Comunidad de Madrid, en los tramos finales de los r√≠os Henares, Jarama y Manzanares. La densidad de yacimientos de hoyos neol√≠ticos en las zonas bajas de estos cursos fluviales ha aportado desde hace a√±os datos muy interesantes para conocer los patrones de asentamiento y los modelos de\n",
    "ocupaci√≥n territorial de las primeras comunidades neol√≠ticas. \n",
    "- Poblamiento neol√≠tico de La Mancha: El modelo de asentamiento neol√≠tico mejor conocido en La Mancha son las ocupaciones en cuevas y abrigos. En este sentido, los yacimientos neol√≠ticos manchegos mejor conocidos son la Cueva del Ni√±o y el Abrigo de Molino de Vadico, en Albacete, y el Abrigo de Verdelpino, en Cuenca, a los que ya nos referimos en el cap√≠tulo anterior. En estos yacimientos se han documentado, adem√°s, ocupaciones previas, por lo que se son especialmente interesantes para estudiar el momento de adopci√≥n de los modos de vida neol√≠ticos. \n",
    "En los √∫ltimos a√±os se han realizado varias intervenciones arqueol√≥gicas en el contexto de las obras de construcci√≥n de grandes infraestructuras. Desde el punto de vista arqueol√≥gico, este tipo de intervenciones implican la prospecci√≥n y, en su caso, excavaci√≥n en zonas aleatorias afectadas por los proyectos constructivos, por lo que no se introducen sesgos relacionados con intereses cient√≠ficos concretos. Por lo tanto, los hallazgos suponen una buena aproximaci√≥n de la existencia o ausencia de distintos tipos de registro arqueol√≥gico. En este sentido, las obras de acceso al aeropuerto de Ciudad Real o los trabajos de la autopista que conecta Oca√±a (Toledo) con La Roda (Ciudad Real), no aportaron hallazgos de asentamientos neol√≠ticos. \n",
    "Si bien es cierto que las investigaciones sobre esta etapa de la Prehistoria en La Mancha han sido escasas y son pocos los equipos de investigaci√≥n que han desarrollado l√≠neas de investigaci√≥n orientadas al conocimiento de las primeras sociedades productoras en esa regi√≥n, no es menos cierto que las intervenciones arqueol√≥gicas llevadas a cabo en el contexto de obras de infraestructura en Castilla-La Mancha apoyan la idea de un poblamiento neol√≠tico caracterizado por su escasa densidad, especialmente si se compara con otras regiones como en valle medio y alto del Tajo.\n",
    "\"\"\",\n",
    "\"\"\"Son el solar situado en la avenida Pablo Iglesias esquina A Rafaeka Jim√©nez, solar situado en la calle La central de Villaricos (cuevas de Almanzora) y en la calle Castillejo (Gador, Almer√≠a).\"\"\",\n",
    "\"\"\"En el a√±o 1886.\"\"\"\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EVALUACI√ìN CON API MISTRAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mistral configurado para RAGAS\n"
     ]
    }
   ],
   "source": [
    "from langchain_mistralai import ChatMistralAI\n",
    "from ragas.metrics import context_precision, context_recall, faithfulness, answer_correctness\n",
    "import time\n",
    "from datasets import Dataset\n",
    "from ragas import evaluate \n",
    "import pandas as pd\n",
    "  # Configurar Mistral\n",
    "mistral_evaluator = ChatMistralAI(\n",
    "    api_key=MISTRAL_API_KEY,\n",
    "    model=\"mistral-small-latest\",\n",
    "    temperature=0.1,\n",
    "    max_retries=3,\n",
    "    timeout= 180 # Timeout para las requests HTTP\n",
    "    \n",
    ")\n",
    "\n",
    "# Prompts espec√≠ficos para m√©tricas\n",
    "context_precision.context_precision_prompt.instruction = \"\"\"\n",
    "Dada una pregunta sobre arqueolog√≠a y un conjunto de contextos que pueden estar en varios idiomas (espa√±ol, ingl√©s, franc√©s, catal√°n, portugu√©s), identifica qu√© contextos son √∫tiles para responder la pregunta.\n",
    "Los contextos pueden contener informaci√≥n t√©cnica, fechas, yacimientos arqueol√≥gicos, cronolog√≠as, dataciones, etc. Un contexto es √∫til si contiene informaci√≥n relevante que ayude a responder la pregunta, aunque sea parcialmente, independientemente      \n",
    "del idioma en que est√© escrito.     \n",
    "\n",
    "Pregunta: {question}\n",
    "Contextos: {contexts}\n",
    "\n",
    "Responde SOLO con un JSON v√°lido en este formato exacto:\n",
    "{\"useful_contexts\": [0, 1, 2]}\n",
    "donde los n√∫meros son los √≠ndices de contextos √∫tiles.\n",
    "\"\"\"\n",
    "\n",
    "context_recall.context_recall_prompt.instruction = \"\"\"\n",
    "Dada una pregunta sobre arqueolog√≠a y un conjunto de contextos que pueden estar en varios idiomas (espa√±ol, ingl√©s, franc√©s, catal√°n, portugu√©s), eval√∫a si el contexto contiene toda la informaci√≥n necesaria para responder la pregunta.\n",
    "Los contextos pueden contener informaci√≥n t√©cnica, fechas, yacimientos arqueol√≥gicos, cronolog√≠as, dataciones, etc. Un contexto es √∫til si contiene informaci√≥n relevante que ayude a responder la pregunta, aunque sea parcialmente, independientemente      \n",
    "del idioma en que est√© escrito.\n",
    "Responde SOLO con un JSON v√°lido en este formato exacto:\n",
    "{\"correctness\": 0.8}\n",
    "donde el valor est√° entre 0.0 y 1.0\n",
    "\"\"\"  \n",
    "print(\"Mistral configurado para RAGAS\")\n",
    "\n",
    "# Funci√≥n de evaluaci√≥n con Mistral y las 4 m√©tricas\n",
    "\n",
    "def evaluate_with_mistral_four_metrics(results_list, embedding_model, max_batch_size=2, delay_between_batches=90):\n",
    "    \"\"\"\n",
    "    Evaluaci√≥n RAGAS con Mistral API usando las 4 m√©tricas principales\n",
    "    \"\"\"\n",
    "    print(f\"Evaluando {len(results_list)} preguntas con 4 m√©tricas en batches de {max_batch_size}\")\n",
    "\n",
    "    all_batch_results = []\n",
    "    total_batches = (len(results_list) + max_batch_size - 1) // max_batch_size\n",
    "\n",
    "    for batch_idx in range(0, len(results_list), max_batch_size):\n",
    "        batch_num = batch_idx // max_batch_size + 1\n",
    "        batch = results_list[batch_idx:batch_idx + max_batch_size]\n",
    "\n",
    "        print(f\"   üîÑ Procesando batch {batch_num}/{total_batches} ({len(batch)} preguntas)\")\n",
    "\n",
    "        # Crear dataset del batch\n",
    "        batch_dataset = Dataset.from_list(batch)\n",
    "\n",
    "        # Intentar evaluaci√≥n con reintentos\n",
    "        batch_success = False\n",
    "        for attempt in range(3):\n",
    "            try:\n",
    "                print(f\"      Intento {attempt + 1}/3 para batch {batch_num}\")\n",
    "\n",
    "                # Evaluar cada m√©trica por separado para mayor estabilidad\n",
    "                batch_metrics = {}\n",
    "\n",
    "                metrics_to_evaluate = [\n",
    "                    ('context_precision', context_precision),\n",
    "                    ('context_recall', context_recall),\n",
    "                    ('faithfulness', faithfulness),\n",
    "                    ('answer_correctness', answer_correctness)\n",
    "                ]\n",
    "\n",
    "                for metric_name, metric_obj in metrics_to_evaluate:\n",
    "                    try:\n",
    "                        print(f\"         Evaluando {metric_name}...\")\n",
    "\n",
    "                        metric_result = evaluate(\n",
    "                            batch_dataset,\n",
    "                            llm=mistral_evaluator,\n",
    "                            embeddings=embedding_model,\n",
    "                            metrics=[metric_obj],\n",
    "                            raise_exceptions=False\n",
    "                        )\n",
    "\n",
    "                        metric_df = metric_result.to_pandas()\n",
    "\n",
    "                        if metric_name in metric_df.columns:\n",
    "                            batch_metrics[metric_name] = metric_df[metric_name]\n",
    "                            print(f\"{metric_name} completado\")\n",
    "                        else:\n",
    "                            batch_metrics[metric_name] = None\n",
    "                            print(f\"{metric_name} no encontrado en resultados\")\n",
    "\n",
    "                        # Pausa entre m√©tricas para evitar rate limits\n",
    "                        time.sleep(25)\n",
    "\n",
    "                    except Exception as metric_error:\n",
    "                        print(f\"{metric_name} fall√≥: {metric_error}\")\n",
    "                        batch_metrics[metric_name] = None\n",
    "                        time.sleep(30)  # Pausa m√°s larga si hay error\n",
    "\n",
    "                # Crear DataFrame combinado del batch\n",
    "                batch_result_df = pd.DataFrame({\n",
    "                    'question': [item['question'] for item in batch],\n",
    "                    'answer': [item['answer'] for item in batch],\n",
    "                    'contexts': [item['contexts'] for item in batch],\n",
    "                    'ground_truth': [item['ground_truth'] for item in batch],\n",
    "                    'context_precision': batch_metrics.get('context_precision'),\n",
    "                    'context_recall': batch_metrics.get('context_recall'),\n",
    "                    'faithfulness': batch_metrics.get('faithfulness'),\n",
    "                    'answer_correctness': batch_metrics.get('answer_correctness')\n",
    "                })\n",
    "\n",
    "                all_batch_results.append(batch_result_df)\n",
    "                batch_success = True\n",
    "                print(f\"Batch {batch_num} completado con 4 m√©tricas\")\n",
    "                break\n",
    "\n",
    "            except Exception as batch_error:\n",
    "                print(f\"Batch {batch_num}, intento {attempt + 1} fall√≥: {batch_error}\")\n",
    "                if attempt < 2:\n",
    "                    wait_time = 120 * (attempt + 1)  # Espera m√°s larga para 4 m√©tricas\n",
    "                    print(f\"         Esperando {wait_time}s antes del siguiente intento...\")\n",
    "                    time.sleep(wait_time)\n",
    "\n",
    "        if not batch_success:\n",
    "            print(f\"Batch {batch_num} fall√≥ despu√©s de 3 intentos, creando resultados vac√≠os\")\n",
    "            # Crear DataFrame vac√≠o para este batch\n",
    "            empty_batch_df = pd.DataFrame({\n",
    "                'question': [item['question'] for item in batch],\n",
    "                'answer': [item['answer'] for item in batch],\n",
    "                'contexts': [item['contexts'] for item in batch],\n",
    "                'ground_truth': [item['ground_truth'] for item in batch],\n",
    "                'context_precision': [None] * len(batch),\n",
    "                'context_recall': [None] * len(batch),\n",
    "                'faithfulness': [None] * len(batch),\n",
    "                'answer_correctness': [None] * len(batch)\n",
    "            })\n",
    "            all_batch_results.append(empty_batch_df)\n",
    "\n",
    "        # Rate limiting: pausa entre batches (m√°s larga para 4 m√©tricas)\n",
    "        if batch_num < total_batches:\n",
    "            print(f\"Esperando {delay_between_batches}s antes del siguiente batch...\")\n",
    "            time.sleep(delay_between_batches)\n",
    "\n",
    "    # Combinar todos los resultados\n",
    "    if all_batch_results:\n",
    "        combined_results = pd.concat(all_batch_results, ignore_index=True)\n",
    "        print(f\"Evaluaci√≥n completada: {len(combined_results)} preguntas con 4 m√©tricas\")\n",
    "        return combined_results\n",
    "    else:\n",
    "        print(f\"No se pudieron procesar resultados\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUANDO CON PROMPT: prompt_zero_shot\n",
      "================================================================================\n",
      "Generando respuestas con LangGraph...\n",
      "Procesando pregunta 1/9 con prompt_zero_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Published by Elsevier Inc. All rights reserved. doi:10.1016/j.yqres.2011.12.003 Contents lists available at SciVerse ScienceDirect Quaternary Research journal homepage: www.elsevier.com/locate/yqres https://doi.org/10.1016/j.yqres.2011.12.003 Published online by Cambridge University Press Introduc...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 2/9 con prompt_zero_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. A data obtida, √© claramente mais recuada que os con¬≠ textos mais antigos reportados em territ√≥rio hoje portu¬≠ gu√™s, nomeadamente Gruta da Nascente do Rio Almonda (OxA¬≠‚Äë9287 ‚Äì 5480¬≠‚Äë5320 cal BC a 2 sigmas) e da Gruta do Caldeir√£o (OxA¬≠‚Äë1036 ‚Äì 5480 ‚Äì 5070 cal BC a 2 sigmas). Entre n√≥s, apenas se rep...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 3/9 con prompt_zero_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 2. ENCUADRE CRONO-CULTURAL DEL HA- LLAZGO: COGOTAS I Entre las entidades arqueol√≥gicas de la Edad del Bronce peninsular, Cogotas I sobresale por su extensa cobertura geogr√°fica, que desborda la Meseta por el Valle del Ebro y Extremadura, y por su dilatada crono- log√≠a ‚Äîc. 1800-1150 cal BC, cubrien...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 4/9 con prompt_zero_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. y NEIRA, A. (1999): ‚ÄúPrehistoria‚Äù, en M.A. Rabanal Alonso (coord.): La His¬≠ toria de Le√≥n, tomo I, Universidad de Le√≥n y Diario de Le√≥n. CELIS S√ÅNCHEZ, J. (1993a): ‚ÄúLa secuencia del poblado de la Primera Edad del Hierro de los ¬´Cuestos de la Estaci√≥n¬ª, Benavente, Zamora‚Äù, en F. Romero, C. Sanz y Z...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 5/9 con prompt_zero_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Con el desarrollo de las excavaciones arqueol√≥gicas en diversos asentamientos, el aumento del n√∫mero de dataciones y la realizaci√≥n de diversos estudios en los √∫ltimos a√±os, las perspectivas de investigaci√≥n sobre el Bronce final en el Levante comienza a variar sustancialmente, estando ya en condi...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 6/9 con prompt_zero_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. En la actualidad, El Argar sigue siendo el grupo arqueo¬≠ l√≥gico de la Edad del Bronce mejor conocido de la pen√≠nsula ib√©rica, con un desarrollo temporal entre el 2200 y el 1550 cal BC. Tambi√©n se puede afirmar que fue una de las sociedades con mayor capacidad productiva y desarrollo social de la E...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Respuestas v√°lidas generadas con prompt_zero_shot: 6\n",
      "\n",
      "EVALUANDO: prompt_zero_shot + all-MiniLM-L6-v2\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 m√©tricas en batches de 2\n",
      "   üîÑ Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\_analytics.py:77: ResourceWarning: unclosed file <_io.TextIOWrapper name='C:\\\\Users\\\\elevi\\\\AppData\\\\Local\\\\ragas\\\\ragas\\\\uuid.json' mode='r' encoding='cp1252'>\n",
      "  user_id = json.load(open(uuid_filepath))[\"userid\"]\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79e230356c8e423e8471e4b3280d93d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01850125092c47688b0de6ab08c911e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d78f4e158354411e86829dcfa53b4af7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f26b5c6063746c79f6126997101bd89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 m√©tricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   üîÑ Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37f2e29ddcee4555afed371b1100a118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5b9887c59ef4dccb43d09bff27a57db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24ff93de7c0d4ae3aeef7a23a2664660",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ff2126fbad14b8cb81e99dbc3f6f401",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 m√©tricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   üîÑ Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8f2fdad20cc48fcb903161090323269",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "317142ce49c44644a3715c0497b310c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aa20fb2e4644eb98a0c6e6ac4e2778f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82d9bd96119f47b38008abd51eac8df6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 m√©tricas\n",
      "Evaluaci√≥n completada: 6 preguntas con 4 m√©tricas\n",
      "\n",
      "COMBINACI√ìN: prompt_zero_shot + all-MiniLM-L6-v2\n",
      "   context_precision: 0.475\n",
      "   context_recall: 0.106\n",
      "   faithfulness: 0.903\n",
      "   answer_correctness: 0.275\n",
      "\n",
      "EVALUANDO: prompt_zero_shot + e5-large-instruct\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 m√©tricas en batches de 2\n",
      "   üîÑ Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9acd151e0ed4d539efeb493342a4ece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fdaf6b6f46a4c3ca6071fa12b7a566d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "867c3c050cff4d6aa1373000ee09d057",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86237c04fe9f49bba26bfa1a7526c57e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 m√©tricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   üîÑ Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1c1cff51cb442fabe42623c8efd8f24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f9401722e3f47a1a69728f2f98e595a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f5f0681703e4041b21f499c8f1ddbf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eb0653bca4a46d999cdb433e2f52555",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 m√©tricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   üîÑ Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdeb4e72cbcf4ae8b4465953f6b7bd8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "464fbdc0a8604605acdb17aaf2442c24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e884d2aab6dc4ea28f9a9320987854b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9266d7b0cca94b0585ecb6f380d97e16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 m√©tricas\n",
      "Evaluaci√≥n completada: 6 preguntas con 4 m√©tricas\n",
      "\n",
      "COMBINACI√ìN: prompt_zero_shot + e5-large-instruct\n",
      "   context_precision: 0.387\n",
      "   context_recall: 0.087\n",
      "   faithfulness: 0.880\n",
      "   answer_correctness: 0.242\n",
      "\n",
      "EVALUANDO: prompt_zero_shot + gte-multilingual-base\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 m√©tricas en batches de 2\n",
      "   üîÑ Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3884547c0f14504ac9f044de0fd51fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a38d8cabf60a4ee48c4df9351263e18d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02232aead2ff4a678f284f6660964281",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32c420ee7dfb42a4b73845da561e0153",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 m√©tricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   üîÑ Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bbfb08cc8cb404385bf1aeef4e53750",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcf74b591187428fa07d7575b4378fe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87677fc0271143dfb956330b33fc8eba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e00228382b694ba69fb6c0f89bccab69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 m√©tricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   üîÑ Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00568aee39ca4bc7babb4bb67e8a23fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c28f87197c454df8965e08dc3cd3ad15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3370c59e5d4f44c881246fb9786b4c5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebe5c8ffe6674093b3e1031b8c0d3d57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 m√©tricas\n",
      "Evaluaci√≥n completada: 6 preguntas con 4 m√©tricas\n",
      "\n",
      "COMBINACI√ìN: prompt_zero_shot + gte-multilingual-base\n",
      "   context_precision: 0.417\n",
      "   context_recall: 0.304\n",
      "   faithfulness: 0.844\n",
      "   answer_correctness: 0.162\n",
      "\n",
      "PAUSA ENTRE PROMPTS: 300 segundos...\n",
      "\n",
      "EVALUANDO CON PROMPT: prompt_one_shot\n",
      "================================================================================\n",
      "Generando respuestas con LangGraph...\n",
      "Procesando pregunta 1/9 con prompt_one_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Published by Elsevier Inc. All rights reserved. doi:10.1016/j.yqres.2011.12.003 Contents lists available at SciVerse ScienceDirect Quaternary Research journal homepage: www.elsevier.com/locate/yqres https://doi.org/10.1016/j.yqres.2011.12.003 Published online by Cambridge University Press Introduc...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 2/9 con prompt_one_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. A data obtida, √© claramente mais recuada que os con¬≠ textos mais antigos reportados em territ√≥rio hoje portu¬≠ gu√™s, nomeadamente Gruta da Nascente do Rio Almonda (OxA¬≠‚Äë9287 ‚Äì 5480¬≠‚Äë5320 cal BC a 2 sigmas) e da Gruta do Caldeir√£o (OxA¬≠‚Äë1036 ‚Äì 5480 ‚Äì 5070 cal BC a 2 sigmas). Entre n√≥s, apenas se rep...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 3/9 con prompt_one_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 2. ENCUADRE CRONO-CULTURAL DEL HA- LLAZGO: COGOTAS I Entre las entidades arqueol√≥gicas de la Edad del Bronce peninsular, Cogotas I sobresale por su extensa cobertura geogr√°fica, que desborda la Meseta por el Valle del Ebro y Extremadura, y por su dilatada crono- log√≠a ‚Äîc. 1800-1150 cal BC, cubrien...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 4/9 con prompt_one_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. y NEIRA, A. (1999): ‚ÄúPrehistoria‚Äù, en M.A. Rabanal Alonso (coord.): La His¬≠ toria de Le√≥n, tomo I, Universidad de Le√≥n y Diario de Le√≥n. CELIS S√ÅNCHEZ, J. (1993a): ‚ÄúLa secuencia del poblado de la Primera Edad del Hierro de los ¬´Cuestos de la Estaci√≥n¬ª, Benavente, Zamora‚Äù, en F. Romero, C. Sanz y Z...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 5/9 con prompt_one_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Con el desarrollo de las excavaciones arqueol√≥gicas en diversos asentamientos, el aumento del n√∫mero de dataciones y la realizaci√≥n de diversos estudios en los √∫ltimos a√±os, las perspectivas de investigaci√≥n sobre el Bronce final en el Levante comienza a variar sustancialmente, estando ya en condi...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 6/9 con prompt_one_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. En la actualidad, El Argar sigue siendo el grupo arqueo¬≠ l√≥gico de la Edad del Bronce mejor conocido de la pen√≠nsula ib√©rica, con un desarrollo temporal entre el 2200 y el 1550 cal BC. Tambi√©n se puede afirmar que fue una de las sociedades con mayor capacidad productiva y desarrollo social de la E...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Respuestas v√°lidas generadas con prompt_one_shot: 6\n",
      "\n",
      "EVALUANDO: prompt_one_shot + all-MiniLM-L6-v2\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 m√©tricas en batches de 2\n",
      "   üîÑ Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71992f71c9b044ffab4df3760c183100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f12d1c3f8e82496293555c392116d6d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8263769784624f9193d79aba3cd7982a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60dfc596de034e849a4b665985f1c38f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 m√©tricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   üîÑ Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94ad3204a4e747bfa8f31f2c416df482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2287ca019d9d4d5080dd83841e1ecb9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fec9f95d4ade4791b8fc3a020e509bbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df1ab209f343403db2464ad3dc5c3e56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 m√©tricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   üîÑ Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "834659f97df04370bc257c35f15dc43f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef844210687946a5bf5e0acf73e83a2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c01455d7fa54af9b78c662b96bad715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f737aa3bcfc477ba07b57c482b14254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 m√©tricas\n",
      "Evaluaci√≥n completada: 6 preguntas con 4 m√©tricas\n",
      "\n",
      "COMBINACI√ìN: prompt_one_shot + all-MiniLM-L6-v2\n",
      "   context_precision: 0.395\n",
      "   context_recall: 0.143\n",
      "   faithfulness: 0.763\n",
      "   answer_correctness: 0.187\n",
      "\n",
      "EVALUANDO: prompt_one_shot + e5-large-instruct\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 m√©tricas en batches de 2\n",
      "   üîÑ Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0ca9aade77c493bb2585cf39105cf85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "605340e1b436486185d6603498eb509d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60b7f5f37ee64c4294bfc3f9ec6a7c67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "810198abe90048d4a12f517c7c281995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 m√©tricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   üîÑ Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b46c598be22f4fadb9bcef688088beb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f42dc0b2fe8a4748b3ad994601f5f574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7465ed0e86784b62b26b8f88aa25a25a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "773c8d5eb75242b4ba952a6c0e432090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 m√©tricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   üîÑ Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b49b58f60d0f4c4da92b5d84ea8b989c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "617cd9e9d74c4576bcf046748ea4f174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7441a46e71054b4d9657ce7ac01782e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a6ec2ab4a3d4cefa96b6e65aa9da0cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 m√©tricas\n",
      "Evaluaci√≥n completada: 6 preguntas con 4 m√©tricas\n",
      "\n",
      "COMBINACI√ìN: prompt_one_shot + e5-large-instruct\n",
      "   context_precision: 0.340\n",
      "   context_recall: 0.342\n",
      "   faithfulness: 0.742\n",
      "   answer_correctness: 0.287\n",
      "\n",
      "EVALUANDO: prompt_one_shot + gte-multilingual-base\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 m√©tricas en batches de 2\n",
      "   üîÑ Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eb2ee11b8e548c9a546f2a262c5c793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "244c47285ac74dc2b2a3ec08005ae2ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9cab6782e2f44e9a0cc741dffbf4f8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fbb1345f43c48ec9146d5aca6efdc68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 m√©tricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   üîÑ Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdc7dd2e2c12415cb9991d05ef6ae295",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9e48e00b6394dc39d84797075bd8df2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6665bb639354445a30e38ed1a384f50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "796b2a0b47d740ddb5ee9d581a5c1d68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 m√©tricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   üîÑ Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fff1f283df149fdb0c225f546d6988e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a407a915991b48be963b4b7544d78cf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46afd26c176c43d8ade3bbea48989758",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2130fbf64c743c587360aab3cc60d39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 m√©tricas\n",
      "Evaluaci√≥n completada: 6 preguntas con 4 m√©tricas\n",
      "\n",
      "COMBINACI√ìN: prompt_one_shot + gte-multilingual-base\n",
      "   context_precision: 0.315\n",
      "   context_recall: 0.092\n",
      "   faithfulness: 0.747\n",
      "   answer_correctness: 0.212\n",
      "\n",
      "PAUSA ENTRE PROMPTS: 300 segundos...\n",
      "\n",
      "EVALUANDO CON PROMPT: prompt_few_shot\n",
      "================================================================================\n",
      "Generando respuestas con LangGraph...\n",
      "Procesando pregunta 1/9 con prompt_few_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Published by Elsevier Inc. All rights reserved. doi:10.1016/j.yqres.2011.12.003 Contents lists available at SciVerse ScienceDirect Quaternary Research journal homepage: www.elsevier.com/locate/yqres https://doi.org/10.1016/j.yqres.2011.12.003 Published online by Cambridge University Press Introduc...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 2/9 con prompt_few_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. A data obtida, √© claramente mais recuada que os con¬≠ textos mais antigos reportados em territ√≥rio hoje portu¬≠ gu√™s, nomeadamente Gruta da Nascente do Rio Almonda (OxA¬≠‚Äë9287 ‚Äì 5480¬≠‚Äë5320 cal BC a 2 sigmas) e da Gruta do Caldeir√£o (OxA¬≠‚Äë1036 ‚Äì 5480 ‚Äì 5070 cal BC a 2 sigmas). Entre n√≥s, apenas se rep...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 3/9 con prompt_few_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 2. ENCUADRE CRONO-CULTURAL DEL HA- LLAZGO: COGOTAS I Entre las entidades arqueol√≥gicas de la Edad del Bronce peninsular, Cogotas I sobresale por su extensa cobertura geogr√°fica, que desborda la Meseta por el Valle del Ebro y Extremadura, y por su dilatada crono- log√≠a ‚Äîc. 1800-1150 cal BC, cubrien...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 4/9 con prompt_few_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. y NEIRA, A. (1999): ‚ÄúPrehistoria‚Äù, en M.A. Rabanal Alonso (coord.): La His¬≠ toria de Le√≥n, tomo I, Universidad de Le√≥n y Diario de Le√≥n. CELIS S√ÅNCHEZ, J. (1993a): ‚ÄúLa secuencia del poblado de la Primera Edad del Hierro de los ¬´Cuestos de la Estaci√≥n¬ª, Benavente, Zamora‚Äù, en F. Romero, C. Sanz y Z...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 5/9 con prompt_few_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Con el desarrollo de las excavaciones arqueol√≥gicas en diversos asentamientos, el aumento del n√∫mero de dataciones y la realizaci√≥n de diversos estudios en los √∫ltimos a√±os, las perspectivas de investigaci√≥n sobre el Bronce final en el Levante comienza a variar sustancialmente, estando ya en condi...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 6/9 con prompt_few_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. En la actualidad, El Argar sigue siendo el grupo arqueo¬≠ l√≥gico de la Edad del Bronce mejor conocido de la pen√≠nsula ib√©rica, con un desarrollo temporal entre el 2200 y el 1550 cal BC. Tambi√©n se puede afirmar que fue una de las sociedades con mayor capacidad productiva y desarrollo social de la E...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Respuestas v√°lidas generadas con prompt_few_shot: 6\n",
      "\n",
      "EVALUANDO: prompt_few_shot + all-MiniLM-L6-v2\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 m√©tricas en batches de 2\n",
      "   üîÑ Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdc3f3ee7bb84eb4a4872d8938077213",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f696d0d910104413aafecf0f42d36686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ad575db7bb5490d9a7776dce10f3d13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dde1f843247f4a8a9f08ea052d16cd91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 m√©tricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   üîÑ Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b1e79e46aa7445dbc9e5170fb6193a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93375959afc54f37a489c89b07e540d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cac54a94b0e94d51b5bfa1945ca5257f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f76661ec65d4441a09e09c5c12b179a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 m√©tricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   üîÑ Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2b520861247479fb19e061bd480f852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64eefc7c712c4e88aba656bcd074a2aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e9b57ba66a941a188e3dc0395ff846c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d2bdbf4eda84d7f9041699c18f49882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 m√©tricas\n",
      "Evaluaci√≥n completada: 6 preguntas con 4 m√©tricas\n",
      "\n",
      "COMBINACI√ìN: prompt_few_shot + all-MiniLM-L6-v2\n",
      "   context_precision: 0.228\n",
      "   context_recall: 0.300\n",
      "   faithfulness: 0.657\n",
      "   answer_correctness: 0.149\n",
      "\n",
      "EVALUANDO: prompt_few_shot + e5-large-instruct\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 m√©tricas en batches de 2\n",
      "   üîÑ Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b8d32418b704dde92fde0d9a5e87aec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "970f8c209c9f4266bf0a14b800a060ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "027061b3bdfc4711970683436fd34039",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fda1d313bf34f3c8086ebb5b45439d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 m√©tricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   üîÑ Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5dfc20e66d94c00ab502f5735b24a27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e02db97c70e4aa08e775f908b71a120",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8096e4278744a59b67d40bfcb77ae10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5516fe7c65f444968a2e926c1f47b8bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 m√©tricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   üîÑ Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adf13c214516406888f96e3cabfdbc12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e0b66a0e0634bf2827240eb046b0abd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca9aa4dbf1d240d7af72e545f7703a50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70912dfb3d8b45788b9ef0b327e4708d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 m√©tricas\n",
      "Evaluaci√≥n completada: 6 preguntas con 4 m√©tricas\n",
      "\n",
      "COMBINACI√ìN: prompt_few_shot + e5-large-instruct\n",
      "   context_precision: 0.356\n",
      "   context_recall: 0.088\n",
      "   faithfulness: 0.587\n",
      "   answer_correctness: 0.236\n",
      "\n",
      "EVALUANDO: prompt_few_shot + gte-multilingual-base\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 m√©tricas en batches de 2\n",
      "   üîÑ Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e39128498f1d468086abfbb297745cf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff3c920881a642b298b21e00fbeb98d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bab7caab578b401390df7330cfb6dbc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "717a962c4f9e474f85fe4daead8ac8f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 m√©tricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   üîÑ Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db512e6c4cc6460abd115be37939adf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b5bdb0a38084c70aa88a962efa263b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "752b72d797564f49aaa04f00c3725734",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a03d609fb154de7885bfb28dd178f6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 m√©tricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   üîÑ Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7613648ebe444866a1c9eb102468de0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b9296ab59414ec39c95bb0496cc731b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f95b9629efb43eaa2d06dc3786dfd7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec0455e47eeb41fdaa2810a8a01fda57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 m√©tricas\n",
      "Evaluaci√≥n completada: 6 preguntas con 4 m√©tricas\n",
      "\n",
      "COMBINACI√ìN: prompt_few_shot + gte-multilingual-base\n",
      "   context_precision: 0.437\n",
      "   context_recall: 0.096\n",
      "   faithfulness: 0.721\n",
      "   answer_correctness: 0.181\n",
      "\"EVALUACI√ìN COMPLETA\n",
      "\n",
      "TABLA DE RESULTADOS:\n",
      "====================================================================================================\n",
      "\n",
      "PROMPT: prompt_zero_shot\n",
      "all-MiniLM-L6-v2:\n",
      "      context_precision: 0.475\n",
      "      context_recall: 0.106\n",
      "      faithfulness: 0.903\n",
      "      answer_correctness: 0.275\n",
      "e5-large-instruct:\n",
      "      context_precision: 0.387\n",
      "      context_recall: 0.087\n",
      "      faithfulness: 0.880\n",
      "      answer_correctness: 0.242\n",
      "gte-multilingual-base:\n",
      "      context_precision: 0.417\n",
      "      context_recall: 0.304\n",
      "      faithfulness: 0.844\n",
      "      answer_correctness: 0.162\n",
      "\n",
      "PROMPT: prompt_one_shot\n",
      "all-MiniLM-L6-v2:\n",
      "      context_precision: 0.395\n",
      "      context_recall: 0.143\n",
      "      faithfulness: 0.763\n",
      "      answer_correctness: 0.187\n",
      "e5-large-instruct:\n",
      "      context_precision: 0.340\n",
      "      context_recall: 0.342\n",
      "      faithfulness: 0.742\n",
      "      answer_correctness: 0.287\n",
      "gte-multilingual-base:\n",
      "      context_precision: 0.315\n",
      "      context_recall: 0.092\n",
      "      faithfulness: 0.747\n",
      "      answer_correctness: 0.212\n",
      "\n",
      "PROMPT: prompt_few_shot\n",
      "all-MiniLM-L6-v2:\n",
      "      context_precision: 0.228\n",
      "      context_recall: 0.300\n",
      "      faithfulness: 0.657\n",
      "      answer_correctness: 0.149\n",
      "e5-large-instruct:\n",
      "      context_precision: 0.356\n",
      "      context_recall: 0.088\n",
      "      faithfulness: 0.587\n",
      "      answer_correctness: 0.236\n",
      "gte-multilingual-base:\n",
      "      context_precision: 0.437\n",
      "      context_recall: 0.096\n",
      "      faithfulness: 0.721\n",
      "      answer_correctness: 0.181\n"
     ]
    }
   ],
   "source": [
    "# Evaluar TODAS las combinaciones: 3 prompts √ó 3 embeddings = 9 combinaciones\n",
    "resultados_completos = {}\n",
    "\n",
    "prompts_list = ['prompt_zero_shot', 'prompt_one_shot', 'prompt_few_shot']\n",
    "\n",
    "for prompt_name in prompts_list:\n",
    "    print(f\"\\nEVALUANDO CON PROMPT: {prompt_name}\")\n",
    "    print(\"=\"*80)\n",
    "    # CAMBIAR EL TEMPLATE GLOBAL (esto es lo clave)\n",
    "    selected_template = PROMPTS[prompt_name]\n",
    "    prompt_template = ChatPromptTemplate.from_template(selected_template)\n",
    "\n",
    "    # Generar respuestas con este prompt espec√≠fico\n",
    "    results_list_prompt = []\n",
    "\n",
    "    # Necesitas generar las respuestas con tu grafo de LangGraph primero\n",
    "    print(\"Generando respuestas con LangGraph...\")\n",
    "\n",
    "    for i, (question, ground_truth) in enumerate(zip(questions, ground_truths)):\n",
    "        print(f\"Procesando pregunta {i+1}/{len(questions)} con {prompt_name}\")\n",
    "\n",
    "\n",
    "        state = {\n",
    "            'question': question,\n",
    "            'llm_name': 'Qwen3-4B-instruct-2507',  \n",
    "            'embedding_name': 'all-MiniLM-L6-v2',  # Se cambiar√° en el bucle    \n",
    "            'prompt_name': prompt_name,\n",
    "            'context': [],\n",
    "            'answer': '',\n",
    "            'metadata': {}\n",
    "        }\n",
    "        try:\n",
    "        \n",
    "            final_state = graph.invoke(state)\n",
    "            answer = final_state.get('answer', '')\n",
    "            contexts = final_state.get('context', [])\n",
    "\n",
    "            if answer and answer.strip():  # Verificar que hay respuesta\n",
    "                  results_list_prompt.append({\n",
    "                      'question': question,\n",
    "                      'answer': answer,\n",
    "                      'contexts': [doc.page_content for doc in contexts] if contexts else ['Sin contexto'],\n",
    "                      'ground_truth': ground_truth\n",
    "                  })\n",
    "            else:\n",
    "                  print(f\"      ‚ö†Ô∏è Pregunta {i+1} sin respuesta v√°lida\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"      ‚ùå Error en pregunta {i+1}: {e}\")\n",
    "\n",
    "    print(f\"Respuestas v√°lidas generadas con {prompt_name}: {len(results_list_prompt)}\")\n",
    "\n",
    "    # Solo evaluar si tenemos respuestas v√°lidas\n",
    "    if len(results_list_prompt) >= 2:\n",
    "          # EVALUAR CON LOS 3 EMBEDDINGS\n",
    "        resultados_por_embedding = {}\n",
    "\n",
    "        for embedding_name, current_embedding_model in EMBEDDING_MODELS.items():\n",
    "            print(f\"\\nEVALUANDO: {prompt_name} + {embedding_name}\")\n",
    "            print(\"-\"*60)\n",
    "\n",
    "            resultado = evaluate_with_mistral_four_metrics(\n",
    "                results_list=results_list_prompt,\n",
    "                  embedding_model=current_embedding_model,\n",
    "                  max_batch_size=2,\n",
    "                  delay_between_batches=120\n",
    "            )\n",
    "\n",
    "            resultados_por_embedding[embedding_name] = resultado\n",
    "\n",
    "              # Mostrar m√©tricas promedio\n",
    "            print(f\"\\nCOMBINACI√ìN: {prompt_name} + {embedding_name}\")\n",
    "            for metric in ['context_precision', 'context_recall', 'faithfulness', 'answer_correctness']:\n",
    "                if metric in resultado.columns:\n",
    "                    valores = resultado[metric].dropna()\n",
    "                    if len(valores) > 0:\n",
    "                        print(f\"   {metric}: {valores.mean():.3f}\")\n",
    "                    else:\n",
    "                        print(f\"   {metric}: Sin valores v√°lidos\")\n",
    "\n",
    "            time.sleep(90)  # Pausa entre embeddings\n",
    "\n",
    "          # Guardar resultados de este prompt\n",
    "        resultados_completos[prompt_name] = resultados_por_embedding\n",
    "\n",
    "    else:\n",
    "        print(f\"No hay suficientes respuestas v√°lidas para {prompt_name}, saltando evaluaci√≥n\")\n",
    "\n",
    "    if prompt_name != prompts_list[-1]:\n",
    "        print(f\"\\nPAUSA ENTRE PROMPTS: 300 segundos...\")\n",
    "        time.sleep(300)\n",
    "\n",
    "print(\"\\\"EVALUACI√ìN COMPLETA\")\n",
    "\n",
    "  # Mostrar tabla final\n",
    "print(\"\\nTABLA DE RESULTADOS:\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "for prompt_name, embeddings_results in resultados_completos.items():\n",
    "    print(f\"\\nPROMPT: {prompt_name}\")\n",
    "    for embedding_name, resultado in embeddings_results.items():\n",
    "        print(f\"{embedding_name}:\")\n",
    "        for metric in ['context_precision', 'context_recall', 'faithfulness', 'answer_correctness']:\n",
    "            if metric in resultado.columns:\n",
    "                valores = resultado[metric].dropna()\n",
    "                if len(valores) > 0:\n",
    "                    print(f\"      {metric}: {valores.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUANDO CON PROMPT: prompt_zero_shot\n",
      "================================================================================\n",
      "Generando respuestas con LangGraph...\n",
      "Procesando pregunta 1/9 con prompt_zero_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Phi-3.5-mini-instruct\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Published by Elsevier Inc. All rights reserved. doi:10.1016/j.yqres.2011.12.003 Contents lists available at SciVerse ScienceDirect Quaternary Research journal homepage: www.elsevier.com/locate/yqres https://doi.org/10.1016/j.yqres.2011.12.003 Published online by Cambridge University Press Introduc...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 2/9 con prompt_zero_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Phi-3.5-mini-instruct\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. A data obtida, √© claramente mais recuada que os con¬≠ textos mais antigos reportados em territ√≥rio hoje portu¬≠ gu√™s, nomeadamente Gruta da Nascente do Rio Almonda (OxA¬≠‚Äë9287 ‚Äì 5480¬≠‚Äë5320 cal BC a 2 sigmas) e da Gruta do Caldeir√£o (OxA¬≠‚Äë1036 ‚Äì 5480 ‚Äì 5070 cal BC a 2 sigmas). Entre n√≥s, apenas se rep...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 3/9 con prompt_zero_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Phi-3.5-mini-instruct\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 2. ENCUADRE CRONO-CULTURAL DEL HA- LLAZGO: COGOTAS I Entre las entidades arqueol√≥gicas de la Edad del Bronce peninsular, Cogotas I sobresale por su extensa cobertura geogr√°fica, que desborda la Meseta por el Valle del Ebro y Extremadura, y por su dilatada crono- log√≠a ‚Äîc. 1800-1150 cal BC, cubrien...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 4/9 con prompt_zero_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Phi-3.5-mini-instruct\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. y NEIRA, A. (1999): ‚ÄúPrehistoria‚Äù, en M.A. Rabanal Alonso (coord.): La His¬≠ toria de Le√≥n, tomo I, Universidad de Le√≥n y Diario de Le√≥n. CELIS S√ÅNCHEZ, J. (1993a): ‚ÄúLa secuencia del poblado de la Primera Edad del Hierro de los ¬´Cuestos de la Estaci√≥n¬ª, Benavente, Zamora‚Äù, en F. Romero, C. Sanz y Z...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 5/9 con prompt_zero_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Phi-3.5-mini-instruct\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Con el desarrollo de las excavaciones arqueol√≥gicas en diversos asentamientos, el aumento del n√∫mero de dataciones y la realizaci√≥n de diversos estudios en los √∫ltimos a√±os, las perspectivas de investigaci√≥n sobre el Bronce final en el Levante comienza a variar sustancialmente, estando ya en condi...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 6/9 con prompt_zero_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Phi-3.5-mini-instruct\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. En la actualidad, El Argar sigue siendo el grupo arqueo¬≠ l√≥gico de la Edad del Bronce mejor conocido de la pen√≠nsula ib√©rica, con un desarrollo temporal entre el 2200 y el 1550 cal BC. Tambi√©n se puede afirmar que fue una de las sociedades con mayor capacidad productiva y desarrollo social de la E...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Respuestas v√°lidas generadas con prompt_zero_shot: 6\n",
      "\n",
      "üîÑ EVALUANDO: prompt_zero_shot + all-MiniLM-L6-v2\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 m√©tricas en batches de 2\n",
      "   üîÑ Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\_analytics.py:77: ResourceWarning: unclosed file <_io.TextIOWrapper name='C:\\\\Users\\\\elevi\\\\AppData\\\\Local\\\\ragas\\\\ragas\\\\uuid.json' mode='r' encoding='cp1252'>\n",
      "  user_id = json.load(open(uuid_filepath))[\"userid\"]\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "663e7bb4fdca4632b82976872ae69b03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fe446edf41c463c9f8be28bbfa38482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0434717ba5324f03857489e0613f3c2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db416305fb414e5abfca3a5b535743b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 m√©tricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   üîÑ Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb018b6bce6842e78e0cf049c3de9e99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cb9740fd15240df937880930de116e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cbbe934b5f049e1ada4a753505e1782",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e050d8be21b8445995db57fa96d42a22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 m√©tricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   üîÑ Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a62cfd3d27e49439c8823249a02e486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d37e08e4b1f34fde8ffcb2667b2ac71a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57166d98962c4aa2ad7349d19d3edd8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "612f611d366c472bb4a7ea442d6b303a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 m√©tricas\n",
      "Evaluaci√≥n completada: 6 preguntas con 4 m√©tricas\n",
      "\n",
      "üìä COMBINACI√ìN: prompt_zero_shot + all-MiniLM-L6-v2\n",
      "   context_precision: 0.404\n",
      "   context_recall: 0.106\n",
      "   faithfulness: 0.705\n",
      "   answer_correctness: 0.179\n",
      "\n",
      "üîÑ EVALUANDO: prompt_zero_shot + e5-large-instruct\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 m√©tricas en batches de 2\n",
      "   üîÑ Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fc1ce17e6a04aaca42e71019b28a8ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc217258522f46aba65a673ad5dc4a2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "935cafa686ea46118f8bcfce6d7e0196",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a64708f6ffe4fc1ac5a6bcae707b8df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 m√©tricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   üîÑ Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91991ab9c05149cfa9eabd28df0ade51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb0ed8e9a6264974a6d596024d1a2aee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "923e866116304871be75f767e69ce279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ff6cfdf8e1a4033b2b58937a603b363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 m√©tricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   üîÑ Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d12b83d50864e5b976822add5b158f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "225a7aa032fd4dc189dac32feb138627",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55be81519e0b41a58ae7a964dd93b046",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a054ededaad4a6ca40fa4644379bdf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 m√©tricas\n",
      "Evaluaci√≥n completada: 6 preguntas con 4 m√©tricas\n",
      "\n",
      "üìä COMBINACI√ìN: prompt_zero_shot + e5-large-instruct\n",
      "   context_precision: 0.458\n",
      "   context_recall: 0.148\n",
      "   faithfulness: 0.772\n",
      "   answer_correctness: 0.266\n",
      "\n",
      "üîÑ EVALUANDO: prompt_zero_shot + gte-multilingual-base\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 m√©tricas en batches de 2\n",
      "   üîÑ Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "575dafa3156448579a03c58b59084ccd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94d620b9d5424786954527ed754cbdc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b8253d98cb3459da9ec83721257f783",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b935b8e893d44feaa702b82591d810e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 m√©tricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   üîÑ Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6a0f197a0f84d728f1aeede4eecb9a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4be0b246eb0c4597a8d6cfdfd26a0cfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "480a2eef5e5b4103b91653ee46271ac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad2e84e5e79048c1ab1ba6cdb7d7b3c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 m√©tricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   üîÑ Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96a13f8b243846ba9c93007898d1b158",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2791b29738f14e21a257067f9b1f5d6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "535a201a013c4f17b306397a56c3e660",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a6f261c6ec14d28849c7fcee48d75e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 m√©tricas\n",
      "Evaluaci√≥n completada: 6 preguntas con 4 m√©tricas\n",
      "\n",
      "üìä COMBINACI√ìN: prompt_zero_shot + gte-multilingual-base\n",
      "   context_precision: 0.475\n",
      "   context_recall: 0.239\n",
      "   faithfulness: 0.733\n",
      "   answer_correctness: 0.148\n",
      "\n",
      "‚è±Ô∏è PAUSA ENTRE PROMPTS: 300 segundos...\n",
      "\n",
      "EVALUANDO CON PROMPT: prompt_one_shot\n",
      "================================================================================\n",
      "Generando respuestas con LangGraph...\n",
      "Procesando pregunta 1/9 con prompt_one_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Phi-3.5-mini-instruct\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Published by Elsevier Inc. All rights reserved. doi:10.1016/j.yqres.2011.12.003 Contents lists available at SciVerse ScienceDirect Quaternary Research journal homepage: www.elsevier.com/locate/yqres https://doi.org/10.1016/j.yqres.2011.12.003 Published online by Cambridge University Press Introduc...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 2/9 con prompt_one_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Phi-3.5-mini-instruct\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. A data obtida, √© claramente mais recuada que os con¬≠ textos mais antigos reportados em territ√≥rio hoje portu¬≠ gu√™s, nomeadamente Gruta da Nascente do Rio Almonda (OxA¬≠‚Äë9287 ‚Äì 5480¬≠‚Äë5320 cal BC a 2 sigmas) e da Gruta do Caldeir√£o (OxA¬≠‚Äë1036 ‚Äì 5480 ‚Äì 5070 cal BC a 2 sigmas). Entre n√≥s, apenas se rep...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 3/9 con prompt_one_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Phi-3.5-mini-instruct\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 2. ENCUADRE CRONO-CULTURAL DEL HA- LLAZGO: COGOTAS I Entre las entidades arqueol√≥gicas de la Edad del Bronce peninsular, Cogotas I sobresale por su extensa cobertura geogr√°fica, que desborda la Meseta por el Valle del Ebro y Extremadura, y por su dilatada crono- log√≠a ‚Äîc. 1800-1150 cal BC, cubrien...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 4/9 con prompt_one_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Phi-3.5-mini-instruct\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. y NEIRA, A. (1999): ‚ÄúPrehistoria‚Äù, en M.A. Rabanal Alonso (coord.): La His¬≠ toria de Le√≥n, tomo I, Universidad de Le√≥n y Diario de Le√≥n. CELIS S√ÅNCHEZ, J. (1993a): ‚ÄúLa secuencia del poblado de la Primera Edad del Hierro de los ¬´Cuestos de la Estaci√≥n¬ª, Benavente, Zamora‚Äù, en F. Romero, C. Sanz y Z...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 5/9 con prompt_one_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Phi-3.5-mini-instruct\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Con el desarrollo de las excavaciones arqueol√≥gicas en diversos asentamientos, el aumento del n√∫mero de dataciones y la realizaci√≥n de diversos estudios en los √∫ltimos a√±os, las perspectivas de investigaci√≥n sobre el Bronce final en el Levante comienza a variar sustancialmente, estando ya en condi...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 6/9 con prompt_one_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Phi-3.5-mini-instruct\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. En la actualidad, El Argar sigue siendo el grupo arqueo¬≠ l√≥gico de la Edad del Bronce mejor conocido de la pen√≠nsula ib√©rica, con un desarrollo temporal entre el 2200 y el 1550 cal BC. Tambi√©n se puede afirmar que fue una de las sociedades con mayor capacidad productiva y desarrollo social de la E...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Respuestas v√°lidas generadas con prompt_one_shot: 6\n",
      "\n",
      "üîÑ EVALUANDO: prompt_one_shot + all-MiniLM-L6-v2\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 m√©tricas en batches de 2\n",
      "   üîÑ Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d42ddc6d6a7460fb51cf4bddcc63bb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cb10a6506d94f9988206fa7217b0793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bd7a798b050424f869936fcfc3a6399",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "482ca3db145d4ccca57f187f0e18c032",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 m√©tricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   üîÑ Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1adf1e16b5b943539bdbc6bd92deac9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbc0114ae25d43dca8b20ed2ce98a347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ab63515dcf94e6687228d98b2b3a043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4deff40965ee48b48348d4ba9294fa55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 m√©tricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   üîÑ Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54b789ce4e0d467da95a7e20473c35a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6602b1baa10247c5b7cc3d0a0aea9ced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77796551f8f8413eb688122eaab30e6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02b46c3ba346472093404e1e09981762",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 m√©tricas\n",
      "Evaluaci√≥n completada: 6 preguntas con 4 m√©tricas\n",
      "\n",
      "üìä COMBINACI√ìN: prompt_one_shot + all-MiniLM-L6-v2\n",
      "   context_precision: 0.429\n",
      "   context_recall: 0.282\n",
      "   faithfulness: 0.967\n",
      "   answer_correctness: 0.215\n",
      "\n",
      "üîÑ EVALUANDO: prompt_one_shot + e5-large-instruct\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 m√©tricas en batches de 2\n",
      "   üîÑ Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbb14bcafa55465cb5efaa960215b064",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99dbc308b71641d7b9d9303cc31f363b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bab457f68c7e4639959151f2ca66f8ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7b8107220574f08bb0b58a75fe63428",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 m√©tricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   üîÑ Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ed740c258414d74b422e5bc9e7542a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3d5e86e6017485cb4aec672c6db3442",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e55f7105c9348b6920ca9b11734e13f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1336b64706f54fbebe8f7a63e4709f8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 m√©tricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   üîÑ Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab2d0529e717486da2402259c6d4f901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1342fad78b8145a083ce6148bdc6bd1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7b4c1ad8fe54f8188ed9d47c6083e0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d726dc55324742cd8a06827b46774384",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 m√©tricas\n",
      "Evaluaci√≥n completada: 6 preguntas con 4 m√©tricas\n",
      "\n",
      "üìä COMBINACI√ìN: prompt_one_shot + e5-large-instruct\n",
      "   context_precision: 0.458\n",
      "   context_recall: 0.130\n",
      "   faithfulness: 0.929\n",
      "   answer_correctness: 0.307\n",
      "\n",
      "üîÑ EVALUANDO: prompt_one_shot + gte-multilingual-base\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 m√©tricas en batches de 2\n",
      "   üîÑ Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b38b5340330247948876ca9714b8d1a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc2473b2667545c89f4942fb786e1da2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43a4a25f304b4ba881721c5abfc98c10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d6f1a6c4b4c4f9f80ce35fcd493cc73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 m√©tricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   üîÑ Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "359c4dbfcd1348aa886e67d5bb516579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f206eafd75d4fc3ae8947a3e0351c24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9420221cc3da4be69fb10da8afc51ab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68082e59e84b4d6cb5c1d87996d98d9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 m√©tricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   üîÑ Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09f7caecd491496b9f6fe5b69160a3f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b463a87afe14694b07ed053c374ebae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b930dbdbef0f46f4a1d59dea99822d9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ce82cc31e504a1cb5a40a717a15823b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 m√©tricas\n",
      "Evaluaci√≥n completada: 6 preguntas con 4 m√©tricas\n",
      "\n",
      "üìä COMBINACI√ìN: prompt_one_shot + gte-multilingual-base\n",
      "   context_precision: 0.527\n",
      "   context_recall: 0.181\n",
      "   faithfulness: 0.888\n",
      "   answer_correctness: 0.211\n",
      "\n",
      "‚è±Ô∏è PAUSA ENTRE PROMPTS: 300 segundos...\n",
      "\n",
      "EVALUANDO CON PROMPT: prompt_few_shot\n",
      "================================================================================\n",
      "Generando respuestas con LangGraph...\n",
      "Procesando pregunta 1/9 con prompt_few_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Phi-3.5-mini-instruct\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Published by Elsevier Inc. All rights reserved. doi:10.1016/j.yqres.2011.12.003 Contents lists available at SciVerse ScienceDirect Quaternary Research journal homepage: www.elsevier.com/locate/yqres https://doi.org/10.1016/j.yqres.2011.12.003 Published online by Cambridge University Press Introduc...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 2/9 con prompt_few_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Phi-3.5-mini-instruct\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. A data obtida, √© claramente mais recuada que os con¬≠ textos mais antigos reportados em territ√≥rio hoje portu¬≠ gu√™s, nomeadamente Gruta da Nascente do Rio Almonda (OxA¬≠‚Äë9287 ‚Äì 5480¬≠‚Äë5320 cal BC a 2 sigmas) e da Gruta do Caldeir√£o (OxA¬≠‚Äë1036 ‚Äì 5480 ‚Äì 5070 cal BC a 2 sigmas). Entre n√≥s, apenas se rep...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 3/9 con prompt_few_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Phi-3.5-mini-instruct\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 2. ENCUADRE CRONO-CULTURAL DEL HA- LLAZGO: COGOTAS I Entre las entidades arqueol√≥gicas de la Edad del Bronce peninsular, Cogotas I sobresale por su extensa cobertura geogr√°fica, que desborda la Meseta por el Valle del Ebro y Extremadura, y por su dilatada crono- log√≠a ‚Äîc. 1800-1150 cal BC, cubrien...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 4/9 con prompt_few_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Phi-3.5-mini-instruct\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. y NEIRA, A. (1999): ‚ÄúPrehistoria‚Äù, en M.A. Rabanal Alonso (coord.): La His¬≠ toria de Le√≥n, tomo I, Universidad de Le√≥n y Diario de Le√≥n. CELIS S√ÅNCHEZ, J. (1993a): ‚ÄúLa secuencia del poblado de la Primera Edad del Hierro de los ¬´Cuestos de la Estaci√≥n¬ª, Benavente, Zamora‚Äù, en F. Romero, C. Sanz y Z...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 5/9 con prompt_few_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Phi-3.5-mini-instruct\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Con el desarrollo de las excavaciones arqueol√≥gicas en diversos asentamientos, el aumento del n√∫mero de dataciones y la realizaci√≥n de diversos estudios en los √∫ltimos a√±os, las perspectivas de investigaci√≥n sobre el Bronce final en el Levante comienza a variar sustancialmente, estando ya en condi...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 6/9 con prompt_few_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Phi-3.5-mini-instruct\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. En la actualidad, El Argar sigue siendo el grupo arqueo¬≠ l√≥gico de la Edad del Bronce mejor conocido de la pen√≠nsula ib√©rica, con un desarrollo temporal entre el 2200 y el 1550 cal BC. Tambi√©n se puede afirmar que fue una de las sociedades con mayor capacidad productiva y desarrollo social de la E...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Respuestas v√°lidas generadas con prompt_few_shot: 6\n",
      "\n",
      "üîÑ EVALUANDO: prompt_few_shot + all-MiniLM-L6-v2\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 m√©tricas en batches de 2\n",
      "   üîÑ Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c8e68f59d8c425e8eb1aae8e62aee35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee539e36aef544058cb6b314f501d20c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d819adf28a5470c8594487aca9ac971",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53b8654942864d43af1444fd2b8c7248",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 m√©tricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   üîÑ Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c7b3c9437b84492a645ffe5bfe780da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afb30791c4164820a170030485f1fe78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4db537fc8a2744a5bc0feb7f566d9d38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fa738e2a81f44e2b0b301ee9094c926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 m√©tricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   üîÑ Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b77224b7a944e9c9cdecfd7e8c107d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "503ba870f82a4dfdb2a37ea111479702",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5815faba5e7a46fc9dbe1a4318242797",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99b23b949bcd4d0d899b36f0ff287096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 m√©tricas\n",
      "Evaluaci√≥n completada: 6 preguntas con 4 m√©tricas\n",
      "\n",
      "üìä COMBINACI√ìN: prompt_few_shot + all-MiniLM-L6-v2\n",
      "   context_precision: 0.367\n",
      "   context_recall: 0.314\n",
      "   faithfulness: 0.845\n",
      "   answer_correctness: 0.180\n",
      "\n",
      "üîÑ EVALUANDO: prompt_few_shot + e5-large-instruct\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 m√©tricas en batches de 2\n",
      "   üîÑ Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb1f27103d744e6aaf3f7dd6bc372964",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c91042a772fc47d68a5d31dba053b3e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4eb298138c44318b7a4ce0a4f756be0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae8d9f09c2054ec68136ce5f6717993e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 m√©tricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   üîÑ Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfefec6d38f0422780c7ca3030fd69fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbcb493f58f044aebda697ab232bb2c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b2f3377bfce4192ae1b82cf7d585bfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "361eac7b71124622a355bd445cb5779f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 m√©tricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   üîÑ Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f43866a5fad46bf9e37c407b78b7b35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcc4f73cecf14710979166bfa5fcda39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b662055f6744957a46372a7da378a08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b0cabac32594f4cad40c7533e6229da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 m√©tricas\n",
      "Evaluaci√≥n completada: 6 preguntas con 4 m√©tricas\n",
      "\n",
      "üìä COMBINACI√ìN: prompt_few_shot + e5-large-instruct\n",
      "   context_precision: 0.479\n",
      "   context_recall: 0.329\n",
      "   faithfulness: 0.860\n",
      "   answer_correctness: 0.262\n",
      "\n",
      "üîÑ EVALUANDO: prompt_few_shot + gte-multilingual-base\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 m√©tricas en batches de 2\n",
      "   üîÑ Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "509b7ba4df694702a9edd097d23bd245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d08e89bff4654fbe864ecb379c9b9ac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "014585d99666401486b9a7f1aa5d94bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aab5f81468964621a14562cd3f0976c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 m√©tricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   üîÑ Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00f1934219db46458fe1033f3057d219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76991506a8f4470b8d9cc8574345bf0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f164e717c6a451e9b696663f67408f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b7593b54fa241a98dd3da9b1707d682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 m√©tricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   üîÑ Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55979c94c11940d48e8dc21455116227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdd0941ea87241e781fbe94a2b154598",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75165e34e9084757806d844abec373c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a74f5cb7ed984d0bbf83a8512abc5992",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 m√©tricas\n",
      "Evaluaci√≥n completada: 6 preguntas con 4 m√©tricas\n",
      "\n",
      "üìä COMBINACI√ìN: prompt_few_shot + gte-multilingual-base\n",
      "   context_precision: 0.471\n",
      "   context_recall: 0.259\n",
      "   faithfulness: 0.866\n",
      "   answer_correctness: 0.158\n",
      "\"EVALUACI√ìN COMPLETA\n",
      "\n",
      "TABLA DE RESULTADOS:\n",
      "====================================================================================================\n",
      "\n",
      "üéØ PROMPT: prompt_zero_shot\n",
      "   üìä all-MiniLM-L6-v2:\n",
      "      context_precision: 0.404\n",
      "      context_recall: 0.106\n",
      "      faithfulness: 0.705\n",
      "      answer_correctness: 0.179\n",
      "   üìä e5-large-instruct:\n",
      "      context_precision: 0.458\n",
      "      context_recall: 0.148\n",
      "      faithfulness: 0.772\n",
      "      answer_correctness: 0.266\n",
      "   üìä gte-multilingual-base:\n",
      "      context_precision: 0.475\n",
      "      context_recall: 0.239\n",
      "      faithfulness: 0.733\n",
      "      answer_correctness: 0.148\n",
      "\n",
      "üéØ PROMPT: prompt_one_shot\n",
      "   üìä all-MiniLM-L6-v2:\n",
      "      context_precision: 0.429\n",
      "      context_recall: 0.282\n",
      "      faithfulness: 0.967\n",
      "      answer_correctness: 0.215\n",
      "   üìä e5-large-instruct:\n",
      "      context_precision: 0.458\n",
      "      context_recall: 0.130\n",
      "      faithfulness: 0.929\n",
      "      answer_correctness: 0.307\n",
      "   üìä gte-multilingual-base:\n",
      "      context_precision: 0.527\n",
      "      context_recall: 0.181\n",
      "      faithfulness: 0.888\n",
      "      answer_correctness: 0.211\n",
      "\n",
      "üéØ PROMPT: prompt_few_shot\n",
      "   üìä all-MiniLM-L6-v2:\n",
      "      context_precision: 0.367\n",
      "      context_recall: 0.314\n",
      "      faithfulness: 0.845\n",
      "      answer_correctness: 0.180\n",
      "   üìä e5-large-instruct:\n",
      "      context_precision: 0.479\n",
      "      context_recall: 0.329\n",
      "      faithfulness: 0.860\n",
      "      answer_correctness: 0.262\n",
      "   üìä gte-multilingual-base:\n",
      "      context_precision: 0.471\n",
      "      context_recall: 0.259\n",
      "      faithfulness: 0.866\n",
      "      answer_correctness: 0.158\n"
     ]
    }
   ],
   "source": [
    "# Evaluar TODAS las combinaciones: 3 prompts √ó 3 embeddings = 9 combinaciones\n",
    "resultados_completos = {}\n",
    "\n",
    "prompts_list = ['prompt_zero_shot', 'prompt_one_shot', 'prompt_few_shot']\n",
    "\n",
    "for prompt_name in prompts_list:\n",
    "    print(f\"\\nEVALUANDO CON PROMPT: {prompt_name}\")\n",
    "    print(\"=\"*80)\n",
    "    # CAMBIAR EL TEMPLATE GLOBAL (esto es lo clave)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    selected_template = PROMPTS[prompt_name]\n",
    "    prompt_template = ChatPromptTemplate.from_template(selected_template)\n",
    "\n",
    "    # Generar respuestas con este prompt espec√≠fico\n",
    "    results_list_prompt = []\n",
    "\n",
    "    # Necesitas generar las respuestas con tu grafo de LangGraph primero\n",
    "    print(\"Generando respuestas con LangGraph...\")\n",
    "\n",
    "    for i, (question, ground_truth) in enumerate(zip(questions, ground_truths)):\n",
    "        print(f\"Procesando pregunta {i+1}/{len(questions)} con {prompt_name}\")\n",
    "\n",
    "        # Aqu√≠ usas tu grafo de LangGraph para generar la respuesta\n",
    "        state = {\n",
    "            'question': question,\n",
    "            'llm_name': 'Phi-3.5-mini-instruct',  # Tu LLM de generaci√≥n\n",
    "            'embedding_name': 'all-MiniLM-L6-v2',  # Se cambiar√° en el bucle    \n",
    "            'prompt_name': prompt_name,\n",
    "            'context': [],\n",
    "            'answer': '',\n",
    "            'metadata': {}\n",
    "        }\n",
    "        try:\n",
    "            # INVOCAR TU GRAFO (ajusta seg√∫n tu c√≥digo)\n",
    "            final_state = graph.invoke(state)\n",
    "            answer = final_state.get('answer', '')\n",
    "            contexts = final_state.get('context', [])\n",
    "\n",
    "            if answer and answer.strip():  # Verificar que hay respuesta\n",
    "                  results_list_prompt.append({\n",
    "                      'question': question,\n",
    "                      'answer': answer,\n",
    "                      'contexts': [doc.page_content for doc in contexts] if contexts else ['Sin contexto'],\n",
    "                      'ground_truth': ground_truth\n",
    "                  })\n",
    "            else:\n",
    "                  print(f\"Pregunta {i+1} sin respuesta v√°lida\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error en pregunta {i+1}: {e}\")\n",
    "\n",
    "    print(f\"Respuestas v√°lidas generadas con {prompt_name}: {len(results_list_prompt)}\")\n",
    "\n",
    "      # Solo evaluar si tenemos respuestas v√°lidas\n",
    "    if len(results_list_prompt) >= 2:\n",
    "          # EVALUAR CON LOS 3 EMBEDDINGS\n",
    "        resultados_por_embedding = {}\n",
    "\n",
    "        for embedding_name, current_embedding_model in EMBEDDING_MODELS.items():\n",
    "            print(f\"\\nEVALUANDO: {prompt_name} + {embedding_name}\")\n",
    "            print(\"-\"*60)\n",
    "\n",
    "            resultado = evaluate_with_mistral_four_metrics(\n",
    "                results_list=results_list_prompt,\n",
    "                  embedding_model=current_embedding_model,\n",
    "                  max_batch_size=2,\n",
    "                  delay_between_batches=120\n",
    "            )\n",
    "\n",
    "            resultados_por_embedding[embedding_name] = resultado\n",
    "\n",
    "              # Mostrar m√©tricas promedio\n",
    "            print(f\"\\nCOMBINACI√ìN: {prompt_name} + {embedding_name}\")\n",
    "            for metric in ['context_precision', 'context_recall', 'faithfulness', 'answer_correctness']:\n",
    "                if metric in resultado.columns:\n",
    "                    valores = resultado[metric].dropna()\n",
    "                    if len(valores) > 0:\n",
    "                        print(f\"   {metric}: {valores.mean():.3f}\")\n",
    "                    else:\n",
    "                        print(f\"   {metric}: Sin valores v√°lidos\")\n",
    "\n",
    "            time.sleep(90)  # Pausa entre embeddings\n",
    "\n",
    "          # Guardar resultados de este prompt\n",
    "        resultados_completos[prompt_name] = resultados_por_embedding\n",
    "\n",
    "    else:\n",
    "        print(f\"No hay suficientes respuestas v√°lidas para {prompt_name}, saltando evaluaci√≥n\")\n",
    "\n",
    "    if prompt_name != prompts_list[-1]:\n",
    "        print(f\"\\nPAUSA ENTRE PROMPTS: 300 segundos...\")\n",
    "        time.sleep(300)\n",
    "\n",
    "print(\"\\\"EVALUACI√ìN COMPLETA\")\n",
    "\n",
    "  # Mostrar tabla final\n",
    "print(\"\\nTABLA DE RESULTADOS:\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "for prompt_name, embeddings_results in resultados_completos.items():\n",
    "    print(f\"\\nPROMPT: {prompt_name}\")\n",
    "    for embedding_name, resultado in embeddings_results.items():\n",
    "        print(f\"{embedding_name}:\")\n",
    "        for metric in ['context_precision', 'context_recall', 'faithfulness', 'answer_correctness']:\n",
    "            if metric in resultado.columns:\n",
    "                valores = resultado[metric].dropna()\n",
    "                if len(valores) > 0:\n",
    "                    print(f\"      {metric}: {valores.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUANDO CON PROMPT: prompt_zero_shot\n",
      "================================================================================\n",
      "Generando respuestas con LangGraph...\n",
      "Procesando pregunta 1/9 con prompt_zero_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Llama-3.2-3B-instruct\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Published by Elsevier Inc. All rights reserved. doi:10.1016/j.yqres.2011.12.003 Contents lists available at SciVerse ScienceDirect Quaternary Research journal homepage: www.elsevier.com/locate/yqres https://doi.org/10.1016/j.yqres.2011.12.003 Published online by Cambridge University Press Introduc...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 2/9 con prompt_zero_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Llama-3.2-3B-instruct\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. A data obtida, √© claramente mais recuada que os con¬≠ textos mais antigos reportados em territ√≥rio hoje portu¬≠ gu√™s, nomeadamente Gruta da Nascente do Rio Almonda (OxA¬≠‚Äë9287 ‚Äì 5480¬≠‚Äë5320 cal BC a 2 sigmas) e da Gruta do Caldeir√£o (OxA¬≠‚Äë1036 ‚Äì 5480 ‚Äì 5070 cal BC a 2 sigmas). Entre n√≥s, apenas se rep...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 3/9 con prompt_zero_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Llama-3.2-3B-instruct\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 2. ENCUADRE CRONO-CULTURAL DEL HA- LLAZGO: COGOTAS I Entre las entidades arqueol√≥gicas de la Edad del Bronce peninsular, Cogotas I sobresale por su extensa cobertura geogr√°fica, que desborda la Meseta por el Valle del Ebro y Extremadura, y por su dilatada crono- log√≠a ‚Äîc. 1800-1150 cal BC, cubrien...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 4/9 con prompt_zero_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Llama-3.2-3B-instruct\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. y NEIRA, A. (1999): ‚ÄúPrehistoria‚Äù, en M.A. Rabanal Alonso (coord.): La His¬≠ toria de Le√≥n, tomo I, Universidad de Le√≥n y Diario de Le√≥n. CELIS S√ÅNCHEZ, J. (1993a): ‚ÄúLa secuencia del poblado de la Primera Edad del Hierro de los ¬´Cuestos de la Estaci√≥n¬ª, Benavente, Zamora‚Äù, en F. Romero, C. Sanz y Z...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 5/9 con prompt_zero_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Llama-3.2-3B-instruct\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Con el desarrollo de las excavaciones arqueol√≥gicas en diversos asentamientos, el aumento del n√∫mero de dataciones y la realizaci√≥n de diversos estudios en los √∫ltimos a√±os, las perspectivas de investigaci√≥n sobre el Bronce final en el Levante comienza a variar sustancialmente, estando ya en condi...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 6/9 con prompt_zero_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Llama-3.2-3B-instruct\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. En la actualidad, El Argar sigue siendo el grupo arqueo¬≠ l√≥gico de la Edad del Bronce mejor conocido de la pen√≠nsula ib√©rica, con un desarrollo temporal entre el 2200 y el 1550 cal BC. Tambi√©n se puede afirmar que fue una de las sociedades con mayor capacidad productiva y desarrollo social de la E...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Respuestas v√°lidas generadas con prompt_zero_shot: 6\n",
      "\n",
      "EVALUANDO: prompt_zero_shot + all-MiniLM-L6-v2\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 m√©tricas en batches de 2\n",
      "   üîÑ Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39bc2025ad63498fb573b9ba9423bfa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15316af68c264e46808b936fe476bf78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d89cff9ca7114170ba656514e4a5c361",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "358ba34e49014bbaaa01fcd822e0db61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 m√©tricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   üîÑ Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b75e79fbedde4b64a17583c6662ba919",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b698712df6f649a9a6f45ea5f0c76133",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f2c95d23e6d47b9a0ab46805ea6b30e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df6243bdba2844ae905a3a3d8a94f314",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 m√©tricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   üîÑ Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3c71764819c4e22b20e1e3d91630c92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41137bb4d8c64713a2044ef51d4996e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4581505ba90042fa817733e229560696",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fa2e4e40ab049dd97ba1ad0868e5b35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 m√©tricas\n",
      "Evaluaci√≥n completada: 6 preguntas con 4 m√©tricas\n",
      "\n",
      "COMBINACI√ìN: prompt_zero_shot + all-MiniLM-L6-v2\n",
      "   context_precision: 0.317\n",
      "   context_recall: 0.157\n",
      "   faithfulness: 0.566\n",
      "   answer_correctness: 0.223\n",
      "\n",
      "EVALUANDO: prompt_zero_shot + e5-large-instruct\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 m√©tricas en batches de 2\n",
      "   üîÑ Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "714157d681c54c7398621b9220aab1cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2a7fd3f24de4245bd2dfec8a863336b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad8ee4deb62e47bf8257018338eba794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2783c33e5d6549e7ab2ea15bdef3dfbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 m√©tricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   üîÑ Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc6fb0229d9447cd88031b30345d7571",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4829a72708446c89307d0783a156a77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d3f15030d074d12ab68bf485ceaebbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "971dd70a5b694e9b8a42b0f053e32180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 m√©tricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   üîÑ Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "196edfd091594f9ea5163138594f2dce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29da80131c574b87a607623c89dbac9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f31d174ffd964a0a8fa11a4ab29b31bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d97d96cd8c7a415fa76b0da4f9b6a942",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 m√©tricas\n",
      "Evaluaci√≥n completada: 6 preguntas con 4 m√©tricas\n",
      "\n",
      "COMBINACI√ìN: prompt_zero_shot + e5-large-instruct\n",
      "   context_precision: 0.365\n",
      "   context_recall: 0.217\n",
      "   faithfulness: 0.626\n",
      "   answer_correctness: 0.350\n",
      "\n",
      "EVALUANDO: prompt_zero_shot + gte-multilingual-base\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 m√©tricas en batches de 2\n",
      "   üîÑ Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a81b969b2a04bf3bf677a1603be39a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4ec50318d1b411cbe521a6e2e56337b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb8a343815534f6fab9fe4fdc62be8d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b61c4becab04fd4a0a27c535a71aa60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 m√©tricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   üîÑ Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53898a4b33f142d7833ad72164686d85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1507690f15a443c28c33948e5715bf43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a8a55021bcf4a41b06d5936b3460f89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f79d3293722c407080ce8fe6d3be7388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 m√©tricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   üîÑ Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daccb81e5bee49cca4e491142ec92b23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "515afd9de0b14ef1899b413885d2a1a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0f5441fcd47433690ae32c9cb0dc1d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d83a4e8ad72e41c798914c43d603f676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 m√©tricas\n",
      "Evaluaci√≥n completada: 6 preguntas con 4 m√©tricas\n",
      "\n",
      "COMBINACI√ìN: prompt_zero_shot + gte-multilingual-base\n",
      "   context_precision: 0.390\n",
      "   context_recall: 0.129\n",
      "   faithfulness: 0.598\n",
      "   answer_correctness: 0.379\n",
      "\n",
      "PAUSA ENTRE PROMPTS: 300 segundos...\n",
      "\n",
      "EVALUANDO CON PROMPT: prompt_one_shot\n",
      "================================================================================\n",
      "Generando respuestas con LangGraph...\n",
      "Procesando pregunta 1/9 con prompt_one_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Llama-3.2-3B-instruct\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Published by Elsevier Inc. All rights reserved. doi:10.1016/j.yqres.2011.12.003 Contents lists available at SciVerse ScienceDirect Quaternary Research journal homepage: www.elsevier.com/locate/yqres https://doi.org/10.1016/j.yqres.2011.12.003 Published online by Cambridge University Press Introduc...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 2/9 con prompt_one_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Llama-3.2-3B-instruct\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. A data obtida, √© claramente mais recuada que os con¬≠ textos mais antigos reportados em territ√≥rio hoje portu¬≠ gu√™s, nomeadamente Gruta da Nascente do Rio Almonda (OxA¬≠‚Äë9287 ‚Äì 5480¬≠‚Äë5320 cal BC a 2 sigmas) e da Gruta do Caldeir√£o (OxA¬≠‚Äë1036 ‚Äì 5480 ‚Äì 5070 cal BC a 2 sigmas). Entre n√≥s, apenas se rep...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 3/9 con prompt_one_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Llama-3.2-3B-instruct\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 2. ENCUADRE CRONO-CULTURAL DEL HA- LLAZGO: COGOTAS I Entre las entidades arqueol√≥gicas de la Edad del Bronce peninsular, Cogotas I sobresale por su extensa cobertura geogr√°fica, que desborda la Meseta por el Valle del Ebro y Extremadura, y por su dilatada crono- log√≠a ‚Äîc. 1800-1150 cal BC, cubrien...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 4/9 con prompt_one_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Llama-3.2-3B-instruct\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. y NEIRA, A. (1999): ‚ÄúPrehistoria‚Äù, en M.A. Rabanal Alonso (coord.): La His¬≠ toria de Le√≥n, tomo I, Universidad de Le√≥n y Diario de Le√≥n. CELIS S√ÅNCHEZ, J. (1993a): ‚ÄúLa secuencia del poblado de la Primera Edad del Hierro de los ¬´Cuestos de la Estaci√≥n¬ª, Benavente, Zamora‚Äù, en F. Romero, C. Sanz y Z...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 5/9 con prompt_one_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Llama-3.2-3B-instruct\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Con el desarrollo de las excavaciones arqueol√≥gicas en diversos asentamientos, el aumento del n√∫mero de dataciones y la realizaci√≥n de diversos estudios en los √∫ltimos a√±os, las perspectivas de investigaci√≥n sobre el Bronce final en el Levante comienza a variar sustancialmente, estando ya en condi...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 6/9 con prompt_one_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Llama-3.2-3B-instruct\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. En la actualidad, El Argar sigue siendo el grupo arqueo¬≠ l√≥gico de la Edad del Bronce mejor conocido de la pen√≠nsula ib√©rica, con un desarrollo temporal entre el 2200 y el 1550 cal BC. Tambi√©n se puede afirmar que fue una de las sociedades con mayor capacidad productiva y desarrollo social de la E...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Respuestas v√°lidas generadas con prompt_one_shot: 6\n",
      "\n",
      "EVALUANDO: prompt_one_shot + all-MiniLM-L6-v2\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 m√©tricas en batches de 2\n",
      "   üîÑ Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb383fb6507f42a1b4e11bbecec69d3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aba0e1a17ec84cfbb4aa99209d5a32dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "915c35a2ab204c07ba1f9c6e0f1949c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a9ad39ff09d43458bbe7df603ce7a84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 m√©tricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   üîÑ Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d489d5f0dd584058a720cb4fd5e924b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "107a6a8eb8804c7ba7cbe4e86f064e0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "029baf081b7047fa9968c2054d57d798",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e22f7add65fa49aeb6f713f83787d278",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 m√©tricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   üîÑ Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd2e8958eb9d4fbbbcce91b5fcd7c6d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1f8f33bb6b14868ac9e7765f347ce09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bbb805c818e451f8676e73b84a05834",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e042018fa7647eda0acd35cef9ce4e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 m√©tricas\n",
      "Evaluaci√≥n completada: 6 preguntas con 4 m√©tricas\n",
      "\n",
      "COMBINACI√ìN: prompt_one_shot + all-MiniLM-L6-v2\n",
      "   context_precision: 0.478\n",
      "   context_recall: 0.273\n",
      "   faithfulness: 0.754\n",
      "   answer_correctness: 0.218\n",
      "\n",
      "EVALUANDO: prompt_one_shot + e5-large-instruct\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 m√©tricas en batches de 2\n",
      "   üîÑ Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f708d9d6181e4de1b7f15fdd77bb2a33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fb6864ee3fa457a8b45909e5901a2e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "652fbadd50a146fd944f135b342884f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd4f469eb2984a9d89b4a590852a4e34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 m√©tricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   üîÑ Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edf89a19651d4c42bb511111c8d08fa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e02294f4aae42b5b937a8bef72dd8bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b44db4a9d433485e848f53e10a26ca54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85f6c1738c6946ba911fd2a130434e13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 m√©tricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   üîÑ Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9384942366734acdac5812fb287bd189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a2d49bac80d423699bec407bb4be33c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57fd992e307f45ccbe4681e56c22b61e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b33f816fafc84c71b40d6141ccedee6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 m√©tricas\n",
      "Evaluaci√≥n completada: 6 preguntas con 4 m√©tricas\n",
      "\n",
      "COMBINACI√ìN: prompt_one_shot + e5-large-instruct\n",
      "   context_precision: 0.450\n",
      "   context_recall: 0.323\n",
      "   faithfulness: 0.733\n",
      "   answer_correctness: 0.353\n",
      "\n",
      "EVALUANDO: prompt_one_shot + gte-multilingual-base\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 m√©tricas en batches de 2\n",
      "   üîÑ Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a909a6359b342df84217ae431976124",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a496ef569db04126bcbbeab8167782d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3d4c429365140828c89332c8c3deba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af74ae2ef749474ca1db5bf58df84e16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 m√©tricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   üîÑ Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5919125796fc4010b8ac3ad84509225e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee500f96c6c9422c98674a633fd30983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "Exception raised in Job[0]: OutputParserException(Invalid json output: ```json\\n{\\n    \"classifications\": [\\n        {\\n            \"statement\": \"Las primeras manifestaciones funerarias datadas se sit√∫an en la primera mitad del V milenio con una estimaci√≥n probabil√≠stica para su inicio de entre el 4975-4785 cal BC (68% de probabilidad) y entre el 4740-4570 cal BC (68% de probabilidad).\",\\n            \"reason\": \"El contexto menciona expl√≠citamente las cronolog√≠as de las primeras manifestaciones funerarias en la pen√≠nsula ib√©rica, incluyendo fechas espec√≠ficas del V milenio cal BC.\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"Las manifestaciones funerarias del Mesol√≠tico en las distintas regiones peninsulares.\\n            \"reason\": \"El contexto no proporciona informaci√≥n espec√≠fica sobre el Mesol√≠tico, ya que se centra en el Neol√≠tico, Calcol√≠tico y Edad del Bronce.\\n            \"attributed\": 0\\n        },\\n        {\\n            \"statement\": \"Las dataciones radiocarb√≥nicas de asentamientos neol√≠ticos se sit√∫an a finales del VI milenio y en la primera mitad del V milenio cal BC.\\n            \"reason\": \"El contexto menciona fechas radiocarb√≥nicas de asentamientos neol√≠ticos, aunque no se especifica su relaci√≥n directa con manifestaciones funerarias.\\n            \"attributed\": 0.5\\n        }\\n    ]\\n}\\n```\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69f98bc79019472895b4145006ab336e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a90e8c5fa7ca40b98ba91ddae795db22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 m√©tricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   üîÑ Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "965b806ff4174d789deb3349f59fe14a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a0f6727983246dd924cd1dbb2e93053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45d6820f1f694e64b5771a7c82a728da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8223633604b4b7f8ec2108c5cb8b709",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 m√©tricas\n",
      "Evaluaci√≥n completada: 6 preguntas con 4 m√©tricas\n",
      "\n",
      "COMBINACI√ìN: prompt_one_shot + gte-multilingual-base\n",
      "   context_precision: 0.479\n",
      "   context_recall: 0.105\n",
      "   faithfulness: 0.746\n",
      "   answer_correctness: 0.246\n",
      "\n",
      "PAUSA ENTRE PROMPTS: 300 segundos...\n",
      "\n",
      "EVALUANDO CON PROMPT: prompt_few_shot\n",
      "================================================================================\n",
      "Generando respuestas con LangGraph...\n",
      "Procesando pregunta 1/9 con prompt_few_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Llama-3.2-3B-instruct\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Published by Elsevier Inc. All rights reserved. doi:10.1016/j.yqres.2011.12.003 Contents lists available at SciVerse ScienceDirect Quaternary Research journal homepage: www.elsevier.com/locate/yqres https://doi.org/10.1016/j.yqres.2011.12.003 Published online by Cambridge University Press Introduc...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 2/9 con prompt_few_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Llama-3.2-3B-instruct\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. A data obtida, √© claramente mais recuada que os con¬≠ textos mais antigos reportados em territ√≥rio hoje portu¬≠ gu√™s, nomeadamente Gruta da Nascente do Rio Almonda (OxA¬≠‚Äë9287 ‚Äì 5480¬≠‚Äë5320 cal BC a 2 sigmas) e da Gruta do Caldeir√£o (OxA¬≠‚Äë1036 ‚Äì 5480 ‚Äì 5070 cal BC a 2 sigmas). Entre n√≥s, apenas se rep...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 3/9 con prompt_few_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Llama-3.2-3B-instruct\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 2. ENCUADRE CRONO-CULTURAL DEL HA- LLAZGO: COGOTAS I Entre las entidades arqueol√≥gicas de la Edad del Bronce peninsular, Cogotas I sobresale por su extensa cobertura geogr√°fica, que desborda la Meseta por el Valle del Ebro y Extremadura, y por su dilatada crono- log√≠a ‚Äîc. 1800-1150 cal BC, cubrien...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 4/9 con prompt_few_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Llama-3.2-3B-instruct\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. y NEIRA, A. (1999): ‚ÄúPrehistoria‚Äù, en M.A. Rabanal Alonso (coord.): La His¬≠ toria de Le√≥n, tomo I, Universidad de Le√≥n y Diario de Le√≥n. CELIS S√ÅNCHEZ, J. (1993a): ‚ÄúLa secuencia del poblado de la Primera Edad del Hierro de los ¬´Cuestos de la Estaci√≥n¬ª, Benavente, Zamora‚Äù, en F. Romero, C. Sanz y Z...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 5/9 con prompt_few_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Llama-3.2-3B-instruct\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Con el desarrollo de las excavaciones arqueol√≥gicas en diversos asentamientos, el aumento del n√∫mero de dataciones y la realizaci√≥n de diversos estudios en los √∫ltimos a√±os, las perspectivas de investigaci√≥n sobre el Bronce final en el Levante comienza a variar sustancialmente, estando ya en condi...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 6/9 con prompt_few_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Llama-3.2-3B-instruct\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. En la actualidad, El Argar sigue siendo el grupo arqueo¬≠ l√≥gico de la Edad del Bronce mejor conocido de la pen√≠nsula ib√©rica, con un desarrollo temporal entre el 2200 y el 1550 cal BC. Tambi√©n se puede afirmar que fue una de las sociedades con mayor capacidad productiva y desarrollo social de la E...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Respuestas v√°lidas generadas con prompt_few_shot: 6\n",
      "\n",
      "EVALUANDO: prompt_few_shot + all-MiniLM-L6-v2\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 m√©tricas en batches de 2\n",
      "   üîÑ Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25903638dd1f4d90b7f5ca2b2524f834",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69dc88d315b2481da99ba42280e316e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6891c162ac5e472396675007d8055435",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67fdab0b9b6f4a0abe292ecc95610764",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 m√©tricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   üîÑ Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e27195b9863483397653f90f69c639d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb8a2226432745bb975cc55534012f96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7ac28ac444a442fa9999bdd8074e990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eab138e0272f41119df95bd396b2fbca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 m√©tricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   üîÑ Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c86f20e755b446196cdfd99d87168c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "febf16cfc41043a5986f024267f68f37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4649337582224404ac4a5c5c734449cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93bd17f6e7804a2a9fd33834fa9d48b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 m√©tricas\n",
      "Evaluaci√≥n completada: 6 preguntas con 4 m√©tricas\n",
      "\n",
      "COMBINACI√ìN: prompt_few_shot + all-MiniLM-L6-v2\n",
      "   context_precision: 0.427\n",
      "   context_recall: 0.254\n",
      "   faithfulness: 0.763\n",
      "   answer_correctness: 0.322\n",
      "\n",
      "EVALUANDO: prompt_few_shot + e5-large-instruct\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 m√©tricas en batches de 2\n",
      "   üîÑ Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1affaa86e0144365888e15467c43c280",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cf1945bdb874d59b886518aca13f866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6fb726a162c42b29776d71bbb0a0081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ccf6edd1ba4490183ffcc80d4111f85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 m√©tricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   üîÑ Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15060a6392a348098d7de0c64e7e04c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8846a1cb86114a2dae181d16a05ad05c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7276bd789046418eb2cf4f227f9e3b1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09ad349f74524fc898cad791413ac7ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 m√©tricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   üîÑ Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c92a5ae5edf94339a7d80a6ad02179bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daaf8fd62d75414084c7d1186be394b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a97581f02a41423990714856bf48afe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "473f7586930f48ec85bb60cafac79320",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 m√©tricas\n",
      "Evaluaci√≥n completada: 6 preguntas con 4 m√©tricas\n",
      "\n",
      "COMBINACI√ìN: prompt_few_shot + e5-large-instruct\n",
      "   context_precision: 0.420\n",
      "   context_recall: 0.187\n",
      "   faithfulness: 0.745\n",
      "   answer_correctness: 0.472\n",
      "\n",
      "EVALUANDO: prompt_few_shot + gte-multilingual-base\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 m√©tricas en batches de 2\n",
      "   üîÑ Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17b942307d4f474886063d9858ac0916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20008a6b98d04250b3fb0a5ba4ecd150",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2335b71c1a624050bbe76ec932b476b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44977d7ff766468791b25ebf64571a41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 m√©tricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   üîÑ Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b51ba5af0415418cb0b5798fb3b3980b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34dc1b58a9534bd7a359b823450c8be8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e45d07e1c5564c6fae2c545503b4d3cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f3942fd460544e4aa60f5c08f732cd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 m√©tricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   üîÑ Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58b44e595d7146a89c3754fabf32106e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42be9723305149d58b5f8dd45e2210fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "969edb4545914b129b9451afff54b090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b20a25f2d73e4e68913e4113732325f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 m√©tricas\n",
      "Evaluaci√≥n completada: 6 preguntas con 4 m√©tricas\n",
      "\n",
      "COMBINACI√ìN: prompt_few_shot + gte-multilingual-base\n",
      "   context_precision: 0.248\n",
      "   context_recall: 0.300\n",
      "   faithfulness: 0.782\n",
      "   answer_correctness: 0.233\n",
      "\"EVALUACI√ìN COMPLETA\n",
      "\n",
      "TABLA DE RESULTADOS:\n",
      "====================================================================================================\n",
      "\n",
      "PROMPT: prompt_zero_shot\n",
      "all-MiniLM-L6-v2:\n",
      "      context_precision: 0.317\n",
      "      context_recall: 0.157\n",
      "      faithfulness: 0.566\n",
      "      answer_correctness: 0.223\n",
      "e5-large-instruct:\n",
      "      context_precision: 0.365\n",
      "      context_recall: 0.217\n",
      "      faithfulness: 0.626\n",
      "      answer_correctness: 0.350\n",
      "gte-multilingual-base:\n",
      "      context_precision: 0.390\n",
      "      context_recall: 0.129\n",
      "      faithfulness: 0.598\n",
      "      answer_correctness: 0.379\n",
      "\n",
      "PROMPT: prompt_one_shot\n",
      "all-MiniLM-L6-v2:\n",
      "      context_precision: 0.478\n",
      "      context_recall: 0.273\n",
      "      faithfulness: 0.754\n",
      "      answer_correctness: 0.218\n",
      "e5-large-instruct:\n",
      "      context_precision: 0.450\n",
      "      context_recall: 0.323\n",
      "      faithfulness: 0.733\n",
      "      answer_correctness: 0.353\n",
      "gte-multilingual-base:\n",
      "      context_precision: 0.479\n",
      "      context_recall: 0.105\n",
      "      faithfulness: 0.746\n",
      "      answer_correctness: 0.246\n",
      "\n",
      "PROMPT: prompt_few_shot\n",
      "all-MiniLM-L6-v2:\n",
      "      context_precision: 0.427\n",
      "      context_recall: 0.254\n",
      "      faithfulness: 0.763\n",
      "      answer_correctness: 0.322\n",
      "e5-large-instruct:\n",
      "      context_precision: 0.420\n",
      "      context_recall: 0.187\n",
      "      faithfulness: 0.745\n",
      "      answer_correctness: 0.472\n",
      "gte-multilingual-base:\n",
      "      context_precision: 0.248\n",
      "      context_recall: 0.300\n",
      "      faithfulness: 0.782\n",
      "      answer_correctness: 0.233\n"
     ]
    }
   ],
   "source": [
    "# Evaluar TODAS las combinaciones: 3 prompts √ó 3 embeddings = 9 combinaciones\n",
    "resultados_completos = {}\n",
    "\n",
    "prompts_list = ['prompt_zero_shot', 'prompt_one_shot', 'prompt_few_shot']\n",
    "\n",
    "for prompt_name in prompts_list:\n",
    "    print(f\"\\nEVALUANDO CON PROMPT: {prompt_name}\")\n",
    "    print(\"=\"*80)\n",
    "    # CAMBIAR EL TEMPLATE GLOBAL (esto es lo clave)\n",
    "    selected_template = PROMPTS[prompt_name]\n",
    "    prompt_template = ChatPromptTemplate.from_template(selected_template)\n",
    "\n",
    "    # Generar respuestas con este prompt espec√≠fico\n",
    "    results_list_prompt = []\n",
    "\n",
    "    # Necesitas generar las respuestas con tu grafo de LangGraph primero\n",
    "    print(\"Generando respuestas con LangGraph...\")\n",
    "\n",
    "    for i, (question, ground_truth) in enumerate(zip(questions, ground_truths)):\n",
    "        print(f\"Procesando pregunta {i+1}/{len(questions)} con {prompt_name}\")\n",
    "\n",
    "        # Aqu√≠ usas tu grafo de LangGraph para generar la respuesta\n",
    "        state = {\n",
    "            'question': question,\n",
    "            'llm_name': 'Llama-3.2-3B-instruct',  # Tu LLM de generaci√≥n\n",
    "            'embedding_name': 'all-MiniLM-L6-v2',  # Se cambiar√° en el bucle    \n",
    "            'prompt_name': prompt_name,\n",
    "            'context': [],\n",
    "            'answer': '',\n",
    "            'metadata': {}\n",
    "        }\n",
    "        try:\n",
    "            # INVOCAR TU GRAFO (ajusta seg√∫n tu c√≥digo)\n",
    "            final_state = graph.invoke(state)\n",
    "            answer = final_state.get('answer', '')\n",
    "            contexts = final_state.get('context', [])\n",
    "\n",
    "            if answer and answer.strip():  # Verificar que hay respuesta\n",
    "                  results_list_prompt.append({\n",
    "                      'question': question,\n",
    "                      'answer': answer,\n",
    "                      'contexts': [doc.page_content for doc in contexts] if contexts else ['Sin contexto'],\n",
    "                      'ground_truth': ground_truth\n",
    "                  })\n",
    "            else:\n",
    "                  print(f\"Pregunta {i+1} sin respuesta v√°lida\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error en pregunta {i+1}: {e}\")\n",
    "\n",
    "    print(f\"Respuestas v√°lidas generadas con {prompt_name}: {len(results_list_prompt)}\")\n",
    "\n",
    "      # Solo evaluar si tenemos respuestas v√°lidas\n",
    "    if len(results_list_prompt) >= 2:\n",
    "          # EVALUAR CON LOS 3 EMBEDDINGS\n",
    "        resultados_por_embedding = {}\n",
    "\n",
    "        for embedding_name, current_embedding_model in EMBEDDING_MODELS.items():\n",
    "            print(f\"\\nEVALUANDO: {prompt_name} + {embedding_name}\")\n",
    "            print(\"-\"*60)\n",
    "\n",
    "            resultado = evaluate_with_mistral_four_metrics(\n",
    "                results_list=results_list_prompt,\n",
    "                  embedding_model=current_embedding_model,\n",
    "                  max_batch_size=2,\n",
    "                  delay_between_batches=120\n",
    "            )\n",
    "\n",
    "            resultados_por_embedding[embedding_name] = resultado\n",
    "\n",
    "              # Mostrar m√©tricas promedio\n",
    "            print(f\"\\nCOMBINACI√ìN: {prompt_name} + {embedding_name}\")\n",
    "            for metric in ['context_precision', 'context_recall', 'faithfulness', 'answer_correctness']:\n",
    "                if metric in resultado.columns:\n",
    "                    valores = resultado[metric].dropna()\n",
    "                    if len(valores) > 0:\n",
    "                        print(f\"   {metric}: {valores.mean():.3f}\")\n",
    "                    else:\n",
    "                        print(f\"   {metric}: Sin valores v√°lidos\")\n",
    "\n",
    "            time.sleep(90)  # Pausa entre embeddings\n",
    "\n",
    "          # Guardar resultados de este prompt\n",
    "        resultados_completos[prompt_name] = resultados_por_embedding\n",
    "\n",
    "    else:\n",
    "        print(f\"No hay suficientes respuestas v√°lidas para {prompt_name}, saltando evaluaci√≥n\")\n",
    "\n",
    "    if prompt_name != prompts_list[-1]:\n",
    "        print(f\"\\nPAUSA ENTRE PROMPTS: 300 segundos...\")\n",
    "        time.sleep(300)\n",
    "\n",
    "print(\"\\\"EVALUACI√ìN COMPLETA\")\n",
    "\n",
    "  # Mostrar tabla final\n",
    "print(\"\\nTABLA DE RESULTADOS:\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "for prompt_name, embeddings_results in resultados_completos.items():\n",
    "    print(f\"\\nPROMPT: {prompt_name}\")\n",
    "    for embedding_name, resultado in embeddings_results.items():\n",
    "        print(f\"{embedding_name}:\")\n",
    "        for metric in ['context_precision', 'context_recall', 'faithfulness', 'answer_correctness']:\n",
    "            if metric in resultado.columns:\n",
    "                valores = resultado[metric].dropna()\n",
    "                if len(valores) > 0:\n",
    "                    print(f\"      {metric}: {valores.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EVALUACI√ìN COM LLAMA QUE NO FUNCIONA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFIGURACI√ìN DE EVALUACI√ìN:\n",
      "LLM Evaluador (RAGAS): hf.co/bartowski/Llama-3.2-3B-Instruct-GGUF:Q8_0\n",
      "LLMs Generadores: Qwen3-4B-instruct-2507, Phi-3.5-mini-instruct\n",
      "M√©tricas: context_precision, context_recall, faithfulness, answer_correctness\n",
      "Embeddings espec√≠ficos para answer_correctness por combinaci√≥n\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "  # Importar RAGAS y m√©tricas\n",
    "from ragas import evaluate  \n",
    "from ragas.metrics import (\n",
    "    context_precision,\n",
    "    context_recall,\n",
    "    faithfulness,\n",
    "    answer_correctness\n",
    "    \n",
    "    \n",
    "    )\n",
    "\n",
    "  # CONFIGURAR LLAMA COMO EVALUADOR PARA RAGAS\n",
    "from langchain_ollama import ChatOllama\n",
    "llama_evaluator = ChatOllama(\n",
    "    model=\"hf.co/bartowski/Llama-3.2-3B-Instruct-GGUF:Q8_0\", \n",
    "    temperature=0.1,\n",
    "    num_predict=200,\n",
    "    timeout=1200,  # 15 minutos para Llama 3B\n",
    "    num_ctx=4096,\n",
    "    num_thread=8\n",
    ")\n",
    "\n",
    "print(\"CONFIGURACI√ìN DE EVALUACI√ìN:\")\n",
    "print(f\"LLM Evaluador (RAGAS): {llama_evaluator.model}\")\n",
    "print(\"LLMs Generadores: Qwen3-4B-instruct-2507, Phi-3.5-mini-instruct\")\n",
    "print(\"M√©tricas: context_precision, context_recall, faithfulness, answer_correctness\")\n",
    "print(\"Embeddings espec√≠ficos para answer_correctness por combinaci√≥n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "  # Variables comunes\n",
    "embeddings = list(EMBEDDING_MODELS.keys())\n",
    "prompts = list(PROMPTS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUACI√ìN CON GENERADOR QWEN\n",
      "Generador: Qwen3-4B-instruct-2507\n",
      "Evaluador: hf.co/bartowski/Llama-3.2-3B-Instruct-GGUF:Q8_0\n",
      "============================================================\n",
      "Evaluando 9 combinaciones para Qwen:\n",
      "   ‚Ä¢ Qwen3-4B-instruct-2507 + all-MiniLM-L6-v2 + prompt_zero_shot\n",
      "   ‚Ä¢ Qwen3-4B-instruct-2507 + all-MiniLM-L6-v2 + prompt_one_shot\n",
      "   ‚Ä¢ Qwen3-4B-instruct-2507 + all-MiniLM-L6-v2 + prompt_few_shot\n",
      "   ‚Ä¢ Qwen3-4B-instruct-2507 + e5-large-instruct + prompt_zero_shot\n",
      "   ‚Ä¢ Qwen3-4B-instruct-2507 + e5-large-instruct + prompt_one_shot\n",
      "   ‚Ä¢ Qwen3-4B-instruct-2507 + e5-large-instruct + prompt_few_shot\n",
      "   ‚Ä¢ Qwen3-4B-instruct-2507 + gte-multilingual-base + prompt_zero_shot\n",
      "   ‚Ä¢ Qwen3-4B-instruct-2507 + gte-multilingual-base + prompt_one_shot\n",
      "   ‚Ä¢ Qwen3-4B-instruct-2507 + gte-multilingual-base + prompt_few_shot\n",
      "\n",
      "QWEN COMBINACI√ìN 1/9\n",
      "   Generador: Qwen3-4B-instruct-2507\n",
      "   Embedding: all-MiniLM-L6-v2 -> IdearqAllMiniLM\n",
      "   Prompt: prompt_zero_shot\n",
      "Generando respuestas con Qwen...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Published by Elsevier Inc. All rights reserved. doi:10.1016/j.yqres.2011.12.003 Contents lists available at SciVerse ScienceDirect Quaternary Research journal homepage: www.elsevier.com/locate/yqres https://doi.org/10.1016/j.yqres.2011.12.003 Published online by Cambridge University Press Introduc...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  12%|‚ñà‚ñé        | 1/8 [04:20<30:22, 260.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. A data obtida, √© claramente mais recuada que os con¬≠ textos mais antigos reportados em territ√≥rio hoje portu¬≠ gu√™s, nomeadamente Gruta da Nascente do Rio Almonda (OxA¬≠‚Äë9287 ‚Äì 5480¬≠‚Äë5320 cal BC a 2 sigmas) e da Gruta do Caldeir√£o (OxA¬≠‚Äë1036 ‚Äì 5480 ‚Äì 5070 cal BC a 2 sigmas). Entre n√≥s, apenas se rep...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  25%|‚ñà‚ñà‚ñå       | 2/8 [05:24<14:29, 144.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 2. ENCUADRE CRONO-CULTURAL DEL HA- LLAZGO: COGOTAS I Entre las entidades arqueol√≥gicas de la Edad del Bronce peninsular, Cogotas I sobresale por su extensa cobertura geogr√°fica, que desborda la Meseta por el Valle del Ebro y Extremadura, y por su dilatada crono- log√≠a ‚Äîc. 1800-1150 cal BC, cubrien...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  38%|‚ñà‚ñà‚ñà‚ñä      | 3/8 [06:24<08:51, 106.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. y NEIRA, A. (1999): ‚ÄúPrehistoria‚Äù, en M.A. Rabanal Alonso (coord.): La His¬≠ toria de Le√≥n, tomo I, Universidad de Le√≥n y Diario de Le√≥n. CELIS S√ÅNCHEZ, J. (1993a): ‚ÄúLa secuencia del poblado de la Primera Edad del Hierro de los ¬´Cuestos de la Estaci√≥n¬ª, Benavente, Zamora‚Äù, en F. Romero, C. Sanz y Z...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4/8 [07:42<06:19, 94.98s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Con el desarrollo de las excavaciones arqueol√≥gicas en diversos asentamientos, el aumento del n√∫mero de dataciones y la realizaci√≥n de diversos estudios en los √∫ltimos a√±os, las perspectivas de investigaci√≥n sobre el Bronce final en el Levante comienza a variar sustancialmente, estando ya en condi...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5/8 [13:44<09:33, 191.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. En la actualidad, El Argar sigue siendo el grupo arqueo¬≠ l√≥gico de la Edad del Bronce mejor conocido de la pen√≠nsula ib√©rica, con un desarrollo temporal entre el 2200 y el 1550 cal BC. Tambi√©n se puede afirmar que fue una de las sociedades con mayor capacidad productiva y desarrollo social de la E...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6/8 [16:00<05:44, 172.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Prehist., 74, N.¬∫ 2, julio-diciembre 2017, pp. 296-318, ISSN: 0082-5638 doi: 10.3989/tp.2017.12196 Torres Ortiz, M. 1996: ‚ÄúLa cronolog√≠a de los t√∫mulos A y B de Setefilla. El origen del rito de la crema- ci√≥n en la cultura tart√©sica‚Äù. Complutum 7: 147-162. Torres Ortiz, M. 1998: ‚ÄúLa cronolog√≠a abs...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 7/8 [17:32<02:26, 146.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Ruiz Alonso, M. Guenaga, A., L√≥pez Quintana, J. C. y Zapata Pe√±a, L. (2010). Antracolog√≠a y yacimientos dolm√©nicos: el caso de Mendigana. En Actas del Congreso Internacional sobre Megalitismo y otras manifestaciones funerarias con- tempor√°neas en su contexto social, econ√≥mico y cultural (pp. 566-5...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [19:15<00:00, 144.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "8/8 preguntas exitosas\n",
      "Evaluando respuestas de Qwen con Llama...\n",
      "Procesando 8 preguntas en lotes de 4...\n",
      "   Evaluando lote 1/2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a656c7e5c0f45198c3cbe3d0c521ac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[1]: TimeoutError()\n",
      "Exception raised in Job[7]: TimeoutError()\n",
      "Exception raised in Job[2]: TimeoutError()\n",
      "Exception raised in Job[4]: TimeoutError()\n",
      "Exception raised in Job[3]: TimeoutError()\n",
      "Exception raised in Job[6]: TimeoutError()\n",
      "Exception raised in Job[5]: TimeoutError()\n",
      "Exception raised in Job[9]: TimeoutError()\n",
      "Exception raised in Job[10]: TimeoutError()\n",
      "Exception raised in Job[8]: TimeoutError()\n",
      "Exception raised in Job[11]: TimeoutError()\n",
      "Exception raised in Job[14]: TimeoutError()\n",
      "Exception raised in Job[13]: TimeoutError()\n",
      "Exception raised in Job[12]: TimeoutError()\n",
      "Exception raised in Job[15]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Evaluando lote 2/2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5488aa3a17e34d6898c5b8554301c273",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[2]: TimeoutError()\n",
      "Exception raised in Job[4]: TimeoutError()\n",
      "Exception raised in Job[3]: TimeoutError()\n",
      "Exception raised in Job[6]: TimeoutError()\n",
      "Exception raised in Job[5]: TimeoutError()\n",
      "Exception raised in Job[7]: TimeoutError()\n",
      "Exception raised in Job[9]: TimeoutError()\n",
      "Exception raised in Job[8]: TimeoutError()\n",
      "Exception raised in Job[14]: TimeoutError()\n",
      "Exception raised in Job[11]: TimeoutError()\n",
      "Exception raised in Job[10]: TimeoutError()\n",
      "Exception raised in Job[12]: TimeoutError()\n",
      "Exception raised in Job[13]: TimeoutError()\n",
      "Exception raised in Job[15]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Evaluaci√≥n Llama ‚Üí Qwen completada:\n",
      "      Context_Recall: 1.000\n",
      "QWEN COMBINACI√ìN 2/9\n",
      "   Generador: Qwen3-4B-instruct-2507\n",
      "   Embedding: all-MiniLM-L6-v2 -> IdearqAllMiniLM\n",
      "   Prompt: prompt_one_shot\n",
      "Generando respuestas con Qwen...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Published by Elsevier Inc. All rights reserved. doi:10.1016/j.yqres.2011.12.003 Contents lists available at SciVerse ScienceDirect Quaternary Research journal homepage: www.elsevier.com/locate/yqres https://doi.org/10.1016/j.yqres.2011.12.003 Published online by Cambridge University Press Introduc...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  12%|‚ñà‚ñé        | 1/8 [03:42<25:55, 222.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. A data obtida, √© claramente mais recuada que os con¬≠ textos mais antigos reportados em territ√≥rio hoje portu¬≠ gu√™s, nomeadamente Gruta da Nascente do Rio Almonda (OxA¬≠‚Äë9287 ‚Äì 5480¬≠‚Äë5320 cal BC a 2 sigmas) e da Gruta do Caldeir√£o (OxA¬≠‚Äë1036 ‚Äì 5480 ‚Äì 5070 cal BC a 2 sigmas). Entre n√≥s, apenas se rep...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  25%|‚ñà‚ñà‚ñå       | 2/8 [04:52<13:18, 133.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 2. ENCUADRE CRONO-CULTURAL DEL HA- LLAZGO: COGOTAS I Entre las entidades arqueol√≥gicas de la Edad del Bronce peninsular, Cogotas I sobresale por su extensa cobertura geogr√°fica, que desborda la Meseta por el Valle del Ebro y Extremadura, y por su dilatada crono- log√≠a ‚Äîc. 1800-1150 cal BC, cubrien...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  38%|‚ñà‚ñà‚ñà‚ñä      | 3/8 [06:16<09:12, 110.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. y NEIRA, A. (1999): ‚ÄúPrehistoria‚Äù, en M.A. Rabanal Alonso (coord.): La His¬≠ toria de Le√≥n, tomo I, Universidad de Le√≥n y Diario de Le√≥n. CELIS S√ÅNCHEZ, J. (1993a): ‚ÄúLa secuencia del poblado de la Primera Edad del Hierro de los ¬´Cuestos de la Estaci√≥n¬ª, Benavente, Zamora‚Äù, en F. Romero, C. Sanz y Z...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4/8 [07:25<06:16, 94.20s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Con el desarrollo de las excavaciones arqueol√≥gicas en diversos asentamientos, el aumento del n√∫mero de dataciones y la realizaci√≥n de diversos estudios en los √∫ltimos a√±os, las perspectivas de investigaci√≥n sobre el Bronce final en el Levante comienza a variar sustancialmente, estando ya en condi...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5/8 [13:09<09:12, 184.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. En la actualidad, El Argar sigue siendo el grupo arqueo¬≠ l√≥gico de la Edad del Bronce mejor conocido de la pen√≠nsula ib√©rica, con un desarrollo temporal entre el 2200 y el 1550 cal BC. Tambi√©n se puede afirmar que fue una de las sociedades con mayor capacidad productiva y desarrollo social de la E...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6/8 [15:13<05:27, 163.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Prehist., 74, N.¬∫ 2, julio-diciembre 2017, pp. 296-318, ISSN: 0082-5638 doi: 10.3989/tp.2017.12196 Torres Ortiz, M. 1996: ‚ÄúLa cronolog√≠a de los t√∫mulos A y B de Setefilla. El origen del rito de la crema- ci√≥n en la cultura tart√©sica‚Äù. Complutum 7: 147-162. Torres Ortiz, M. 1998: ‚ÄúLa cronolog√≠a abs...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 7/8 [16:22<02:12, 132.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Ruiz Alonso, M. Guenaga, A., L√≥pez Quintana, J. C. y Zapata Pe√±a, L. (2010). Antracolog√≠a y yacimientos dolm√©nicos: el caso de Mendigana. En Actas del Congreso Internacional sobre Megalitismo y otras manifestaciones funerarias con- tempor√°neas en su contexto social, econ√≥mico y cultural (pp. 566-5...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [17:49<00:00, 133.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "8/8 preguntas exitosas\n",
      "Evaluando respuestas de Qwen con Llama...\n",
      "Procesando 8 preguntas en lotes de 4...\n",
      "   Evaluando lote 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6f5a9dad2dc4720ad057920de96f5b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[1]: TimeoutError()\n",
      "Exception raised in Job[2]: TimeoutError()\n",
      "Exception raised in Job[4]: TimeoutError()\n",
      "Exception raised in Job[3]: TimeoutError()\n",
      "Exception raised in Job[6]: TimeoutError()\n",
      "Exception raised in Job[5]: TimeoutError()\n",
      "Exception raised in Job[7]: TimeoutError()\n",
      "Exception raised in Job[9]: TimeoutError()\n",
      "Exception raised in Job[10]: TimeoutError()\n",
      "Exception raised in Job[11]: TimeoutError()\n",
      "Exception raised in Job[8]: TimeoutError()\n",
      "Exception raised in Job[13]: TimeoutError()\n",
      "Exception raised in Job[14]: TimeoutError()\n",
      "Exception raised in Job[12]: TimeoutError()\n",
      "Exception raised in Job[15]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Evaluando lote 2/2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5351a2a3417d4f6199cade67362ee1e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[2]: TimeoutError()\n",
      "Exception raised in Job[5]: TimeoutError()\n",
      "Exception raised in Job[6]: TimeoutError()\n",
      "Exception raised in Job[4]: TimeoutError()\n",
      "Exception raised in Job[1]: TimeoutError()\n",
      "Exception raised in Job[3]: TimeoutError()\n",
      "Exception raised in Job[12]: TimeoutError()\n",
      "Exception raised in Job[9]: TimeoutError()\n",
      "Exception raised in Job[11]: TimeoutError()\n",
      "Exception raised in Job[10]: TimeoutError()\n",
      "Exception raised in Job[7]: TimeoutError()\n",
      "Exception raised in Job[8]: TimeoutError()\n",
      "Exception raised in Job[13]: TimeoutError()\n",
      "Exception raised in Job[14]: TimeoutError()\n",
      "Exception raised in Job[15]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Evaluaci√≥n Llama ‚Üí Qwen completada:\n",
      "QWEN COMBINACI√ìN 3/9\n",
      "   Generador: Qwen3-4B-instruct-2507\n",
      "   Embedding: all-MiniLM-L6-v2 -> IdearqAllMiniLM\n",
      "   Prompt: prompt_few_shot\n",
      "Generando respuestas con Qwen...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Published by Elsevier Inc. All rights reserved. doi:10.1016/j.yqres.2011.12.003 Contents lists available at SciVerse ScienceDirect Quaternary Research journal homepage: www.elsevier.com/locate/yqres https://doi.org/10.1016/j.yqres.2011.12.003 Published online by Cambridge University Press Introduc...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  12%|‚ñà‚ñé        | 1/8 [03:43<26:04, 223.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. A data obtida, √© claramente mais recuada que os con¬≠ textos mais antigos reportados em territ√≥rio hoje portu¬≠ gu√™s, nomeadamente Gruta da Nascente do Rio Almonda (OxA¬≠‚Äë9287 ‚Äì 5480¬≠‚Äë5320 cal BC a 2 sigmas) e da Gruta do Caldeir√£o (OxA¬≠‚Äë1036 ‚Äì 5480 ‚Äì 5070 cal BC a 2 sigmas). Entre n√≥s, apenas se rep...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  25%|‚ñà‚ñà‚ñå       | 2/8 [04:38<12:27, 124.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 2. ENCUADRE CRONO-CULTURAL DEL HA- LLAZGO: COGOTAS I Entre las entidades arqueol√≥gicas de la Edad del Bronce peninsular, Cogotas I sobresale por su extensa cobertura geogr√°fica, que desborda la Meseta por el Valle del Ebro y Extremadura, y por su dilatada crono- log√≠a ‚Äîc. 1800-1150 cal BC, cubrien...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  38%|‚ñà‚ñà‚ñà‚ñä      | 3/8 [04:56<06:18, 75.66s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. y NEIRA, A. (1999): ‚ÄúPrehistoria‚Äù, en M.A. Rabanal Alonso (coord.): La His¬≠ toria de Le√≥n, tomo I, Universidad de Le√≥n y Diario de Le√≥n. CELIS S√ÅNCHEZ, J. (1993a): ‚ÄúLa secuencia del poblado de la Primera Edad del Hierro de los ¬´Cuestos de la Estaci√≥n¬ª, Benavente, Zamora‚Äù, en F. Romero, C. Sanz y Z...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4/8 [06:14<05:07, 76.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Con el desarrollo de las excavaciones arqueol√≥gicas en diversos asentamientos, el aumento del n√∫mero de dataciones y la realizaci√≥n de diversos estudios en los √∫ltimos a√±os, las perspectivas de investigaci√≥n sobre el Bronce final en el Levante comienza a variar sustancialmente, estando ya en condi...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5/8 [11:55<08:35, 171.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. En la actualidad, El Argar sigue siendo el grupo arqueo¬≠ l√≥gico de la Edad del Bronce mejor conocido de la pen√≠nsula ib√©rica, con un desarrollo temporal entre el 2200 y el 1550 cal BC. Tambi√©n se puede afirmar que fue una de las sociedades con mayor capacidad productiva y desarrollo social de la E...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6/8 [14:49<05:45, 172.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Prehist., 74, N.¬∫ 2, julio-diciembre 2017, pp. 296-318, ISSN: 0082-5638 doi: 10.3989/tp.2017.12196 Torres Ortiz, M. 1996: ‚ÄúLa cronolog√≠a de los t√∫mulos A y B de Setefilla. El origen del rito de la crema- ci√≥n en la cultura tart√©sica‚Äù. Complutum 7: 147-162. Torres Ortiz, M. 1998: ‚ÄúLa cronolog√≠a abs...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 7/8 [15:49<02:15, 135.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Ruiz Alonso, M. Guenaga, A., L√≥pez Quintana, J. C. y Zapata Pe√±a, L. (2010). Antracolog√≠a y yacimientos dolm√©nicos: el caso de Mendigana. En Actas del Congreso Internacional sobre Megalitismo y otras manifestaciones funerarias con- tempor√°neas en su contexto social, econ√≥mico y cultural (pp. 566-5...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [17:21<00:00, 130.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "8/8 preguntas exitosas\n",
      "Evaluando respuestas de Qwen con Llama...\n",
      "Procesando 8 preguntas en lotes de 4...\n",
      "   Evaluando lote 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98adeb6c97f940ba97aed5a3f8a291d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[2]: TimeoutError()\n",
      "Exception raised in Job[1]: TimeoutError()\n",
      "Exception raised in Job[5]: TimeoutError()\n",
      "Exception raised in Job[4]: TimeoutError()\n",
      "Exception raised in Job[3]: TimeoutError()\n",
      "Exception raised in Job[6]: TimeoutError()\n",
      "Exception raised in Job[8]: TimeoutError()\n",
      "Exception raised in Job[7]: TimeoutError()\n",
      "Exception raised in Job[11]: TimeoutError()\n",
      "Exception raised in Job[9]: TimeoutError()\n",
      "Exception raised in Job[10]: TimeoutError()\n",
      "Exception raised in Job[13]: TimeoutError()\n",
      "Exception raised in Job[14]: TimeoutError()\n",
      "Exception raised in Job[12]: TimeoutError()\n",
      "Exception raised in Job[15]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Evaluando lote 2/2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25b1fe6d45da423294d58af8c993bc4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[2]: TimeoutError()\n",
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[1]: TimeoutError()\n",
      "Exception raised in Job[6]: TimeoutError()\n",
      "Exception raised in Job[4]: TimeoutError()\n",
      "Exception raised in Job[5]: TimeoutError()\n",
      "Exception raised in Job[7]: TimeoutError()\n",
      "Exception raised in Job[3]: TimeoutError()\n",
      "Exception raised in Job[10]: TimeoutError()\n",
      "Exception raised in Job[9]: TimeoutError()\n",
      "Exception raised in Job[8]: TimeoutError()\n",
      "Exception raised in Job[11]: TimeoutError()\n",
      "Exception raised in Job[14]: TimeoutError()\n",
      "Exception raised in Job[13]: TimeoutError()\n",
      "Exception raised in Job[12]: TimeoutError()\n",
      "Exception raised in Job[15]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Evaluaci√≥n Llama ‚Üí Qwen completada:\n",
      "QWEN COMBINACI√ìN 4/9\n",
      "   Generador: Qwen3-4B-instruct-2507\n",
      "   Embedding: e5-large-instruct -> IdearqE5\n",
      "   Prompt: prompt_zero_shot\n",
      "Generando respuestas con Qwen...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. This article must therefore be hereby marked ‚Äúadvertisement‚Äù in accordance with 18 U.S.C. ¬ß1734 solely to indicate this fact. 14180‚Äì14185 PNAS November 20, 2001 vol. 98 no. 24 www.pnas.org cgi doi 10.1073 pnas.241522898 Downloaded from https://www.pnas.org by 2.138.20.97 on August 12, 2025 from IP...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  12%|‚ñà‚ñé        | 1/8 [05:13<36:32, 313.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'5.¬∫ CONGRESSO DO NEOL√çTICO PENINSULAR 405 1. Introducci√≥n La miner√≠a del s√≠lex en la Europa prehist√≥rica tiene lugar en un marco cronol√≥gico bien conocido. Hay esca‚Äë sas y ocasionalmente ambiguas evidencias de explota‚Äë ciones del Pleistoceno (p.e. Baena et al., 2011), alguna dispersa para el Mesol√≠t...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  25%|‚ñà‚ñà‚ñå       | 2/8 [07:08<19:39, 196.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. La cronolog√≠a radiocarb√≥nica de las primeras manifestaciones megal√≠ticas en el sureste de la Pen√≠nsula Ib√©rica‚Ä¶ 273 Trab. Prehist., 74, N.¬∫ 2, julio-diciembre 2017, pp. 257-277, ISSN: 0082-5638 doi: 10.3989/tp.2017.12194 de probabilidad), posiblemente entre el 2395-2270 cal BC (68% de probabilidad...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  38%|‚ñà‚ñà‚ñà‚ñä      | 3/8 [11:40<19:16, 231.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 1984: ‚ÄúLa Muela de Alarilla. Un yacimiento de la Edad del Bronce en el valle medio del r√≠o Henares‚Äù. Revista de Arqueolog√≠a 37: 6-16. Misiego, J. C.; Sanz, F. J.; Marcos, G. J. y Mart√≠n, M. A. 1999: ‚ÄúExcavaciones Arqueol√≥gicas en el castro de Sacaojos (Santiago de la Valduerna, Le√≥n)‚Äù. Nu¬≠ mantia ...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4/8 [13:26<12:06, 181.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'81 ISSN: 1131-6993 El Bronce Final en el Levante de la pen√≠nsula Ib√©rica: bases arqueol√≥gicas y periodizaci√≥n Late Bronze Age in Eastern Iberian Peninsula: Archaeological Bases and Periodization Francisco Javier Jover Maestre*, Alberto Lorrio Alvarado**\\n\\n---\\n\\n. Con el desarrollo de las excavacio...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5/8 [18:23<11:09, 223.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Introducci√≥n Los objetos de adorno realizados con marfil de pro¬≠ bosc√≠deo son una constante en el registro material de los yacimientos de la pen√≠nsula ib√©rica, sobre todo a partir de la primera mitad del II milenio cal BC, si bien en el sur est√°n presentes desde inicios del III milenio cal BC. La ...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6/8 [22:28<07:41, 230.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Demograf√≠a y poblamiento en la Meseta Sur entre el 5500 y el 1200 cal BC. Una perspectiva desde el Radiocarbono 84 La base de datos de dataciones de 14C de la Meseta Sur peninsular se caracteriza por la estructuraci√≥n de la informaci√≥n cronol√≥gica en campos que permitan la situaci√≥n geogr√°fica de ...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 7/8 [27:36<04:16, 256.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. La cronolog√≠a radiocarb√≥nica de las primeras manifestaciones megal√≠ticas en el sureste de la Pen√≠nsula Ib√©rica‚Ä¶ 273 Trab. Prehist., 74, N.¬∫ 2, julio-diciembre 2017, pp. 257-277, ISSN: 0082-5638 doi: 10.3989/tp.2017.12194 de probabilidad), posiblemente entre el 2395-2270 cal BC (68% de probabilidad...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [30:19<00:00, 227.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "8/8 preguntas exitosas\n",
      "Evaluando respuestas de Qwen con Llama...\n",
      "Procesando 8 preguntas en lotes de 4...\n",
      "   Evaluando lote 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90908f2d6d564f40944bc23cdf3d3b1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[2]: TimeoutError()\n",
      "Exception raised in Job[1]: TimeoutError()\n",
      "Exception raised in Job[4]: TimeoutError()\n",
      "Exception raised in Job[3]: TimeoutError()\n",
      "Exception raised in Job[6]: TimeoutError()\n",
      "Exception raised in Job[5]: TimeoutError()\n",
      "Exception raised in Job[7]: TimeoutError()\n",
      "Exception raised in Job[10]: TimeoutError()\n",
      "Exception raised in Job[9]: TimeoutError()\n",
      "Exception raised in Job[8]: TimeoutError()\n",
      "Exception raised in Job[14]: TimeoutError()\n",
      "Exception raised in Job[11]: TimeoutError()\n",
      "Exception raised in Job[12]: TimeoutError()\n",
      "Exception raised in Job[13]: TimeoutError()\n",
      "Exception raised in Job[15]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Evaluando lote 2/2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1aab8b090224ee9a545aa46f5fc0581",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[2]: TimeoutError()\n",
      "Exception raised in Job[4]: TimeoutError()\n",
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[1]: TimeoutError()\n",
      "Exception raised in Job[3]: TimeoutError()\n",
      "Exception raised in Job[6]: TimeoutError()\n",
      "Exception raised in Job[7]: TimeoutError()\n",
      "Exception raised in Job[5]: TimeoutError()\n",
      "Exception raised in Job[9]: TimeoutError()\n",
      "Exception raised in Job[8]: TimeoutError()\n",
      "Exception raised in Job[11]: TimeoutError()\n",
      "Exception raised in Job[10]: TimeoutError()\n",
      "Exception raised in Job[12]: TimeoutError()\n",
      "Exception raised in Job[14]: TimeoutError()\n",
      "Exception raised in Job[13]: TimeoutError()\n",
      "Exception raised in Job[15]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Evaluaci√≥n Llama ‚Üí Qwen completada:\n",
      "QWEN COMBINACI√ìN 5/9\n",
      "   Generador: Qwen3-4B-instruct-2507\n",
      "   Embedding: e5-large-instruct -> IdearqE5\n",
      "   Prompt: prompt_one_shot\n",
      "Generando respuestas con Qwen...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. This article must therefore be hereby marked ‚Äúadvertisement‚Äù in accordance with 18 U.S.C. ¬ß1734 solely to indicate this fact. 14180‚Äì14185 PNAS November 20, 2001 vol. 98 no. 24 www.pnas.org cgi doi 10.1073 pnas.241522898 Downloaded from https://www.pnas.org by 2.138.20.97 on August 12, 2025 from IP...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  12%|‚ñà‚ñé        | 1/8 [04:58<34:50, 298.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'5.¬∫ CONGRESSO DO NEOL√çTICO PENINSULAR 405 1. Introducci√≥n La miner√≠a del s√≠lex en la Europa prehist√≥rica tiene lugar en un marco cronol√≥gico bien conocido. Hay esca‚Äë sas y ocasionalmente ambiguas evidencias de explota‚Äë ciones del Pleistoceno (p.e. Baena et al., 2011), alguna dispersa para el Mesol√≠t...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  25%|‚ñà‚ñà‚ñå       | 2/8 [06:27<17:31, 175.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. La cronolog√≠a radiocarb√≥nica de las primeras manifestaciones megal√≠ticas en el sureste de la Pen√≠nsula Ib√©rica‚Ä¶ 273 Trab. Prehist., 74, N.¬∫ 2, julio-diciembre 2017, pp. 257-277, ISSN: 0082-5638 doi: 10.3989/tp.2017.12194 de probabilidad), posiblemente entre el 2395-2270 cal BC (68% de probabilidad...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  38%|‚ñà‚ñà‚ñà‚ñä      | 3/8 [11:04<18:29, 221.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 1984: ‚ÄúLa Muela de Alarilla. Un yacimiento de la Edad del Bronce en el valle medio del r√≠o Henares‚Äù. Revista de Arqueolog√≠a 37: 6-16. Misiego, J. C.; Sanz, F. J.; Marcos, G. J. y Mart√≠n, M. A. 1999: ‚ÄúExcavaciones Arqueol√≥gicas en el castro de Sacaojos (Santiago de la Valduerna, Le√≥n)‚Äù. Nu¬≠ mantia ...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4/8 [12:29<11:10, 167.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'81 ISSN: 1131-6993 El Bronce Final en el Levante de la pen√≠nsula Ib√©rica: bases arqueol√≥gicas y periodizaci√≥n Late Bronze Age in Eastern Iberian Peninsula: Archaeological Bases and Periodization Francisco Javier Jover Maestre*, Alberto Lorrio Alvarado**\\n\\n---\\n\\n. Con el desarrollo de las excavacio...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5/8 [17:19<10:35, 211.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Introducci√≥n Los objetos de adorno realizados con marfil de pro¬≠ bosc√≠deo son una constante en el registro material de los yacimientos de la pen√≠nsula ib√©rica, sobre todo a partir de la primera mitad del II milenio cal BC, si bien en el sur est√°n presentes desde inicios del III milenio cal BC. La ...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6/8 [20:10<06:36, 198.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Demograf√≠a y poblamiento en la Meseta Sur entre el 5500 y el 1200 cal BC. Una perspectiva desde el Radiocarbono 84 La base de datos de dataciones de 14C de la Meseta Sur peninsular se caracteriza por la estructuraci√≥n de la informaci√≥n cronol√≥gica en campos que permitan la situaci√≥n geogr√°fica de ...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 7/8 [25:39<04:00, 240.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. La cronolog√≠a radiocarb√≥nica de las primeras manifestaciones megal√≠ticas en el sureste de la Pen√≠nsula Ib√©rica‚Ä¶ 273 Trab. Prehist., 74, N.¬∫ 2, julio-diciembre 2017, pp. 257-277, ISSN: 0082-5638 doi: 10.3989/tp.2017.12194 de probabilidad), posiblemente entre el 2395-2270 cal BC (68% de probabilidad...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [28:55<00:00, 216.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "8/8 preguntas exitosas\n",
      "Evaluando respuestas de Qwen con Llama...\n",
      "Procesando 8 preguntas en lotes de 4...\n",
      "   Evaluando lote 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b70ee78f9cff47a18a5a5fbcef088fed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[2]: TimeoutError()\n",
      "Exception raised in Job[1]: TimeoutError()\n",
      "Exception raised in Job[3]: TimeoutError()\n",
      "Exception raised in Job[6]: TimeoutError()\n",
      "Exception raised in Job[5]: TimeoutError()\n",
      "Exception raised in Job[4]: TimeoutError()\n",
      "Exception raised in Job[7]: TimeoutError()\n",
      "Exception raised in Job[11]: TimeoutError()\n",
      "Exception raised in Job[10]: TimeoutError()\n",
      "Exception raised in Job[9]: TimeoutError()\n",
      "Exception raised in Job[8]: TimeoutError()\n",
      "Exception raised in Job[14]: TimeoutError()\n",
      "Exception raised in Job[12]: TimeoutError()\n",
      "Exception raised in Job[15]: TimeoutError()\n",
      "Exception raised in Job[13]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Evaluando lote 2/2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9259637802884924bc19cf989a28624f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[2]: TimeoutError()\n",
      "Exception raised in Job[5]: TimeoutError()\n",
      "Exception raised in Job[6]: TimeoutError()\n",
      "Exception raised in Job[3]: TimeoutError()\n",
      "Exception raised in Job[4]: TimeoutError()\n",
      "Exception raised in Job[1]: TimeoutError()\n",
      "Exception raised in Job[11]: TimeoutError()\n",
      "Exception raised in Job[12]: TimeoutError()\n",
      "Exception raised in Job[9]: TimeoutError()\n",
      "Exception raised in Job[7]: TimeoutError()\n",
      "Exception raised in Job[10]: TimeoutError()\n",
      "Exception raised in Job[8]: TimeoutError()\n",
      "Exception raised in Job[13]: TimeoutError()\n",
      "Exception raised in Job[14]: TimeoutError()\n",
      "Exception raised in Job[15]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Evaluaci√≥n Llama ‚Üí Qwen completada:\n",
      "QWEN COMBINACI√ìN 6/9\n",
      "   Generador: Qwen3-4B-instruct-2507\n",
      "   Embedding: e5-large-instruct -> IdearqE5\n",
      "   Prompt: prompt_few_shot\n",
      "Generando respuestas con Qwen...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. This article must therefore be hereby marked ‚Äúadvertisement‚Äù in accordance with 18 U.S.C. ¬ß1734 solely to indicate this fact. 14180‚Äì14185 PNAS November 20, 2001 vol. 98 no. 24 www.pnas.org cgi doi 10.1073 pnas.241522898 Downloaded from https://www.pnas.org by 2.138.20.97 on August 12, 2025 from IP...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  12%|‚ñà‚ñé        | 1/8 [04:23<30:44, 263.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'5.¬∫ CONGRESSO DO NEOL√çTICO PENINSULAR 405 1. Introducci√≥n La miner√≠a del s√≠lex en la Europa prehist√≥rica tiene lugar en un marco cronol√≥gico bien conocido. Hay esca‚Äë sas y ocasionalmente ambiguas evidencias de explota‚Äë ciones del Pleistoceno (p.e. Baena et al., 2011), alguna dispersa para el Mesol√≠t...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  25%|‚ñà‚ñà‚ñå       | 2/8 [05:54<16:11, 161.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. La cronolog√≠a radiocarb√≥nica de las primeras manifestaciones megal√≠ticas en el sureste de la Pen√≠nsula Ib√©rica‚Ä¶ 273 Trab. Prehist., 74, N.¬∫ 2, julio-diciembre 2017, pp. 257-277, ISSN: 0082-5638 doi: 10.3989/tp.2017.12194 de probabilidad), posiblemente entre el 2395-2270 cal BC (68% de probabilidad...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  38%|‚ñà‚ñà‚ñà‚ñä      | 3/8 [09:11<14:49, 178.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 1984: ‚ÄúLa Muela de Alarilla. Un yacimiento de la Edad del Bronce en el valle medio del r√≠o Henares‚Äù. Revista de Arqueolog√≠a 37: 6-16. Misiego, J. C.; Sanz, F. J.; Marcos, G. J. y Mart√≠n, M. A. 1999: ‚ÄúExcavaciones Arqueol√≥gicas en el castro de Sacaojos (Santiago de la Valduerna, Le√≥n)‚Äù. Nu¬≠ mantia ...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4/8 [10:55<09:55, 148.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'81 ISSN: 1131-6993 El Bronce Final en el Levante de la pen√≠nsula Ib√©rica: bases arqueol√≥gicas y periodizaci√≥n Late Bronze Age in Eastern Iberian Peninsula: Archaeological Bases and Periodization Francisco Javier Jover Maestre*, Alberto Lorrio Alvarado**\\n\\n---\\n\\n. Con el desarrollo de las excavacio...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5/8 [15:52<10:06, 202.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Introducci√≥n Los objetos de adorno realizados con marfil de pro¬≠ bosc√≠deo son una constante en el registro material de los yacimientos de la pen√≠nsula ib√©rica, sobre todo a partir de la primera mitad del II milenio cal BC, si bien en el sur est√°n presentes desde inicios del III milenio cal BC. La ...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6/8 [19:46<07:06, 213.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Demograf√≠a y poblamiento en la Meseta Sur entre el 5500 y el 1200 cal BC. Una perspectiva desde el Radiocarbono 84 La base de datos de dataciones de 14C de la Meseta Sur peninsular se caracteriza por la estructuraci√≥n de la informaci√≥n cronol√≥gica en campos que permitan la situaci√≥n geogr√°fica de ...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 7/8 [25:00<04:06, 246.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. La cronolog√≠a radiocarb√≥nica de las primeras manifestaciones megal√≠ticas en el sureste de la Pen√≠nsula Ib√©rica‚Ä¶ 273 Trab. Prehist., 74, N.¬∫ 2, julio-diciembre 2017, pp. 257-277, ISSN: 0082-5638 doi: 10.3989/tp.2017.12194 de probabilidad), posiblemente entre el 2395-2270 cal BC (68% de probabilidad...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [27:29<00:00, 206.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "8/8 preguntas exitosas\n",
      "Evaluando respuestas de Qwen con Llama...\n",
      "Procesando 8 preguntas en lotes de 4...\n",
      "   Evaluando lote 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86187debbb8e45a0949f8e53bcc36015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[3]: TimeoutError()\n",
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[1]: TimeoutError()\n",
      "Exception raised in Job[6]: TimeoutError()\n",
      "Exception raised in Job[2]: TimeoutError()\n",
      "Exception raised in Job[5]: TimeoutError()\n",
      "Exception raised in Job[4]: TimeoutError()\n",
      "Exception raised in Job[10]: TimeoutError()\n",
      "Exception raised in Job[9]: TimeoutError()\n",
      "Exception raised in Job[8]: TimeoutError()\n",
      "Exception raised in Job[7]: TimeoutError()\n",
      "Exception raised in Job[14]: TimeoutError()\n",
      "Exception raised in Job[12]: TimeoutError()\n",
      "Exception raised in Job[13]: TimeoutError()\n",
      "Exception raised in Job[15]: TimeoutError()\n",
      "Exception raised in Job[11]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Evaluando lote 2/2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a85de74ce72e48729f2ee83cab8952d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[2]: TimeoutError()\n",
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[1]: TimeoutError()\n",
      "Exception raised in Job[6]: TimeoutError()\n",
      "Exception raised in Job[4]: TimeoutError()\n",
      "Exception raised in Job[5]: TimeoutError()\n",
      "Exception raised in Job[3]: TimeoutError()\n",
      "Exception raised in Job[9]: TimeoutError()\n",
      "Exception raised in Job[7]: TimeoutError()\n",
      "Exception raised in Job[10]: TimeoutError()\n",
      "Exception raised in Job[8]: TimeoutError()\n",
      "Exception raised in Job[11]: TimeoutError()\n",
      "Exception raised in Job[12]: TimeoutError()\n",
      "Exception raised in Job[13]: TimeoutError()\n",
      "Exception raised in Job[15]: TimeoutError()\n",
      "Exception raised in Job[14]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Evaluaci√≥n Llama ‚Üí Qwen completada:\n",
      "QWEN COMBINACI√ìN 7/9\n",
      "   Generador: Qwen3-4B-instruct-2507\n",
      "   Embedding: gte-multilingual-base -> IdearqGTE\n",
      "   Prompt: prompt_zero_shot\n",
      "Generando respuestas con Qwen...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Published by Elsevier Inc. All rights reserved. doi:10.1016/j.yqres.2011.12.003 Contents lists available at SciVerse ScienceDirect Quaternary Research journal homepage: www.elsevier.com/locate/yqres https://doi.org/10.1016/j.yqres.2011.12.003 Published online by Cambridge University Press Introduc...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  12%|‚ñà‚ñé        | 1/8 [04:53<34:13, 293.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'5.¬∫ CONGRESSO DO NEOL√çTICO PENINSULAR 405 1. Introducci√≥n La miner√≠a del s√≠lex en la Europa prehist√≥rica tiene lugar en un marco cronol√≥gico bien conocido. Hay esca‚Äë sas y ocasionalmente ambiguas evidencias de explota‚Äë ciones del Pleistoceno (p.e. Baena et al., 2011), alguna dispersa para el Mesol√≠t...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  25%|‚ñà‚ñà‚ñå       | 2/8 [07:25<21:02, 210.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. P√°gs. 253-273 ISBN: 978-84-8317-921-5 ¬∑ ISBN: 978-84-940141-2-3 Resumen La regi√≥n cant√°brica ha proporcionado una de las principales concentraciones de testimonios funerarios mesol√≠ticos del continente europeo, con un registro pr√°cticamente continuo desde el Aziliense hasta el final del per√≠odo, e...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  38%|‚ñà‚ñà‚ñà‚ñä      | 3/8 [12:18<20:40, 248.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 141 Complutum 32(1) 2021: 141-165 Complutum ISSN: 1131-6993 https://dx.doi.org//cmpl.76452 ART√çCULOS La panoplia de finales de la II¬™ Edad del Hierro de la sima de La Cerrosa-Laga√±a (Suar√≠as, Pe√±amellera Baja, Asturias). ¬øUn conjunto asociado a las Guerras C√°ntabras?1 Susana de Luis Mari√±o2; Maria...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4/8 [13:40<12:09, 182.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Con el desarrollo de las excavaciones arqueol√≥gicas en diversos asentamientos, el aumento del n√∫mero de dataciones y la realizaci√≥n de diversos estudios en los √∫ltimos a√±os, las perspectivas de investigaci√≥n sobre el Bronce final en el Levante comienza a variar sustancialmente, estando ya en condi...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5/8 [19:14<11:51, 237.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Jover Maestre, F.J., L√≥pez, J.A. y Garc√≠a, G. (2021): De las primeras comunidades neol√≠ticas a la confi¬≠ guraci√≥n de los grupos iberos en el Levante de la pe¬≠ n√≠nsula ib√©rica. Alicante Kristiansen, K. y Larsson, T.B. (2006): La emergen¬≠ cia de la sociedad del Bronce. Viajes, transmisiones y transf...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6/8 [22:56<07:43, 231.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Causas internas m√°s o menos imbricadas con la evoluci√≥n paleoambiental y las respuestas sociales a estos cambios, o bien, de origen externo ligadas a la presi√≥n ejer- cida por los primeros grupos neol√≠ticos han sido descritas (Garc√≠a Puchol et al., 2006). - De este modo, la pionera implantaci√≥n ne...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 7/8 [27:57<04:14, 254.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. MESTRES, J.S. y NICOL√ÅS, J.C. de, 1999, Contribuci√≥n de la dataci√≥n por radiocarbono al establecimiento de la cronolog√≠a absoluta de la prehistoria de Menorca, Caesaraugusta, 73, Zaragoza, p.327-341. El megalitismo mallorqu√≠n en el contexto del... MOLIST, M. y CLOP, X., 2000, La investigaci√≥n sobr...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [31:23<00:00, 235.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "8/8 preguntas exitosas\n",
      "Evaluando respuestas de Qwen con Llama...\n",
      "Procesando 8 preguntas en lotes de 4...\n",
      "   Evaluando lote 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41c395ee539445ea94fb03d6c389fbfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[1]: TimeoutError()\n",
      "Exception raised in Job[2]: TimeoutError()\n",
      "Exception raised in Job[4]: TimeoutError()\n",
      "Exception raised in Job[3]: TimeoutError()\n",
      "Exception raised in Job[5]: TimeoutError()\n",
      "Exception raised in Job[6]: TimeoutError()\n",
      "Exception raised in Job[7]: TimeoutError()\n",
      "Exception raised in Job[9]: TimeoutError()\n",
      "Exception raised in Job[8]: TimeoutError()\n",
      "Exception raised in Job[14]: TimeoutError()\n",
      "Exception raised in Job[12]: TimeoutError()\n",
      "Exception raised in Job[13]: TimeoutError()\n",
      "Exception raised in Job[11]: TimeoutError()\n",
      "Exception raised in Job[10]: TimeoutError()\n",
      "Exception raised in Job[15]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Evaluando lote 2/2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "229db13dc95f42f3bec8a5b55b277e7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[1]: TimeoutError()\n",
      "Exception raised in Job[5]: TimeoutError()\n",
      "Exception raised in Job[2]: TimeoutError()\n",
      "Exception raised in Job[4]: TimeoutError()\n",
      "Exception raised in Job[3]: TimeoutError()\n",
      "Exception raised in Job[6]: TimeoutError()\n",
      "Exception raised in Job[8]: TimeoutError()\n",
      "Exception raised in Job[7]: TimeoutError()\n",
      "Exception raised in Job[10]: TimeoutError()\n",
      "Exception raised in Job[11]: TimeoutError()\n",
      "Exception raised in Job[9]: TimeoutError()\n",
      "Exception raised in Job[13]: TimeoutError()\n",
      "Exception raised in Job[14]: TimeoutError()\n",
      "Exception raised in Job[15]: TimeoutError()\n",
      "Exception raised in Job[12]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Evaluaci√≥n Llama ‚Üí Qwen completada:\n",
      "QWEN COMBINACI√ìN 8/9\n",
      "   Generador: Qwen3-4B-instruct-2507\n",
      "   Embedding: gte-multilingual-base -> IdearqGTE\n",
      "   Prompt: prompt_one_shot\n",
      "Generando respuestas con Qwen...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Published by Elsevier Inc. All rights reserved. doi:10.1016/j.yqres.2011.12.003 Contents lists available at SciVerse ScienceDirect Quaternary Research journal homepage: www.elsevier.com/locate/yqres https://doi.org/10.1016/j.yqres.2011.12.003 Published online by Cambridge University Press Introduc...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  12%|‚ñà‚ñé        | 1/8 [05:35<39:06, 335.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'5.¬∫ CONGRESSO DO NEOL√çTICO PENINSULAR 405 1. Introducci√≥n La miner√≠a del s√≠lex en la Europa prehist√≥rica tiene lugar en un marco cronol√≥gico bien conocido. Hay esca‚Äë sas y ocasionalmente ambiguas evidencias de explota‚Äë ciones del Pleistoceno (p.e. Baena et al., 2011), alguna dispersa para el Mesol√≠t...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  25%|‚ñà‚ñà‚ñå       | 2/8 [07:49<21:40, 216.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. P√°gs. 253-273 ISBN: 978-84-8317-921-5 ¬∑ ISBN: 978-84-940141-2-3 Resumen La regi√≥n cant√°brica ha proporcionado una de las principales concentraciones de testimonios funerarios mesol√≠ticos del continente europeo, con un registro pr√°cticamente continuo desde el Aziliense hasta el final del per√≠odo, e...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  38%|‚ñà‚ñà‚ñà‚ñä      | 3/8 [12:37<20:47, 249.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 141 Complutum 32(1) 2021: 141-165 Complutum ISSN: 1131-6993 https://dx.doi.org//cmpl.76452 ART√çCULOS La panoplia de finales de la II¬™ Edad del Hierro de la sima de La Cerrosa-Laga√±a (Suar√≠as, Pe√±amellera Baja, Asturias). ¬øUn conjunto asociado a las Guerras C√°ntabras?1 Susana de Luis Mari√±o2; Maria...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4/8 [14:06<12:24, 186.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Con el desarrollo de las excavaciones arqueol√≥gicas en diversos asentamientos, el aumento del n√∫mero de dataciones y la realizaci√≥n de diversos estudios en los √∫ltimos a√±os, las perspectivas de investigaci√≥n sobre el Bronce final en el Levante comienza a variar sustancialmente, estando ya en condi...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5/8 [18:20<10:31, 210.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Jover Maestre, F.J., L√≥pez, J.A. y Garc√≠a, G. (2021): De las primeras comunidades neol√≠ticas a la confi¬≠ guraci√≥n de los grupos iberos en el Levante de la pe¬≠ n√≠nsula ib√©rica. Alicante Kristiansen, K. y Larsson, T.B. (2006): La emergen¬≠ cia de la sociedad del Bronce. Viajes, transmisiones y transf...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6/8 [22:13<07:16, 218.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Causas internas m√°s o menos imbricadas con la evoluci√≥n paleoambiental y las respuestas sociales a estos cambios, o bien, de origen externo ligadas a la presi√≥n ejer- cida por los primeros grupos neol√≠ticos han sido descritas (Garc√≠a Puchol et al., 2006). - De este modo, la pionera implantaci√≥n ne...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 7/8 [27:52<04:17, 257.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. MESTRES, J.S. y NICOL√ÅS, J.C. de, 1999, Contribuci√≥n de la dataci√≥n por radiocarbono al establecimiento de la cronolog√≠a absoluta de la prehistoria de Menorca, Caesaraugusta, 73, Zaragoza, p.327-341. El megalitismo mallorqu√≠n en el contexto del... MOLIST, M. y CLOP, X., 2000, La investigaci√≥n sobr...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [30:48<00:00, 231.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "8/8 preguntas exitosas\n",
      "Evaluando respuestas de Qwen con Llama...\n",
      "Procesando 8 preguntas en lotes de 4...\n",
      "   Evaluando lote 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c61fba15ef1c48fb9b2eb156427f4cd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[1]: TimeoutError()\n",
      "Exception raised in Job[2]: TimeoutError()\n",
      "Exception raised in Job[4]: TimeoutError()\n",
      "Exception raised in Job[3]: TimeoutError()\n",
      "Exception raised in Job[5]: TimeoutError()\n",
      "Exception raised in Job[6]: TimeoutError()\n",
      "Exception raised in Job[8]: TimeoutError()\n",
      "Exception raised in Job[7]: TimeoutError()\n",
      "Exception raised in Job[10]: TimeoutError()\n",
      "Exception raised in Job[11]: TimeoutError()\n",
      "Exception raised in Job[9]: TimeoutError()\n",
      "Exception raised in Job[12]: TimeoutError()\n",
      "Exception raised in Job[13]: TimeoutError()\n",
      "Exception raised in Job[14]: TimeoutError()\n",
      "Exception raised in Job[15]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Evaluando lote 2/2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d76f8f391454e69afffd3768627d67e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[1]: TimeoutError()\n",
      "Exception raised in Job[2]: TimeoutError()\n",
      "Exception raised in Job[5]: TimeoutError()\n",
      "Exception raised in Job[4]: TimeoutError()\n",
      "Exception raised in Job[3]: TimeoutError()\n",
      "Exception raised in Job[6]: TimeoutError()\n",
      "Exception raised in Job[10]: TimeoutError()\n",
      "Exception raised in Job[9]: TimeoutError()\n",
      "Exception raised in Job[8]: TimeoutError()\n",
      "Exception raised in Job[7]: TimeoutError()\n",
      "Exception raised in Job[13]: TimeoutError()\n",
      "Exception raised in Job[12]: TimeoutError()\n",
      "Exception raised in Job[15]: TimeoutError()\n",
      "Exception raised in Job[11]: TimeoutError()\n",
      "Exception raised in Job[14]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Evaluaci√≥n Llama ‚Üí Qwen completada:\n",
      "QWEN COMBINACI√ìN 9/9\n",
      "   Generador: Qwen3-4B-instruct-2507\n",
      "   Embedding: gte-multilingual-base -> IdearqGTE\n",
      "   Prompt: prompt_few_shot\n",
      "Generando respuestas con Qwen...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Published by Elsevier Inc. All rights reserved. doi:10.1016/j.yqres.2011.12.003 Contents lists available at SciVerse ScienceDirect Quaternary Research journal homepage: www.elsevier.com/locate/yqres https://doi.org/10.1016/j.yqres.2011.12.003 Published online by Cambridge University Press Introduc...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  12%|‚ñà‚ñé        | 1/8 [05:51<40:57, 351.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'5.¬∫ CONGRESSO DO NEOL√çTICO PENINSULAR 405 1. Introducci√≥n La miner√≠a del s√≠lex en la Europa prehist√≥rica tiene lugar en un marco cronol√≥gico bien conocido. Hay esca‚Äë sas y ocasionalmente ambiguas evidencias de explota‚Äë ciones del Pleistoceno (p.e. Baena et al., 2011), alguna dispersa para el Mesol√≠t...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  25%|‚ñà‚ñà‚ñå       | 2/8 [08:33<23:59, 240.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. P√°gs. 253-273 ISBN: 978-84-8317-921-5 ¬∑ ISBN: 978-84-940141-2-3 Resumen La regi√≥n cant√°brica ha proporcionado una de las principales concentraciones de testimonios funerarios mesol√≠ticos del continente europeo, con un registro pr√°cticamente continuo desde el Aziliense hasta el final del per√≠odo, e...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  38%|‚ñà‚ñà‚ñà‚ñä      | 3/8 [12:22<19:36, 235.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 141 Complutum 32(1) 2021: 141-165 Complutum ISSN: 1131-6993 https://dx.doi.org//cmpl.76452 ART√çCULOS La panoplia de finales de la II¬™ Edad del Hierro de la sima de La Cerrosa-Laga√±a (Suar√≠as, Pe√±amellera Baja, Asturias). ¬øUn conjunto asociado a las Guerras C√°ntabras?1 Susana de Luis Mari√±o2; Maria...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4/8 [13:44<11:38, 174.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Con el desarrollo de las excavaciones arqueol√≥gicas en diversos asentamientos, el aumento del n√∫mero de dataciones y la realizaci√≥n de diversos estudios en los √∫ltimos a√±os, las perspectivas de investigaci√≥n sobre el Bronce final en el Levante comienza a variar sustancialmente, estando ya en condi...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5/8 [20:37<13:01, 260.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Jover Maestre, F.J., L√≥pez, J.A. y Garc√≠a, G. (2021): De las primeras comunidades neol√≠ticas a la confi¬≠ guraci√≥n de los grupos iberos en el Levante de la pe¬≠ n√≠nsula ib√©rica. Alicante Kristiansen, K. y Larsson, T.B. (2006): La emergen¬≠ cia de la sociedad del Bronce. Viajes, transmisiones y transf...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6/8 [24:20<08:15, 247.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Causas internas m√°s o menos imbricadas con la evoluci√≥n paleoambiental y las respuestas sociales a estos cambios, o bien, de origen externo ligadas a la presi√≥n ejer- cida por los primeros grupos neol√≠ticos han sido descritas (Garc√≠a Puchol et al., 2006). - De este modo, la pionera implantaci√≥n ne...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 7/8 [29:53<04:35, 275.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. MESTRES, J.S. y NICOL√ÅS, J.C. de, 1999, Contribuci√≥n de la dataci√≥n por radiocarbono al establecimiento de la cronolog√≠a absoluta de la prehistoria de Menorca, Caesaraugusta, 73, Zaragoza, p.327-341. El megalitismo mallorqu√≠n en el contexto del... MOLIST, M. y CLOP, X., 2000, La investigaci√≥n sobr...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [32:10<00:00, 241.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "8/8 preguntas exitosas\n",
      "Evaluando respuestas de Qwen con Llama...\n",
      "Procesando 8 preguntas en lotes de 4...\n",
      "   Evaluando lote 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da9b3178bdb54c3fa1fff0781ab737bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[2]: TimeoutError()\n",
      "Exception raised in Job[1]: TimeoutError()\n",
      "Exception raised in Job[3]: TimeoutError()\n",
      "Exception raised in Job[6]: TimeoutError()\n",
      "Exception raised in Job[5]: TimeoutError()\n",
      "Exception raised in Job[4]: TimeoutError()\n",
      "Exception raised in Job[9]: TimeoutError()\n",
      "Exception raised in Job[10]: TimeoutError()\n",
      "Exception raised in Job[8]: TimeoutError()\n",
      "Exception raised in Job[7]: TimeoutError()\n",
      "Exception raised in Job[11]: TimeoutError()\n",
      "Exception raised in Job[14]: TimeoutError()\n",
      "Exception raised in Job[13]: TimeoutError()\n",
      "Exception raised in Job[12]: TimeoutError()\n",
      "Exception raised in Job[15]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Evaluando lote 2/2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef59d3a4a40244b48989a563e2ab8ba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/16 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[2]: TimeoutError()\n",
      "Exception raised in Job[1]: TimeoutError()\n",
      "Exception raised in Job[3]: TimeoutError()\n",
      "Exception raised in Job[5]: TimeoutError()\n",
      "Exception raised in Job[4]: TimeoutError()\n",
      "Exception raised in Job[9]: TimeoutError()\n",
      "Exception raised in Job[6]: TimeoutError()\n",
      "Exception raised in Job[8]: TimeoutError()\n",
      "Exception raised in Job[7]: TimeoutError()\n",
      "Exception raised in Job[11]: TimeoutError()\n",
      "Exception raised in Job[13]: TimeoutError()\n",
      "Exception raised in Job[10]: TimeoutError()\n",
      "Exception raised in Job[12]: TimeoutError()\n",
      "Exception raised in Job[15]: TimeoutError()\n",
      "Exception raised in Job[14]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Evaluaci√≥n Llama ‚Üí Qwen completada:\n",
      "\n",
      "================================================================================\n",
      "EVALUACI√ìN QWEN COMPLETADA\n",
      "================================================================================\n",
      "‚úÖ Resultados detallados Qwen: (72, 13)\n",
      "‚úÖ M√©tricas resumen Qwen: (9, 17)\n",
      "Resultados Qwen guardados:\n",
      "   Detallado: qwen_evaluation_detailed_20250916_022939.csv\n",
      "   M√©tricas: qwen_evaluation_metrics_20250916_022939.csv\n",
      "\n",
      "RESUMEN QWEN:\n",
      "   Combinaciones totales: 9\n",
      "   Evaluaciones exitosas: 9\n",
      "   Tasa de √©xito: 100.0%\n",
      "\n",
      "MEJORES COMBINACIONES QWEN:\n",
      "\n",
      "CONTEXT RECALL MEAN:\n",
      " embedding_model      prompt_type  context_recall_mean\n",
      "all-MiniLM-L6-v2 prompt_zero_shot                  1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"EVALUACI√ìN CON GENERADOR QWEN\")\n",
    "print(\"Generador: Qwen3-4B-instruct-2507\")\n",
    "print(f\"Evaluador: {llama_evaluator.model}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Configuraci√≥n espec√≠fica para Qwen como GENERADOR\n",
    "test_llm = 'Qwen3-4B-instruct-2507'  # GENERADOR de respuestas RAG\n",
    "\n",
    "# Listas para almacenar resultados de Qwen\n",
    "qwen_detailed_results = []\n",
    "qwen_metrics_results = []\n",
    "\n",
    "# Generar combinaciones solo para Qwen\n",
    "qwen_combinations = list(product([test_llm], embeddings, prompts))\n",
    "total_qwen_combinations = len(qwen_combinations)\n",
    "\n",
    "print(f\"Evaluando {total_qwen_combinations} combinaciones para Qwen:\")\n",
    "for emb in embeddings:\n",
    "    for prompt in prompts:\n",
    "         print(f\"   ‚Ä¢ {test_llm} + {emb} + {prompt}\")\n",
    "print()\n",
    "\n",
    "# Evaluar cada combinaci√≥n de Qwen\n",
    "for combo_idx, (llm_name, test_embedding, test_prompt) in enumerate(qwen_combinations):\n",
    "\n",
    "    print(f\"QWEN COMBINACI√ìN {combo_idx+1}/{total_qwen_combinations}\")\n",
    "    print(f\"   Generador: {llm_name}\")\n",
    "    print(f\"   Embedding: {test_embedding} -> {WEAVIATE_CLASSES[test_embedding]}\")\n",
    "    print(f\"   Prompt: {test_prompt}\")\n",
    "\n",
    "    combination_start_time = time.time()\n",
    "    results_list = []\n",
    "    successful_questions = 0\n",
    "\n",
    "    # Generar respuestas para todas las preguntas\n",
    "    print(\"Generando respuestas con Qwen...\")\n",
    "    for q_idx, question in enumerate(tqdm(questions, desc=\"   Preguntas\")):\n",
    "        try:\n",
    "            state = {\n",
    "                'question': question,\n",
    "                'llm_name': llm_name,  # Qwen genera la respuesta\n",
    "                'embedding_name': test_embedding,\n",
    "                'prompt_name': test_prompt,\n",
    "                'context': [], 'answer': '', 'metadata': {}\n",
    "            }\n",
    "\n",
    "            final_state = graph.invoke(state)  # Qwen genera respuesta RAG\n",
    "            answer = final_state.get('answer', '')\n",
    "            contexts = final_state.get('context', [])\n",
    "\n",
    "            if answer and 'ERROR:' not in answer and len(contexts) > 0:\n",
    "                # Almacenar para dataset RAGAS\n",
    "                results_list.append({\n",
    "                    'question': question,\n",
    "                    'answer': answer,  # Respuesta generada por Qwen\n",
    "                    'contexts': [doc.page_content for doc in contexts],\n",
    "                    'ground_truth': ground_truths[q_idx] if q_idx < len(ground_truths) else ''\n",
    "                 })\n",
    "                successful_questions += 1\n",
    "\n",
    "            # Almacenar detalles individuales\n",
    "            qwen_detailed_results.append({\n",
    "                'combination_id': combo_idx,\n",
    "                'generator_llm': llm_name,  # Qwen generador\n",
    "                'evaluator_llm': llama_evaluator.model,  # Llama evaluador\n",
    "                'embedding_model': test_embedding,\n",
    "                'weaviate_collection': WEAVIATE_CLASSES[test_embedding],\n",
    "                'prompt_type': test_prompt,\n",
    "                'question_id': q_idx,\n",
    "                'question': question,\n",
    "                'answer': answer,\n",
    "                'contexts': [doc.page_content for doc in contexts],\n",
    "                'num_contexts': len(contexts),\n",
    "                'ground_truth': ground_truths[q_idx] if q_idx < len(ground_truths) else '',\n",
    "                'status': 'success' if answer and 'ERROR:' not in answer else 'error'\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error en pregunta {q_idx+1}: {e}\")\n",
    "            qwen_detailed_results.append({\n",
    "                'combination_id': combo_idx,\n",
    "                'generator_llm': llm_name,\n",
    "                'evaluator_llm': llama_evaluator.model,\n",
    "                'embedding_model': test_embedding,\n",
    "                'weaviate_collection': WEAVIATE_CLASSES[test_embedding],\n",
    "                'prompt_type': test_prompt,\n",
    "                'question_id': q_idx,\n",
    "                'question': question,\n",
    "                'answer': f'ERROR: {str(e)}',\n",
    "                'contexts': [],\n",
    "                'num_contexts': 0,\n",
    "                'ground_truth': ground_truths[q_idx] if q_idx < len(ground_truths) else '',\n",
    "                'status': 'error'\n",
    "             })\n",
    "\n",
    "    print(f\"{successful_questions}/{len(questions)} preguntas exitosas\")\n",
    "\n",
    "    # Evaluar con RAGAS usando Llama como evaluador\n",
    "    if successful_questions >= 2:\n",
    "        print(\"Evaluando respuestas de Qwen con Llama...\" )\n",
    "\n",
    "        try:\n",
    "            dataset = Dataset.from_list(results_list)\n",
    "              # USAR EL EMBEDDING ESPEC√çFICO DE ESTA COMBINACI√ìN\n",
    "            current_embedding_model = EMBEDDING_MODELS[test_embedding]\n",
    "\n",
    "            # CONFIGURACI√ìN PARA EVITAR TIMEOUTS\n",
    "            import asyncio\n",
    "            asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())\n",
    "\n",
    "            # Procesar en lotes peque√±os si hay muchas preguntas\n",
    "            if len(results_list) > 4:\n",
    "                print(f\"Procesando {len(results_list)} preguntas en lotes de 4...\")\n",
    "\n",
    "                # Dividir en lotes de 4\n",
    "                batch_results = []\n",
    "                for i in range(0, len(results_list), 4):\n",
    "                    batch = results_list[i:i+4]\n",
    "                    batch_dataset = Dataset.from_list(batch)\n",
    "\n",
    "                    print(f\"   Evaluando lote {i//4 + 1}/{(len(results_list) + 3)//4}\")\n",
    "\n",
    "                    batch_eval = evaluate(\n",
    "                        batch_dataset,\n",
    "                        llm=llama_evaluator,\n",
    "                        embeddings=current_embedding_model,\n",
    "                        metrics=[context_precision, context_recall, faithfulness, answer_correctness],\n",
    "                        raise_exceptions=False\n",
    "                    )\n",
    "                    batch_results.append(batch_eval.to_pandas())\n",
    "\n",
    "                    # Pausa entre lotes\n",
    "                    time.sleep(30)\n",
    "\n",
    "                # Combinar resultados\n",
    "                metrics_df = pd.concat(batch_results, ignore_index=True)\n",
    "\n",
    "            else:\n",
    "                # Evaluaci√≥n normal para pocos elementos\n",
    "                evaluation_results = evaluate(\n",
    "                    dataset,\n",
    "                    llm=llama_evaluator,\n",
    "                    embeddings=current_embedding_model,\n",
    "                    metrics=[context_precision, context_recall, faithfulness, answer_correctness],\n",
    "                    raise_exceptions=False\n",
    "                )\n",
    "                metrics_df = evaluation_results.to_pandas()\n",
    "\n",
    "            # Funci√≥n para calcular m√©tricas seguras\n",
    "            def safe_mean_std(series):\n",
    "                clean_series = series.dropna()\n",
    "                if len(clean_series) > 0:\n",
    "                    return clean_series.mean(), clean_series.std()\n",
    "                return None, None\n",
    "\n",
    "            avg_metrics = {}\n",
    "            for metric in ['context_precision', 'context_recall', 'faithfulness', 'answer_correctness']:\n",
    "                if metric in metrics_df.columns:\n",
    "                    mean_val, std_val = safe_mean_std(metrics_df[metric])\n",
    "                    avg_metrics[f'{metric}_mean'] = mean_val\n",
    "                    avg_metrics[f'{metric}_std'] = std_val\n",
    "\n",
    "            # Guardar m√©tricas de la combinaci√≥n\n",
    "            combination_metrics = {\n",
    "                'combination_id': combo_idx,\n",
    "                'generator_llm': llm_name,\n",
    "                'evaluator_llm': llama_evaluator.model,\n",
    "                'embedding_model': test_embedding,\n",
    "                'weaviate_collection': WEAVIATE_CLASSES[test_embedding],\n",
    "                'prompt_type': test_prompt,\n",
    "                'total_questions': len(questions),\n",
    "                'successful_questions': successful_questions,\n",
    "                'evaluation_time_seconds': time.time() - combination_start_time,\n",
    "                **avg_metrics\n",
    "            }\n",
    "            qwen_metrics_results.append(combination_metrics)\n",
    "\n",
    "            print(f\"   ‚úÖ Evaluaci√≥n Llama ‚Üí Qwen completada:\")\n",
    "            for metric in ['context_precision_mean', 'context_recall_mean', 'faithfulness_mean', 'answer_correctness_mean']:\n",
    "                if metric in avg_metrics and avg_metrics[metric] is not None:\n",
    "                    print(f\"      {metric.replace('_mean', '').title()}: {avg_metrics[metric]:.3f}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Error en evaluaci√≥n RAGAS: {e}\")\n",
    "            qwen_metrics_results.append({\n",
    "                'combination_id': combo_idx,\n",
    "                'generator_llm': llm_name,\n",
    "                'evaluator_llm': llama_evaluator.model,\n",
    "                'embedding_model': test_embedding,\n",
    "                'weaviate_collection': WEAVIATE_CLASSES[test_embedding],\n",
    "                'prompt_type': test_prompt,\n",
    "                'total_questions': len(questions),\n",
    "                'successful_questions': successful_questions,\n",
    "                'evaluation_time_seconds': time.time() - combination_start_time,\n",
    "                'context_precision_mean': None,\n",
    "                'context_recall_mean': None,\n",
    "                'faithfulness_mean': None,\n",
    "                'answer_correctness_mean': None,\n",
    "                'context_precision_std': None,\n",
    "                'context_recall_std': None,\n",
    "                'faithfulness_std': None,\n",
    "                'answer_correctness_std': None,\n",
    "                'error': str(e)\n",
    "            })\n",
    "    else:\n",
    "        print(f\"   ‚ö†Ô∏è  Solo {successful_questions} preguntas exitosas, saltando RAGAS\")\n",
    "        qwen_metrics_results.append({\n",
    "            'combination_id': combo_idx,\n",
    "            'generator_llm': llm_name,\n",
    "            'evaluator_llm': llama_evaluator.model,\n",
    "            'embedding_model': test_embedding,\n",
    "            'weaviate_collection': WEAVIATE_CLASSES[test_embedding],\n",
    "            'prompt_type': test_prompt,\n",
    "            'total_questions': len(questions),\n",
    "            'successful_questions': successful_questions,\n",
    "            'evaluation_time_seconds': time.time() - combination_start_time,\n",
    "             'error': 'Insufficient successful questions'\n",
    "     })\n",
    "\n",
    "  # Crear DataFrames de resultados de Qwen\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EVALUACI√ìN QWEN COMPLETADA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "qwen_detailed_df = pd.DataFrame(qwen_detailed_results)\n",
    "qwen_metrics_df = pd.DataFrame(qwen_metrics_results)\n",
    "\n",
    "print(f\"‚úÖ Resultados detallados Qwen: {qwen_detailed_df.shape}\")\n",
    "print(f\"‚úÖ M√©tricas resumen Qwen: {qwen_metrics_df.shape}\")\n",
    "\n",
    "  # Guardar resultados de Qwen\n",
    "timestamp = pd.Timestamp.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "qwen_detailed_csv = f'qwen_evaluation_detailed_{timestamp}.csv'\n",
    "qwen_metrics_csv = f'qwen_evaluation_metrics_{timestamp}.csv'\n",
    "\n",
    "qwen_detailed_df.to_csv(qwen_detailed_csv, index=False, encoding='utf-8')\n",
    "qwen_metrics_df.to_csv(qwen_metrics_csv, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"Resultados Qwen guardados:\")\n",
    "print(f\"   Detallado: {qwen_detailed_csv}\")\n",
    "print(f\"   M√©tricas: {qwen_metrics_csv}\")\n",
    "\n",
    "  # Mostrar mejores combinaciones de Qwen\n",
    "if not qwen_metrics_df.empty:\n",
    "    successful_qwen = len([c for c in qwen_metrics_results if 'error' not in c or not c.get('error')])\n",
    "    print(f\"\\nRESUMEN QWEN:\")\n",
    "    print(f\"   Combinaciones totales: {total_qwen_combinations}\")\n",
    "    print(f\"   Evaluaciones exitosas: {successful_qwen}\")\n",
    "    print(f\"   Tasa de √©xito: {successful_qwen/total_qwen_combinations*100:.1f}%\")\n",
    "\n",
    "    print(f\"\\nMEJORES COMBINACIONES QWEN:\")\n",
    "\n",
    "    for metric in ['context_precision_mean', 'context_recall_mean', 'faithfulness_mean', 'answer_correctness_mean']:\n",
    "        if metric in qwen_metrics_df.columns:\n",
    "            valid_data = qwen_metrics_df[qwen_metrics_df[metric].notna()]\n",
    "            if not valid_data.empty:\n",
    "                print(f\"\\n{metric.upper().replace('_', ' ')}:\")\n",
    "                top_qwen = valid_data.nlargest(3, metric)[['embedding_model', 'prompt_type', metric]]\n",
    "                print(top_qwen.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROBQAR EWSTYO\n",
    "Los modelos m√°s r√°pidos para evitar timeouts:\n",
    "\n",
    "  1. llama3.2:1b - El m√°s r√°pido (20-30 segundos por evaluaci√≥n)        \n",
    "  2. qwen2.5:1.5b - Muy r√°pido (30-40 segundos)\n",
    "  3. phi3.5:3.8b - R√°pido (60-90 segundos)\n",
    "\n",
    "  üéØ Opci√≥n 2: Volver a Mistral API (recomendado)\n",
    "\n",
    "  Mucho m√°s r√°pido que cualquier modelo local (~2-5 segundos vs minutos)\n",
    "\n",
    "  üìã C√ìDIGO: Solo Qwen con Mistral API como evaluador\n",
    "\n",
    "  from itertools import product\n",
    "  from datasets import Dataset\n",
    "  import pandas as pd\n",
    "  import time\n",
    "  from tqdm import tqdm\n",
    "  import warnings\n",
    "  import random\n",
    "  warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "  # Importar RAGAS y m√©tricas\n",
    "  from ragas import evaluate\n",
    "  from ragas.metrics import (\n",
    "      context_precision,\n",
    "      context_recall,\n",
    "      faithfulness,\n",
    "      answer_correctness\n",
    "  )\n",
    "\n",
    "  # üéØ VOLVER A MISTRAL API COMO EVALUADOR (M√ÅS R√ÅPIDO)\n",
    "  from langchain_mistralai import ChatMistralAI\n",
    "\n",
    "  mistral_evaluator = ChatMistralAI(\n",
    "      api_key=\"dv0RMPhxjgwM6pePID1FXvloyU2iltVu\",\n",
    "      model=\"mistral-small-latest\",\n",
    "      temperature=0.1,\n",
    "      max_retries=5\n",
    "  )\n",
    "\n",
    "  # Funci√≥n para manejar rate limits autom√°ticamente\n",
    "  def evaluate_with_rate_limit_handling(dataset, llm, embeddings_model, max_attempts=3):\n",
    "      base_delay = 60\n",
    "\n",
    "      for attempt in range(max_attempts):\n",
    "          try:\n",
    "              print(f\"      üîÑ Evaluaci√≥n intento {attempt + 1}/{max_attempts}\")\n",
    "\n",
    "              result = evaluate(\n",
    "                  dataset,\n",
    "                  llm=llm,\n",
    "                  embeddings=embeddings_model,\n",
    "                  metrics=[context_precision, context_recall, faithfulness, answer_correctness],\n",
    "                  raise_exceptions=False\n",
    "              )\n",
    "\n",
    "              print(f\"      ‚úÖ Evaluaci√≥n exitosa en intento {attempt + 1}\")\n",
    "              return result, None\n",
    "\n",
    "          except Exception as e:\n",
    "              error_msg = str(e).lower()\n",
    "\n",
    "              if \"rate limit\" in error_msg or \"429\" in str(e):\n",
    "                  delay = base_delay * (2 ** attempt) + random.uniform(0, 30)\n",
    "                  print(f\"      ‚è∞ Rate limit. Esperando {delay:.0f} segundos...\")\n",
    "                  time.sleep(delay)\n",
    "              else:\n",
    "                  print(f\"      ‚ùå Error: {e}\")\n",
    "                  if attempt == max_attempts - 1:\n",
    "                      return None, str(e)\n",
    "                  time.sleep(30)\n",
    "\n",
    "      return None, \"M√°ximo de intentos alcanzado\"\n",
    "\n",
    "  print(\"üöÄ EVALUACI√ìN SOLO QWEN CON MISTRAL API\")\n",
    "  print(\"ü§ñ Generador: Qwen3-4B-instruct-2507\")\n",
    "  print(f\"üß† Evaluador: Mistral API ({mistral_evaluator.model})\")\n",
    "  print(\"üìä M√©tricas: context_precision, context_recall, faithfulness, answer_correctness\")\n",
    "  print(\"=\"*80)\n",
    "\n",
    "  # Configuraci√≥n espec√≠fica para solo Qwen\n",
    "  test_llm = 'Qwen3-4B-instruct-2507'  # Solo Qwen como generador\n",
    "  embeddings = list(EMBEDDING_MODELS.keys())  # 3 embeddings\n",
    "  prompts = list(PROMPTS.keys())  # 3 prompts\n",
    "\n",
    "  # Listas para almacenar resultados\n",
    "  qwen_detailed_results = []\n",
    "  qwen_metrics_results = []\n",
    "\n",
    "  # Generar combinaciones solo para Qwen\n",
    "  qwen_combinations = list(product([test_llm], embeddings, prompts))\n",
    "  total_combinations = len(qwen_combinations)\n",
    "\n",
    "  print(f\"üìã Evaluando {total_combinations} combinaciones para Qwen:\")\n",
    "  for emb in embeddings:\n",
    "      for prompt in prompts:\n",
    "          print(f\"   ‚Ä¢ {test_llm} + {emb} + {prompt}\")\n",
    "  print()\n",
    "\n",
    "  # Evaluar cada combinaci√≥n\n",
    "  for combo_idx, (llm_name, test_embedding, test_prompt) in enumerate(qwen_combinations):\n",
    "\n",
    "      print(f\"üîÑ QWEN COMBINACI√ìN {combo_idx+1}/{total_combinations}\")\n",
    "      print(f\"   Generador: {llm_name}\")\n",
    "      print(f\"   Embedding: {test_embedding} -> {WEAVIATE_CLASSES[test_embedding]}\")\n",
    "      print(f\"   Prompt: {test_prompt}\")\n",
    "\n",
    "      combination_start_time = time.time()\n",
    "      results_list = []\n",
    "      successful_questions = 0\n",
    "\n",
    "      # Generar respuestas con Qwen\n",
    "      print(\"   üìù Generando respuestas con Qwen...\")\n",
    "      for q_idx, question in enumerate(tqdm(questions, desc=\"   Preguntas\")):\n",
    "          try:\n",
    "              state = {\n",
    "                  'question': question,\n",
    "                  'llm_name': llm_name,  # Qwen genera\n",
    "                  'embedding_name': test_embedding,\n",
    "                  'prompt_name': test_prompt,\n",
    "                  'context': [], 'answer': '', 'metadata': {}\n",
    "              }\n",
    "\n",
    "              final_state = graph.invoke(state)\n",
    "              answer = final_state.get('answer', '')\n",
    "              contexts = final_state.get('context', [])\n",
    "\n",
    "              if answer and 'ERROR:' not in answer and len(contexts) > 0:\n",
    "                  results_list.append({\n",
    "                      'question': question,\n",
    "                      'answer': answer,\n",
    "                      'contexts': [doc.page_content for doc in contexts],\n",
    "                      'ground_truth': ground_truths[q_idx] if q_idx < len(ground_truths) else ''\n",
    "                  })\n",
    "                  successful_questions += 1\n",
    "\n",
    "              # Almacenar detalles\n",
    "              qwen_detailed_results.append({\n",
    "                  'combination_id': combo_idx,\n",
    "                  'generator_llm': llm_name,\n",
    "                  'evaluator_llm': 'mistral-small-latest',\n",
    "                  'embedding_model': test_embedding,\n",
    "                  'weaviate_collection': WEAVIATE_CLASSES[test_embedding],\n",
    "                  'prompt_type': test_prompt,\n",
    "                  'question_id': q_idx,\n",
    "                  'question': question,\n",
    "                  'answer': answer,\n",
    "                  'contexts': [doc.page_content for doc in contexts],\n",
    "                  'num_contexts': len(contexts),\n",
    "                  'ground_truth': ground_truths[q_idx] if q_idx < len(ground_truths) else '',\n",
    "                  'status': 'success' if answer and 'ERROR:' not in answer else 'error'\n",
    "              })\n",
    "\n",
    "          except Exception as e:\n",
    "              print(f\"      ‚ùå Error en pregunta {q_idx+1}: {e}\")\n",
    "              qwen_detailed_results.append({\n",
    "                  'combination_id': combo_idx,\n",
    "                  'generator_llm': llm_name,\n",
    "                  'evaluator_llm': 'mistral-small-latest',\n",
    "                  'embedding_model': test_embedding,\n",
    "                  'weaviate_collection': WEAVIATE_CLASSES[test_embedding],\n",
    "                  'prompt_type': test_prompt,\n",
    "                  'question_id': q_idx,\n",
    "                  'question': question,\n",
    "                  'answer': f'ERROR: {str(e)}',\n",
    "                  'contexts': [],\n",
    "                  'num_contexts': 0,\n",
    "                  'ground_truth': ground_truths[q_idx] if q_idx < len(ground_truths) else '',\n",
    "                  'status': 'error'\n",
    "              })\n",
    "\n",
    "      print(f\"   ‚úÖ {successful_questions}/{len(questions)} preguntas exitosas\")\n",
    "\n",
    "      # Evaluar con RAGAS usando Mistral\n",
    "      if successful_questions >= 2:\n",
    "          print(\"   üßÆ Evaluando respuestas de Qwen con Mistral API...\" )\n",
    "\n",
    "          dataset = Dataset.from_list(results_list)\n",
    "          current_embedding_model = EMBEDDING_MODELS[test_embedding]\n",
    "\n",
    "          # üéØ USAR FUNCI√ìN CON MANEJO DE RATE LIMIT\n",
    "          evaluation_results, error = evaluate_with_rate_limit_handling(\n",
    "              dataset,\n",
    "              mistral_evaluator,\n",
    "              current_embedding_model\n",
    "          )\n",
    "\n",
    "          if evaluation_results is not None:\n",
    "              # Procesar m√©tricas\n",
    "              metrics_df = evaluation_results.to_pandas()\n",
    "\n",
    "              def safe_mean_std(series):\n",
    "                  clean_series = series.dropna()\n",
    "                  if len(clean_series) > 0:\n",
    "                      return clean_series.mean(), clean_series.std()\n",
    "                  return None, None\n",
    "\n",
    "              avg_metrics = {}\n",
    "              for metric in ['context_precision', 'context_recall', 'faithfulness', 'answer_correctness']:\n",
    "                  if metric in metrics_df.columns:\n",
    "                      mean_val, std_val = safe_mean_std(metrics_df[metric])\n",
    "                      avg_metrics[f'{metric}_mean'] = mean_val\n",
    "                      avg_metrics[f'{metric}_std'] = std_val\n",
    "\n",
    "              combination_metrics = {\n",
    "                  'combination_id': combo_idx,\n",
    "                  'generator_llm': llm_name,\n",
    "                  'evaluator_llm': 'mistral-small-latest',\n",
    "                  'embedding_model': test_embedding,\n",
    "                  'weaviate_collection': WEAVIATE_CLASSES[test_embedding],\n",
    "                  'prompt_type': test_prompt,\n",
    "                  'total_questions': len(questions),\n",
    "                  'successful_questions': successful_questions,\n",
    "                  'evaluation_time_seconds': time.time() - combination_start_time,\n",
    "                  **avg_metrics\n",
    "              }\n",
    "              qwen_metrics_results.append(combination_metrics)\n",
    "\n",
    "              print(f\"   ‚úÖ Evaluaci√≥n Mistral ‚Üí Qwen completada:\")\n",
    "              for metric in ['context_precision_mean', 'context_recall_mean', 'faithfulness_mean', 'answer_correctness_mean']:\n",
    "                  if metric in avg_metrics and avg_metrics[metric] is not None:\n",
    "                      print(f\"      {metric.replace('_mean', '').title()}: {avg_metrics[metric]:.3f}\")\n",
    "\n",
    "          else:\n",
    "              print(f\"   ‚ùå Evaluaci√≥n fall√≥: {error}\")\n",
    "              qwen_metrics_results.append({\n",
    "                  'combination_id': combo_idx,\n",
    "                  'generator_llm': llm_name,\n",
    "                  'evaluator_llm': 'mistral-small-latest',\n",
    "                  'embedding_model': test_embedding,\n",
    "                  'weaviate_collection': WEAVIATE_CLASSES[test_embedding],\n",
    "                  'prompt_type': test_prompt,\n",
    "                  'total_questions': len(questions),\n",
    "                  'successful_questions': successful_questions,\n",
    "                  'evaluation_time_seconds': time.time() - combination_start_time,\n",
    "                  'error': error\n",
    "              })\n",
    "\n",
    "      # Delay inteligente entre combinaciones\n",
    "      if combo_idx < len(qwen_combinations) - 1:\n",
    "          base_delay = 90 + random.uniform(0, 30)  # 1.5-2 minutos\n",
    "          print(f\"   ‚è∏Ô∏è  Esperando {base_delay:.0f} segundos antes de siguiente combinaci√≥n...\")\n",
    "          time.sleep(base_delay)\n",
    "\n",
    "  # Crear DataFrames finales\n",
    "  print(\"\\n\" + \"=\"*80)\n",
    "  print(\"üéâ EVALUACI√ìN QWEN CON MISTRAL COMPLETADA\")\n",
    "  print(\"=\"*80)\n",
    "\n",
    "  qwen_detailed_df = pd.DataFrame(qwen_detailed_results)\n",
    "  qwen_metrics_df = pd.DataFrame(qwen_metrics_results)\n",
    "\n",
    "  print(f\"‚úÖ Resultados detallados: {qwen_detailed_df.shape}\")\n",
    "  print(f\"‚úÖ M√©tricas resumen: {qwen_metrics_df.shape}\")\n",
    "\n",
    "  # Guardar resultados\n",
    "  timestamp = pd.Timestamp.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "  detailed_csv = f'qwen_mistral_evaluation_detailed_{timestamp}.csv'\n",
    "  metrics_csv = f'qwen_mistral_evaluation_metrics_{timestamp}.csv'\n",
    "\n",
    "  qwen_detailed_df.to_csv(detailed_csv, index=False, encoding='utf-8')\n",
    "  qwen_metrics_df.to_csv(metrics_csv, index=False, encoding='utf-8')\n",
    "\n",
    "  print(f\"üíæ Resultados guardados:\")\n",
    "  print(f\"   Detallado: {detailed_csv}\")\n",
    "  print(f\"   M√©tricas: {metrics_csv}\")\n",
    "\n",
    "  # Mostrar mejores combinaciones\n",
    "  if not qwen_metrics_df.empty:\n",
    "      successful_evaluations = len([c for c in qwen_metrics_results if 'error' not in c or not c.get('error')])\n",
    "      print(f\"\\nüìä RESUMEN:\")\n",
    "      print(f\"   Combinaciones totales: {total_combinations}\")\n",
    "      print(f\"   Evaluaciones exitosas: {successful_evaluations}\")\n",
    "      print(f\"   Tasa de √©xito: {successful_evaluations/total_combinations*100:.1f}%\")\n",
    "\n",
    "      print(f\"\\nüèÜ MEJORES COMBINACIONES QWEN:\")\n",
    "\n",
    "      for metric in ['context_precision_mean', 'context_recall_mean', 'faithfulness_mean', 'answer_correctness_mean']:\n",
    "          if metric in qwen_metrics_df.columns:\n",
    "              valid_data = qwen_metrics_df[qwen_metrics_df[metric].notna()]\n",
    "              if not valid_data.empty:\n",
    "                  print(f\"\\nüìä {metric.upper().replace('_', ' ')}:\")\n",
    "                  top_3 = valid_data.nlargest(3, metric)[['embedding_model', 'prompt_type', metric]]\n",
    "                  print(top_3.to_string(index=False))\n",
    "\n",
    "  ‚ö° Ventajas de esta aproximaci√≥n:\n",
    "\n",
    "  1. Mucho m√°s r√°pido: ~30 minutos vs ~6 horas\n",
    "  2. Menos complejo: Solo 9 combinaciones vs 18\n",
    "  3. Gesti√≥n autom√°tica de rate limits\n",
    "  4. Resultados comparables: Mistral da evaluaciones de buena calidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.metrics import (\n",
    "    context_precision,    \n",
    "    context_recall,       \n",
    "    faithfulness,         \n",
    "    answer_correctness    \n",
    "  )\n",
    "import asyncio\n",
    "# Configurar Mistral para evaluaci√≥n RAGAS\n",
    "from langchain_mistralai import ChatMistralAI\n",
    "mistral_llm = ChatMistralAI(\n",
    "    api_key=\"dv0RMPhxjgwM6pePID1FXvloyU2iltVu\",\n",
    "    model=\"mistral-small-latest\",\n",
    "    temperature=0.1,\n",
    "    timeout=120,  # 2 minutos por llamada\n",
    "    max_retries=3\n",
    "  )\n",
    "\n",
    "# Embeddings para evaluaci√≥n\n",
    "#eval_embeddings = EMBEDDING_MODELS[\"all-MiniLM-L6-v2\"]\n",
    "# Configuraci√≥n de modelos, embeddings y prompts\n",
    "llm_models = list(LLM.keys())  # Usa los LLMs definidos en tu notebook\n",
    "embeddings = list(EMBEDDING_MODELS.keys())  # Usa los embeddings definidos\n",
    "prompts = list(PROMPTS.keys())  # Usa los prompts definidos\n",
    "\n",
    "# DataFrame para todos los resultados\n",
    "df_results_list = []\n",
    "combination_metrics_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "from langchain_ollama import ChatOllama\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "# Importar RAGAS y m√©tricas\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    context_precision,\n",
    "    context_recall,\n",
    "    faithfulness,\n",
    "    answer_correctness\n",
    ")\n",
    "\n",
    "# Configurar Mistral para evaluaci√≥n RAGAS\n",
    "from langchain_mistralai import ChatMistralAI\n",
    "evaluation_llm = ChatOllama(\n",
    "      model=\"hf.co/bartowski/Llama-3.2-3B-Instruct-GGUF:Q8_0\",  # Tu modelo exacto\n",
    "      temperature=0.1,\n",
    "      num_predict=1000,\n",
    "      timeout=300\n",
    ")\n",
    "\n",
    "  # PERSONALIZAR EL PROMPT DE CONTEXT_PRECISION EN ESPA√ëOL\n",
    "context_precision.context_precision_prompt.instruction = \"\"\"\n",
    "  Dada una pregunta sobre arqueolog√≠a y un conjunto de contextos que pueden estar en varios idiomas (espa√±ol, ingl√©s, franc√©s, catal√°n, portugu√©s), identifica qu√© contextos son √∫tiles para responder la pregunta.\n",
    "  Los contextos pueden contener informaci√≥n t√©cnica, fechas, yacimientos arqueol√≥gicos, cronolog√≠as, dataciones, etc. Un contexto es √∫til si contiene informaci√≥n relevante que ayude a responder la pregunta, aunque sea parcialmente, independientemente      \n",
    "  del idioma en que est√© escrito.\n",
    "\n",
    "  Pregunta: {question}\n",
    "  Contextos: {contexts}\n",
    "\n",
    "  Contextos √∫tiles (devuelve solo los √≠ndices de contextos √∫tiles, ej: [0, 2]):\n",
    "  \"\"\"\n",
    "\n",
    "# Configuraci√≥n seg√∫n tu notebook\n",
    "llm_models = list(LLM.keys())\n",
    "embeddings = list(EMBEDDING_MODELS.keys())\n",
    "prompts = list(PROMPTS.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuando desde combinaci√≥n 2\n",
      "EVALUACI√ìN RAGAS CON 27 COMBINACIONES\n",
      "M√©tricas: context_precision, context_recall, faithfulness, answer_correctness\n",
      "Evaluador: Mistral API (mistral-small-latest)\n",
      "Prompt personalizado en espa√±ol para arqueolog√≠a\n",
      "================================================================================\n",
      "\n",
      "COMBINACI√ìN 1/27\n",
      "   LLM: Qwen3-4B-instruct-2507\n",
      "   Embedding: all-MiniLM-L6-v2 -> IdearqAllMiniLM\n",
      "   Prompt: prompt_zero_shot\n",
      "Generando respuestas...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Published by Elsevier Inc. All rights reserved. doi:10.1016/j.yqres.2011.12.003 Contents lists available at SciVerse ScienceDirect Quaternary Research journal homepage: www.elsevier.com/locate/yqres https://doi.org/10.1016/j.yqres.2011.12.003 Published online by Cambridge University Press Introduc...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  12%|‚ñà‚ñé        | 1/8 [04:31<31:39, 271.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. A data obtida, √© claramente mais recuada que os con¬≠ textos mais antigos reportados em territ√≥rio hoje portu¬≠ gu√™s, nomeadamente Gruta da Nascente do Rio Almonda (OxA¬≠‚Äë9287 ‚Äì 5480¬≠‚Äë5320 cal BC a 2 sigmas) e da Gruta do Caldeir√£o (OxA¬≠‚Äë1036 ‚Äì 5480 ‚Äì 5070 cal BC a 2 sigmas). Entre n√≥s, apenas se rep...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  25%|‚ñà‚ñà‚ñå       | 2/8 [05:50<15:50, 158.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 2. ENCUADRE CRONO-CULTURAL DEL HA- LLAZGO: COGOTAS I Entre las entidades arqueol√≥gicas de la Edad del Bronce peninsular, Cogotas I sobresale por su extensa cobertura geogr√°fica, que desborda la Meseta por el Valle del Ebro y Extremadura, y por su dilatada crono- log√≠a ‚Äîc. 1800-1150 cal BC, cubrien...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  38%|‚ñà‚ñà‚ñà‚ñä      | 3/8 [06:54<09:35, 115.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. y NEIRA, A. (1999): ‚ÄúPrehistoria‚Äù, en M.A. Rabanal Alonso (coord.): La His¬≠ toria de Le√≥n, tomo I, Universidad de Le√≥n y Diario de Le√≥n. CELIS S√ÅNCHEZ, J. (1993a): ‚ÄúLa secuencia del poblado de la Primera Edad del Hierro de los ¬´Cuestos de la Estaci√≥n¬ª, Benavente, Zamora‚Äù, en F. Romero, C. Sanz y Z...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4/8 [08:14<06:45, 101.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Con el desarrollo de las excavaciones arqueol√≥gicas en diversos asentamientos, el aumento del n√∫mero de dataciones y la realizaci√≥n de diversos estudios en los √∫ltimos a√±os, las perspectivas de investigaci√≥n sobre el Bronce final en el Levante comienza a variar sustancialmente, estando ya en condi...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5/8 [13:28<08:53, 177.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. En la actualidad, El Argar sigue siendo el grupo arqueo¬≠ l√≥gico de la Edad del Bronce mejor conocido de la pen√≠nsula ib√©rica, con un desarrollo temporal entre el 2200 y el 1550 cal BC. Tambi√©n se puede afirmar que fue una de las sociedades con mayor capacidad productiva y desarrollo social de la E...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6/8 [15:35<05:21, 160.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Prehist., 74, N.¬∫ 2, julio-diciembre 2017, pp. 296-318, ISSN: 0082-5638 doi: 10.3989/tp.2017.12196 Torres Ortiz, M. 1996: ‚ÄúLa cronolog√≠a de los t√∫mulos A y B de Setefilla. El origen del rito de la crema- ci√≥n en la cultura tart√©sica‚Äù. Complutum 7: 147-162. Torres Ortiz, M. 1998: ‚ÄúLa cronolog√≠a abs...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 7/8 [16:58<02:15, 135.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Ruiz Alonso, M. Guenaga, A., L√≥pez Quintana, J. C. y Zapata Pe√±a, L. (2010). Antracolog√≠a y yacimientos dolm√©nicos: el caso de Mendigana. En Actas del Congreso Internacional sobre Megalitismo y otras manifestaciones funerarias con- tempor√°neas en su contexto social, econ√≥mico y cultural (pp. 566-5...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [18:17<00:00, 137.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "16/8 preguntas exitosas\n",
      "Evaluando con RAGAS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ca140168fef4584b75c9faa8af90bf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[1]: TimeoutError()\n",
      "Exception raised in Job[2]: TimeoutError()\n",
      "Exception raised in Job[3]: TimeoutError()\n",
      "Exception raised in Job[4]: TimeoutError()\n",
      "Exception raised in Job[5]: TimeoutError()\n",
      "Exception raised in Job[6]: TimeoutError()\n",
      "Exception raised in Job[7]: TimeoutError()\n",
      "Exception raised in Job[9]: TimeoutError()\n",
      "Exception raised in Job[8]: TimeoutError()\n",
      "Exception raised in Job[10]: TimeoutError()\n",
      "Exception raised in Job[11]: TimeoutError()\n",
      "Exception raised in Job[13]: TimeoutError()\n",
      "Exception raised in Job[12]: TimeoutError()\n",
      "Exception raised in Job[14]: TimeoutError()\n",
      "Exception raised in Job[15]: TimeoutError()\n",
      "Exception raised in Job[16]: TimeoutError()\n",
      "Exception raised in Job[18]: TimeoutError()\n",
      "Exception raised in Job[19]: TimeoutError()\n",
      "Exception raised in Job[22]: TimeoutError()\n",
      "Exception raised in Job[20]: TimeoutError()\n",
      "Exception raised in Job[23]: TimeoutError()\n",
      "Exception raised in Job[25]: TimeoutError()\n",
      "Exception raised in Job[24]: TimeoutError()\n",
      "Exception raised in Job[26]: TimeoutError()\n",
      "Exception raised in Job[27]: TimeoutError()\n",
      "Exception raised in Job[29]: TimeoutError()\n",
      "Exception raised in Job[28]: TimeoutError()\n",
      "Exception raised in Job[31]: TimeoutError()\n",
      "Exception raised in Job[30]: TimeoutError()\n",
      "Exception raised in Job[32]: TimeoutError()\n",
      "Exception raised in Job[33]: TimeoutError()\n",
      "Exception raised in Job[34]: TimeoutError()\n",
      "Exception raised in Job[35]: TimeoutError()\n",
      "Exception raised in Job[36]: TimeoutError()\n",
      "Exception raised in Job[37]: TimeoutError()\n",
      "Exception raised in Job[38]: TimeoutError()\n",
      "Exception raised in Job[39]: TimeoutError()\n",
      "Exception raised in Job[40]: TimeoutError()\n",
      "Exception raised in Job[41]: TimeoutError()\n",
      "Exception raised in Job[42]: TimeoutError()\n",
      "Exception raised in Job[43]: TimeoutError()\n",
      "Exception raised in Job[44]: TimeoutError()\n",
      "Exception raised in Job[45]: TimeoutError()\n",
      "Exception raised in Job[46]: TimeoutError()\n",
      "Exception raised in Job[47]: TimeoutError()\n",
      "Exception raised in Job[48]: TimeoutError()\n",
      "Exception raised in Job[50]: TimeoutError()\n",
      "Exception raised in Job[51]: TimeoutError()\n",
      "Exception raised in Job[52]: TimeoutError()\n",
      "Exception raised in Job[53]: TimeoutError()\n",
      "Exception raised in Job[54]: TimeoutError()\n",
      "Exception raised in Job[55]: TimeoutError()\n",
      "Exception raised in Job[56]: TimeoutError()\n",
      "Exception raised in Job[57]: TimeoutError()\n",
      "Exception raised in Job[59]: TimeoutError()\n",
      "Exception raised in Job[58]: TimeoutError()\n",
      "Exception raised in Job[60]: TimeoutError()\n",
      "Exception raised in Job[63]: TimeoutError()\n",
      "Exception raised in Job[61]: TimeoutError()\n",
      "Exception raised in Job[62]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      üìä Columnas disponibles: ['user_input', 'retrieved_contexts', 'response', 'reference', 'context_precision', 'context_recall', 'faithfulness', 'answer_correctness']\n",
      "      üìä Filas en dataset: 16\n",
      "      context_precision: ‚ùå Sin valores v√°lidos\n",
      "      context_recall: 0.667 (calculado en 3/16 preguntas)\n",
      "      faithfulness: ‚ùå Sin valores v√°lidos\n",
      "      answer_correctness: ‚ùå Sin valores v√°lidos\n",
      "RAGAS completado:\n",
      "      Context_Recall: 0.667\n",
      "   ‚è∏Ô∏è  Esperando 60 segundos para evitar rate limit...\n",
      "\n",
      "COMBINACI√ìN 2/27\n",
      "   LLM: Qwen3-4B-instruct-2507\n",
      "   Embedding: all-MiniLM-L6-v2 -> IdearqAllMiniLM\n",
      "   Prompt: prompt_one_shot\n",
      "Generando respuestas...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Published by Elsevier Inc. All rights reserved. doi:10.1016/j.yqres.2011.12.003 Contents lists available at SciVerse ScienceDirect Quaternary Research journal homepage: www.elsevier.com/locate/yqres https://doi.org/10.1016/j.yqres.2011.12.003 Published online by Cambridge University Press Introduc...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  12%|‚ñà‚ñé        | 1/8 [04:19<30:17, 259.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. A data obtida, √© claramente mais recuada que os con¬≠ textos mais antigos reportados em territ√≥rio hoje portu¬≠ gu√™s, nomeadamente Gruta da Nascente do Rio Almonda (OxA¬≠‚Äë9287 ‚Äì 5480¬≠‚Äë5320 cal BC a 2 sigmas) e da Gruta do Caldeir√£o (OxA¬≠‚Äë1036 ‚Äì 5480 ‚Äì 5070 cal BC a 2 sigmas). Entre n√≥s, apenas se rep...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  25%|‚ñà‚ñà‚ñå       | 2/8 [05:35<15:08, 151.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 2. ENCUADRE CRONO-CULTURAL DEL HA- LLAZGO: COGOTAS I Entre las entidades arqueol√≥gicas de la Edad del Bronce peninsular, Cogotas I sobresale por su extensa cobertura geogr√°fica, que desborda la Meseta por el Valle del Ebro y Extremadura, y por su dilatada crono- log√≠a ‚Äîc. 1800-1150 cal BC, cubrien...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  38%|‚ñà‚ñà‚ñà‚ñä      | 3/8 [05:49<07:22, 88.54s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. y NEIRA, A. (1999): ‚ÄúPrehistoria‚Äù, en M.A. Rabanal Alonso (coord.): La His¬≠ toria de Le√≥n, tomo I, Universidad de Le√≥n y Diario de Le√≥n. CELIS S√ÅNCHEZ, J. (1993a): ‚ÄúLa secuencia del poblado de la Primera Edad del Hierro de los ¬´Cuestos de la Estaci√≥n¬ª, Benavente, Zamora‚Äù, en F. Romero, C. Sanz y Z...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4/8 [07:13<05:47, 86.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Con el desarrollo de las excavaciones arqueol√≥gicas en diversos asentamientos, el aumento del n√∫mero de dataciones y la realizaci√≥n de diversos estudios en los √∫ltimos a√±os, las perspectivas de investigaci√≥n sobre el Bronce final en el Levante comienza a variar sustancialmente, estando ya en condi...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5/8 [13:35<09:40, 193.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. En la actualidad, El Argar sigue siendo el grupo arqueo¬≠ l√≥gico de la Edad del Bronce mejor conocido de la pen√≠nsula ib√©rica, con un desarrollo temporal entre el 2200 y el 1550 cal BC. Tambi√©n se puede afirmar que fue una de las sociedades con mayor capacidad productiva y desarrollo social de la E...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6/8 [15:39<05:39, 169.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Prehist., 74, N.¬∫ 2, julio-diciembre 2017, pp. 296-318, ISSN: 0082-5638 doi: 10.3989/tp.2017.12196 Torres Ortiz, M. 1996: ‚ÄúLa cronolog√≠a de los t√∫mulos A y B de Setefilla. El origen del rito de la crema- ci√≥n en la cultura tart√©sica‚Äù. Complutum 7: 147-162. Torres Ortiz, M. 1998: ‚ÄúLa cronolog√≠a abs...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 7/8 [16:44<02:15, 135.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [17:14<00:00, 129.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error en pregunta 8: [WinError 10054] Se ha forzado la interrupci√≥n de una conexi√≥n existente por el host remoto\n",
      "14/8 preguntas exitosas\n",
      "Evaluando con RAGAS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "815ea19d0acc4ff29537b4c799a61bfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[1]: TimeoutError()\n",
      "Exception raised in Job[2]: TimeoutError()\n",
      "Exception raised in Job[5]: TimeoutError()\n",
      "Exception raised in Job[4]: TimeoutError()\n",
      "Exception raised in Job[3]: TimeoutError()\n",
      "Exception raised in Job[6]: TimeoutError()\n",
      "Exception raised in Job[10]: TimeoutError()\n",
      "Exception raised in Job[9]: TimeoutError()\n",
      "Exception raised in Job[8]: TimeoutError()\n",
      "Exception raised in Job[7]: TimeoutError()\n",
      "Exception raised in Job[13]: TimeoutError()\n",
      "Exception raised in Job[12]: TimeoutError()\n",
      "Exception raised in Job[15]: TimeoutError()\n",
      "Exception raised in Job[11]: TimeoutError()\n",
      "Exception raised in Job[14]: TimeoutError()\n",
      "Exception raised in Job[16]: TimeoutError()\n",
      "Exception raised in Job[18]: TimeoutError()\n",
      "Exception raised in Job[19]: TimeoutError()\n",
      "Exception raised in Job[21]: TimeoutError()\n",
      "Exception raised in Job[20]: TimeoutError()\n",
      "Exception raised in Job[22]: TimeoutError()\n",
      "Exception raised in Job[24]: TimeoutError()\n",
      "Exception raised in Job[23]: TimeoutError()\n",
      "Exception raised in Job[27]: TimeoutError()\n",
      "Exception raised in Job[26]: TimeoutError()\n",
      "Exception raised in Job[25]: TimeoutError()\n",
      "Exception raised in Job[29]: TimeoutError()\n",
      "Exception raised in Job[28]: TimeoutError()\n",
      "Exception raised in Job[30]: TimeoutError()\n",
      "Exception raised in Job[31]: TimeoutError()\n",
      "Exception raised in Job[32]: TimeoutError()\n",
      "Exception raised in Job[33]: TimeoutError()\n",
      "Exception raised in Job[35]: TimeoutError()\n",
      "Exception raised in Job[34]: TimeoutError()\n",
      "Exception raised in Job[37]: TimeoutError()\n",
      "Exception raised in Job[36]: TimeoutError()\n",
      "Exception raised in Job[38]: TimeoutError()\n",
      "Exception raised in Job[39]: TimeoutError()\n",
      "Exception raised in Job[40]: TimeoutError()\n",
      "Exception raised in Job[42]: TimeoutError()\n",
      "Exception raised in Job[41]: TimeoutError()\n",
      "Exception raised in Job[44]: TimeoutError()\n",
      "Exception raised in Job[43]: TimeoutError()\n",
      "Exception raised in Job[46]: TimeoutError()\n",
      "Exception raised in Job[45]: TimeoutError()\n",
      "Exception raised in Job[47]: TimeoutError()\n",
      "Exception raised in Job[48]: TimeoutError()\n",
      "Exception raised in Job[50]: TimeoutError()\n",
      "Exception raised in Job[51]: TimeoutError()\n",
      "Exception raised in Job[52]: TimeoutError()\n",
      "Exception raised in Job[53]: TimeoutError()\n",
      "Exception raised in Job[54]: TimeoutError()\n",
      "Exception raised in Job[55]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      üìä Columnas disponibles: ['user_input', 'retrieved_contexts', 'response', 'reference', 'context_precision', 'context_recall', 'faithfulness', 'answer_correctness']\n",
      "      üìä Filas en dataset: 14\n",
      "      context_precision: ‚ùå Sin valores v√°lidos\n",
      "      context_recall: 0.500 (calculado en 2/14 preguntas)\n",
      "      faithfulness: ‚ùå Sin valores v√°lidos\n",
      "      answer_correctness: ‚ùå Sin valores v√°lidos\n",
      "RAGAS completado:\n",
      "      Context_Recall: 0.500\n",
      "   ‚è∏Ô∏è  Esperando 60 segundos para evitar rate limit...\n",
      "\n",
      "COMBINACI√ìN 3/27\n",
      "   LLM: Qwen3-4B-instruct-2507\n",
      "   Embedding: all-MiniLM-L6-v2 -> IdearqAllMiniLM\n",
      "   Prompt: prompt_few_shot\n",
      "Generando respuestas...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Published by Elsevier Inc. All rights reserved. doi:10.1016/j.yqres.2011.12.003 Contents lists available at SciVerse ScienceDirect Quaternary Research journal homepage: www.elsevier.com/locate/yqres https://doi.org/10.1016/j.yqres.2011.12.003 Published online by Cambridge University Press Introduc...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  12%|‚ñà‚ñé        | 1/8 [04:23<30:47, 263.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. A data obtida, √© claramente mais recuada que os con¬≠ textos mais antigos reportados em territ√≥rio hoje portu¬≠ gu√™s, nomeadamente Gruta da Nascente do Rio Almonda (OxA¬≠‚Äë9287 ‚Äì 5480¬≠‚Äë5320 cal BC a 2 sigmas) e da Gruta do Caldeir√£o (OxA¬≠‚Äë1036 ‚Äì 5480 ‚Äì 5070 cal BC a 2 sigmas). Entre n√≥s, apenas se rep...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  25%|‚ñà‚ñà‚ñå       | 2/8 [05:18<14:03, 140.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 2. ENCUADRE CRONO-CULTURAL DEL HA- LLAZGO: COGOTAS I Entre las entidades arqueol√≥gicas de la Edad del Bronce peninsular, Cogotas I sobresale por su extensa cobertura geogr√°fica, que desborda la Meseta por el Valle del Ebro y Extremadura, y por su dilatada crono- log√≠a ‚Äîc. 1800-1150 cal BC, cubrien...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  38%|‚ñà‚ñà‚ñà‚ñä      | 3/8 [05:32<06:53, 82.78s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. y NEIRA, A. (1999): ‚ÄúPrehistoria‚Äù, en M.A. Rabanal Alonso (coord.): La His¬≠ toria de Le√≥n, tomo I, Universidad de Le√≥n y Diario de Le√≥n. CELIS S√ÅNCHEZ, J. (1993a): ‚ÄúLa secuencia del poblado de la Primera Edad del Hierro de los ¬´Cuestos de la Estaci√≥n¬ª, Benavente, Zamora‚Äù, en F. Romero, C. Sanz y Z...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4/8 [06:40<05:08, 77.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Con el desarrollo de las excavaciones arqueol√≥gicas en diversos asentamientos, el aumento del n√∫mero de dataciones y la realizaci√≥n de diversos estudios en los √∫ltimos a√±os, las perspectivas de investigaci√≥n sobre el Bronce final en el Levante comienza a variar sustancialmente, estando ya en condi...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5/8 [11:38<07:50, 156.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. En la actualidad, El Argar sigue siendo el grupo arqueo¬≠ l√≥gico de la Edad del Bronce mejor conocido de la pen√≠nsula ib√©rica, con un desarrollo temporal entre el 2200 y el 1550 cal BC. Tambi√©n se puede afirmar que fue una de las sociedades con mayor capacidad productiva y desarrollo social de la E...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6/8 [13:56<05:00, 150.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Prehist., 74, N.¬∫ 2, julio-diciembre 2017, pp. 296-318, ISSN: 0082-5638 doi: 10.3989/tp.2017.12196 Torres Ortiz, M. 1996: ‚ÄúLa cronolog√≠a de los t√∫mulos A y B de Setefilla. El origen del rito de la crema- ci√≥n en la cultura tart√©sica‚Äù. Complutum 7: 147-162. Torres Ortiz, M. 1998: ‚ÄúLa cronolog√≠a abs...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 7/8 [15:16<02:07, 127.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Ruiz Alonso, M. Guenaga, A., L√≥pez Quintana, J. C. y Zapata Pe√±a, L. (2010). Antracolog√≠a y yacimientos dolm√©nicos: el caso de Mendigana. En Actas del Congreso Internacional sobre Megalitismo y otras manifestaciones funerarias con- tempor√°neas en su contexto social, econ√≥mico y cultural (pp. 566-5...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [16:34<00:00, 124.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "16/8 preguntas exitosas\n",
      "Evaluando con RAGAS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "509fd548d0bf448d9fa224da5c124fe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[1]: TimeoutError()\n",
      "Exception raised in Job[2]: TimeoutError()\n",
      "Exception raised in Job[5]: TimeoutError()\n",
      "Exception raised in Job[4]: TimeoutError()\n",
      "Exception raised in Job[3]: TimeoutError()\n",
      "Exception raised in Job[6]: TimeoutError()\n",
      "Exception raised in Job[8]: TimeoutError()\n",
      "Exception raised in Job[7]: TimeoutError()\n",
      "Exception raised in Job[10]: TimeoutError()\n",
      "Exception raised in Job[9]: TimeoutError()\n",
      "Exception raised in Job[12]: TimeoutError()\n",
      "Exception raised in Job[13]: TimeoutError()\n",
      "Exception raised in Job[11]: TimeoutError()\n",
      "Exception raised in Job[14]: TimeoutError()\n",
      "Exception raised in Job[15]: TimeoutError()\n",
      "Exception raised in Job[16]: TimeoutError()\n",
      "Exception raised in Job[18]: TimeoutError()\n",
      "Exception raised in Job[20]: TimeoutError()\n",
      "Exception raised in Job[19]: TimeoutError()\n",
      "Exception raised in Job[21]: TimeoutError()\n",
      "Exception raised in Job[24]: TimeoutError()\n",
      "Exception raised in Job[23]: TimeoutError()\n",
      "Exception raised in Job[22]: TimeoutError()\n",
      "Exception raised in Job[25]: TimeoutError()\n",
      "Exception raised in Job[26]: TimeoutError()\n",
      "Exception raised in Job[28]: TimeoutError()\n",
      "Exception raised in Job[27]: TimeoutError()\n",
      "Exception raised in Job[29]: TimeoutError()\n",
      "Exception raised in Job[30]: TimeoutError()\n",
      "Exception raised in Job[31]: TimeoutError()\n",
      "Exception raised in Job[32]: TimeoutError()\n",
      "Exception raised in Job[33]: TimeoutError()\n",
      "Exception raised in Job[34]: TimeoutError()\n",
      "Exception raised in Job[36]: TimeoutError()\n",
      "Exception raised in Job[35]: TimeoutError()\n",
      "Exception raised in Job[37]: TimeoutError()\n",
      "Exception raised in Job[38]: TimeoutError()\n",
      "Exception raised in Job[39]: TimeoutError()\n",
      "Exception raised in Job[40]: TimeoutError()\n",
      "Exception raised in Job[41]: TimeoutError()\n",
      "Exception raised in Job[42]: TimeoutError()\n",
      "Exception raised in Job[44]: TimeoutError()\n",
      "Exception raised in Job[43]: TimeoutError()\n",
      "Exception raised in Job[45]: TimeoutError()\n",
      "Exception raised in Job[46]: TimeoutError()\n",
      "Exception raised in Job[47]: TimeoutError()\n",
      "Exception raised in Job[48]: TimeoutError()\n",
      "Exception raised in Job[51]: TimeoutError()\n",
      "Exception raised in Job[50]: TimeoutError()\n",
      "Exception raised in Job[52]: TimeoutError()\n",
      "Exception raised in Job[55]: TimeoutError()\n",
      "Exception raised in Job[53]: TimeoutError()\n",
      "Exception raised in Job[54]: TimeoutError()\n",
      "Exception raised in Job[56]: TimeoutError()\n",
      "Exception raised in Job[57]: TimeoutError()\n",
      "Exception raised in Job[59]: TimeoutError()\n",
      "Exception raised in Job[58]: TimeoutError()\n",
      "Exception raised in Job[60]: TimeoutError()\n",
      "Exception raised in Job[61]: TimeoutError()\n",
      "Exception raised in Job[62]: TimeoutError()\n",
      "Exception raised in Job[63]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      üìä Columnas disponibles: ['user_input', 'retrieved_contexts', 'response', 'reference', 'context_precision', 'context_recall', 'faithfulness', 'answer_correctness']\n",
      "      üìä Filas en dataset: 16\n",
      "      context_precision: ‚ùå Sin valores v√°lidos\n",
      "      context_recall: 0.500 (calculado en 2/16 preguntas)\n",
      "      faithfulness: ‚ùå Sin valores v√°lidos\n",
      "      answer_correctness: ‚ùå Sin valores v√°lidos\n",
      "RAGAS completado:\n",
      "      Context_Recall: 0.500\n",
      "   ‚è∏Ô∏è  Esperando 60 segundos para evitar rate limit...\n",
      "\n",
      "COMBINACI√ìN 4/27\n",
      "   LLM: Qwen3-4B-instruct-2507\n",
      "   Embedding: e5-large-instruct -> IdearqE5\n",
      "   Prompt: prompt_zero_shot\n",
      "Generando respuestas...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. This article must therefore be hereby marked ‚Äúadvertisement‚Äù in accordance with 18 U.S.C. ¬ß1734 solely to indicate this fact. 14180‚Äì14185 PNAS November 20, 2001 vol. 98 no. 24 www.pnas.org cgi doi 10.1073 pnas.241522898 Downloaded from https://www.pnas.org by 2.138.20.97 on August 12, 2025 from IP...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  12%|‚ñà‚ñé        | 1/8 [04:43<33:02, 283.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'5.¬∫ CONGRESSO DO NEOL√çTICO PENINSULAR 405 1. Introducci√≥n La miner√≠a del s√≠lex en la Europa prehist√≥rica tiene lugar en un marco cronol√≥gico bien conocido. Hay esca‚Äë sas y ocasionalmente ambiguas evidencias de explota‚Äë ciones del Pleistoceno (p.e. Baena et al., 2011), alguna dispersa para el Mesol√≠t...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  25%|‚ñà‚ñà‚ñå       | 2/8 [06:16<17:07, 171.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. La cronolog√≠a radiocarb√≥nica de las primeras manifestaciones megal√≠ticas en el sureste de la Pen√≠nsula Ib√©rica‚Ä¶ 273 Trab. Prehist., 74, N.¬∫ 2, julio-diciembre 2017, pp. 257-277, ISSN: 0082-5638 doi: 10.3989/tp.2017.12194 de probabilidad), posiblemente entre el 2395-2270 cal BC (68% de probabilidad...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  38%|‚ñà‚ñà‚ñà‚ñä      | 3/8 [10:48<18:07, 217.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 1984: ‚ÄúLa Muela de Alarilla. Un yacimiento de la Edad del Bronce en el valle medio del r√≠o Henares‚Äù. Revista de Arqueolog√≠a 37: 6-16. Misiego, J. C.; Sanz, F. J.; Marcos, G. J. y Mart√≠n, M. A. 1999: ‚ÄúExcavaciones Arqueol√≥gicas en el castro de Sacaojos (Santiago de la Valduerna, Le√≥n)‚Äù. Nu¬≠ mantia ...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4/8 [12:32<11:30, 172.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'81 ISSN: 1131-6993 El Bronce Final en el Levante de la pen√≠nsula Ib√©rica: bases arqueol√≥gicas y periodizaci√≥n Late Bronze Age in Eastern Iberian Peninsula: Archaeological Bases and Periodization Francisco Javier Jover Maestre*, Alberto Lorrio Alvarado**\\n\\n---\\n\\n. Con el desarrollo de las excavacio...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5/8 [17:07<10:28, 209.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Introducci√≥n Los objetos de adorno realizados con marfil de pro¬≠ bosc√≠deo son una constante en el registro material de los yacimientos de la pen√≠nsula ib√©rica, sobre todo a partir de la primera mitad del II milenio cal BC, si bien en el sur est√°n presentes desde inicios del III milenio cal BC. La ...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6/8 [21:14<07:24, 222.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Demograf√≠a y poblamiento en la Meseta Sur entre el 5500 y el 1200 cal BC. Una perspectiva desde el Radiocarbono 84 La base de datos de dataciones de 14C de la Meseta Sur peninsular se caracteriza por la estructuraci√≥n de la informaci√≥n cronol√≥gica en campos que permitan la situaci√≥n geogr√°fica de ...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 7/8 [27:16<04:27, 267.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. La cronolog√≠a radiocarb√≥nica de las primeras manifestaciones megal√≠ticas en el sureste de la Pen√≠nsula Ib√©rica‚Ä¶ 273 Trab. Prehist., 74, N.¬∫ 2, julio-diciembre 2017, pp. 257-277, ISSN: 0082-5638 doi: 10.3989/tp.2017.12194 de probabilidad), posiblemente entre el 2395-2270 cal BC (68% de probabilidad...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [29:53<00:00, 224.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "16/8 preguntas exitosas\n",
      "Evaluando con RAGAS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6a10a058644457f9efd3d1afbdf39a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[1]: TimeoutError()\n",
      "Exception raised in Job[2]: TimeoutError()\n",
      "Exception raised in Job[4]: TimeoutError()\n",
      "Exception raised in Job[3]: TimeoutError()\n",
      "Exception raised in Job[6]: TimeoutError()\n",
      "Exception raised in Job[5]: TimeoutError()\n",
      "Exception raised in Job[7]: TimeoutError()\n",
      "Exception raised in Job[8]: TimeoutError()\n",
      "Exception raised in Job[11]: TimeoutError()\n",
      "Exception raised in Job[10]: TimeoutError()\n",
      "Exception raised in Job[9]: TimeoutError()\n",
      "Exception raised in Job[12]: TimeoutError()\n",
      "Exception raised in Job[13]: TimeoutError()\n",
      "Exception raised in Job[14]: TimeoutError()\n",
      "Exception raised in Job[15]: TimeoutError()\n",
      "Exception raised in Job[16]: TimeoutError()\n",
      "Exception raised in Job[18]: TimeoutError()\n",
      "Exception raised in Job[19]: TimeoutError()\n",
      "Exception raised in Job[20]: TimeoutError()\n",
      "Exception raised in Job[23]: TimeoutError()\n",
      "Exception raised in Job[21]: TimeoutError()\n",
      "Exception raised in Job[22]: TimeoutError()\n",
      "Exception raised in Job[24]: TimeoutError()\n",
      "Exception raised in Job[25]: TimeoutError()\n",
      "Exception raised in Job[27]: TimeoutError()\n",
      "Exception raised in Job[26]: TimeoutError()\n",
      "Exception raised in Job[28]: TimeoutError()\n",
      "Exception raised in Job[29]: TimeoutError()\n",
      "Exception raised in Job[30]: TimeoutError()\n",
      "Exception raised in Job[31]: TimeoutError()\n",
      "Exception raised in Job[32]: TimeoutError()\n",
      "Exception raised in Job[34]: TimeoutError()\n",
      "Exception raised in Job[35]: TimeoutError()\n",
      "Exception raised in Job[36]: TimeoutError()\n",
      "Exception raised in Job[38]: TimeoutError()\n",
      "Exception raised in Job[37]: TimeoutError()\n",
      "Exception raised in Job[39]: TimeoutError()\n",
      "Exception raised in Job[40]: TimeoutError()\n",
      "Exception raised in Job[42]: TimeoutError()\n",
      "Exception raised in Job[41]: TimeoutError()\n",
      "Exception raised in Job[43]: TimeoutError()\n",
      "Exception raised in Job[44]: TimeoutError()\n",
      "Exception raised in Job[46]: TimeoutError()\n",
      "Exception raised in Job[45]: TimeoutError()\n",
      "Exception raised in Job[47]: TimeoutError()\n",
      "Exception raised in Job[48]: TimeoutError()\n",
      "Exception raised in Job[51]: TimeoutError()\n",
      "Exception raised in Job[50]: TimeoutError()\n",
      "Exception raised in Job[52]: TimeoutError()\n",
      "Exception raised in Job[53]: TimeoutError()\n",
      "Exception raised in Job[54]: TimeoutError()\n",
      "Exception raised in Job[55]: TimeoutError()\n",
      "Exception raised in Job[56]: TimeoutError()\n",
      "Exception raised in Job[57]: TimeoutError()\n",
      "Exception raised in Job[58]: TimeoutError()\n",
      "Exception raised in Job[59]: TimeoutError()\n",
      "Exception raised in Job[61]: TimeoutError()\n",
      "Exception raised in Job[60]: TimeoutError()\n",
      "Exception raised in Job[62]: TimeoutError()\n",
      "Exception raised in Job[63]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      üìä Columnas disponibles: ['user_input', 'retrieved_contexts', 'response', 'reference', 'context_precision', 'context_recall', 'faithfulness', 'answer_correctness']\n",
      "      üìä Filas en dataset: 16\n",
      "      context_precision: ‚ùå Sin valores v√°lidos\n",
      "      context_recall: 0.867 (calculado en 3/16 preguntas)\n",
      "      faithfulness: ‚ùå Sin valores v√°lidos\n",
      "      answer_correctness: ‚ùå Sin valores v√°lidos\n",
      "RAGAS completado:\n",
      "      Context_Recall: 0.867\n",
      "   ‚è∏Ô∏è  Esperando 60 segundos para evitar rate limit...\n",
      "\n",
      "COMBINACI√ìN 5/27\n",
      "   LLM: Qwen3-4B-instruct-2507\n",
      "   Embedding: e5-large-instruct -> IdearqE5\n",
      "   Prompt: prompt_one_shot\n",
      "Generando respuestas...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. This article must therefore be hereby marked ‚Äúadvertisement‚Äù in accordance with 18 U.S.C. ¬ß1734 solely to indicate this fact. 14180‚Äì14185 PNAS November 20, 2001 vol. 98 no. 24 www.pnas.org cgi doi 10.1073 pnas.241522898 Downloaded from https://www.pnas.org by 2.138.20.97 on August 12, 2025 from IP...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  12%|‚ñà‚ñé        | 1/8 [05:56<41:35, 356.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'5.¬∫ CONGRESSO DO NEOL√çTICO PENINSULAR 405 1. Introducci√≥n La miner√≠a del s√≠lex en la Europa prehist√≥rica tiene lugar en un marco cronol√≥gico bien conocido. Hay esca‚Äë sas y ocasionalmente ambiguas evidencias de explota‚Äë ciones del Pleistoceno (p.e. Baena et al., 2011), alguna dispersa para el Mesol√≠t...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  25%|‚ñà‚ñà‚ñå       | 2/8 [07:33<20:23, 203.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. La cronolog√≠a radiocarb√≥nica de las primeras manifestaciones megal√≠ticas en el sureste de la Pen√≠nsula Ib√©rica‚Ä¶ 273 Trab. Prehist., 74, N.¬∫ 2, julio-diciembre 2017, pp. 257-277, ISSN: 0082-5638 doi: 10.3989/tp.2017.12194 de probabilidad), posiblemente entre el 2395-2270 cal BC (68% de probabilidad...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  38%|‚ñà‚ñà‚ñà‚ñä      | 3/8 [13:02<21:44, 260.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 1984: ‚ÄúLa Muela de Alarilla. Un yacimiento de la Edad del Bronce en el valle medio del r√≠o Henares‚Äù. Revista de Arqueolog√≠a 37: 6-16. Misiego, J. C.; Sanz, F. J.; Marcos, G. J. y Mart√≠n, M. A. 1999: ‚ÄúExcavaciones Arqueol√≥gicas en el castro de Sacaojos (Santiago de la Valduerna, Le√≥n)‚Äù. Nu¬≠ mantia ...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4/8 [15:45<14:48, 222.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'81 ISSN: 1131-6993 El Bronce Final en el Levante de la pen√≠nsula Ib√©rica: bases arqueol√≥gicas y periodizaci√≥n Late Bronze Age in Eastern Iberian Peninsula: Archaeological Bases and Periodization Francisco Javier Jover Maestre*, Alberto Lorrio Alvarado**\\n\\n---\\n\\n. Con el desarrollo de las excavacio...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5/8 [21:15<13:03, 261.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Introducci√≥n Los objetos de adorno realizados con marfil de pro¬≠ bosc√≠deo son una constante en el registro material de los yacimientos de la pen√≠nsula ib√©rica, sobre todo a partir de la primera mitad del II milenio cal BC, si bien en el sur est√°n presentes desde inicios del III milenio cal BC. La ...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6/8 [25:23<08:33, 256.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Demograf√≠a y poblamiento en la Meseta Sur entre el 5500 y el 1200 cal BC. Una perspectiva desde el Radiocarbono 84 La base de datos de dataciones de 14C de la Meseta Sur peninsular se caracteriza por la estructuraci√≥n de la informaci√≥n cronol√≥gica en campos que permitan la situaci√≥n geogr√°fica de ...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 7/8 [30:35<04:34, 274.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. La cronolog√≠a radiocarb√≥nica de las primeras manifestaciones megal√≠ticas en el sureste de la Pen√≠nsula Ib√©rica‚Ä¶ 273 Trab. Prehist., 74, N.¬∫ 2, julio-diciembre 2017, pp. 257-277, ISSN: 0082-5638 doi: 10.3989/tp.2017.12194 de probabilidad), posiblemente entre el 2395-2270 cal BC (68% de probabilidad...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [33:52<00:00, 254.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "16/8 preguntas exitosas\n",
      "Evaluando con RAGAS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e6a8b692c5f46b3aad95d3a83b16aea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[8]: TimeoutError()\n",
      "Exception raised in Job[2]: TimeoutError()\n",
      "Exception raised in Job[1]: TimeoutError()\n",
      "Exception raised in Job[5]: TimeoutError()\n",
      "Exception raised in Job[4]: TimeoutError()\n",
      "Exception raised in Job[3]: TimeoutError()\n",
      "Exception raised in Job[6]: TimeoutError()\n",
      "Exception raised in Job[7]: TimeoutError()\n",
      "Exception raised in Job[10]: TimeoutError()\n",
      "Exception raised in Job[9]: TimeoutError()\n",
      "Exception raised in Job[11]: TimeoutError()\n",
      "Exception raised in Job[13]: TimeoutError()\n",
      "Exception raised in Job[12]: TimeoutError()\n",
      "Exception raised in Job[15]: TimeoutError()\n",
      "Exception raised in Job[14]: TimeoutError()\n",
      "Exception raised in Job[16]: TimeoutError()\n",
      "Exception raised in Job[18]: TimeoutError()\n",
      "Exception raised in Job[21]: TimeoutError()\n",
      "Exception raised in Job[19]: TimeoutError()\n",
      "Exception raised in Job[20]: TimeoutError()\n",
      "Exception raised in Job[22]: TimeoutError()\n",
      "Exception raised in Job[24]: TimeoutError()\n",
      "Exception raised in Job[23]: TimeoutError()\n",
      "Exception raised in Job[26]: TimeoutError()\n",
      "Exception raised in Job[25]: TimeoutError()\n",
      "Exception raised in Job[29]: TimeoutError()\n",
      "Exception raised in Job[28]: TimeoutError()\n",
      "Exception raised in Job[27]: TimeoutError()\n",
      "Exception raised in Job[31]: TimeoutError()\n",
      "Exception raised in Job[30]: TimeoutError()\n",
      "Exception raised in Job[32]: TimeoutError()\n",
      "Exception raised in Job[35]: TimeoutError()\n",
      "Exception raised in Job[34]: TimeoutError()\n",
      "Exception raised in Job[36]: TimeoutError()\n",
      "Exception raised in Job[38]: TimeoutError()\n",
      "Exception raised in Job[39]: TimeoutError()\n",
      "Exception raised in Job[40]: TimeoutError()\n",
      "Exception raised in Job[41]: TimeoutError()\n",
      "Exception raised in Job[42]: TimeoutError()\n",
      "Exception raised in Job[43]: TimeoutError()\n",
      "Exception raised in Job[46]: TimeoutError()\n",
      "Exception raised in Job[44]: TimeoutError()\n",
      "Exception raised in Job[45]: TimeoutError()\n",
      "Exception raised in Job[47]: TimeoutError()\n",
      "Exception raised in Job[48]: TimeoutError()\n",
      "Exception raised in Job[49]: TimeoutError()\n",
      "Exception raised in Job[50]: TimeoutError()\n",
      "Exception raised in Job[51]: TimeoutError()\n",
      "Exception raised in Job[52]: TimeoutError()\n",
      "Exception raised in Job[53]: TimeoutError()\n",
      "Exception raised in Job[54]: TimeoutError()\n",
      "Exception raised in Job[55]: TimeoutError()\n",
      "Exception raised in Job[56]: TimeoutError()\n",
      "Exception raised in Job[57]: TimeoutError()\n",
      "Exception raised in Job[58]: TimeoutError()\n",
      "Exception raised in Job[59]: TimeoutError()\n",
      "Exception raised in Job[60]: TimeoutError()\n",
      "Exception raised in Job[62]: TimeoutError()\n",
      "Exception raised in Job[61]: TimeoutError()\n",
      "Exception raised in Job[63]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      üìä Columnas disponibles: ['user_input', 'retrieved_contexts', 'response', 'reference', 'context_precision', 'context_recall', 'faithfulness', 'answer_correctness']\n",
      "      üìä Filas en dataset: 16\n",
      "      context_precision: ‚ùå Sin valores v√°lidos\n",
      "      context_recall: 0.800 (calculado en 3/16 preguntas)\n",
      "      faithfulness: ‚ùå Sin valores v√°lidos\n",
      "      answer_correctness: ‚ùå Sin valores v√°lidos\n",
      "RAGAS completado:\n",
      "      Context_Recall: 0.800\n",
      "   ‚è∏Ô∏è  Esperando 60 segundos para evitar rate limit...\n",
      "\n",
      "COMBINACI√ìN 6/27\n",
      "   LLM: Qwen3-4B-instruct-2507\n",
      "   Embedding: e5-large-instruct -> IdearqE5\n",
      "   Prompt: prompt_few_shot\n",
      "Generando respuestas...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. This article must therefore be hereby marked ‚Äúadvertisement‚Äù in accordance with 18 U.S.C. ¬ß1734 solely to indicate this fact. 14180‚Äì14185 PNAS November 20, 2001 vol. 98 no. 24 www.pnas.org cgi doi 10.1073 pnas.241522898 Downloaded from https://www.pnas.org by 2.138.20.97 on August 12, 2025 from IP...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  12%|‚ñà‚ñé        | 1/8 [04:39<32:33, 279.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'5.¬∫ CONGRESSO DO NEOL√çTICO PENINSULAR 405 1. Introducci√≥n La miner√≠a del s√≠lex en la Europa prehist√≥rica tiene lugar en un marco cronol√≥gico bien conocido. Hay esca‚Äë sas y ocasionalmente ambiguas evidencias de explota‚Äë ciones del Pleistoceno (p.e. Baena et al., 2011), alguna dispersa para el Mesol√≠t...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  25%|‚ñà‚ñà‚ñå       | 2/8 [06:37<18:28, 184.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. La cronolog√≠a radiocarb√≥nica de las primeras manifestaciones megal√≠ticas en el sureste de la Pen√≠nsula Ib√©rica‚Ä¶ 273 Trab. Prehist., 74, N.¬∫ 2, julio-diciembre 2017, pp. 257-277, ISSN: 0082-5638 doi: 10.3989/tp.2017.12194 de probabilidad), posiblemente entre el 2395-2270 cal BC (68% de probabilidad...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  38%|‚ñà‚ñà‚ñà‚ñä      | 3/8 [10:17<16:43, 200.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 1984: ‚ÄúLa Muela de Alarilla. Un yacimiento de la Edad del Bronce en el valle medio del r√≠o Henares‚Äù. Revista de Arqueolog√≠a 37: 6-16. Misiego, J. C.; Sanz, F. J.; Marcos, G. J. y Mart√≠n, M. A. 1999: ‚ÄúExcavaciones Arqueol√≥gicas en el castro de Sacaojos (Santiago de la Valduerna, Le√≥n)‚Äù. Nu¬≠ mantia ...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4/8 [12:11<11:05, 166.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'81 ISSN: 1131-6993 El Bronce Final en el Levante de la pen√≠nsula Ib√©rica: bases arqueol√≥gicas y periodizaci√≥n Late Bronze Age in Eastern Iberian Peninsula: Archaeological Bases and Periodization Francisco Javier Jover Maestre*, Alberto Lorrio Alvarado**\\n\\n---\\n\\n. Con el desarrollo de las excavacio...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5/8 [17:20<10:53, 217.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Introducci√≥n Los objetos de adorno realizados con marfil de pro¬≠ bosc√≠deo son una constante en el registro material de los yacimientos de la pen√≠nsula ib√©rica, sobre todo a partir de la primera mitad del II milenio cal BC, si bien en el sur est√°n presentes desde inicios del III milenio cal BC. La ...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6/8 [20:28<06:55, 207.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Demograf√≠a y poblamiento en la Meseta Sur entre el 5500 y el 1200 cal BC. Una perspectiva desde el Radiocarbono 84 La base de datos de dataciones de 14C de la Meseta Sur peninsular se caracteriza por la estructuraci√≥n de la informaci√≥n cronol√≥gica en campos que permitan la situaci√≥n geogr√°fica de ...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 7/8 [24:42<03:42, 222.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. La cronolog√≠a radiocarb√≥nica de las primeras manifestaciones megal√≠ticas en el sureste de la Pen√≠nsula Ib√©rica‚Ä¶ 273 Trab. Prehist., 74, N.¬∫ 2, julio-diciembre 2017, pp. 257-277, ISSN: 0082-5638 doi: 10.3989/tp.2017.12194 de probabilidad), posiblemente entre el 2395-2270 cal BC (68% de probabilidad...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [27:04<00:00, 203.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "16/8 preguntas exitosas\n",
      "Evaluando con RAGAS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49d5155e76a24269a02ad19f9f756534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[1]: TimeoutError()\n",
      "Exception raised in Job[5]: TimeoutError()\n",
      "Exception raised in Job[2]: TimeoutError()\n",
      "Exception raised in Job[4]: TimeoutError()\n",
      "Exception raised in Job[3]: TimeoutError()\n",
      "Exception raised in Job[6]: TimeoutError()\n",
      "Exception raised in Job[8]: TimeoutError()\n",
      "Exception raised in Job[7]: TimeoutError()\n",
      "Exception raised in Job[11]: TimeoutError()\n",
      "Exception raised in Job[10]: TimeoutError()\n",
      "Exception raised in Job[9]: TimeoutError()\n",
      "Exception raised in Job[15]: TimeoutError()\n",
      "Exception raised in Job[14]: TimeoutError()\n",
      "Exception raised in Job[13]: TimeoutError()\n",
      "Exception raised in Job[12]: TimeoutError()\n",
      "Exception raised in Job[16]: TimeoutError()\n",
      "Exception raised in Job[18]: TimeoutError()\n",
      "Exception raised in Job[22]: TimeoutError()\n",
      "Exception raised in Job[21]: TimeoutError()\n",
      "Exception raised in Job[20]: TimeoutError()\n",
      "Exception raised in Job[19]: TimeoutError()\n",
      "Exception raised in Job[23]: TimeoutError()\n",
      "Exception raised in Job[24]: TimeoutError()\n",
      "Exception raised in Job[25]: TimeoutError()\n",
      "Exception raised in Job[26]: TimeoutError()\n",
      "Exception raised in Job[28]: TimeoutError()\n",
      "Exception raised in Job[27]: TimeoutError()\n",
      "Exception raised in Job[30]: TimeoutError()\n",
      "Exception raised in Job[31]: TimeoutError()\n",
      "Exception raised in Job[29]: TimeoutError()\n",
      "Exception raised in Job[32]: TimeoutError()\n",
      "Exception raised in Job[35]: TimeoutError()\n",
      "Exception raised in Job[34]: TimeoutError()\n",
      "Exception raised in Job[36]: TimeoutError()\n",
      "Exception raised in Job[37]: TimeoutError()\n",
      "Exception raised in Job[38]: TimeoutError()\n",
      "Exception raised in Job[39]: TimeoutError()\n",
      "Exception raised in Job[41]: TimeoutError()\n",
      "Exception raised in Job[40]: TimeoutError()\n",
      "Exception raised in Job[42]: TimeoutError()\n",
      "Exception raised in Job[45]: TimeoutError()\n",
      "Exception raised in Job[44]: TimeoutError()\n",
      "Exception raised in Job[43]: TimeoutError()\n",
      "Exception raised in Job[46]: TimeoutError()\n",
      "Exception raised in Job[47]: TimeoutError()\n",
      "Exception raised in Job[48]: TimeoutError()\n",
      "Exception raised in Job[49]: TimeoutError()\n",
      "Exception raised in Job[50]: TimeoutError()\n",
      "Exception raised in Job[51]: TimeoutError()\n",
      "Exception raised in Job[53]: TimeoutError()\n",
      "Exception raised in Job[52]: TimeoutError()\n",
      "Exception raised in Job[54]: TimeoutError()\n",
      "Exception raised in Job[55]: TimeoutError()\n",
      "Exception raised in Job[56]: TimeoutError()\n",
      "Exception raised in Job[57]: TimeoutError()\n",
      "Exception raised in Job[58]: TimeoutError()\n",
      "Exception raised in Job[59]: TimeoutError()\n",
      "Exception raised in Job[60]: TimeoutError()\n",
      "Exception raised in Job[61]: TimeoutError()\n",
      "Exception raised in Job[62]: TimeoutError()\n",
      "Exception raised in Job[63]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      üìä Columnas disponibles: ['user_input', 'retrieved_contexts', 'response', 'reference', 'context_precision', 'context_recall', 'faithfulness', 'answer_correctness']\n",
      "      üìä Filas en dataset: 16\n",
      "      context_precision: ‚ùå Sin valores v√°lidos\n",
      "      context_recall: 0.800 (calculado en 2/16 preguntas)\n",
      "      faithfulness: ‚ùå Sin valores v√°lidos\n",
      "      answer_correctness: ‚ùå Sin valores v√°lidos\n",
      "RAGAS completado:\n",
      "      Context_Recall: 0.800\n",
      "   ‚è∏Ô∏è  Esperando 60 segundos para evitar rate limit...\n",
      "\n",
      "COMBINACI√ìN 7/27\n",
      "   LLM: Qwen3-4B-instruct-2507\n",
      "   Embedding: gte-multilingual-base -> IdearqGTE\n",
      "   Prompt: prompt_zero_shot\n",
      "Generando respuestas...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Published by Elsevier Inc. All rights reserved. doi:10.1016/j.yqres.2011.12.003 Contents lists available at SciVerse ScienceDirect Quaternary Research journal homepage: www.elsevier.com/locate/yqres https://doi.org/10.1016/j.yqres.2011.12.003 Published online by Cambridge University Press Introduc...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  12%|‚ñà‚ñé        | 1/8 [04:51<33:59, 291.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'5.¬∫ CONGRESSO DO NEOL√çTICO PENINSULAR 405 1. Introducci√≥n La miner√≠a del s√≠lex en la Europa prehist√≥rica tiene lugar en un marco cronol√≥gico bien conocido. Hay esca‚Äë sas y ocasionalmente ambiguas evidencias de explota‚Äë ciones del Pleistoceno (p.e. Baena et al., 2011), alguna dispersa para el Mesol√≠t...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  25%|‚ñà‚ñà‚ñå       | 2/8 [07:31<21:25, 214.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. P√°gs. 253-273 ISBN: 978-84-8317-921-5 ¬∑ ISBN: 978-84-940141-2-3 Resumen La regi√≥n cant√°brica ha proporcionado una de las principales concentraciones de testimonios funerarios mesol√≠ticos del continente europeo, con un registro pr√°cticamente continuo desde el Aziliense hasta el final del per√≠odo, e...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  38%|‚ñà‚ñà‚ñà‚ñä      | 3/8 [11:58<19:51, 238.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 141 Complutum 32(1) 2021: 141-165 Complutum ISSN: 1131-6993 https://dx.doi.org//cmpl.76452 ART√çCULOS La panoplia de finales de la II¬™ Edad del Hierro de la sima de La Cerrosa-Laga√±a (Suar√≠as, Pe√±amellera Baja, Asturias). ¬øUn conjunto asociado a las Guerras C√°ntabras?1 Susana de Luis Mari√±o2; Maria...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4/8 [13:54<12:39, 189.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Con el desarrollo de las excavaciones arqueol√≥gicas en diversos asentamientos, el aumento del n√∫mero de dataciones y la realizaci√≥n de diversos estudios en los √∫ltimos a√±os, las perspectivas de investigaci√≥n sobre el Bronce final en el Levante comienza a variar sustancialmente, estando ya en condi...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5/8 [19:24<12:01, 240.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Jover Maestre, F.J., L√≥pez, J.A. y Garc√≠a, G. (2021): De las primeras comunidades neol√≠ticas a la confi¬≠ guraci√≥n de los grupos iberos en el Levante de la pe¬≠ n√≠nsula ib√©rica. Alicante Kristiansen, K. y Larsson, T.B. (2006): La emergen¬≠ cia de la sociedad del Bronce. Viajes, transmisiones y transf...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6/8 [23:00<07:44, 232.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Causas internas m√°s o menos imbricadas con la evoluci√≥n paleoambiental y las respuestas sociales a estos cambios, o bien, de origen externo ligadas a la presi√≥n ejer- cida por los primeros grupos neol√≠ticos han sido descritas (Garc√≠a Puchol et al., 2006). - De este modo, la pionera implantaci√≥n ne...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 7/8 [27:08<03:57, 237.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. MESTRES, J.S. y NICOL√ÅS, J.C. de, 1999, Contribuci√≥n de la dataci√≥n por radiocarbono al establecimiento de la cronolog√≠a absoluta de la prehistoria de Menorca, Caesaraugusta, 73, Zaragoza, p.327-341. El megalitismo mallorqu√≠n en el contexto del... MOLIST, M. y CLOP, X., 2000, La investigaci√≥n sobr...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [29:43<00:00, 222.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "16/8 preguntas exitosas\n",
      "Evaluando con RAGAS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c88442355da244f3bbff24939af6861c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[2]: TimeoutError()\n",
      "Exception raised in Job[4]: TimeoutError()\n",
      "Exception raised in Job[3]: TimeoutError()\n",
      "Exception raised in Job[6]: TimeoutError()\n",
      "Exception raised in Job[5]: TimeoutError()\n",
      "Exception raised in Job[8]: TimeoutError()\n",
      "Exception raised in Job[7]: TimeoutError()\n",
      "Exception raised in Job[11]: TimeoutError()\n",
      "Exception raised in Job[10]: TimeoutError()\n",
      "Exception raised in Job[9]: TimeoutError()\n",
      "Exception raised in Job[12]: TimeoutError()\n",
      "Exception raised in Job[15]: TimeoutError()\n",
      "Exception raised in Job[14]: TimeoutError()\n",
      "Exception raised in Job[13]: TimeoutError()\n",
      "Exception raised in Job[16]: TimeoutError()\n",
      "Exception raised in Job[18]: TimeoutError()\n",
      "Exception raised in Job[19]: TimeoutError()\n",
      "Exception raised in Job[20]: TimeoutError()\n",
      "Exception raised in Job[21]: TimeoutError()\n",
      "Exception raised in Job[22]: TimeoutError()\n",
      "Exception raised in Job[24]: TimeoutError()\n",
      "Exception raised in Job[23]: TimeoutError()\n",
      "Exception raised in Job[26]: TimeoutError()\n",
      "Exception raised in Job[25]: TimeoutError()\n",
      "Exception raised in Job[29]: TimeoutError()\n",
      "Exception raised in Job[28]: TimeoutError()\n",
      "Exception raised in Job[27]: TimeoutError()\n",
      "Exception raised in Job[31]: TimeoutError()\n",
      "Exception raised in Job[30]: TimeoutError()\n",
      "Exception raised in Job[32]: TimeoutError()\n",
      "Exception raised in Job[35]: TimeoutError()\n",
      "Exception raised in Job[34]: TimeoutError()\n",
      "Exception raised in Job[36]: TimeoutError()\n",
      "Exception raised in Job[37]: TimeoutError()\n",
      "Exception raised in Job[40]: TimeoutError()\n",
      "Exception raised in Job[39]: TimeoutError()\n",
      "Exception raised in Job[38]: TimeoutError()\n",
      "Exception raised in Job[41]: TimeoutError()\n",
      "Exception raised in Job[42]: TimeoutError()\n",
      "Exception raised in Job[43]: TimeoutError()\n",
      "Exception raised in Job[46]: TimeoutError()\n",
      "Exception raised in Job[45]: TimeoutError()\n",
      "Exception raised in Job[44]: TimeoutError()\n",
      "Exception raised in Job[47]: TimeoutError()\n",
      "Exception raised in Job[48]: TimeoutError()\n",
      "Exception raised in Job[50]: TimeoutError()\n",
      "Exception raised in Job[51]: TimeoutError()\n",
      "Exception raised in Job[52]: TimeoutError()\n",
      "Exception raised in Job[53]: TimeoutError()\n",
      "Exception raised in Job[54]: TimeoutError()\n",
      "Exception raised in Job[56]: TimeoutError()\n",
      "Exception raised in Job[55]: TimeoutError()\n",
      "Exception raised in Job[58]: TimeoutError()\n",
      "Exception raised in Job[57]: TimeoutError()\n",
      "Exception raised in Job[59]: TimeoutError()\n",
      "Exception raised in Job[60]: TimeoutError()\n",
      "Exception raised in Job[61]: TimeoutError()\n",
      "Exception raised in Job[62]: TimeoutError()\n",
      "Exception raised in Job[63]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      üìä Columnas disponibles: ['user_input', 'retrieved_contexts', 'response', 'reference', 'context_precision', 'context_recall', 'faithfulness', 'answer_correctness']\n",
      "      üìä Filas en dataset: 16\n",
      "      context_precision: ‚ùå Sin valores v√°lidos\n",
      "      context_recall: 0.938 (calculado en 4/16 preguntas)\n",
      "      faithfulness: ‚ùå Sin valores v√°lidos\n",
      "      answer_correctness: ‚ùå Sin valores v√°lidos\n",
      "RAGAS completado:\n",
      "      Context_Recall: 0.938\n",
      "   ‚è∏Ô∏è  Esperando 60 segundos para evitar rate limit...\n",
      "\n",
      "COMBINACI√ìN 8/27\n",
      "   LLM: Qwen3-4B-instruct-2507\n",
      "   Embedding: gte-multilingual-base -> IdearqGTE\n",
      "   Prompt: prompt_one_shot\n",
      "Generando respuestas...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Published by Elsevier Inc. All rights reserved. doi:10.1016/j.yqres.2011.12.003 Contents lists available at SciVerse ScienceDirect Quaternary Research journal homepage: www.elsevier.com/locate/yqres https://doi.org/10.1016/j.yqres.2011.12.003 Published online by Cambridge University Press Introduc...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  12%|‚ñà‚ñé        | 1/8 [06:00<42:00, 360.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'5.¬∫ CONGRESSO DO NEOL√çTICO PENINSULAR 405 1. Introducci√≥n La miner√≠a del s√≠lex en la Europa prehist√≥rica tiene lugar en un marco cronol√≥gico bien conocido. Hay esca‚Äë sas y ocasionalmente ambiguas evidencias de explota‚Äë ciones del Pleistoceno (p.e. Baena et al., 2011), alguna dispersa para el Mesol√≠t...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  25%|‚ñà‚ñà‚ñå       | 2/8 [08:19<23:00, 230.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. P√°gs. 253-273 ISBN: 978-84-8317-921-5 ¬∑ ISBN: 978-84-940141-2-3 Resumen La regi√≥n cant√°brica ha proporcionado una de las principales concentraciones de testimonios funerarios mesol√≠ticos del continente europeo, con un registro pr√°cticamente continuo desde el Aziliense hasta el final del per√≠odo, e...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  38%|‚ñà‚ñà‚ñà‚ñä      | 3/8 [12:28<19:55, 239.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 141 Complutum 32(1) 2021: 141-165 Complutum ISSN: 1131-6993 https://dx.doi.org//cmpl.76452 ART√çCULOS La panoplia de finales de la II¬™ Edad del Hierro de la sima de La Cerrosa-Laga√±a (Suar√≠as, Pe√±amellera Baja, Asturias). ¬øUn conjunto asociado a las Guerras C√°ntabras?1 Susana de Luis Mari√±o2; Maria...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4/8 [13:43<11:37, 174.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Con el desarrollo de las excavaciones arqueol√≥gicas en diversos asentamientos, el aumento del n√∫mero de dataciones y la realizaci√≥n de diversos estudios en los √∫ltimos a√±os, las perspectivas de investigaci√≥n sobre el Bronce final en el Levante comienza a variar sustancialmente, estando ya en condi...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5/8 [18:37<10:51, 217.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Jover Maestre, F.J., L√≥pez, J.A. y Garc√≠a, G. (2021): De las primeras comunidades neol√≠ticas a la confi¬≠ guraci√≥n de los grupos iberos en el Levante de la pe¬≠ n√≠nsula ib√©rica. Alicante Kristiansen, K. y Larsson, T.B. (2006): La emergen¬≠ cia de la sociedad del Bronce. Viajes, transmisiones y transf...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6/8 [23:38<08:11, 245.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Causas internas m√°s o menos imbricadas con la evoluci√≥n paleoambiental y las respuestas sociales a estos cambios, o bien, de origen externo ligadas a la presi√≥n ejer- cida por los primeros grupos neol√≠ticos han sido descritas (Garc√≠a Puchol et al., 2006). - De este modo, la pionera implantaci√≥n ne...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 7/8 [28:41<04:24, 264.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. MESTRES, J.S. y NICOL√ÅS, J.C. de, 1999, Contribuci√≥n de la dataci√≥n por radiocarbono al establecimiento de la cronolog√≠a absoluta de la prehistoria de Menorca, Caesaraugusta, 73, Zaragoza, p.327-341. El megalitismo mallorqu√≠n en el contexto del... MOLIST, M. y CLOP, X., 2000, La investigaci√≥n sobr...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [31:29<00:00, 236.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "16/8 preguntas exitosas\n",
      "Evaluando con RAGAS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dc8acbb9f9946ab823d854ea4179e24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[2]: TimeoutError()\n",
      "Exception raised in Job[1]: TimeoutError()\n",
      "Exception raised in Job[5]: TimeoutError()\n",
      "Exception raised in Job[6]: TimeoutError()\n",
      "Exception raised in Job[4]: TimeoutError()\n",
      "Exception raised in Job[3]: TimeoutError()\n",
      "Exception raised in Job[9]: TimeoutError()\n",
      "Exception raised in Job[8]: TimeoutError()\n",
      "Exception raised in Job[7]: TimeoutError()\n",
      "Exception raised in Job[12]: TimeoutError()\n",
      "Exception raised in Job[11]: TimeoutError()\n",
      "Exception raised in Job[10]: TimeoutError()\n",
      "Exception raised in Job[13]: TimeoutError()\n",
      "Exception raised in Job[14]: TimeoutError()\n",
      "Exception raised in Job[15]: TimeoutError()\n",
      "Exception raised in Job[16]: TimeoutError()\n",
      "Exception raised in Job[18]: TimeoutError()\n",
      "Exception raised in Job[19]: TimeoutError()\n",
      "Exception raised in Job[21]: TimeoutError()\n",
      "Exception raised in Job[20]: TimeoutError()\n",
      "Exception raised in Job[22]: TimeoutError()\n",
      "Exception raised in Job[24]: TimeoutError()\n",
      "Exception raised in Job[23]: TimeoutError()\n",
      "Exception raised in Job[25]: TimeoutError()\n",
      "Exception raised in Job[27]: TimeoutError()\n",
      "Exception raised in Job[26]: TimeoutError()\n",
      "Exception raised in Job[28]: TimeoutError()\n",
      "Exception raised in Job[29]: TimeoutError()\n",
      "Exception raised in Job[30]: TimeoutError()\n",
      "Exception raised in Job[31]: TimeoutError()\n"
     ]
    }
   ],
   "source": [
    "# Listas para almacenar resultados\n",
    "df_results_list = []\n",
    "combination_metrics_list = []\n",
    "\n",
    "# Generar todas las combinaciones\n",
    "combinations = list(product(llm_models, embeddings, prompts))\n",
    "total_combinations = len(combinations)\n",
    "\n",
    "# VERIFICAR RESULTADOS PARCIALES\n",
    "existing_combinations = []\n",
    "try:\n",
    "    existing_df = pd.read_csv('rag_evaluation_metrics_20250906_024221.csv')  # Cambiar por tu archivo\n",
    "    existing_combinations = existing_df['combination_id'].tolist()\n",
    "    print(f\"Continuando desde combinaci√≥n {len(existing_combinations)+1}\")\n",
    "except:\n",
    "    print(\"Empezando evaluaci√≥n desde el inicio\")\n",
    "\n",
    "print(f\"EVALUACI√ìN RAGAS CON {total_combinations} COMBINACIONES\")\n",
    "print(f\"M√©tricas: context_precision, context_recall, faithfulness, answer_correctness\")\n",
    "print(f\"Evaluador: Mistral API ({mistral_llm.model})\")\n",
    "print(f\"Prompt personalizado en espa√±ol para arqueolog√≠a\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Evaluar cada combinaci√≥n\n",
    "for combo_idx, (test_llm, test_embedding, test_prompt) in enumerate(combinations):\n",
    "\n",
    "    # SALTAR SI YA SE EVALU√ì\n",
    "    if combo_idx in existing_combinations:\n",
    "        print(f\"Saltando combinaci√≥n {combo_idx+1} (ya evaluada)\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\nCOMBINACI√ìN {combo_idx+1}/{total_combinations}\")\n",
    "    print(f\"   LLM: {test_llm}\")\n",
    "    print(f\"   Embedding: {test_embedding} -> {WEAVIATE_CLASSES[test_embedding]}\")\n",
    "    print(f\"   Prompt: {test_prompt}\")\n",
    "\n",
    "    combination_start_time = time.time()\n",
    "    results_list = []\n",
    "    successful_questions = 0\n",
    "\n",
    "    # Generar respuestas para todas las preguntas\n",
    "    print(\"Generando respuestas...\")\n",
    "    for q_idx, question in enumerate(tqdm(questions, desc=\"   Preguntas\")):\n",
    "        try:\n",
    "            state = {\n",
    "                'question': question,\n",
    "                'llm_name': test_llm,\n",
    "                'embedding_name': test_embedding,\n",
    "                'prompt_name': test_prompt,\n",
    "                'context': [], 'answer': '', 'metadata': {}\n",
    "            }\n",
    "\n",
    "            final_state = graph.invoke(state)\n",
    "            answer = final_state.get('answer', '')\n",
    "            contexts = final_state.get('context', [])\n",
    "\n",
    "            if answer and 'ERROR:' not in answer and len(contexts) > 0:\n",
    "                # Almacenar para dataset RAGAS\n",
    "                results_list.append({\n",
    "                    'question': question,\n",
    "                    'answer': answer,\n",
    "                    'contexts': [str(doc.page_content) for doc in contexts],  # Forzar string\n",
    "                    'ground_truth': ground_truths[q_idx] if q_idx < len(ground_truths) else ''\n",
    "                })\n",
    "                successful_questions += 1\n",
    "\n",
    "            # Almacenar para dataset RAGAS\n",
    "            if answer and 'ERROR:' not in answer and len(contexts) > 0:\n",
    "                results_list.append({\n",
    "                    'question': question,\n",
    "                    'answer': final_state.get('answer', ''),\n",
    "                    'contexts': [doc.page_content for doc in final_state.get('context', [])],\n",
    "                    'ground_truth': ground_truths[q_idx] if q_idx < len(ground_truths) else ''\n",
    "                })\n",
    "                successful_questions += 1\n",
    "\n",
    "            # Almacenar detalles individuales\n",
    "            df_results_list.append({\n",
    "                'combination_id': combo_idx,\n",
    "                'llm_model': test_llm,\n",
    "                'embedding_model': test_embedding,\n",
    "                'weaviate_collection': WEAVIATE_CLASSES[test_embedding],\n",
    "                'prompt_type': test_prompt,\n",
    "                'question_id': q_idx,\n",
    "                'question': question,\n",
    "                'answer': answer,\n",
    "                'contexts': [doc.page_content for doc in final_state.get('context', [])],\n",
    "                'num_contexts': len(final_state.get('context', [])),\n",
    "                'ground_truth': ground_truths[q_idx] if q_idx < len(ground_truths) else '',\n",
    "                'status': 'success' if answer and 'ERROR:' not in answer else 'error'\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error en pregunta {q_idx+1}: {e}\")\n",
    "            df_results_list.append({\n",
    "                'combination_id': combo_idx,\n",
    "                'llm_model': test_llm,\n",
    "                'embedding_model': test_embedding,\n",
    "                'weaviate_collection': WEAVIATE_CLASSES[test_embedding],\n",
    "                'prompt_type': test_prompt,\n",
    "                'question_id': q_idx,\n",
    "                'question': question,\n",
    "                'answer': f'ERROR: {str(e)}',\n",
    "                'contexts': [],\n",
    "                'num_contexts': 0,\n",
    "                'ground_truth': ground_truths[q_idx] if q_idx < len(ground_truths) else '',\n",
    "                'status': 'error'\n",
    "            })\n",
    "    print(f\"{successful_questions}/{len(questions)} preguntas exitosas\")\n",
    "\n",
    "    # Evaluar con RAGAS si hay resultados v√°lidos\n",
    "    if successful_questions >= 2:\n",
    "        print(\"Evaluando con RAGAS...\" )\n",
    "\n",
    "        try:\n",
    "            dataset = Dataset.from_list(results_list)\n",
    "            current_embedding_model = EMBEDDING_MODELS[test_embedding]\n",
    "\n",
    "            evaluation_results = evaluate(\n",
    "                dataset,\n",
    "                llm=evaluation_llm,\n",
    "                embeddings=current_embedding_model,\n",
    "                metrics=[\n",
    "                    context_precision,\n",
    "                    context_recall,\n",
    "                    faithfulness,\n",
    "                    answer_correctness\n",
    "                ],\n",
    "                raise_exceptions=False # Continuar si una m√©trica falla\n",
    "            )\n",
    "\n",
    "            # Extraer m√©tricas promedio\n",
    "            metrics_df = evaluation_results.to_pandas()\n",
    "\n",
    "            if evaluation_results is not None:\n",
    "                # Procesar m√©tricas normalmente\n",
    "                metrics_df = evaluation_results.to_pandas()\n",
    "\n",
    "                # üîç DEBUG: Ver qu√© m√©tricas se calcularon\n",
    "                print(f\"      üìä Columnas disponibles: {list(metrics_df.columns)}\")\n",
    "                print(f\"      üìä Filas en dataset: {len(metrics_df)}\")\n",
    "\n",
    "                # Mostrar valores de cada m√©trica\n",
    "                for metric in ['context_precision', 'context_recall', 'faithfulness', 'answer_correctness']:\n",
    "                    if metric in metrics_df.columns:\n",
    "                        values = metrics_df[metric].dropna()\n",
    "                        if len(values) > 0:\n",
    "                            print(f\"      {metric}: {values.mean():.3f} (calculado en {len(values)}/{len(metrics_df)} preguntas)\")\n",
    "                        else:\n",
    "                            print(f\"      {metric}: ‚ùå Sin valores v√°lidos\")\n",
    "                    else:\n",
    "                        print(f\"      {metric}: ‚ùå Columna no encontrada\")\n",
    "\n",
    "            # Funci√≥n para calcular m√©tricas seguras\n",
    "            def safe_mean_std(series):\n",
    "                clean_series = series.dropna()\n",
    "                if len(clean_series) > 0:\n",
    "                    return clean_series.mean(), clean_series.std()\n",
    "                return None, None\n",
    "\n",
    "            avg_metrics = {}\n",
    "            for metric in ['context_precision', 'context_recall', 'faithfulness', 'answer_correctness']:\n",
    "                if metric in metrics_df.columns:\n",
    "                    mean_val, std_val = safe_mean_std(metrics_df[metric])\n",
    "                    avg_metrics[f'{metric}_mean'] = mean_val\n",
    "                    avg_metrics[f'{metric}_std'] = std_val\n",
    "\n",
    "            # Guardar m√©tricas de la combinaci√≥n\n",
    "            combination_metrics = {\n",
    "                'combination_id': combo_idx,\n",
    "                'llm_model': test_llm,\n",
    "                'embedding_model': test_embedding,\n",
    "                'weaviate_collection': WEAVIATE_CLASSES[test_embedding],\n",
    "                'prompt_type': test_prompt,\n",
    "                'total_questions': len(questions),\n",
    "                'successful_questions': successful_questions,\n",
    "                'evaluation_time_seconds': time.time() - combination_start_time,\n",
    "                **avg_metrics\n",
    "            }\n",
    "            combination_metrics_list.append(combination_metrics)\n",
    "\n",
    "            print(f\"RAGAS completado:\")\n",
    "            for metric in ['context_precision_mean', 'context_recall_mean', 'faithfulness_mean', 'answer_correctness_mean']:\n",
    "                if metric in avg_metrics and avg_metrics[metric] is not None:\n",
    "                    print(f\"      {metric.replace('_mean', '').title()}: {avg_metrics[metric]:.3f}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error en evaluaci√≥n RAGAS: {e}\")\n",
    "            combination_metrics_list.append({\n",
    "                'combination_id': combo_idx,\n",
    "                'llm_model': test_llm,\n",
    "                'embedding_model': test_embedding,\n",
    "                'weaviate_collection': WEAVIATE_CLASSES[test_embedding],\n",
    "                'prompt_type': test_prompt,\n",
    "                'total_questions': len(questions),\n",
    "                'successful_questions': successful_questions,\n",
    "                'evaluation_time_seconds': time.time() - combination_start_time,\n",
    "                'context_precision_mean': None,\n",
    "                'context_recall_mean': None,\n",
    "                'faithfulness_mean': None,\n",
    "                'answer_correctness_mean': None,\n",
    "                'context_precision_std': None,\n",
    "                'context_recall_std': None,\n",
    "                'faithfulness_std': None,\n",
    "                'answer_correctness_std': None,\n",
    "                'error': str(e)\n",
    "                })\n",
    "    else:\n",
    "        print(f\"Solo {successful_questions} preguntas exitosas, saltando RAGAS\")\n",
    "        combination_metrics_list.append({\n",
    "            'combination_id': combo_idx,\n",
    "            'llm_model': test_llm,\n",
    "            'embedding_model': test_embedding,\n",
    "            'weaviate_collection': WEAVIATE_CLASSES[test_embedding],\n",
    "            'prompt_type': test_prompt,\n",
    "            'total_questions': len(questions),\n",
    "            'successful_questions': successful_questions,\n",
    "            'evaluation_time_seconds': time.time() - combination_start_time,\n",
    "            'error': 'Insufficient successful questions'\n",
    "        })\n",
    "\n",
    "    # DELAY ENTRE COMBINACIONES\n",
    "    if combo_idx < len(combinations) - 1:\n",
    "        print(f\"   ‚è∏Ô∏è  Esperando 60 segundos para evitar rate limit...\")\n",
    "        time.sleep(60)\n",
    "\n",
    "  # Crear DataFrames finales\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EVALUACI√ìN COMPLETADA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "detailed_results_df = pd.DataFrame(df_results_list)\n",
    "metrics_summary_df = pd.DataFrame(combination_metrics_list)\n",
    "\n",
    "print(f\"Evaluaciones detalladas: {detailed_results_df.shape}\")\n",
    "print(f\"Resumen de m√©tricas: {metrics_summary_df.shape}\")\n",
    "\n",
    "# Guardar resultados\n",
    "timestamp = pd.Timestamp.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "detailed_csv = f'rag_evaluation_detailed_{timestamp}.csv'\n",
    "metrics_csv = f'rag_evaluation_metrics_{timestamp}.csv'\n",
    "\n",
    "detailed_results_df.to_csv(detailed_csv, index=False, encoding='utf-8')\n",
    "metrics_summary_df.to_csv(metrics_csv, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"Resultados guardados:\")\n",
    "print(f\"   Detallado: {detailed_csv}\")\n",
    "print(f\"   M√©tricas: {metrics_csv}\")\n",
    "\n",
    "# Mostrar ranking de mejores combinaciones\n",
    "if not metrics_summary_df.empty:\n",
    "    successful_evaluations = len([c for c in combination_metrics_list if 'error' not in c or not c.get('error')])\n",
    "    print(f\"\\nRESUMEN:\")\n",
    "    print(f\"   Combinaciones totales: {total_combinations}\")\n",
    "    print(f\"   Evaluaciones exitosas: {successful_evaluations}\")\n",
    "    print(f\"   Tasa de √©xito: {successful_evaluations/total_combinations*100:.1f}%\")\n",
    "\n",
    "    print(f\"\\nTOP 5 COMBINACIONES POR M√âTRICA:\")\n",
    "\n",
    "    for metric in ['context_precision_mean', 'context_recall_mean', 'faithfulness_mean', 'answer_correctness_mean']:\n",
    "        if metric in metrics_summary_df.columns:\n",
    "            valid_data = metrics_summary_df[metrics_summary_df[metric].notna()]\n",
    "            if not valid_data.empty:\n",
    "                print(f\"\\n{metric.upper().replace('_', ' ')}:\")\n",
    "                top_5 = valid_data.nlargest(5, metric)[['llm_model', 'embedding_model', 'prompt_type', metric]]\n",
    "                print(top_5.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar todas las combinaciones\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "combinations = list(product(llm_models, embeddings, prompts))\n",
    "total_combinations = len(combinations)\n",
    "\n",
    "print(f\"EVALUACI√ìN RAGAS CON {total_combinations} COMBINACIONES\")\n",
    "print(f\"M√©tricas: context_precision, context_recall, faithfulness, answer_correctness\")me s\n",
    "print(f\"Evaluador: Mistral API ({mistral_llm.model})\")\n",
    "print(f\"Embeddings para evaluaci√≥n: {eval_embeddings}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Evaluar cada combinaci√≥n\n",
    "for combo_idx, (test_llm, test_embedding, test_prompt) in enumerate(combinations):\n",
    "    print(f\"\\nCOMBINACI√ìN {combo_idx+1}/{total_combinations}\")\n",
    "    print(f\"   LLM: {test_llm}\")\n",
    "    print(f\"   Embedding: {test_embedding} -> {WEAVIATE_CLASSES[test_embedding]}\")\n",
    "    print(f\"   Prompt: {test_prompt}\")\n",
    "\n",
    "    combination_start_time = time.time()\n",
    "    results_list = []\n",
    "\n",
    "    # Generar respuestas para todas las preguntas\n",
    "    print(\"Generando respuestas...\")\n",
    "    for q_idx, question in enumerate(tqdm(questions, desc=\"   Preguntas\")):\n",
    "        try:\n",
    "            state = {\n",
    "                'question': question,\n",
    "                'llm_name': test_llm,\n",
    "                'embedding_name': test_embedding,\n",
    "                'prompt_name': test_prompt,\n",
    "                'context': [], 'answer': '', 'metadata': {}\n",
    "            }\n",
    "\n",
    "            final_state = graph.invoke(state)\n",
    "\n",
    "            # Almacenar para dataset RAGAS\n",
    "            results_list.append({\n",
    "                'question': question,\n",
    "                'answer': final_state.get('answer', ''),\n",
    "                'contexts': [doc.page_content for doc in final_state.get('context', [])],\n",
    "                'ground_truth': ground_truths[q_idx] if q_idx < len(ground_truths) else ''\n",
    "            })\n",
    "\n",
    "            # Almacenar detalles individuales\n",
    "            df_results_list.append({\n",
    "                'combination_id': combo_idx,\n",
    "                'llm_model': test_llm,\n",
    "                'embedding_model': test_embedding,\n",
    "                'weaviate_collection': WEAVIATE_CLASSES[test_embedding],\n",
    "                'prompt_type': test_prompt,\n",
    "                'question_id': q_idx,\n",
    "                'question': question,\n",
    "                'answer': final_state.get('answer', ''),\n",
    "                'contexts': [doc.page_content for doc in final_state.get('context', [])],\n",
    "                'num_contexts': len(final_state.get('context', [])),\n",
    "                'ground_truth': ground_truths[q_idx] if q_idx < len(ground_truths) else '',\n",
    "                'status': 'success'\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error en pregunta {q_idx+1}: {e}\")\n",
    "            df_results_list.append({\n",
    "                'combination_id': combo_idx,\n",
    "                'llm_model': test_llm,\n",
    "                'embedding_model': test_embedding,\n",
    "                'weaviate_collection': WEAVIATE_CLASSES[test_embedding],\n",
    "                'prompt_type': test_prompt,\n",
    "                'question_id': q_idx,\n",
    "                'question': question,\n",
    "                'answer': f'ERROR: {str(e)}',\n",
    "                'contexts': [],\n",
    "                'num_contexts': 0,\n",
    "                'ground_truth': ground_truths[q_idx] if q_idx < len(ground_truths) else '',\n",
    "                'status': 'error'\n",
    "            })\n",
    "\n",
    "      # Evaluar con RAGAS si hay resultados v√°lidos\n",
    "    if results_list and len([r for r in results_list if r['answer'] and 'ERROR:' not in r['answer']]) > 0:\n",
    "        print(\"Evaluando con RAGAS...\" )\n",
    "        try:\n",
    "            \n",
    "            # Crear dataset\n",
    "            dataset = Dataset.from_list(results_list)\n",
    "\n",
    "            # Evaluar con RAGAS\n",
    "            current_embedding_model = EMBEDDING_MODELS[test_embedding]\n",
    "            evaluation_results = evaluate(\n",
    "                dataset,\n",
    "                llm=mistral_llm,\n",
    "                embeddings=current_embedding_model,\n",
    "                #embeddings=eval_embeddings,\n",
    "                metrics=[\n",
    "                    context_precision,\n",
    "                    context_recall,\n",
    "                    faithfulness,\n",
    "                    answer_correctness\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            # Extraer m√©tricas promedio\n",
    "            metrics_df = evaluation_results.to_pandas()\n",
    "            avg_metrics = {\n",
    "                'context_precision_mean': metrics_df['context_precision'].mean(),\n",
    "                'context_recall_mean': metrics_df['context_recall'].mean(),\n",
    "                'faithfulness_mean': metrics_df['faithfulness'].mean(),\n",
    "                'answer_correctness_mean': metrics_df['answer_correctness'].mean(),\n",
    "                'context_precision_std': metrics_df['context_precision'].std(),\n",
    "                'context_recall_std': metrics_df['context_recall'].std(),\n",
    "                'faithfulness_std': metrics_df['faithfulness'].std(),\n",
    "                'answer_correctness_std': metrics_df['answer_correctness'].std()\n",
    "            }\n",
    "\n",
    "            # Guardar m√©tricas de la combinaci√≥n\n",
    "            combination_metrics = {\n",
    "                'combination_id': combo_idx,\n",
    "                'llm_model': test_llm,\n",
    "                'embedding_model': test_embedding,\n",
    "                'weaviate_collection': WEAVIATE_CLASSES[test_embedding],\n",
    "                'prompt_type': test_prompt,\n",
    "                'total_questions': len(questions),\n",
    "                'successful_questions': len([r for r in results_list if r['answer'] and 'ERROR:' not in r['answer']]),\n",
    "                'evaluation_time_seconds': time.time() - combination_start_time,\n",
    "                **avg_metrics\n",
    "            }\n",
    "\n",
    "            combination_metrics_list.append(combination_metrics)\n",
    "\n",
    "            print(f\"RAGAS completado:\")\n",
    "            print(f\"      Context Precision: {avg_metrics['context_precision_mean']:.3f}\")\n",
    "            print(f\"      Context Recall: {avg_metrics['context_recall_mean']:.3f}\")\n",
    "            print(f\"      Faithfulness: {avg_metrics['faithfulness_mean']:.3f}\")\n",
    "            print(f\"      Answer Correctness: {avg_metrics['answer_correctness_mean']:.3f}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error en evaluaci√≥n RAGAS: {e}\")\n",
    "            # Guardar combinaci√≥n con error\n",
    "            combination_metrics_list.append({\n",
    "                'combination_id': combo_idx,\n",
    "                'llm_model': test_llm,\n",
    "                'embedding_model': test_embedding,\n",
    "                'weaviate_collection': WEAVIATE_CLASSES[test_embedding],\n",
    "                'prompt_type': test_prompt,\n",
    "                'total_questions': len(questions),\n",
    "                'successful_questions': 0,\n",
    "                'evaluation_time_seconds': time.time() - combination_start_time,\n",
    "                'context_precision_mean': None,\n",
    "                'context_recall_mean': None,\n",
    "                'faithfulness_mean': None,\n",
    "                'answer_correctness_mean': None,\n",
    "                'context_precision_std': None,\n",
    "                'context_recall_std': None,\n",
    "                'faithfulness_std': None,\n",
    "                'answer_correctness_std': None,\n",
    "                'error': str(e)\n",
    "            })\n",
    "    else:\n",
    "        print(\"No hay resultados v√°lidos para evaluar con RAGAS\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EVALUACI√ìN COMPLETADA\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear DataFrames finales\n",
    "detailed_results_df = pd.DataFrame(all_results_list)\n",
    "metrics_summary_df = pd.DataFrame(combination_metrics_list)\n",
    "\n",
    "print(f\"Evaluaciones detalladas: {detailed_results_df.shape}\")pero\n",
    "print(f\"Resumen de m√©tricas: {metrics_summary_df.shape}\")\n",
    "\n",
    "# Guardar resultados\n",
    "timestamp = pd.Timestamp.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "detailed_csv = f'rag_evaluation_detailed_{timestamp}.csv'\n",
    "metrics_csv = f'rag_evaluation_metrics_{timestamp}.csv'\n",
    "\n",
    "detailed_results_df.to_csv(detailed_csv, index=False, encoding='utf-8')\n",
    "metrics_summary_df.to_csv(metrics_csv, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"Resultados detallados: {detailed_csv}\")\n",
    "print(f\"M√©tricas resumen: {metrics_csv}\")\n",
    "\n",
    "# Mostrar ranking de mejores combinaciones\n",
    "if not metrics_summary_df.empty:\n",
    "    print(f\"\\nTOP 5 COMBINACIONES POR M√âTRICA:\")\n",
    "\n",
    "    for metric in ['context_precision_mean', 'context_recall_mean', 'faithfulness_mean', 'answer_correctness_mean']:\n",
    "        if metric in metrics_summary_df.columns:\n",
    "            print(f\"\\n{metric.upper()}:\")\n",
    "            top_5 = metrics_summary_df.nlargest(5, metric)[['llm_model', 'embedding_model', 'prompt_type', metric]]\n",
    "            print(top_5.to_string(index=False))\n",
    "\n",
    "print(f\"\\nEstad√≠sticas generales:\")\n",
    "print(f\"   Total combinaciones: {len(combination_metrics_list)}\")\n",
    "print(f\"   Evaluaciones exitosas: {len([c for c in combination_metrics_list if 'error' not in c])}\")\n",
    "print(f\"   Tasa de √©xito: {len([c for c in combination_metrics_list if 'error' not in c])/len(combination_metrics_list)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prueba con una combinaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_llm = 'Phi-3.5-mini-instruct'\n",
    "test_embedding = 'gte-multilingual-base'\n",
    "test_prompt = 'prompt_zero_shot'\n",
    "\n",
    "results_list = []\n",
    "\n",
    "# 3. El bucle que ejecuta el grafo para cada pregunta\n",
    "print(f\"--- Ejecutando bucle con la combinaci√≥n: {test_llm} | {test_embedding} | {test_prompt} ---\")\n",
    "for q_idx, question in enumerate(questions):\n",
    "    print(f\"Procesando pregunta #{q_idx}...\")\n",
    "    try:\n",
    "        state = {\n",
    "            'question': question,\n",
    "            'llm_name': test_llm,\n",
    "            'embedding_name': test_embedding,\n",
    "            'prompt_name': test_prompt,\n",
    "            'context': [], 'answer': '', 'metadata': {}\n",
    "        }\n",
    "        \n",
    "        final_state = graph.invoke(state)\n",
    "        \n",
    "        results_list.append({\n",
    "            'question': question,\n",
    "            'answer': final_state.get('answer', ''),\n",
    "            'contexts': [doc.page_content for doc in final_state.get('context', [])],\n",
    "            'ground_truth': ground_truths[q_idx] if q_idx < len(ground_truths) else ''\n",
    "        })\n",
    "        print(f\"  -> Pregunta #{q_idx} procesada.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  -> ERROR con la pregunta #{q_idx}: {e}\")\n",
    "\n",
    "# 4. Creamos la variable 'dataset'\n",
    "print(\"\\n--- Bucle terminado. Creando el objeto Dataset... ---\")\n",
    "dataset = Dataset.from_list(results_list)\n",
    "\n",
    "print(\"\\n¬°LISTO! La variable 'dataset' ha sido creada.\")\n",
    "print(\"Ahora ya puedes ejecutar la celda de 'evaluate'.\")\n",
    "print(\"\\nContenido del dataset que se ha creado:\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para api mistral\n",
    "from langchain_mistralai import ChatMistralAI\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    context_precision, # Corresponds to your LLMContextPrecision\n",
    "    context_recall,    # Corresponds to your LLMContextRecall\n",
    "    faithfulness,      # Corresponds to your Faithfulness\n",
    "    answer_correctness # Corresponds to your FactualCorrectness\n",
    ")\n",
    "\n",
    "#evaluator_llm = LangchainLLMWrapper(mistral_llm)\n",
    "\n",
    "\n",
    "mistral_llm = ChatMistralAI(api_key=\"dv0RMPhxjgwM6pePID1FXvloyU2iltVu\", model=\"mistral-small-latest\")\n",
    "\n",
    "eval_embeddings = EMBEDDING_MODELS[\"all-MiniLM-L6-v2\"]\n",
    "# La evaluaci√≥n se ejecuta una vez sobre todo el dataset\n",
    "evaluation_results = evaluate(\n",
    "    dataset=dataset,  \n",
    "    llm=mistral_llm, \n",
    "    embeddings=eval_embeddings, \n",
    "    metrics=[\n",
    "        context_precision,\n",
    "        context_recall,\n",
    "        faithfulness,\n",
    "        answer_correctness,\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 'evaluation_results' ahora contiene los scores.\n",
    "# Puedes convertirlo a un DataFrame de pandas para verlo mejor\n",
    "df_results = evaluation_results.to_pandas()\n",
    "print(df_results.head())\n",
    "\n",
    "# time.sleep(2) probablemente ya no es necesario sin un bucle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG pipeline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
