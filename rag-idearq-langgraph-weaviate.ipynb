{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:98;} </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "import os\n",
    "import pprint\n",
    "import logging\n",
    "import time\n",
    "import json\n",
    "import itertools\n",
    "import pathlib\n",
    "import torch\n",
    "import pandas as pd\n",
    "import ragas\n",
    "from ragas import evaluate\n",
    "from dotenv import load_dotenv\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_weaviate import WeaviateVectorStore\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.documents import Document\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "from pydantic import BaseModel, Field, ValidationError\n",
    "from langchain_ollama import OllamaLLM\n",
    "import weaviate\n",
    "from langchain.embeddings.base import Embeddings\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "from sentence_transformers import CrossEncoder, SentenceTransformer\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any, Optional, TypedDict\n",
    "from datetime import datetime, timezone\n",
    "from langsmith import Client\n",
    "from langsmith.evaluation import evaluate as ls_evaluate, LangChainStringEvaluator\n",
    "from ragas.metrics import (\n",
    "    ContextRecall,\n",
    "    Faithfulness,\n",
    "    ContextPrecision,\n",
    "    ResponseRelevancy,\n",
    "    AnswerCorrectness,\n",
    "    AnswerSimilarity,\n",
    "    SemanticSimilarity\n",
    ")\n",
    "from datasets import Dataset\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "load_dotenv(override=True)\n",
    "\n",
    "from IPython.display import display, HTML, Image\n",
    "display(HTML(\"<style>.container { width:98;} </style>\"))\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# Para el aviso de Triton, pesos y otros transformers \n",
    "logging.getLogger(\"xformers\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith configurado: True\n",
      "Proyecto: RAG-IDEArq\n"
     ]
    }
   ],
   "source": [
    "WEAVIATE_URL = os.getenv('WEAVIATE_URL', 'http://localhost:8080')\n",
    "LANGSMITH_API_KEY = os.getenv('LANGSMITH_API_KEY')\n",
    "LANGSMITH_PROJECT = os.getenv('LANGSMITH_PROJECT', 'RAG-IDEArq')\n",
    "LANGSMITH_TRACING = os.getenv('LANGSMITH_TRACING', 'true')\n",
    "MISTRAL_API_KEY = os.getenv(\"MISTRAL_API_KEY\")\n",
    "# Configurar LangSmith\n",
    "if LANGSMITH_API_KEY:\n",
    "    os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "    os.environ[\"LANGCHAIN_API_KEY\"] = LANGSMITH_API_KEY\n",
    "    os.environ[\"LANGCHAIN_PROJECT\"] = LANGSMITH_PROJECT\n",
    "\n",
    "\n",
    "RESULTS_DIR = pathlib.Path('./results')\n",
    "RESULTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f'LangSmith configurado: {LANGSMITH_API_KEY is not None}')\n",
    "print(f'Proyecto: {LANGSMITH_PROJECT}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memoria GPU limpiada\n"
     ]
    }
   ],
   "source": [
    "# Limpiar memoria GPU si está disponible\n",
    "import gc\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    print(f'Memoria GPU limpiada')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuración de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activamos los modelos LLM con Ollama:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ollama run hf.co/unsloth/Qwen3-4B-Instruct-2507-GGUF:Q8_0 \n",
    "# ollama run hf.co/MaziyarPanahi/Phi-3.5-mini-instruct-GGUF:Q6_K \n",
    "# ollama run hf.co/bartowski/Llama-3.2-3B-Instruct-GGUF:Q8_0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo para embeddings: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:530: DeprecationWarning: the load_module() method is deprecated and slated for removal in Python 3.15; use exec_module() instead\n",
      "Some weights of the model checkpoint at Alibaba-NLP/gte-multilingual-base were not used when initializing NewModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing NewModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing NewModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Usando dispositivo para embeddings: {device}')\n",
    "# embedding gte\n",
    "model_kwargs = {\n",
    "    'device': device,\n",
    "    'trust_remote_code': True\n",
    "}\n",
    "\n",
    "'''Wrapper personalizado para el modelo de embeddings E5 Instruct.\n",
    "   Añade prefijos específicos (\"passage:\" para documentos, \"query:\" para consultas) \n",
    "   Métodos:\n",
    "    - embed_documents(): Procesa listas de documentos\n",
    "    - embed_query(): Procesa una consulta individual\n",
    "'''\n",
    "\n",
    "class E5InstructEmbeddings(Embeddings):\n",
    "    def __init__(self, model_name=\"intfloat/multilingual-e5-large-instruct\", device=None):\n",
    "        \"\"\"Inicializa el modelo de embeddings E5 Instruct con prefijos específicos para documentos y queries.\"\"\"\n",
    "        if device is None:\n",
    "            device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        \n",
    "        self.device = device\n",
    "        self.model = SentenceTransformer(model_name, device=device)\n",
    "    \n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        \"\"\"Para documentos - añadir prefix 'passage:'\"\"\"\n",
    "        prefixed_texts = [f\"passage: {text}\" for text in texts]\n",
    "        return self.model.encode(prefixed_texts, device=self.device).tolist()\n",
    "    \n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        \"\"\"Para queries - añadir prefix 'query:'\"\"\"\n",
    "        prefixed_text = f\"query: {text}\"\n",
    "        return self.model.encode([prefixed_text], device=self.device)[0].tolist()\n",
    "\n",
    "LLM = {\n",
    "    'Qwen3-4B-instruct-2507': OllamaLLM(model=\"hf.co/unsloth/Qwen3-4B-Instruct-2507-GGUF:Q8_0\", temperatura = 0.5),\n",
    "    'Llama-3.2-3B-instruct': OllamaLLM(model=\"hf.co/bartowski/Llama-3.2-3B-Instruct-GGUF:Q8_0\", temperatura = 0.5),\n",
    "    'Phi-3.5-mini-instruct': OllamaLLM(model=\"hf.co/MaziyarPanahi/Phi-3.5-mini-instruct-GGUF:Q6_K\", temperatura = 0.5)\n",
    "}\n",
    "\n",
    "EMBEDDING_MODELS = {\n",
    "    \"all-MiniLM-L6-v2\": HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "        model_kwargs={\"device\": device}),\n",
    "    \"e5-large-instruct\": E5InstructEmbeddings(\n",
    "        model_name=\"intfloat/multilingual-e5-large-instruct\",\n",
    "        device=device),\n",
    "    \"gte-multilingual-base\": HuggingFaceEmbeddings(\n",
    "        model_name=\"Alibaba-NLP/gte-multilingual-base\",\n",
    "        model_kwargs=model_kwargs)\n",
    "}\n",
    "\n",
    "# Cliente Weaviate\n",
    "client = weaviate.connect_to_local(\n",
    "    host=\"localhost\",\n",
    "    port=8080,\n",
    "    grpc_port=50051\n",
    ")\n",
    "\n",
    "# Mapear embeddings a las clases de Weaviate\n",
    "WEAVIATE_CLASSES = {\n",
    "    'all-MiniLM-L6-v2': 'IdearqAllMiniLM',\n",
    "    'e5-large-instruct': 'IdearqE5',\n",
    "    'gte-multilingual-base': 'IdearqGTE'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPTS = {\n",
    "'prompt_zero_shot': \"\"\"Eres un asistente experto en arqueología, historia y datos geoespaciales. Responde la pregunta usando los contextos proporcionados, que pueden estar en español, inglés, francés, catalán o portugués.\n",
    "Sintetiza información de todos los contextos relevantes independientemente de su idioma. Si encuentras información relevante en cualquier idioma, úsala para construir tu respuesta en el mismo idioma en el que se realiza la pregunta.\n",
    "\n",
    "Contexto: {context}\n",
    "\n",
    "Pregunta: {question}\n",
    "\n",
    "Instrucciones:\n",
    "- Si encuentras información parcial en el contexto, intégrala en la respuesta aunque no sea completa.\n",
    "- Si no hay absolutamente nada relevante, responde claramente: \"No hay información suficiente en el contexto\".\n",
    "- No inventes ni alucines información fuera del contexto.\n",
    "- Cuando sea posible, cita explícitamente los puntos clave del contexto (ej. autores, años, títulos de publicaciones, yacimientos, cronologías).\n",
    "- Responde siempre de forma clara, estructurada y útil para un investigador.\n",
    "\n",
    "Respuesta:\"\"\",\n",
    "\n",
    "    'prompt_one_shot': \"\"\"Eres un asistente experto en arqueología, historia y datos geoespaciales. Responde la pregunta usando los contextos proporcionados, que pueden estar en español, inglés, francés, catalán o portugués.\n",
    "Sintetiza información de todos los contextos relevantes independientemente de su idioma. Si encuentras información relevante en cualquier idioma, úsala para construir tu respuesta en el mismo idioma en el que se realiza la pregunta.\n",
    "\n",
    "Contexto: {context}\n",
    "\n",
    "Pregunta: {question}\n",
    "\n",
    "Instrucciones:\n",
    "- Si encuentras información parcial en el contexto, intégrala en la respuesta aunque no sea completa.\n",
    "- Si no hay absolutamente nada relevante, responde claramente: \"No hay información suficiente en el contexto\".\n",
    "- No inventes ni alucines información fuera del contexto.\n",
    "- Cuando sea posible, cita explícitamente los puntos clave del contexto (ej. autores, años, títulos de publicaciones, yacimientos, cronologías).\n",
    "- Responde siempre de forma clara, estructurada y útil para un investigador.\n",
    "\n",
    "Ejemplo:\n",
    "Q: ¿Cuál es la utilidad de los análisis de isótopos de estroncio en Arqueología?\n",
    "A: El tema del desplazamiento, la movilidad y la migración ha sido altamente destacado como uno de los cinco grandes retos de la investigación arqueológica contemporánea. El uso del análisis de isótopos de estroncio es hoy en día uno de los métodos más eficaces para afrontar este reto, ofreciendo un enfoque sistemático, cuantitativo y comparable a la movilidad de las poblaciones humanas y animales del pasado (Larsen 2018).\n",
    "\n",
    "Respuesta:\"\"\",\n",
    "\n",
    "    'prompt_few_shot': \"\"\"Eres un asistente experto en arqueología, historia y datos geoespaciales. Responde la pregunta usando los contextos proporcionados, que pueden estar en español, inglés, francés, catalán o portugués.\n",
    "Sintetiza información de todos los contextos relevantes independientemente de su idioma. Si encuentras información relevante en cualquier idioma, úsala para construir tu respuesta en el mismo idioma en el que se realiza la pregunta.\n",
    "Contexto: {context}\n",
    "\n",
    "Pregunta: {question}\n",
    "\n",
    "Instrucciones:\n",
    "- Si encuentras información parcial en el contexto, intégrala en la respuesta aunque no sea completa.\n",
    "- Si no hay absolutamente nada relevante, responde claramente: \"No hay información suficiente en el contexto\".\n",
    "- No inventes ni alucines información fuera del contexto.\n",
    "- Cuando sea posible, cita explícitamente los puntos clave del contexto (ej. autores, años, títulos de publicaciones, yacimientos, cronologías).\n",
    "- Responde siempre de forma clara, estructurada y útil para un investigador.\n",
    "\n",
    "Ejemplos:\n",
    "Q: ¿Cuál es la utilidad de los análisis de isótopos de estroncio en Arqueología?\n",
    "A: El tema del desplazamiento, la movilidad y la migración ha sido altamente destacado como uno de los cinco grandes retos de la investigación arqueológica contemporánea. El uso del análisis de isótopos de estroncio es hoy en día uno de los métodos más eficaces para afrontar este reto, ofreciendo un enfoque sistemático, cuantitativo y comparable a la movilidad de las poblaciones humanas y animales del pasado (Larsen 2018).\n",
    "\n",
    "Q: ¿Cuáles son las características de la distribución geográfica de la muestra disponible de análisis de isótopos de estroncio en la Península Ibérica?\n",
    "A: La distribución de la muestra es variable y discontinua, con concentraciones asociadas a focos de investigación específicos (p. ej., Lisboa, valle del Ebro). La cobertura es irregular tanto geográfica como cronológicamente, lo que dificulta los estudios a escala ibérica para la mayoría de los periodos, a excepción de la Edad del Cobre (764 muestras). La escasez de datos es crítica en algunas épocas, como el Mesolítico, que cuenta con una única muestra. \n",
    "\n",
    "Respuesta:\"\"\"\n",
    "}\n",
    "\n",
    "selected_template = PROMPTS['prompt_few_shot']\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(selected_template)\n",
    "\n",
    "example_messages = prompt_template.invoke(\n",
    "    {\"context\": \"Contexto de ejemplo.\", \"question\": \"Pregunta de ejemplo.\"}\n",
    ").to_messages()\n",
    "\n",
    "# Results dir\n",
    "RESULTS_DIR = pathlib.Path('./results')\n",
    "RESULTS_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos el grafo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estado del grafo con TypedDict\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    llm_name: str\n",
    "    embedding_name: str\n",
    "    prompt_name: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "    metadata: Dict[str, Any]\n",
    "\n",
    "# Clase para almacenar resultados con todas las métricas\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "@dataclass\n",
    "class RunResultComplete:\n",
    "    llm: str\n",
    "    embedding: str\n",
    "    prompt: str\n",
    "    question: str\n",
    "    answer: Optional[str]\n",
    "    contexts: List[str]\n",
    "    ground_truth: Optional[str]\n",
    "    docs: List[Dict[str, Any]]\n",
    "    latency: float\n",
    "    metadata: Dict[str, Any]\n",
    "    \n",
    "    # Métricas RAGAS con LLM\n",
    "    context_recall: Optional[float] = None\n",
    "    faithfulness: Optional[float] = None\n",
    "    context_precision: Optional[float] = None  \n",
    "    response_relevancy: Optional[float] = None\n",
    "    \n",
    "    # Métricas RAGAS sin LLM\n",
    "    answer_correctness: Optional[float] = None  \n",
    "    semantic_similarity: Optional[float] = None\n",
    "    exact_match: Optional[float] = None  \n",
    "    \n",
    "    # Métricas LangSmith con LLM\n",
    "    ls_correctness: Optional[float] = None\n",
    "    ls_helpfulness: Optional[float] = None\n",
    "    ls_relevance: Optional[float] = None\n",
    "    \n",
    "    # Métricas LangSmith sin LLM\n",
    "    ls_string_distance: Optional[float] = None\n",
    "    ls_regex_match: Optional[float] = None\n",
    "\n",
    "def retrieve(state: State):\n",
    "    # Obtener el modelo de embedding correspondiente\n",
    "    embedding_model = EMBEDDING_MODELS[state[\"embedding_name\"]]     \n",
    "    class_name = WEAVIATE_CLASSES[state[\"embedding_name\"]]   \n",
    "\n",
    "    vector_store = WeaviateVectorStore(\n",
    "        client=client,\n",
    "        index_name=class_name,\n",
    "        text_key=\"content\",\n",
    "        embedding=embedding_model,\n",
    "        attributes=[\"filename\", \"title\", \"source\", \"chunk_index\", \"doc_index\"]\n",
    "    )\n",
    "\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"], k = 10)\n",
    "    #print(f\"Recuperados {len(retrieved_docs)} docs para {state['embedding_name']}\")\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "def generate(state: State):\n",
    "    print(\"    -> Entrando en el nodo 'generate'...\")\n",
    "    try:\n",
    "        # 1. Preparamos el contexto y el prompt\n",
    "        docs_content = \"\\\\n\\\\n---\\\\n\\\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "        template = PROMPTS[state[\"prompt_name\"]]\n",
    "        prompt = ChatPromptTemplate.from_template(template)\n",
    "        \n",
    "        # 2. Seleccionamos el LLM\n",
    "        current_llm = LLM[state[\"llm_name\"]]\n",
    "        \n",
    "        # --- INICIO DE DEPURACIÓN ---\n",
    "        print(f\"       - LLM a usar: {state['llm_name']}\")\n",
    "        print(f\"       - Prompt a usar: {state['prompt_name']}\")\n",
    "        # Imprimimos solo los primeros 300 caracteres del contexto para no llenar la pantalla\n",
    "        print(f\"       - Contexto para el prompt (primeros 300 chars):\\\\n'{docs_content[:300]}...'\")\n",
    "        # --- FIN DE DEPURACIÓN ---\n",
    "\n",
    "        # 3. Invocamos el LLM\n",
    "        messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "        response = current_llm.invoke(messages)\n",
    "        \n",
    "        print(\"    -> El LLM ha devuelto una respuesta.\")\n",
    "        \n",
    "        latency = 0 \n",
    "        metadata = { \"latency\": latency }\n",
    "\n",
    "        return {\"answer\": response, \"metadata\": metadata}\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"    -> ERROR DENTRO DEL NODO 'generate': {e}\")\n",
    "        return {\"answer\": \"\", \"metadata\": {\"error\": str(e)}}\n",
    "\n",
    "def extract_sources_from_docs(docs: List[Document]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Extraer metadatos de fuentes de los documentos\"\"\"\n",
    "    sources = []\n",
    "    for doc in docs:\n",
    "        metadata = doc.metadata\n",
    "        source_info = {\n",
    "            'filename': metadata.get('filename', 'Unknown'),\n",
    "            'title': metadata.get('title', metadata.get('doc_title', 'Sin título')),\n",
    "            'page_content_preview': doc.page_content[:200] + \"...\"\n",
    "        }\n",
    "        sources.append(source_info)\n",
    "    return sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Crear el grafo \n",
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(\"retrieve\", retrieve)\n",
    "graph_builder.add_node(\"generate\", generate)\n",
    "\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph_builder.add_edge(\"retrieve\", \"generate\")\n",
    "\n",
    "graph = graph_builder.compile()\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurar la evaluación con RAGAS y LangSmith"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from datasets import Dataset\n",
    "\n",
    "# Preguntas y ground truths\n",
    "questions = [\n",
    "    'What are the main theoretical models of Neolithic expansion in Europe?',\n",
    "    'Quais são as datas mais antigas da extração de sílex na península central?',\n",
    "    '¿Cuáles son las cronologías de las manifestaciones funerarias del Mesolítico en las distintas regiones peninsulares?',\n",
    "    'Principales yacimientos de la Segunda Edad del Hierro en la provincia de León.',\n",
    "    'Periodización del Bronce Final en el Levante de la Península Ibérica, cronología de las fases y principales ejemplos de yacimientos asignados a las mismas.',\n",
    "    'Yacimientos Calcolíticos de la Península Ibérica  en los que se han hallado objetos de marfil.',\n",
    "    'Cronología y districubión espacial del poblamiento neolítixco en la Meseta Sur.',\n",
    "    'Dataciones más antiguas para el megalitismo en la zona Sureste de la Península Ibérica.'\n",
    "    'Excavaciones de urgencia de la Junta de Andalucía en la provincia de Almería publicadas en 2001.',\n",
    "    '¿En qué año excavaron en el yacimiento de La Bastida de Totana los hermanos Siret?'\n",
    "]\n",
    "ground_truths = [\n",
    "    \"\"\"These can be divided into two main positions: the first, known as demic diffusion, emphasises the movement of Neolithic societies and, by extension, agricultural practices; the second, referred to in the literature as cultural diffusion, focuses on the importance of the transmission of the Neolithic package—technology (e.g., pottery), plants, and domesticated animals—as a trigger for the expansion of the Neolithic.\"\"\",\n",
    "    \"\"\"A única mina de sílex do Neolítico no centro de Espanha é a de Casamontero (Madrid). A série completa de datas de radiocarbono é apresentada na Fig. 3 e a sua distribuição espacial na Fig. 4 do artigo de Díaz del Río e Consuegra, 2015.\n",
    "        Infelizmente, a amostra de Sus sp. não tinha colagénio suficiente para ser datada. O teste X2 mostra que todas as datas, com a única exceção da Beta-232890, são estatisticamente idênticas. Recentemente, foi enviada outra matriz de anel para datação num fragmento de fémur de Ovis aries. O resultado, 6200+/ -40 BP (Beta-295152), é estatisticamente igual a dez das onze datas anteriores.\n",
    "       Assumindo a hipótese plausível de que elas datam diferentes eventos de mineração, há uma probabilidade de 65% de que todos os episódios de mineração tenham ocorrido entre 5327-5215 cal BC (1σ), um período de tempo de apenas cem anos. Portanto, estas datas de radiocarbono não permitem observar a evolução espácio-temporal da exploração mineira, mas indicam que o principal episódio de atividade da Casa Montero durou pouco mais de um século, quatro gerações. Esta interpretação não é apenas possível, é provável.\"\"\"\n",
    "    \"\"\"Modelo construido a partir de muestras individuales de radiocarbono de esqueletos mesolíticos encontrados en los cementerios ibéricos. La diferencia más significativa entre la región mediterránea y la región cantábrica y Portugal se observa en la aparición de cementerios durante el Mesolítico temprano. Además, al evaluar los datos de las tres zonas de la Península Ibérica, se pueden identificar los siguientes patrones cronológicos.\n",
    "        - En la región mediterránea, las fechas de El Collado muestran que los cementerios aparecieron alrededor de 9475-9300 cal BP. Este tipo de práctica funeraria continuará en otros yacimientos cercanos, como Casa Corona y Cingle del Mas Nou. A diferencia del cementerio de El Collado, que estuvo en uso durante unos 1100 años, según las fechas obtenidas, en Casa Corona y Cingle del Mas Nou, su periodo de uso es mucho más breve (8007-7583 cal BP). Además, Cingle del Mas Nou se diferencia de otros yacimientos funerarios mesolíticos de la Península Ibérica en que los restos de siete individuos (completos e incompletos) fueron depositados en una única estructura.\n",
    "        - En la fachada atlántica de Portugal, las primeras pruebas de cementerios en el estuario de Muge datan de 8409-8030 cal BP (en Cabeço de Arruda, por ejemplo). Estos están asociados a grandes concheros de más de 5 m de espesor, utilizados durante un largo periodo de tiempo. En el estuario del Sado, las fechas son ligeramente más recientes que en Muge, comenzando alrededor del 8200 cal BP (por ejemplo, en Amoreiras). Está claro que entre el 8160 y el 7970 cal BP, los grupos mesolíticos enterraban sistemáticamente a todos o algunos de sus muertos en cementerios.\n",
    "        - Por último, las fechas de los yacimientos funerarios del norte de la Península Ibérica (costa cantábrica) con dos o más individuos indican que los primeros enterramientos mesolíticos agrupados fueron un poco más recientes (entre 7981 y 6636 cal BP). En cualquier caso, cabe destacar que, a diferencia de las otras dos zonas, en la mayoría de los yacimientos solo se ha documentado un único individuo o grupos mucho más reducidos, como en Los Canes y La Braña.\"\"\"\n",
    "    \"\"\"\n",
    "        - Castro de la Edad de Hierro de Valencia de Don Juan\n",
    "        - La Muela (al otro lado de la carretera de acceso a Valencia de Don Juan)\n",
    "        - Antigua ciudad astur-romana de Lancia: otro de los grandes de oppida de la Segunda Edad del Hierro\n",
    "        - Regueras de Arriba o San Martín de Torres.\n",
    "        - En la zona cántabra, los castros laciniaegos de la Mesa en Rioscuro, que se delimita con una potente muralla de módulos, fechada seguramente en los siglos II y I a.C., y el castro de La Zamora, en sosas de Laciana.\n",
    "        - También en la zona cántabra en el municipio de Puebla de Lillo se han podido reconocer ciertas piezas metalíticas de la Segunda Edad del Hierro, recogidas en el antiguo castro de Castiltejón. \n",
    "        - El castro de Chano en la comarca de Fornela.\n",
    "        - Peña del Castro (La Ercina), ubicado a 2 km de la localidad de la Ercina \n",
    "        - El Castrelín de San Juan dse Paluezas\n",
    "        - La Corona del Castro en Borrenes\n",
    "        - La Peña del Hombre en el ayuntamiento de Priaranza\n",
    "        - Castro de Columbrianos\n",
    "        - Peña Piñera, en la Vega de Espinareda\n",
    "        - Por último, se ha señalado un conjunto de castros en altitudes considerables en las sierras del Teleno, la Valdería y el Bierzo, algunos ya conocidos en la bibliografía y en la Carta Arqueológica de León, con grandes amurallamientos, que se extienden entre afloramientos rocosos de materiales de la era Primaria; yacimientos como Portillo de Xandequín en Pozos, Peña Rayada en Cunas, Alto de San Vicente-Los Conventos en Morla de la Valdería, Yera de los Piornos-Peña del Tren en Torneros de la Valdería, Sierra del Pueblo en Torneros de la Valdería, El Pajarín-La Formosida en Boisán (Lucillo) y los bercianos localizados en Folgoso de la Ribera, Torre del Bierzo y Molinaseca. \"\"\"\n",
    "    \"\"\"Bronce tardío o reciente (c. 1550/1500-1300/1250 cal BC):\n",
    "        - Oropesa la Vella\n",
    "        - Torreló d’Onda\n",
    "        - Les Raboses\n",
    "        - Altet de Palau\n",
    "        - Cap Prim\n",
    "        - Mas del Corral\n",
    "        - Cabezo Redondo\n",
    "        - Peña de Sax\n",
    "        - El Negret\n",
    "        - Illeta del Banyets\n",
    "        - Tabayá\n",
    "\n",
    "    Bronce final I (c. 1300/1250-1000 cal BC):\n",
    "        - Costamar\n",
    "        - Oropesa la Vella\n",
    "        - El Castellet\n",
    "        - Torrelló de Boverot\n",
    "        - Pic dels Corbs III y IV\n",
    "        - Cova d’en Pardo\n",
    "        - Cova de la Pastora\n",
    "        - Cap Prim\n",
    "        - Peña de Sax\n",
    "        - El Negret\n",
    "        - Tabayá\n",
    "        - Botx-Grupitex\n",
    "\n",
    "    Bronce final II (1000-850 cal BC):\n",
    "        - Ereta del Castellar\n",
    "        - El Castellet\n",
    "        - Torrelló de Boverot\n",
    "        - Pic dels Corbs V\n",
    "        - Solana del Castell I\n",
    "        - Mola d’Agres\n",
    "        - Tabayá\n",
    "        - Caramoro\n",
    "        - Botx\n",
    "\n",
    "    Bronce final III (850-725 cal BC):\n",
    "        -Ereta del Castellar\n",
    "        - El Castellet\n",
    "        -Torrelló de Boverot\n",
    "        -Vinarragell\n",
    "        - La Vital\n",
    "        -Solana del Castell II\n",
    "        -Mola d’Agres\n",
    "        -Cova de la Sarsa\n",
    "        -Tabayá\n",
    "        -Peña Negra I\n",
    "        - Barranc del Botx\n",
    "        -Saladares Ia1/IA2\n",
    "\n",
    "    Hierro antiguo o fase Orientalizante (725-550 cal BC):\n",
    "        - Vinarragell\n",
    "        - El Molón\n",
    "        - Los Villares\n",
    "        - Solana del Castell III\n",
    "        - El Castellar\n",
    "        - El Puig\n",
    "        - Camara\n",
    "        - Tabayá\n",
    "        - Peña Negra II\n",
    "        - Casa Secà\n",
    "        - Saladares IA3\n",
    "\"\"\",\n",
    "\"\"\"Calcolítico antiguo (pre-campaniforme [bell beaker]):\n",
    "        - Zambujal\n",
    "        - Vila Nova de São Pedro\n",
    "        - Leceiaa\n",
    "        - Praia das Maçãs\n",
    "        - Palmela\n",
    "        - Alcalar\n",
    "        - Perdigões \n",
    "        - Señorío de Guzmán\n",
    "        - La Pijotilla\n",
    "        - Valencina de la Concepción\n",
    "        - Gilena\n",
    "        - Los Millares\n",
    "\n",
    "Calcolítico reciente (campaniforme [bell beaker]):\n",
    "        - Palmela\n",
    "        - Pedra do Ouro\n",
    "        - Verdelha dos Ruivos\n",
    "        - Vila Nova de São Pedro\n",
    "        - Perdigões\n",
    "        - Valencina de la Concepción\n",
    "        - Los Algarbes\n",
    "        - Cerro de la Virgen\n",
    "        - Camino de Yeseras\n",
    "        - La Pijotilla\n",
    "\"\"\",\n",
    "\"\"\"Lo dividimos en dos áreas: poblamiento neolítico en el valle medio y alto del Tajo y poblamiento neolítico de La Mancha.\n",
    "- Valle del Tajo: En la zona de la Sierra madrileña se localizan las cuevas la Cueva de La Ventana o la Cueva de la Higuera. Ambas son especialmente importantes para comprender los asentamientos en cueva, ya que disponen de dataciones radiocarbónicas asociadas a contextos de habitación. Ya en la provincia de Guadalajara destacan los yacimientos de la Cueva de la Hoz, Abrigo de Tordelrrábano  la Cueva de Jarama II, los enclaves de Sorbe II (Humanes de Mohernando), II y VII, la Cueva del Paso, el Abrigo de los Enebrales, Cueva del Reno y la Cueva del Destete.  Sin embargo, son los yacimientos de hoyos los que constituyen el principal modelo de asentamiento. Las excavaciones arqueológicas en extensión realizadas en los últimos años han puesto de manifiesto el predominio del hábitat en asentamientos al aire libre durante este periodo. Tan sólo se han documentado 8 enclaves neolíticos serranos de un total de 24 yacimientos cartografiados en la región. Los 16 yacimientos restantes se ubican en zonas bajas de los valles. A estas cifras hay que sumar tres nuevos yacimientos neolíticos: Soto del Henares, La Serna y Prado de Galápagos, recientemente publicados por C. Blasco et al.\n",
    "(2016) que amplían el listado de asentamientos de hoyos ubicados en los fondos de\n",
    "valle.\n",
    "La concentración de yacimientos neolíticos es especialmente interesante en la zona sureste de la Comunidad de Madrid, en los tramos finales de los ríos Henares, Jarama y Manzanares. La densidad de yacimientos de hoyos neolíticos en las zonas bajas de estos cursos fluviales ha aportado desde hace años datos muy interesantes para conocer los patrones de asentamiento y los modelos de\n",
    "ocupación territorial de las primeras comunidades neolíticas. \n",
    "- Poblamiento neolítico de La Mancha: El modelo de asentamiento neolítico mejor conocido en La Mancha son las ocupaciones en cuevas y abrigos. En este sentido, los yacimientos neolíticos manchegos mejor conocidos son la Cueva del Niño y el Abrigo de Molino de Vadico, en Albacete, y el Abrigo de Verdelpino, en Cuenca, a los que ya nos referimos en el capítulo anterior. En estos yacimientos se han documentado, además, ocupaciones previas, por lo que se son especialmente interesantes para estudiar el momento de adopción de los modos de vida neolíticos. \n",
    "En los últimos años se han realizado varias intervenciones arqueológicas en el contexto de las obras de construcción de grandes infraestructuras. Desde el punto de vista arqueológico, este tipo de intervenciones implican la prospección y, en su caso, excavación en zonas aleatorias afectadas por los proyectos constructivos, por lo que no se introducen sesgos relacionados con intereses científicos concretos. Por lo tanto, los hallazgos suponen una buena aproximación de la existencia o ausencia de distintos tipos de registro arqueológico. En este sentido, las obras de acceso al aeropuerto de Ciudad Real o los trabajos de la autopista que conecta Ocaña (Toledo) con La Roda (Ciudad Real), no aportaron hallazgos de asentamientos neolíticos. \n",
    "Si bien es cierto que las investigaciones sobre esta etapa de la Prehistoria en La Mancha han sido escasas y son pocos los equipos de investigación que han desarrollado líneas de investigación orientadas al conocimiento de las primeras sociedades productoras en esa región, no es menos cierto que las intervenciones arqueológicas llevadas a cabo en el contexto de obras de infraestructura en Castilla-La Mancha apoyan la idea de un poblamiento neolítico caracterizado por su escasa densidad, especialmente si se compara con otras regiones como en valle medio y alto del Tajo.\n",
    "\"\"\",\n",
    "\"\"\"Son el solar situado en la avenida Pablo Iglesias esquina A Rafaeka Jiménez, solar situado en la calle La central de Villaricos (cuevas de Almanzora) y en la calle Castillejo (Gador, Almería).\"\"\",\n",
    "\"\"\"En el año 1886.\"\"\"\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EVALUACIÓN CON API MISTRAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mistral configurado para RAGAS\n"
     ]
    }
   ],
   "source": [
    "from langchain_mistralai import ChatMistralAI\n",
    "from ragas.metrics import context_precision, context_recall, faithfulness, answer_correctness\n",
    "import time\n",
    "from datasets import Dataset\n",
    "from ragas import evaluate \n",
    "import pandas as pd\n",
    "  # Configurar Mistral\n",
    "mistral_evaluator = ChatMistralAI(\n",
    "    api_key=MISTRAL_API_KEY,\n",
    "    model=\"mistral-small-latest\",\n",
    "    temperature=0.1,\n",
    "    max_retries=3,\n",
    "    timeout= 180 # Timeout para las requests HTTP\n",
    "    \n",
    ")\n",
    "\n",
    "# Prompts específicos para métricas\n",
    "context_precision.context_precision_prompt.instruction = \"\"\"\n",
    "Dada una pregunta sobre arqueología y un conjunto de contextos que pueden estar en varios idiomas (español, inglés, francés, catalán, portugués), identifica qué contextos son útiles para responder la pregunta.\n",
    "Los contextos pueden contener información técnica, fechas, yacimientos arqueológicos, cronologías, dataciones, etc. Un contexto es útil si contiene información relevante que ayude a responder la pregunta, aunque sea parcialmente, independientemente      \n",
    "del idioma en que esté escrito.     \n",
    "\n",
    "Pregunta: {question}\n",
    "Contextos: {contexts}\n",
    "\n",
    "Responde SOLO con un JSON válido en este formato exacto:\n",
    "{\"useful_contexts\": [0, 1, 2]}\n",
    "donde los números son los índices de contextos útiles.\n",
    "\"\"\"\n",
    "\n",
    "context_recall.context_recall_prompt.instruction = \"\"\"\n",
    "Dada una pregunta sobre arqueología y un conjunto de contextos que pueden estar en varios idiomas (español, inglés, francés, catalán, portugués), evalúa si el contexto contiene toda la información necesaria para responder la pregunta.\n",
    "Los contextos pueden contener información técnica, fechas, yacimientos arqueológicos, cronologías, dataciones, etc. Un contexto es útil si contiene información relevante que ayude a responder la pregunta, aunque sea parcialmente, independientemente      \n",
    "del idioma en que esté escrito.\n",
    "Responde SOLO con un JSON válido en este formato exacto:\n",
    "{\"correctness\": 0.8}\n",
    "donde el valor está entre 0.0 y 1.0\n",
    "\"\"\"  \n",
    "print(\"Mistral configurado para RAGAS\")\n",
    "\n",
    "# Función de evaluación con Mistral y las 4 métricas\n",
    "\n",
    "def evaluate_with_mistral_four_metrics(results_list, embedding_model, max_batch_size=2, delay_between_batches=90):\n",
    "    \"\"\"\n",
    "    Evaluación RAGAS con Mistral API usando las 4 métricas principales\n",
    "    \"\"\"\n",
    "    print(f\"Evaluando {len(results_list)} preguntas con 4 métricas en batches de {max_batch_size}\")\n",
    "\n",
    "    all_batch_results = []\n",
    "    total_batches = (len(results_list) + max_batch_size - 1) // max_batch_size\n",
    "\n",
    "    for batch_idx in range(0, len(results_list), max_batch_size):\n",
    "        batch_num = batch_idx // max_batch_size + 1\n",
    "        batch = results_list[batch_idx:batch_idx + max_batch_size]\n",
    "\n",
    "        print(f\"   🔄 Procesando batch {batch_num}/{total_batches} ({len(batch)} preguntas)\")\n",
    "\n",
    "        # Crear dataset del batch\n",
    "        batch_dataset = Dataset.from_list(batch)\n",
    "\n",
    "        # Intentar evaluación con reintentos\n",
    "        batch_success = False\n",
    "        for attempt in range(3):\n",
    "            try:\n",
    "                print(f\"      Intento {attempt + 1}/3 para batch {batch_num}\")\n",
    "\n",
    "                # Evaluar cada métrica por separado para mayor estabilidad\n",
    "                batch_metrics = {}\n",
    "\n",
    "                metrics_to_evaluate = [\n",
    "                    ('context_precision', context_precision),\n",
    "                    ('context_recall', context_recall),\n",
    "                    ('faithfulness', faithfulness),\n",
    "                    ('answer_correctness', answer_correctness)\n",
    "                ]\n",
    "\n",
    "                for metric_name, metric_obj in metrics_to_evaluate:\n",
    "                    try:\n",
    "                        print(f\"         Evaluando {metric_name}...\")\n",
    "\n",
    "                        metric_result = evaluate(\n",
    "                            batch_dataset,\n",
    "                            llm=mistral_evaluator,\n",
    "                            embeddings=embedding_model,\n",
    "                            metrics=[metric_obj],\n",
    "                            raise_exceptions=False\n",
    "                        )\n",
    "\n",
    "                        metric_df = metric_result.to_pandas()\n",
    "\n",
    "                        if metric_name in metric_df.columns:\n",
    "                            batch_metrics[metric_name] = metric_df[metric_name]\n",
    "                            print(f\"{metric_name} completado\")\n",
    "                        else:\n",
    "                            batch_metrics[metric_name] = None\n",
    "                            print(f\"{metric_name} no encontrado en resultados\")\n",
    "\n",
    "                        # Pausa entre métricas para evitar rate limits\n",
    "                        time.sleep(25)\n",
    "\n",
    "                    except Exception as metric_error:\n",
    "                        print(f\"{metric_name} falló: {metric_error}\")\n",
    "                        batch_metrics[metric_name] = None\n",
    "                        time.sleep(30)  # Pausa más larga si hay error\n",
    "\n",
    "                # Crear DataFrame combinado del batch\n",
    "                batch_result_df = pd.DataFrame({\n",
    "                    'question': [item['question'] for item in batch],\n",
    "                    'answer': [item['answer'] for item in batch],\n",
    "                    'contexts': [item['contexts'] for item in batch],\n",
    "                    'ground_truth': [item['ground_truth'] for item in batch],\n",
    "                    'context_precision': batch_metrics.get('context_precision'),\n",
    "                    'context_recall': batch_metrics.get('context_recall'),\n",
    "                    'faithfulness': batch_metrics.get('faithfulness'),\n",
    "                    'answer_correctness': batch_metrics.get('answer_correctness')\n",
    "                })\n",
    "\n",
    "                all_batch_results.append(batch_result_df)\n",
    "                batch_success = True\n",
    "                print(f\"Batch {batch_num} completado con 4 métricas\")\n",
    "                break\n",
    "\n",
    "            except Exception as batch_error:\n",
    "                print(f\"Batch {batch_num}, intento {attempt + 1} falló: {batch_error}\")\n",
    "                if attempt < 2:\n",
    "                    wait_time = 120 * (attempt + 1)  # Espera más larga para 4 métricas\n",
    "                    print(f\"         Esperando {wait_time}s antes del siguiente intento...\")\n",
    "                    time.sleep(wait_time)\n",
    "\n",
    "        if not batch_success:\n",
    "            print(f\"Batch {batch_num} falló después de 3 intentos, creando resultados vacíos\")\n",
    "            # Crear DataFrame vacío para este batch\n",
    "            empty_batch_df = pd.DataFrame({\n",
    "                'question': [item['question'] for item in batch],\n",
    "                'answer': [item['answer'] for item in batch],\n",
    "                'contexts': [item['contexts'] for item in batch],\n",
    "                'ground_truth': [item['ground_truth'] for item in batch],\n",
    "                'context_precision': [None] * len(batch),\n",
    "                'context_recall': [None] * len(batch),\n",
    "                'faithfulness': [None] * len(batch),\n",
    "                'answer_correctness': [None] * len(batch)\n",
    "            })\n",
    "            all_batch_results.append(empty_batch_df)\n",
    "\n",
    "        # Rate limiting: pausa entre batches (más larga para 4 métricas)\n",
    "        if batch_num < total_batches:\n",
    "            print(f\"Esperando {delay_between_batches}s antes del siguiente batch...\")\n",
    "            time.sleep(delay_between_batches)\n",
    "\n",
    "    # Combinar todos los resultados\n",
    "    if all_batch_results:\n",
    "        combined_results = pd.concat(all_batch_results, ignore_index=True)\n",
    "        print(f\"Evaluación completada: {len(combined_results)} preguntas con 4 métricas\")\n",
    "        return combined_results\n",
    "    else:\n",
    "        print(f\"No se pudieron procesar resultados\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUANDO CON PROMPT: prompt_zero_shot\n",
      "================================================================================\n",
      "Generando respuestas con LangGraph...\n",
      "Procesando pregunta 1/9 con prompt_zero_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Published by Elsevier Inc. All rights reserved. doi:10.1016/j.yqres.2011.12.003 Contents lists available at SciVerse ScienceDirect Quaternary Research journal homepage: www.elsevier.com/locate/yqres https://doi.org/10.1016/j.yqres.2011.12.003 Published online by Cambridge University Press Introduc...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 2/9 con prompt_zero_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. A data obtida, é claramente mais recuada que os con­ textos mais antigos reportados em território hoje portu­ guês, nomeadamente Gruta da Nascente do Rio Almonda (OxA­‑9287 – 5480­‑5320 cal BC a 2 sigmas) e da Gruta do Caldeirão (OxA­‑1036 – 5480 – 5070 cal BC a 2 sigmas). Entre nós, apenas se rep...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 3/9 con prompt_zero_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 2. ENCUADRE CRONO-CULTURAL DEL HA- LLAZGO: COGOTAS I Entre las entidades arqueológicas de la Edad del Bronce peninsular, Cogotas I sobresale por su extensa cobertura geográfica, que desborda la Meseta por el Valle del Ebro y Extremadura, y por su dilatada crono- logía —c. 1800-1150 cal BC, cubrien...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 4/9 con prompt_zero_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. y NEIRA, A. (1999): “Prehistoria”, en M.A. Rabanal Alonso (coord.): La His­ toria de León, tomo I, Universidad de León y Diario de León. CELIS SÁNCHEZ, J. (1993a): “La secuencia del poblado de la Primera Edad del Hierro de los «Cuestos de la Estación», Benavente, Zamora”, en F. Romero, C. Sanz y Z...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 5/9 con prompt_zero_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Con el desarrollo de las excavaciones arqueológicas en diversos asentamientos, el aumento del número de dataciones y la realización de diversos estudios en los últimos años, las perspectivas de investigación sobre el Bronce final en el Levante comienza a variar sustancialmente, estando ya en condi...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 6/9 con prompt_zero_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. En la actualidad, El Argar sigue siendo el grupo arqueo­ lógico de la Edad del Bronce mejor conocido de la península ibérica, con un desarrollo temporal entre el 2200 y el 1550 cal BC. También se puede afirmar que fue una de las sociedades con mayor capacidad productiva y desarrollo social de la E...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Respuestas válidas generadas con prompt_zero_shot: 6\n",
      "\n",
      "EVALUANDO: prompt_zero_shot + all-MiniLM-L6-v2\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 métricas en batches de 2\n",
      "   🔄 Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\_analytics.py:77: ResourceWarning: unclosed file <_io.TextIOWrapper name='C:\\\\Users\\\\elevi\\\\AppData\\\\Local\\\\ragas\\\\ragas\\\\uuid.json' mode='r' encoding='cp1252'>\n",
      "  user_id = json.load(open(uuid_filepath))[\"userid\"]\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79e230356c8e423e8471e4b3280d93d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01850125092c47688b0de6ab08c911e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d78f4e158354411e86829dcfa53b4af7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f26b5c6063746c79f6126997101bd89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37f2e29ddcee4555afed371b1100a118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5b9887c59ef4dccb43d09bff27a57db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24ff93de7c0d4ae3aeef7a23a2664660",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ff2126fbad14b8cb81e99dbc3f6f401",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8f2fdad20cc48fcb903161090323269",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "317142ce49c44644a3715c0497b310c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aa20fb2e4644eb98a0c6e6ac4e2778f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82d9bd96119f47b38008abd51eac8df6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 métricas\n",
      "Evaluación completada: 6 preguntas con 4 métricas\n",
      "\n",
      "COMBINACIÓN: prompt_zero_shot + all-MiniLM-L6-v2\n",
      "   context_precision: 0.475\n",
      "   context_recall: 0.106\n",
      "   faithfulness: 0.903\n",
      "   answer_correctness: 0.275\n",
      "\n",
      "EVALUANDO: prompt_zero_shot + e5-large-instruct\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 métricas en batches de 2\n",
      "   🔄 Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9acd151e0ed4d539efeb493342a4ece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fdaf6b6f46a4c3ca6071fa12b7a566d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "867c3c050cff4d6aa1373000ee09d057",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86237c04fe9f49bba26bfa1a7526c57e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1c1cff51cb442fabe42623c8efd8f24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f9401722e3f47a1a69728f2f98e595a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f5f0681703e4041b21f499c8f1ddbf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eb0653bca4a46d999cdb433e2f52555",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdeb4e72cbcf4ae8b4465953f6b7bd8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "464fbdc0a8604605acdb17aaf2442c24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e884d2aab6dc4ea28f9a9320987854b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9266d7b0cca94b0585ecb6f380d97e16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 métricas\n",
      "Evaluación completada: 6 preguntas con 4 métricas\n",
      "\n",
      "COMBINACIÓN: prompt_zero_shot + e5-large-instruct\n",
      "   context_precision: 0.387\n",
      "   context_recall: 0.087\n",
      "   faithfulness: 0.880\n",
      "   answer_correctness: 0.242\n",
      "\n",
      "EVALUANDO: prompt_zero_shot + gte-multilingual-base\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 métricas en batches de 2\n",
      "   🔄 Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3884547c0f14504ac9f044de0fd51fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a38d8cabf60a4ee48c4df9351263e18d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02232aead2ff4a678f284f6660964281",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32c420ee7dfb42a4b73845da561e0153",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bbfb08cc8cb404385bf1aeef4e53750",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcf74b591187428fa07d7575b4378fe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87677fc0271143dfb956330b33fc8eba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e00228382b694ba69fb6c0f89bccab69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00568aee39ca4bc7babb4bb67e8a23fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c28f87197c454df8965e08dc3cd3ad15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3370c59e5d4f44c881246fb9786b4c5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebe5c8ffe6674093b3e1031b8c0d3d57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 métricas\n",
      "Evaluación completada: 6 preguntas con 4 métricas\n",
      "\n",
      "COMBINACIÓN: prompt_zero_shot + gte-multilingual-base\n",
      "   context_precision: 0.417\n",
      "   context_recall: 0.304\n",
      "   faithfulness: 0.844\n",
      "   answer_correctness: 0.162\n",
      "\n",
      "PAUSA ENTRE PROMPTS: 300 segundos...\n",
      "\n",
      "EVALUANDO CON PROMPT: prompt_one_shot\n",
      "================================================================================\n",
      "Generando respuestas con LangGraph...\n",
      "Procesando pregunta 1/9 con prompt_one_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Published by Elsevier Inc. All rights reserved. doi:10.1016/j.yqres.2011.12.003 Contents lists available at SciVerse ScienceDirect Quaternary Research journal homepage: www.elsevier.com/locate/yqres https://doi.org/10.1016/j.yqres.2011.12.003 Published online by Cambridge University Press Introduc...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 2/9 con prompt_one_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. A data obtida, é claramente mais recuada que os con­ textos mais antigos reportados em território hoje portu­ guês, nomeadamente Gruta da Nascente do Rio Almonda (OxA­‑9287 – 5480­‑5320 cal BC a 2 sigmas) e da Gruta do Caldeirão (OxA­‑1036 – 5480 – 5070 cal BC a 2 sigmas). Entre nós, apenas se rep...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 3/9 con prompt_one_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 2. ENCUADRE CRONO-CULTURAL DEL HA- LLAZGO: COGOTAS I Entre las entidades arqueológicas de la Edad del Bronce peninsular, Cogotas I sobresale por su extensa cobertura geográfica, que desborda la Meseta por el Valle del Ebro y Extremadura, y por su dilatada crono- logía —c. 1800-1150 cal BC, cubrien...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 4/9 con prompt_one_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. y NEIRA, A. (1999): “Prehistoria”, en M.A. Rabanal Alonso (coord.): La His­ toria de León, tomo I, Universidad de León y Diario de León. CELIS SÁNCHEZ, J. (1993a): “La secuencia del poblado de la Primera Edad del Hierro de los «Cuestos de la Estación», Benavente, Zamora”, en F. Romero, C. Sanz y Z...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 5/9 con prompt_one_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Con el desarrollo de las excavaciones arqueológicas en diversos asentamientos, el aumento del número de dataciones y la realización de diversos estudios en los últimos años, las perspectivas de investigación sobre el Bronce final en el Levante comienza a variar sustancialmente, estando ya en condi...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 6/9 con prompt_one_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. En la actualidad, El Argar sigue siendo el grupo arqueo­ lógico de la Edad del Bronce mejor conocido de la península ibérica, con un desarrollo temporal entre el 2200 y el 1550 cal BC. También se puede afirmar que fue una de las sociedades con mayor capacidad productiva y desarrollo social de la E...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Respuestas válidas generadas con prompt_one_shot: 6\n",
      "\n",
      "EVALUANDO: prompt_one_shot + all-MiniLM-L6-v2\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 métricas en batches de 2\n",
      "   🔄 Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71992f71c9b044ffab4df3760c183100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f12d1c3f8e82496293555c392116d6d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8263769784624f9193d79aba3cd7982a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60dfc596de034e849a4b665985f1c38f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94ad3204a4e747bfa8f31f2c416df482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2287ca019d9d4d5080dd83841e1ecb9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fec9f95d4ade4791b8fc3a020e509bbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df1ab209f343403db2464ad3dc5c3e56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "834659f97df04370bc257c35f15dc43f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef844210687946a5bf5e0acf73e83a2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c01455d7fa54af9b78c662b96bad715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f737aa3bcfc477ba07b57c482b14254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 métricas\n",
      "Evaluación completada: 6 preguntas con 4 métricas\n",
      "\n",
      "COMBINACIÓN: prompt_one_shot + all-MiniLM-L6-v2\n",
      "   context_precision: 0.395\n",
      "   context_recall: 0.143\n",
      "   faithfulness: 0.763\n",
      "   answer_correctness: 0.187\n",
      "\n",
      "EVALUANDO: prompt_one_shot + e5-large-instruct\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 métricas en batches de 2\n",
      "   🔄 Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0ca9aade77c493bb2585cf39105cf85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "605340e1b436486185d6603498eb509d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60b7f5f37ee64c4294bfc3f9ec6a7c67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "810198abe90048d4a12f517c7c281995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b46c598be22f4fadb9bcef688088beb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f42dc0b2fe8a4748b3ad994601f5f574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7465ed0e86784b62b26b8f88aa25a25a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "773c8d5eb75242b4ba952a6c0e432090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b49b58f60d0f4c4da92b5d84ea8b989c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "617cd9e9d74c4576bcf046748ea4f174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7441a46e71054b4d9657ce7ac01782e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a6ec2ab4a3d4cefa96b6e65aa9da0cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 métricas\n",
      "Evaluación completada: 6 preguntas con 4 métricas\n",
      "\n",
      "COMBINACIÓN: prompt_one_shot + e5-large-instruct\n",
      "   context_precision: 0.340\n",
      "   context_recall: 0.342\n",
      "   faithfulness: 0.742\n",
      "   answer_correctness: 0.287\n",
      "\n",
      "EVALUANDO: prompt_one_shot + gte-multilingual-base\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 métricas en batches de 2\n",
      "   🔄 Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eb2ee11b8e548c9a546f2a262c5c793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "244c47285ac74dc2b2a3ec08005ae2ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9cab6782e2f44e9a0cc741dffbf4f8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fbb1345f43c48ec9146d5aca6efdc68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdc7dd2e2c12415cb9991d05ef6ae295",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9e48e00b6394dc39d84797075bd8df2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6665bb639354445a30e38ed1a384f50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "796b2a0b47d740ddb5ee9d581a5c1d68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fff1f283df149fdb0c225f546d6988e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a407a915991b48be963b4b7544d78cf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46afd26c176c43d8ade3bbea48989758",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2130fbf64c743c587360aab3cc60d39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 métricas\n",
      "Evaluación completada: 6 preguntas con 4 métricas\n",
      "\n",
      "COMBINACIÓN: prompt_one_shot + gte-multilingual-base\n",
      "   context_precision: 0.315\n",
      "   context_recall: 0.092\n",
      "   faithfulness: 0.747\n",
      "   answer_correctness: 0.212\n",
      "\n",
      "PAUSA ENTRE PROMPTS: 300 segundos...\n",
      "\n",
      "EVALUANDO CON PROMPT: prompt_few_shot\n",
      "================================================================================\n",
      "Generando respuestas con LangGraph...\n",
      "Procesando pregunta 1/9 con prompt_few_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Published by Elsevier Inc. All rights reserved. doi:10.1016/j.yqres.2011.12.003 Contents lists available at SciVerse ScienceDirect Quaternary Research journal homepage: www.elsevier.com/locate/yqres https://doi.org/10.1016/j.yqres.2011.12.003 Published online by Cambridge University Press Introduc...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 2/9 con prompt_few_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. A data obtida, é claramente mais recuada que os con­ textos mais antigos reportados em território hoje portu­ guês, nomeadamente Gruta da Nascente do Rio Almonda (OxA­‑9287 – 5480­‑5320 cal BC a 2 sigmas) e da Gruta do Caldeirão (OxA­‑1036 – 5480 – 5070 cal BC a 2 sigmas). Entre nós, apenas se rep...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 3/9 con prompt_few_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 2. ENCUADRE CRONO-CULTURAL DEL HA- LLAZGO: COGOTAS I Entre las entidades arqueológicas de la Edad del Bronce peninsular, Cogotas I sobresale por su extensa cobertura geográfica, que desborda la Meseta por el Valle del Ebro y Extremadura, y por su dilatada crono- logía —c. 1800-1150 cal BC, cubrien...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 4/9 con prompt_few_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. y NEIRA, A. (1999): “Prehistoria”, en M.A. Rabanal Alonso (coord.): La His­ toria de León, tomo I, Universidad de León y Diario de León. CELIS SÁNCHEZ, J. (1993a): “La secuencia del poblado de la Primera Edad del Hierro de los «Cuestos de la Estación», Benavente, Zamora”, en F. Romero, C. Sanz y Z...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 5/9 con prompt_few_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Con el desarrollo de las excavaciones arqueológicas en diversos asentamientos, el aumento del número de dataciones y la realización de diversos estudios en los últimos años, las perspectivas de investigación sobre el Bronce final en el Levante comienza a variar sustancialmente, estando ya en condi...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 6/9 con prompt_few_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. En la actualidad, El Argar sigue siendo el grupo arqueo­ lógico de la Edad del Bronce mejor conocido de la península ibérica, con un desarrollo temporal entre el 2200 y el 1550 cal BC. También se puede afirmar que fue una de las sociedades con mayor capacidad productiva y desarrollo social de la E...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Respuestas válidas generadas con prompt_few_shot: 6\n",
      "\n",
      "EVALUANDO: prompt_few_shot + all-MiniLM-L6-v2\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 métricas en batches de 2\n",
      "   🔄 Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdc3f3ee7bb84eb4a4872d8938077213",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f696d0d910104413aafecf0f42d36686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ad575db7bb5490d9a7776dce10f3d13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dde1f843247f4a8a9f08ea052d16cd91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b1e79e46aa7445dbc9e5170fb6193a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93375959afc54f37a489c89b07e540d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cac54a94b0e94d51b5bfa1945ca5257f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f76661ec65d4441a09e09c5c12b179a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2b520861247479fb19e061bd480f852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64eefc7c712c4e88aba656bcd074a2aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e9b57ba66a941a188e3dc0395ff846c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d2bdbf4eda84d7f9041699c18f49882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 métricas\n",
      "Evaluación completada: 6 preguntas con 4 métricas\n",
      "\n",
      "COMBINACIÓN: prompt_few_shot + all-MiniLM-L6-v2\n",
      "   context_precision: 0.228\n",
      "   context_recall: 0.300\n",
      "   faithfulness: 0.657\n",
      "   answer_correctness: 0.149\n",
      "\n",
      "EVALUANDO: prompt_few_shot + e5-large-instruct\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 métricas en batches de 2\n",
      "   🔄 Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b8d32418b704dde92fde0d9a5e87aec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "970f8c209c9f4266bf0a14b800a060ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "027061b3bdfc4711970683436fd34039",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fda1d313bf34f3c8086ebb5b45439d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5dfc20e66d94c00ab502f5735b24a27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e02db97c70e4aa08e775f908b71a120",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8096e4278744a59b67d40bfcb77ae10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5516fe7c65f444968a2e926c1f47b8bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adf13c214516406888f96e3cabfdbc12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e0b66a0e0634bf2827240eb046b0abd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca9aa4dbf1d240d7af72e545f7703a50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70912dfb3d8b45788b9ef0b327e4708d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 métricas\n",
      "Evaluación completada: 6 preguntas con 4 métricas\n",
      "\n",
      "COMBINACIÓN: prompt_few_shot + e5-large-instruct\n",
      "   context_precision: 0.356\n",
      "   context_recall: 0.088\n",
      "   faithfulness: 0.587\n",
      "   answer_correctness: 0.236\n",
      "\n",
      "EVALUANDO: prompt_few_shot + gte-multilingual-base\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 métricas en batches de 2\n",
      "   🔄 Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e39128498f1d468086abfbb297745cf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff3c920881a642b298b21e00fbeb98d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bab7caab578b401390df7330cfb6dbc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "717a962c4f9e474f85fe4daead8ac8f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db512e6c4cc6460abd115be37939adf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b5bdb0a38084c70aa88a962efa263b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "752b72d797564f49aaa04f00c3725734",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a03d609fb154de7885bfb28dd178f6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7613648ebe444866a1c9eb102468de0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b9296ab59414ec39c95bb0496cc731b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f95b9629efb43eaa2d06dc3786dfd7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec0455e47eeb41fdaa2810a8a01fda57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 métricas\n",
      "Evaluación completada: 6 preguntas con 4 métricas\n",
      "\n",
      "COMBINACIÓN: prompt_few_shot + gte-multilingual-base\n",
      "   context_precision: 0.437\n",
      "   context_recall: 0.096\n",
      "   faithfulness: 0.721\n",
      "   answer_correctness: 0.181\n",
      "\"EVALUACIÓN COMPLETA\n",
      "\n",
      "TABLA DE RESULTADOS:\n",
      "====================================================================================================\n",
      "\n",
      "PROMPT: prompt_zero_shot\n",
      "all-MiniLM-L6-v2:\n",
      "      context_precision: 0.475\n",
      "      context_recall: 0.106\n",
      "      faithfulness: 0.903\n",
      "      answer_correctness: 0.275\n",
      "e5-large-instruct:\n",
      "      context_precision: 0.387\n",
      "      context_recall: 0.087\n",
      "      faithfulness: 0.880\n",
      "      answer_correctness: 0.242\n",
      "gte-multilingual-base:\n",
      "      context_precision: 0.417\n",
      "      context_recall: 0.304\n",
      "      faithfulness: 0.844\n",
      "      answer_correctness: 0.162\n",
      "\n",
      "PROMPT: prompt_one_shot\n",
      "all-MiniLM-L6-v2:\n",
      "      context_precision: 0.395\n",
      "      context_recall: 0.143\n",
      "      faithfulness: 0.763\n",
      "      answer_correctness: 0.187\n",
      "e5-large-instruct:\n",
      "      context_precision: 0.340\n",
      "      context_recall: 0.342\n",
      "      faithfulness: 0.742\n",
      "      answer_correctness: 0.287\n",
      "gte-multilingual-base:\n",
      "      context_precision: 0.315\n",
      "      context_recall: 0.092\n",
      "      faithfulness: 0.747\n",
      "      answer_correctness: 0.212\n",
      "\n",
      "PROMPT: prompt_few_shot\n",
      "all-MiniLM-L6-v2:\n",
      "      context_precision: 0.228\n",
      "      context_recall: 0.300\n",
      "      faithfulness: 0.657\n",
      "      answer_correctness: 0.149\n",
      "e5-large-instruct:\n",
      "      context_precision: 0.356\n",
      "      context_recall: 0.088\n",
      "      faithfulness: 0.587\n",
      "      answer_correctness: 0.236\n",
      "gte-multilingual-base:\n",
      "      context_precision: 0.437\n",
      "      context_recall: 0.096\n",
      "      faithfulness: 0.721\n",
      "      answer_correctness: 0.181\n"
     ]
    }
   ],
   "source": [
    "# Evaluar TODAS las combinaciones: 3 prompts × 3 embeddings = 9 combinaciones\n",
    "resultados_completos = {}\n",
    "\n",
    "prompts_list = ['prompt_zero_shot', 'prompt_one_shot', 'prompt_few_shot']\n",
    "\n",
    "for prompt_name in prompts_list:\n",
    "    print(f\"\\nEVALUANDO CON PROMPT: {prompt_name}\")\n",
    "    print(\"=\"*80)\n",
    "    # CAMBIAR EL TEMPLATE GLOBAL (esto es lo clave)\n",
    "    selected_template = PROMPTS[prompt_name]\n",
    "    prompt_template = ChatPromptTemplate.from_template(selected_template)\n",
    "\n",
    "    # Generar respuestas con este prompt específico\n",
    "    results_list_prompt = []\n",
    "\n",
    "    # Necesitas generar las respuestas con tu grafo de LangGraph primero\n",
    "    print(\"Generando respuestas con LangGraph...\")\n",
    "\n",
    "    for i, (question, ground_truth) in enumerate(zip(questions, ground_truths)):\n",
    "        print(f\"Procesando pregunta {i+1}/{len(questions)} con {prompt_name}\")\n",
    "\n",
    "\n",
    "        state = {\n",
    "            'question': question,\n",
    "            'llm_name': 'Qwen3-4B-instruct-2507',  \n",
    "            'embedding_name': 'all-MiniLM-L6-v2',  # Se cambiará en el bucle    \n",
    "            'prompt_name': prompt_name,\n",
    "            'context': [],\n",
    "            'answer': '',\n",
    "            'metadata': {}\n",
    "        }\n",
    "        try:\n",
    "        \n",
    "            final_state = graph.invoke(state)\n",
    "            answer = final_state.get('answer', '')\n",
    "            contexts = final_state.get('context', [])\n",
    "\n",
    "            if answer and answer.strip():  # Verificar que hay respuesta\n",
    "                  results_list_prompt.append({\n",
    "                      'question': question,\n",
    "                      'answer': answer,\n",
    "                      'contexts': [doc.page_content for doc in contexts] if contexts else ['Sin contexto'],\n",
    "                      'ground_truth': ground_truth\n",
    "                  })\n",
    "            else:\n",
    "                  print(f\"      ⚠️ Pregunta {i+1} sin respuesta válida\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"      ❌ Error en pregunta {i+1}: {e}\")\n",
    "\n",
    "    print(f\"Respuestas válidas generadas con {prompt_name}: {len(results_list_prompt)}\")\n",
    "\n",
    "    # Solo evaluar si tenemos respuestas válidas\n",
    "    if len(results_list_prompt) >= 2:\n",
    "          # EVALUAR CON LOS 3 EMBEDDINGS\n",
    "        resultados_por_embedding = {}\n",
    "\n",
    "        for embedding_name, current_embedding_model in EMBEDDING_MODELS.items():\n",
    "            print(f\"\\nEVALUANDO: {prompt_name} + {embedding_name}\")\n",
    "            print(\"-\"*60)\n",
    "\n",
    "            resultado = evaluate_with_mistral_four_metrics(\n",
    "                results_list=results_list_prompt,\n",
    "                  embedding_model=current_embedding_model,\n",
    "                  max_batch_size=2,\n",
    "                  delay_between_batches=120\n",
    "            )\n",
    "\n",
    "            resultados_por_embedding[embedding_name] = resultado\n",
    "\n",
    "              # Mostrar métricas promedio\n",
    "            print(f\"\\nCOMBINACIÓN: {prompt_name} + {embedding_name}\")\n",
    "            for metric in ['context_precision', 'context_recall', 'faithfulness', 'answer_correctness']:\n",
    "                if metric in resultado.columns:\n",
    "                    valores = resultado[metric].dropna()\n",
    "                    if len(valores) > 0:\n",
    "                        print(f\"   {metric}: {valores.mean():.3f}\")\n",
    "                    else:\n",
    "                        print(f\"   {metric}: Sin valores válidos\")\n",
    "\n",
    "            time.sleep(90)  # Pausa entre embeddings\n",
    "\n",
    "          # Guardar resultados de este prompt\n",
    "        resultados_completos[prompt_name] = resultados_por_embedding\n",
    "\n",
    "    else:\n",
    "        print(f\"No hay suficientes respuestas válidas para {prompt_name}, saltando evaluación\")\n",
    "\n",
    "    if prompt_name != prompts_list[-1]:\n",
    "        print(f\"\\nPAUSA ENTRE PROMPTS: 300 segundos...\")\n",
    "        time.sleep(300)\n",
    "\n",
    "print(\"\\\"EVALUACIÓN COMPLETA\")\n",
    "\n",
    "  # Mostrar tabla final\n",
    "print(\"\\nTABLA DE RESULTADOS:\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "for prompt_name, embeddings_results in resultados_completos.items():\n",
    "    print(f\"\\nPROMPT: {prompt_name}\")\n",
    "    for embedding_name, resultado in embeddings_results.items():\n",
    "        print(f\"{embedding_name}:\")\n",
    "        for metric in ['context_precision', 'context_recall', 'faithfulness', 'answer_correctness']:\n",
    "            if metric in resultado.columns:\n",
    "                valores = resultado[metric].dropna()\n",
    "                if len(valores) > 0:\n",
    "                    print(f\"      {metric}: {valores.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUANDO CON PROMPT: prompt_zero_shot\n",
      "================================================================================\n",
      "Generando respuestas con LangGraph...\n",
      "Procesando pregunta 1/9 con prompt_zero_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Phi-3.5-mini-instruct\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Published by Elsevier Inc. All rights reserved. doi:10.1016/j.yqres.2011.12.003 Contents lists available at SciVerse ScienceDirect Quaternary Research journal homepage: www.elsevier.com/locate/yqres https://doi.org/10.1016/j.yqres.2011.12.003 Published online by Cambridge University Press Introduc...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 2/9 con prompt_zero_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Phi-3.5-mini-instruct\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. A data obtida, é claramente mais recuada que os con­ textos mais antigos reportados em território hoje portu­ guês, nomeadamente Gruta da Nascente do Rio Almonda (OxA­‑9287 – 5480­‑5320 cal BC a 2 sigmas) e da Gruta do Caldeirão (OxA­‑1036 – 5480 – 5070 cal BC a 2 sigmas). Entre nós, apenas se rep...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 3/9 con prompt_zero_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Phi-3.5-mini-instruct\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 2. ENCUADRE CRONO-CULTURAL DEL HA- LLAZGO: COGOTAS I Entre las entidades arqueológicas de la Edad del Bronce peninsular, Cogotas I sobresale por su extensa cobertura geográfica, que desborda la Meseta por el Valle del Ebro y Extremadura, y por su dilatada crono- logía —c. 1800-1150 cal BC, cubrien...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 4/9 con prompt_zero_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Phi-3.5-mini-instruct\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. y NEIRA, A. (1999): “Prehistoria”, en M.A. Rabanal Alonso (coord.): La His­ toria de León, tomo I, Universidad de León y Diario de León. CELIS SÁNCHEZ, J. (1993a): “La secuencia del poblado de la Primera Edad del Hierro de los «Cuestos de la Estación», Benavente, Zamora”, en F. Romero, C. Sanz y Z...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 5/9 con prompt_zero_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Phi-3.5-mini-instruct\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Con el desarrollo de las excavaciones arqueológicas en diversos asentamientos, el aumento del número de dataciones y la realización de diversos estudios en los últimos años, las perspectivas de investigación sobre el Bronce final en el Levante comienza a variar sustancialmente, estando ya en condi...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 6/9 con prompt_zero_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Phi-3.5-mini-instruct\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. En la actualidad, El Argar sigue siendo el grupo arqueo­ lógico de la Edad del Bronce mejor conocido de la península ibérica, con un desarrollo temporal entre el 2200 y el 1550 cal BC. También se puede afirmar que fue una de las sociedades con mayor capacidad productiva y desarrollo social de la E...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Respuestas válidas generadas con prompt_zero_shot: 6\n",
      "\n",
      "🔄 EVALUANDO: prompt_zero_shot + all-MiniLM-L6-v2\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 métricas en batches de 2\n",
      "   🔄 Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\_analytics.py:77: ResourceWarning: unclosed file <_io.TextIOWrapper name='C:\\\\Users\\\\elevi\\\\AppData\\\\Local\\\\ragas\\\\ragas\\\\uuid.json' mode='r' encoding='cp1252'>\n",
      "  user_id = json.load(open(uuid_filepath))[\"userid\"]\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "663e7bb4fdca4632b82976872ae69b03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fe446edf41c463c9f8be28bbfa38482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0434717ba5324f03857489e0613f3c2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db416305fb414e5abfca3a5b535743b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb018b6bce6842e78e0cf049c3de9e99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cb9740fd15240df937880930de116e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cbbe934b5f049e1ada4a753505e1782",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e050d8be21b8445995db57fa96d42a22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a62cfd3d27e49439c8823249a02e486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d37e08e4b1f34fde8ffcb2667b2ac71a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57166d98962c4aa2ad7349d19d3edd8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "612f611d366c472bb4a7ea442d6b303a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 métricas\n",
      "Evaluación completada: 6 preguntas con 4 métricas\n",
      "\n",
      "📊 COMBINACIÓN: prompt_zero_shot + all-MiniLM-L6-v2\n",
      "   context_precision: 0.404\n",
      "   context_recall: 0.106\n",
      "   faithfulness: 0.705\n",
      "   answer_correctness: 0.179\n",
      "\n",
      "🔄 EVALUANDO: prompt_zero_shot + e5-large-instruct\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 métricas en batches de 2\n",
      "   🔄 Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fc1ce17e6a04aaca42e71019b28a8ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc217258522f46aba65a673ad5dc4a2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "935cafa686ea46118f8bcfce6d7e0196",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a64708f6ffe4fc1ac5a6bcae707b8df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91991ab9c05149cfa9eabd28df0ade51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb0ed8e9a6264974a6d596024d1a2aee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "923e866116304871be75f767e69ce279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ff6cfdf8e1a4033b2b58937a603b363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d12b83d50864e5b976822add5b158f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "225a7aa032fd4dc189dac32feb138627",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55be81519e0b41a58ae7a964dd93b046",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a054ededaad4a6ca40fa4644379bdf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 métricas\n",
      "Evaluación completada: 6 preguntas con 4 métricas\n",
      "\n",
      "📊 COMBINACIÓN: prompt_zero_shot + e5-large-instruct\n",
      "   context_precision: 0.458\n",
      "   context_recall: 0.148\n",
      "   faithfulness: 0.772\n",
      "   answer_correctness: 0.266\n",
      "\n",
      "🔄 EVALUANDO: prompt_zero_shot + gte-multilingual-base\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 métricas en batches de 2\n",
      "   🔄 Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "575dafa3156448579a03c58b59084ccd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94d620b9d5424786954527ed754cbdc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b8253d98cb3459da9ec83721257f783",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b935b8e893d44feaa702b82591d810e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6a0f197a0f84d728f1aeede4eecb9a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4be0b246eb0c4597a8d6cfdfd26a0cfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "480a2eef5e5b4103b91653ee46271ac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad2e84e5e79048c1ab1ba6cdb7d7b3c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96a13f8b243846ba9c93007898d1b158",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2791b29738f14e21a257067f9b1f5d6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "535a201a013c4f17b306397a56c3e660",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a6f261c6ec14d28849c7fcee48d75e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 métricas\n",
      "Evaluación completada: 6 preguntas con 4 métricas\n",
      "\n",
      "📊 COMBINACIÓN: prompt_zero_shot + gte-multilingual-base\n",
      "   context_precision: 0.475\n",
      "   context_recall: 0.239\n",
      "   faithfulness: 0.733\n",
      "   answer_correctness: 0.148\n",
      "\n",
      "⏱️ PAUSA ENTRE PROMPTS: 300 segundos...\n",
      "\n",
      "EVALUANDO CON PROMPT: prompt_one_shot\n",
      "================================================================================\n",
      "Generando respuestas con LangGraph...\n",
      "Procesando pregunta 1/9 con prompt_one_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Phi-3.5-mini-instruct\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Published by Elsevier Inc. All rights reserved. doi:10.1016/j.yqres.2011.12.003 Contents lists available at SciVerse ScienceDirect Quaternary Research journal homepage: www.elsevier.com/locate/yqres https://doi.org/10.1016/j.yqres.2011.12.003 Published online by Cambridge University Press Introduc...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 2/9 con prompt_one_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Phi-3.5-mini-instruct\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. A data obtida, é claramente mais recuada que os con­ textos mais antigos reportados em território hoje portu­ guês, nomeadamente Gruta da Nascente do Rio Almonda (OxA­‑9287 – 5480­‑5320 cal BC a 2 sigmas) e da Gruta do Caldeirão (OxA­‑1036 – 5480 – 5070 cal BC a 2 sigmas). Entre nós, apenas se rep...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 3/9 con prompt_one_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Phi-3.5-mini-instruct\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 2. ENCUADRE CRONO-CULTURAL DEL HA- LLAZGO: COGOTAS I Entre las entidades arqueológicas de la Edad del Bronce peninsular, Cogotas I sobresale por su extensa cobertura geográfica, que desborda la Meseta por el Valle del Ebro y Extremadura, y por su dilatada crono- logía —c. 1800-1150 cal BC, cubrien...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 4/9 con prompt_one_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Phi-3.5-mini-instruct\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. y NEIRA, A. (1999): “Prehistoria”, en M.A. Rabanal Alonso (coord.): La His­ toria de León, tomo I, Universidad de León y Diario de León. CELIS SÁNCHEZ, J. (1993a): “La secuencia del poblado de la Primera Edad del Hierro de los «Cuestos de la Estación», Benavente, Zamora”, en F. Romero, C. Sanz y Z...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 5/9 con prompt_one_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Phi-3.5-mini-instruct\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Con el desarrollo de las excavaciones arqueológicas en diversos asentamientos, el aumento del número de dataciones y la realización de diversos estudios en los últimos años, las perspectivas de investigación sobre el Bronce final en el Levante comienza a variar sustancialmente, estando ya en condi...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 6/9 con prompt_one_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Phi-3.5-mini-instruct\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. En la actualidad, El Argar sigue siendo el grupo arqueo­ lógico de la Edad del Bronce mejor conocido de la península ibérica, con un desarrollo temporal entre el 2200 y el 1550 cal BC. También se puede afirmar que fue una de las sociedades con mayor capacidad productiva y desarrollo social de la E...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Respuestas válidas generadas con prompt_one_shot: 6\n",
      "\n",
      "🔄 EVALUANDO: prompt_one_shot + all-MiniLM-L6-v2\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 métricas en batches de 2\n",
      "   🔄 Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d42ddc6d6a7460fb51cf4bddcc63bb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cb10a6506d94f9988206fa7217b0793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bd7a798b050424f869936fcfc3a6399",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "482ca3db145d4ccca57f187f0e18c032",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1adf1e16b5b943539bdbc6bd92deac9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbc0114ae25d43dca8b20ed2ce98a347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ab63515dcf94e6687228d98b2b3a043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4deff40965ee48b48348d4ba9294fa55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54b789ce4e0d467da95a7e20473c35a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6602b1baa10247c5b7cc3d0a0aea9ced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77796551f8f8413eb688122eaab30e6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02b46c3ba346472093404e1e09981762",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 métricas\n",
      "Evaluación completada: 6 preguntas con 4 métricas\n",
      "\n",
      "📊 COMBINACIÓN: prompt_one_shot + all-MiniLM-L6-v2\n",
      "   context_precision: 0.429\n",
      "   context_recall: 0.282\n",
      "   faithfulness: 0.967\n",
      "   answer_correctness: 0.215\n",
      "\n",
      "🔄 EVALUANDO: prompt_one_shot + e5-large-instruct\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 métricas en batches de 2\n",
      "   🔄 Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbb14bcafa55465cb5efaa960215b064",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99dbc308b71641d7b9d9303cc31f363b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bab457f68c7e4639959151f2ca66f8ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7b8107220574f08bb0b58a75fe63428",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ed740c258414d74b422e5bc9e7542a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3d5e86e6017485cb4aec672c6db3442",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e55f7105c9348b6920ca9b11734e13f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1336b64706f54fbebe8f7a63e4709f8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab2d0529e717486da2402259c6d4f901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1342fad78b8145a083ce6148bdc6bd1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7b4c1ad8fe54f8188ed9d47c6083e0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d726dc55324742cd8a06827b46774384",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 métricas\n",
      "Evaluación completada: 6 preguntas con 4 métricas\n",
      "\n",
      "📊 COMBINACIÓN: prompt_one_shot + e5-large-instruct\n",
      "   context_precision: 0.458\n",
      "   context_recall: 0.130\n",
      "   faithfulness: 0.929\n",
      "   answer_correctness: 0.307\n",
      "\n",
      "🔄 EVALUANDO: prompt_one_shot + gte-multilingual-base\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 métricas en batches de 2\n",
      "   🔄 Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b38b5340330247948876ca9714b8d1a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc2473b2667545c89f4942fb786e1da2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43a4a25f304b4ba881721c5abfc98c10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d6f1a6c4b4c4f9f80ce35fcd493cc73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "359c4dbfcd1348aa886e67d5bb516579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f206eafd75d4fc3ae8947a3e0351c24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9420221cc3da4be69fb10da8afc51ab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68082e59e84b4d6cb5c1d87996d98d9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09f7caecd491496b9f6fe5b69160a3f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b463a87afe14694b07ed053c374ebae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b930dbdbef0f46f4a1d59dea99822d9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ce82cc31e504a1cb5a40a717a15823b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 métricas\n",
      "Evaluación completada: 6 preguntas con 4 métricas\n",
      "\n",
      "📊 COMBINACIÓN: prompt_one_shot + gte-multilingual-base\n",
      "   context_precision: 0.527\n",
      "   context_recall: 0.181\n",
      "   faithfulness: 0.888\n",
      "   answer_correctness: 0.211\n",
      "\n",
      "⏱️ PAUSA ENTRE PROMPTS: 300 segundos...\n",
      "\n",
      "EVALUANDO CON PROMPT: prompt_few_shot\n",
      "================================================================================\n",
      "Generando respuestas con LangGraph...\n",
      "Procesando pregunta 1/9 con prompt_few_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Phi-3.5-mini-instruct\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Published by Elsevier Inc. All rights reserved. doi:10.1016/j.yqres.2011.12.003 Contents lists available at SciVerse ScienceDirect Quaternary Research journal homepage: www.elsevier.com/locate/yqres https://doi.org/10.1016/j.yqres.2011.12.003 Published online by Cambridge University Press Introduc...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 2/9 con prompt_few_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Phi-3.5-mini-instruct\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. A data obtida, é claramente mais recuada que os con­ textos mais antigos reportados em território hoje portu­ guês, nomeadamente Gruta da Nascente do Rio Almonda (OxA­‑9287 – 5480­‑5320 cal BC a 2 sigmas) e da Gruta do Caldeirão (OxA­‑1036 – 5480 – 5070 cal BC a 2 sigmas). Entre nós, apenas se rep...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 3/9 con prompt_few_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Phi-3.5-mini-instruct\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 2. ENCUADRE CRONO-CULTURAL DEL HA- LLAZGO: COGOTAS I Entre las entidades arqueológicas de la Edad del Bronce peninsular, Cogotas I sobresale por su extensa cobertura geográfica, que desborda la Meseta por el Valle del Ebro y Extremadura, y por su dilatada crono- logía —c. 1800-1150 cal BC, cubrien...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 4/9 con prompt_few_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Phi-3.5-mini-instruct\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. y NEIRA, A. (1999): “Prehistoria”, en M.A. Rabanal Alonso (coord.): La His­ toria de León, tomo I, Universidad de León y Diario de León. CELIS SÁNCHEZ, J. (1993a): “La secuencia del poblado de la Primera Edad del Hierro de los «Cuestos de la Estación», Benavente, Zamora”, en F. Romero, C. Sanz y Z...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 5/9 con prompt_few_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Phi-3.5-mini-instruct\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Con el desarrollo de las excavaciones arqueológicas en diversos asentamientos, el aumento del número de dataciones y la realización de diversos estudios en los últimos años, las perspectivas de investigación sobre el Bronce final en el Levante comienza a variar sustancialmente, estando ya en condi...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 6/9 con prompt_few_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Phi-3.5-mini-instruct\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. En la actualidad, El Argar sigue siendo el grupo arqueo­ lógico de la Edad del Bronce mejor conocido de la península ibérica, con un desarrollo temporal entre el 2200 y el 1550 cal BC. También se puede afirmar que fue una de las sociedades con mayor capacidad productiva y desarrollo social de la E...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Respuestas válidas generadas con prompt_few_shot: 6\n",
      "\n",
      "🔄 EVALUANDO: prompt_few_shot + all-MiniLM-L6-v2\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 métricas en batches de 2\n",
      "   🔄 Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c8e68f59d8c425e8eb1aae8e62aee35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee539e36aef544058cb6b314f501d20c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d819adf28a5470c8594487aca9ac971",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53b8654942864d43af1444fd2b8c7248",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c7b3c9437b84492a645ffe5bfe780da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afb30791c4164820a170030485f1fe78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4db537fc8a2744a5bc0feb7f566d9d38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fa738e2a81f44e2b0b301ee9094c926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b77224b7a944e9c9cdecfd7e8c107d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "503ba870f82a4dfdb2a37ea111479702",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5815faba5e7a46fc9dbe1a4318242797",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99b23b949bcd4d0d899b36f0ff287096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 métricas\n",
      "Evaluación completada: 6 preguntas con 4 métricas\n",
      "\n",
      "📊 COMBINACIÓN: prompt_few_shot + all-MiniLM-L6-v2\n",
      "   context_precision: 0.367\n",
      "   context_recall: 0.314\n",
      "   faithfulness: 0.845\n",
      "   answer_correctness: 0.180\n",
      "\n",
      "🔄 EVALUANDO: prompt_few_shot + e5-large-instruct\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 métricas en batches de 2\n",
      "   🔄 Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb1f27103d744e6aaf3f7dd6bc372964",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c91042a772fc47d68a5d31dba053b3e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4eb298138c44318b7a4ce0a4f756be0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae8d9f09c2054ec68136ce5f6717993e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfefec6d38f0422780c7ca3030fd69fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbcb493f58f044aebda697ab232bb2c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b2f3377bfce4192ae1b82cf7d585bfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "361eac7b71124622a355bd445cb5779f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f43866a5fad46bf9e37c407b78b7b35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcc4f73cecf14710979166bfa5fcda39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b662055f6744957a46372a7da378a08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b0cabac32594f4cad40c7533e6229da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 métricas\n",
      "Evaluación completada: 6 preguntas con 4 métricas\n",
      "\n",
      "📊 COMBINACIÓN: prompt_few_shot + e5-large-instruct\n",
      "   context_precision: 0.479\n",
      "   context_recall: 0.329\n",
      "   faithfulness: 0.860\n",
      "   answer_correctness: 0.262\n",
      "\n",
      "🔄 EVALUANDO: prompt_few_shot + gte-multilingual-base\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 métricas en batches de 2\n",
      "   🔄 Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "509b7ba4df694702a9edd097d23bd245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d08e89bff4654fbe864ecb379c9b9ac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "014585d99666401486b9a7f1aa5d94bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aab5f81468964621a14562cd3f0976c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00f1934219db46458fe1033f3057d219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76991506a8f4470b8d9cc8574345bf0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f164e717c6a451e9b696663f67408f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b7593b54fa241a98dd3da9b1707d682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55979c94c11940d48e8dc21455116227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdd0941ea87241e781fbe94a2b154598",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75165e34e9084757806d844abec373c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a74f5cb7ed984d0bbf83a8512abc5992",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 métricas\n",
      "Evaluación completada: 6 preguntas con 4 métricas\n",
      "\n",
      "📊 COMBINACIÓN: prompt_few_shot + gte-multilingual-base\n",
      "   context_precision: 0.471\n",
      "   context_recall: 0.259\n",
      "   faithfulness: 0.866\n",
      "   answer_correctness: 0.158\n",
      "\"EVALUACIÓN COMPLETA\n",
      "\n",
      "TABLA DE RESULTADOS:\n",
      "====================================================================================================\n",
      "\n",
      "🎯 PROMPT: prompt_zero_shot\n",
      "   📊 all-MiniLM-L6-v2:\n",
      "      context_precision: 0.404\n",
      "      context_recall: 0.106\n",
      "      faithfulness: 0.705\n",
      "      answer_correctness: 0.179\n",
      "   📊 e5-large-instruct:\n",
      "      context_precision: 0.458\n",
      "      context_recall: 0.148\n",
      "      faithfulness: 0.772\n",
      "      answer_correctness: 0.266\n",
      "   📊 gte-multilingual-base:\n",
      "      context_precision: 0.475\n",
      "      context_recall: 0.239\n",
      "      faithfulness: 0.733\n",
      "      answer_correctness: 0.148\n",
      "\n",
      "🎯 PROMPT: prompt_one_shot\n",
      "   📊 all-MiniLM-L6-v2:\n",
      "      context_precision: 0.429\n",
      "      context_recall: 0.282\n",
      "      faithfulness: 0.967\n",
      "      answer_correctness: 0.215\n",
      "   📊 e5-large-instruct:\n",
      "      context_precision: 0.458\n",
      "      context_recall: 0.130\n",
      "      faithfulness: 0.929\n",
      "      answer_correctness: 0.307\n",
      "   📊 gte-multilingual-base:\n",
      "      context_precision: 0.527\n",
      "      context_recall: 0.181\n",
      "      faithfulness: 0.888\n",
      "      answer_correctness: 0.211\n",
      "\n",
      "🎯 PROMPT: prompt_few_shot\n",
      "   📊 all-MiniLM-L6-v2:\n",
      "      context_precision: 0.367\n",
      "      context_recall: 0.314\n",
      "      faithfulness: 0.845\n",
      "      answer_correctness: 0.180\n",
      "   📊 e5-large-instruct:\n",
      "      context_precision: 0.479\n",
      "      context_recall: 0.329\n",
      "      faithfulness: 0.860\n",
      "      answer_correctness: 0.262\n",
      "   📊 gte-multilingual-base:\n",
      "      context_precision: 0.471\n",
      "      context_recall: 0.259\n",
      "      faithfulness: 0.866\n",
      "      answer_correctness: 0.158\n"
     ]
    }
   ],
   "source": [
    "# Evaluar TODAS las combinaciones: 3 prompts × 3 embeddings = 9 combinaciones\n",
    "resultados_completos = {}\n",
    "\n",
    "prompts_list = ['prompt_zero_shot', 'prompt_one_shot', 'prompt_few_shot']\n",
    "\n",
    "for prompt_name in prompts_list:\n",
    "    print(f\"\\nEVALUANDO CON PROMPT: {prompt_name}\")\n",
    "    print(\"=\"*80)\n",
    "    # CAMBIAR EL TEMPLATE GLOBAL (esto es lo clave)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    selected_template = PROMPTS[prompt_name]\n",
    "    prompt_template = ChatPromptTemplate.from_template(selected_template)\n",
    "\n",
    "    # Generar respuestas con este prompt específico\n",
    "    results_list_prompt = []\n",
    "\n",
    "    # Necesitas generar las respuestas con tu grafo de LangGraph primero\n",
    "    print(\"Generando respuestas con LangGraph...\")\n",
    "\n",
    "    for i, (question, ground_truth) in enumerate(zip(questions, ground_truths)):\n",
    "        print(f\"Procesando pregunta {i+1}/{len(questions)} con {prompt_name}\")\n",
    "\n",
    "        # Aquí usas tu grafo de LangGraph para generar la respuesta\n",
    "        state = {\n",
    "            'question': question,\n",
    "            'llm_name': 'Phi-3.5-mini-instruct',  # Tu LLM de generación\n",
    "            'embedding_name': 'all-MiniLM-L6-v2',  # Se cambiará en el bucle    \n",
    "            'prompt_name': prompt_name,\n",
    "            'context': [],\n",
    "            'answer': '',\n",
    "            'metadata': {}\n",
    "        }\n",
    "        try:\n",
    "            # INVOCAR TU GRAFO (ajusta según tu código)\n",
    "            final_state = graph.invoke(state)\n",
    "            answer = final_state.get('answer', '')\n",
    "            contexts = final_state.get('context', [])\n",
    "\n",
    "            if answer and answer.strip():  # Verificar que hay respuesta\n",
    "                  results_list_prompt.append({\n",
    "                      'question': question,\n",
    "                      'answer': answer,\n",
    "                      'contexts': [doc.page_content for doc in contexts] if contexts else ['Sin contexto'],\n",
    "                      'ground_truth': ground_truth\n",
    "                  })\n",
    "            else:\n",
    "                  print(f\"Pregunta {i+1} sin respuesta válida\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error en pregunta {i+1}: {e}\")\n",
    "\n",
    "    print(f\"Respuestas válidas generadas con {prompt_name}: {len(results_list_prompt)}\")\n",
    "\n",
    "      # Solo evaluar si tenemos respuestas válidas\n",
    "    if len(results_list_prompt) >= 2:\n",
    "          # EVALUAR CON LOS 3 EMBEDDINGS\n",
    "        resultados_por_embedding = {}\n",
    "\n",
    "        for embedding_name, current_embedding_model in EMBEDDING_MODELS.items():\n",
    "            print(f\"\\nEVALUANDO: {prompt_name} + {embedding_name}\")\n",
    "            print(\"-\"*60)\n",
    "\n",
    "            resultado = evaluate_with_mistral_four_metrics(\n",
    "                results_list=results_list_prompt,\n",
    "                  embedding_model=current_embedding_model,\n",
    "                  max_batch_size=2,\n",
    "                  delay_between_batches=120\n",
    "            )\n",
    "\n",
    "            resultados_por_embedding[embedding_name] = resultado\n",
    "\n",
    "              # Mostrar métricas promedio\n",
    "            print(f\"\\nCOMBINACIÓN: {prompt_name} + {embedding_name}\")\n",
    "            for metric in ['context_precision', 'context_recall', 'faithfulness', 'answer_correctness']:\n",
    "                if metric in resultado.columns:\n",
    "                    valores = resultado[metric].dropna()\n",
    "                    if len(valores) > 0:\n",
    "                        print(f\"   {metric}: {valores.mean():.3f}\")\n",
    "                    else:\n",
    "                        print(f\"   {metric}: Sin valores válidos\")\n",
    "\n",
    "            time.sleep(90)  # Pausa entre embeddings\n",
    "\n",
    "          # Guardar resultados de este prompt\n",
    "        resultados_completos[prompt_name] = resultados_por_embedding\n",
    "\n",
    "    else:\n",
    "        print(f\"No hay suficientes respuestas válidas para {prompt_name}, saltando evaluación\")\n",
    "\n",
    "    if prompt_name != prompts_list[-1]:\n",
    "        print(f\"\\nPAUSA ENTRE PROMPTS: 300 segundos...\")\n",
    "        time.sleep(300)\n",
    "\n",
    "print(\"\\\"EVALUACIÓN COMPLETA\")\n",
    "\n",
    "  # Mostrar tabla final\n",
    "print(\"\\nTABLA DE RESULTADOS:\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "for prompt_name, embeddings_results in resultados_completos.items():\n",
    "    print(f\"\\nPROMPT: {prompt_name}\")\n",
    "    for embedding_name, resultado in embeddings_results.items():\n",
    "        print(f\"{embedding_name}:\")\n",
    "        for metric in ['context_precision', 'context_recall', 'faithfulness', 'answer_correctness']:\n",
    "            if metric in resultado.columns:\n",
    "                valores = resultado[metric].dropna()\n",
    "                if len(valores) > 0:\n",
    "                    print(f\"      {metric}: {valores.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUANDO CON PROMPT: prompt_zero_shot\n",
      "================================================================================\n",
      "Generando respuestas con LangGraph...\n",
      "Procesando pregunta 1/9 con prompt_zero_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Llama-3.2-3B-instruct\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Published by Elsevier Inc. All rights reserved. doi:10.1016/j.yqres.2011.12.003 Contents lists available at SciVerse ScienceDirect Quaternary Research journal homepage: www.elsevier.com/locate/yqres https://doi.org/10.1016/j.yqres.2011.12.003 Published online by Cambridge University Press Introduc...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 2/9 con prompt_zero_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Llama-3.2-3B-instruct\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. A data obtida, é claramente mais recuada que os con­ textos mais antigos reportados em território hoje portu­ guês, nomeadamente Gruta da Nascente do Rio Almonda (OxA­‑9287 – 5480­‑5320 cal BC a 2 sigmas) e da Gruta do Caldeirão (OxA­‑1036 – 5480 – 5070 cal BC a 2 sigmas). Entre nós, apenas se rep...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 3/9 con prompt_zero_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Llama-3.2-3B-instruct\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 2. ENCUADRE CRONO-CULTURAL DEL HA- LLAZGO: COGOTAS I Entre las entidades arqueológicas de la Edad del Bronce peninsular, Cogotas I sobresale por su extensa cobertura geográfica, que desborda la Meseta por el Valle del Ebro y Extremadura, y por su dilatada crono- logía —c. 1800-1150 cal BC, cubrien...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 4/9 con prompt_zero_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Llama-3.2-3B-instruct\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. y NEIRA, A. (1999): “Prehistoria”, en M.A. Rabanal Alonso (coord.): La His­ toria de León, tomo I, Universidad de León y Diario de León. CELIS SÁNCHEZ, J. (1993a): “La secuencia del poblado de la Primera Edad del Hierro de los «Cuestos de la Estación», Benavente, Zamora”, en F. Romero, C. Sanz y Z...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 5/9 con prompt_zero_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Llama-3.2-3B-instruct\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Con el desarrollo de las excavaciones arqueológicas en diversos asentamientos, el aumento del número de dataciones y la realización de diversos estudios en los últimos años, las perspectivas de investigación sobre el Bronce final en el Levante comienza a variar sustancialmente, estando ya en condi...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 6/9 con prompt_zero_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Llama-3.2-3B-instruct\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. En la actualidad, El Argar sigue siendo el grupo arqueo­ lógico de la Edad del Bronce mejor conocido de la península ibérica, con un desarrollo temporal entre el 2200 y el 1550 cal BC. También se puede afirmar que fue una de las sociedades con mayor capacidad productiva y desarrollo social de la E...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Respuestas válidas generadas con prompt_zero_shot: 6\n",
      "\n",
      "EVALUANDO: prompt_zero_shot + all-MiniLM-L6-v2\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 métricas en batches de 2\n",
      "   🔄 Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39bc2025ad63498fb573b9ba9423bfa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15316af68c264e46808b936fe476bf78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d89cff9ca7114170ba656514e4a5c361",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "358ba34e49014bbaaa01fcd822e0db61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b75e79fbedde4b64a17583c6662ba919",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b698712df6f649a9a6f45ea5f0c76133",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f2c95d23e6d47b9a0ab46805ea6b30e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df6243bdba2844ae905a3a3d8a94f314",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3c71764819c4e22b20e1e3d91630c92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41137bb4d8c64713a2044ef51d4996e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4581505ba90042fa817733e229560696",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fa2e4e40ab049dd97ba1ad0868e5b35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 métricas\n",
      "Evaluación completada: 6 preguntas con 4 métricas\n",
      "\n",
      "COMBINACIÓN: prompt_zero_shot + all-MiniLM-L6-v2\n",
      "   context_precision: 0.317\n",
      "   context_recall: 0.157\n",
      "   faithfulness: 0.566\n",
      "   answer_correctness: 0.223\n",
      "\n",
      "EVALUANDO: prompt_zero_shot + e5-large-instruct\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 métricas en batches de 2\n",
      "   🔄 Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "714157d681c54c7398621b9220aab1cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2a7fd3f24de4245bd2dfec8a863336b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad8ee4deb62e47bf8257018338eba794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2783c33e5d6549e7ab2ea15bdef3dfbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc6fb0229d9447cd88031b30345d7571",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4829a72708446c89307d0783a156a77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d3f15030d074d12ab68bf485ceaebbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "971dd70a5b694e9b8a42b0f053e32180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "196edfd091594f9ea5163138594f2dce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29da80131c574b87a607623c89dbac9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f31d174ffd964a0a8fa11a4ab29b31bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d97d96cd8c7a415fa76b0da4f9b6a942",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 métricas\n",
      "Evaluación completada: 6 preguntas con 4 métricas\n",
      "\n",
      "COMBINACIÓN: prompt_zero_shot + e5-large-instruct\n",
      "   context_precision: 0.365\n",
      "   context_recall: 0.217\n",
      "   faithfulness: 0.626\n",
      "   answer_correctness: 0.350\n",
      "\n",
      "EVALUANDO: prompt_zero_shot + gte-multilingual-base\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 métricas en batches de 2\n",
      "   🔄 Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a81b969b2a04bf3bf677a1603be39a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4ec50318d1b411cbe521a6e2e56337b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb8a343815534f6fab9fe4fdc62be8d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b61c4becab04fd4a0a27c535a71aa60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53898a4b33f142d7833ad72164686d85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1507690f15a443c28c33948e5715bf43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a8a55021bcf4a41b06d5936b3460f89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f79d3293722c407080ce8fe6d3be7388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daccb81e5bee49cca4e491142ec92b23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "515afd9de0b14ef1899b413885d2a1a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0f5441fcd47433690ae32c9cb0dc1d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d83a4e8ad72e41c798914c43d603f676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 métricas\n",
      "Evaluación completada: 6 preguntas con 4 métricas\n",
      "\n",
      "COMBINACIÓN: prompt_zero_shot + gte-multilingual-base\n",
      "   context_precision: 0.390\n",
      "   context_recall: 0.129\n",
      "   faithfulness: 0.598\n",
      "   answer_correctness: 0.379\n",
      "\n",
      "PAUSA ENTRE PROMPTS: 300 segundos...\n",
      "\n",
      "EVALUANDO CON PROMPT: prompt_one_shot\n",
      "================================================================================\n",
      "Generando respuestas con LangGraph...\n",
      "Procesando pregunta 1/9 con prompt_one_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Llama-3.2-3B-instruct\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Published by Elsevier Inc. All rights reserved. doi:10.1016/j.yqres.2011.12.003 Contents lists available at SciVerse ScienceDirect Quaternary Research journal homepage: www.elsevier.com/locate/yqres https://doi.org/10.1016/j.yqres.2011.12.003 Published online by Cambridge University Press Introduc...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 2/9 con prompt_one_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Llama-3.2-3B-instruct\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. A data obtida, é claramente mais recuada que os con­ textos mais antigos reportados em território hoje portu­ guês, nomeadamente Gruta da Nascente do Rio Almonda (OxA­‑9287 – 5480­‑5320 cal BC a 2 sigmas) e da Gruta do Caldeirão (OxA­‑1036 – 5480 – 5070 cal BC a 2 sigmas). Entre nós, apenas se rep...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 3/9 con prompt_one_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Llama-3.2-3B-instruct\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 2. ENCUADRE CRONO-CULTURAL DEL HA- LLAZGO: COGOTAS I Entre las entidades arqueológicas de la Edad del Bronce peninsular, Cogotas I sobresale por su extensa cobertura geográfica, que desborda la Meseta por el Valle del Ebro y Extremadura, y por su dilatada crono- logía —c. 1800-1150 cal BC, cubrien...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 4/9 con prompt_one_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Llama-3.2-3B-instruct\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. y NEIRA, A. (1999): “Prehistoria”, en M.A. Rabanal Alonso (coord.): La His­ toria de León, tomo I, Universidad de León y Diario de León. CELIS SÁNCHEZ, J. (1993a): “La secuencia del poblado de la Primera Edad del Hierro de los «Cuestos de la Estación», Benavente, Zamora”, en F. Romero, C. Sanz y Z...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 5/9 con prompt_one_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Llama-3.2-3B-instruct\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Con el desarrollo de las excavaciones arqueológicas en diversos asentamientos, el aumento del número de dataciones y la realización de diversos estudios en los últimos años, las perspectivas de investigación sobre el Bronce final en el Levante comienza a variar sustancialmente, estando ya en condi...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 6/9 con prompt_one_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Llama-3.2-3B-instruct\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. En la actualidad, El Argar sigue siendo el grupo arqueo­ lógico de la Edad del Bronce mejor conocido de la península ibérica, con un desarrollo temporal entre el 2200 y el 1550 cal BC. También se puede afirmar que fue una de las sociedades con mayor capacidad productiva y desarrollo social de la E...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Respuestas válidas generadas con prompt_one_shot: 6\n",
      "\n",
      "EVALUANDO: prompt_one_shot + all-MiniLM-L6-v2\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 métricas en batches de 2\n",
      "   🔄 Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb383fb6507f42a1b4e11bbecec69d3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aba0e1a17ec84cfbb4aa99209d5a32dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "915c35a2ab204c07ba1f9c6e0f1949c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a9ad39ff09d43458bbe7df603ce7a84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d489d5f0dd584058a720cb4fd5e924b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "107a6a8eb8804c7ba7cbe4e86f064e0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "029baf081b7047fa9968c2054d57d798",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e22f7add65fa49aeb6f713f83787d278",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd2e8958eb9d4fbbbcce91b5fcd7c6d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1f8f33bb6b14868ac9e7765f347ce09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bbb805c818e451f8676e73b84a05834",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e042018fa7647eda0acd35cef9ce4e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 métricas\n",
      "Evaluación completada: 6 preguntas con 4 métricas\n",
      "\n",
      "COMBINACIÓN: prompt_one_shot + all-MiniLM-L6-v2\n",
      "   context_precision: 0.478\n",
      "   context_recall: 0.273\n",
      "   faithfulness: 0.754\n",
      "   answer_correctness: 0.218\n",
      "\n",
      "EVALUANDO: prompt_one_shot + e5-large-instruct\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 métricas en batches de 2\n",
      "   🔄 Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f708d9d6181e4de1b7f15fdd77bb2a33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fb6864ee3fa457a8b45909e5901a2e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "652fbadd50a146fd944f135b342884f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd4f469eb2984a9d89b4a590852a4e34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edf89a19651d4c42bb511111c8d08fa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e02294f4aae42b5b937a8bef72dd8bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b44db4a9d433485e848f53e10a26ca54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85f6c1738c6946ba911fd2a130434e13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9384942366734acdac5812fb287bd189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a2d49bac80d423699bec407bb4be33c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57fd992e307f45ccbe4681e56c22b61e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b33f816fafc84c71b40d6141ccedee6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 métricas\n",
      "Evaluación completada: 6 preguntas con 4 métricas\n",
      "\n",
      "COMBINACIÓN: prompt_one_shot + e5-large-instruct\n",
      "   context_precision: 0.450\n",
      "   context_recall: 0.323\n",
      "   faithfulness: 0.733\n",
      "   answer_correctness: 0.353\n",
      "\n",
      "EVALUANDO: prompt_one_shot + gte-multilingual-base\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 métricas en batches de 2\n",
      "   🔄 Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a909a6359b342df84217ae431976124",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a496ef569db04126bcbbeab8167782d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3d4c429365140828c89332c8c3deba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af74ae2ef749474ca1db5bf58df84e16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5919125796fc4010b8ac3ad84509225e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee500f96c6c9422c98674a633fd30983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "Exception raised in Job[0]: OutputParserException(Invalid json output: ```json\\n{\\n    \"classifications\": [\\n        {\\n            \"statement\": \"Las primeras manifestaciones funerarias datadas se sitúan en la primera mitad del V milenio con una estimación probabilística para su inicio de entre el 4975-4785 cal BC (68% de probabilidad) y entre el 4740-4570 cal BC (68% de probabilidad).\",\\n            \"reason\": \"El contexto menciona explícitamente las cronologías de las primeras manifestaciones funerarias en la península ibérica, incluyendo fechas específicas del V milenio cal BC.\\n            \"attributed\": 1\\n        },\\n        {\\n            \"statement\": \"Las manifestaciones funerarias del Mesolítico en las distintas regiones peninsulares.\\n            \"reason\": \"El contexto no proporciona información específica sobre el Mesolítico, ya que se centra en el Neolítico, Calcolítico y Edad del Bronce.\\n            \"attributed\": 0\\n        },\\n        {\\n            \"statement\": \"Las dataciones radiocarbónicas de asentamientos neolíticos se sitúan a finales del VI milenio y en la primera mitad del V milenio cal BC.\\n            \"reason\": \"El contexto menciona fechas radiocarbónicas de asentamientos neolíticos, aunque no se especifica su relación directa con manifestaciones funerarias.\\n            \"attributed\": 0.5\\n        }\\n    ]\\n}\\n```\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69f98bc79019472895b4145006ab336e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a90e8c5fa7ca40b98ba91ddae795db22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "965b806ff4174d789deb3349f59fe14a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a0f6727983246dd924cd1dbb2e93053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45d6820f1f694e64b5771a7c82a728da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8223633604b4b7f8ec2108c5cb8b709",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 métricas\n",
      "Evaluación completada: 6 preguntas con 4 métricas\n",
      "\n",
      "COMBINACIÓN: prompt_one_shot + gte-multilingual-base\n",
      "   context_precision: 0.479\n",
      "   context_recall: 0.105\n",
      "   faithfulness: 0.746\n",
      "   answer_correctness: 0.246\n",
      "\n",
      "PAUSA ENTRE PROMPTS: 300 segundos...\n",
      "\n",
      "EVALUANDO CON PROMPT: prompt_few_shot\n",
      "================================================================================\n",
      "Generando respuestas con LangGraph...\n",
      "Procesando pregunta 1/9 con prompt_few_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Llama-3.2-3B-instruct\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Published by Elsevier Inc. All rights reserved. doi:10.1016/j.yqres.2011.12.003 Contents lists available at SciVerse ScienceDirect Quaternary Research journal homepage: www.elsevier.com/locate/yqres https://doi.org/10.1016/j.yqres.2011.12.003 Published online by Cambridge University Press Introduc...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 2/9 con prompt_few_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Llama-3.2-3B-instruct\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. A data obtida, é claramente mais recuada que os con­ textos mais antigos reportados em território hoje portu­ guês, nomeadamente Gruta da Nascente do Rio Almonda (OxA­‑9287 – 5480­‑5320 cal BC a 2 sigmas) e da Gruta do Caldeirão (OxA­‑1036 – 5480 – 5070 cal BC a 2 sigmas). Entre nós, apenas se rep...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 3/9 con prompt_few_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Llama-3.2-3B-instruct\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 2. ENCUADRE CRONO-CULTURAL DEL HA- LLAZGO: COGOTAS I Entre las entidades arqueológicas de la Edad del Bronce peninsular, Cogotas I sobresale por su extensa cobertura geográfica, que desborda la Meseta por el Valle del Ebro y Extremadura, y por su dilatada crono- logía —c. 1800-1150 cal BC, cubrien...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 4/9 con prompt_few_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Llama-3.2-3B-instruct\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. y NEIRA, A. (1999): “Prehistoria”, en M.A. Rabanal Alonso (coord.): La His­ toria de León, tomo I, Universidad de León y Diario de León. CELIS SÁNCHEZ, J. (1993a): “La secuencia del poblado de la Primera Edad del Hierro de los «Cuestos de la Estación», Benavente, Zamora”, en F. Romero, C. Sanz y Z...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 5/9 con prompt_few_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Llama-3.2-3B-instruct\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Con el desarrollo de las excavaciones arqueológicas en diversos asentamientos, el aumento del número de dataciones y la realización de diversos estudios en los últimos años, las perspectivas de investigación sobre el Bronce final en el Levante comienza a variar sustancialmente, estando ya en condi...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Procesando pregunta 6/9 con prompt_few_shot\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Llama-3.2-3B-instruct\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. En la actualidad, El Argar sigue siendo el grupo arqueo­ lógico de la Edad del Bronce mejor conocido de la península ibérica, con un desarrollo temporal entre el 2200 y el 1550 cal BC. También se puede afirmar que fue una de las sociedades con mayor capacidad productiva y desarrollo social de la E...'\n",
      "    -> El LLM ha devuelto una respuesta.\n",
      "Respuestas válidas generadas con prompt_few_shot: 6\n",
      "\n",
      "EVALUANDO: prompt_few_shot + all-MiniLM-L6-v2\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 métricas en batches de 2\n",
      "   🔄 Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25903638dd1f4d90b7f5ca2b2524f834",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69dc88d315b2481da99ba42280e316e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6891c162ac5e472396675007d8055435",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67fdab0b9b6f4a0abe292ecc95610764",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e27195b9863483397653f90f69c639d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb8a2226432745bb975cc55534012f96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7ac28ac444a442fa9999bdd8074e990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eab138e0272f41119df95bd396b2fbca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c86f20e755b446196cdfd99d87168c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "febf16cfc41043a5986f024267f68f37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4649337582224404ac4a5c5c734449cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93bd17f6e7804a2a9fd33834fa9d48b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 métricas\n",
      "Evaluación completada: 6 preguntas con 4 métricas\n",
      "\n",
      "COMBINACIÓN: prompt_few_shot + all-MiniLM-L6-v2\n",
      "   context_precision: 0.427\n",
      "   context_recall: 0.254\n",
      "   faithfulness: 0.763\n",
      "   answer_correctness: 0.322\n",
      "\n",
      "EVALUANDO: prompt_few_shot + e5-large-instruct\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 métricas en batches de 2\n",
      "   🔄 Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1affaa86e0144365888e15467c43c280",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cf1945bdb874d59b886518aca13f866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6fb726a162c42b29776d71bbb0a0081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ccf6edd1ba4490183ffcc80d4111f85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15060a6392a348098d7de0c64e7e04c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8846a1cb86114a2dae181d16a05ad05c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7276bd789046418eb2cf4f227f9e3b1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09ad349f74524fc898cad791413ac7ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c92a5ae5edf94339a7d80a6ad02179bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daaf8fd62d75414084c7d1186be394b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a97581f02a41423990714856bf48afe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "473f7586930f48ec85bb60cafac79320",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 métricas\n",
      "Evaluación completada: 6 preguntas con 4 métricas\n",
      "\n",
      "COMBINACIÓN: prompt_few_shot + e5-large-instruct\n",
      "   context_precision: 0.420\n",
      "   context_recall: 0.187\n",
      "   faithfulness: 0.745\n",
      "   answer_correctness: 0.472\n",
      "\n",
      "EVALUANDO: prompt_few_shot + gte-multilingual-base\n",
      "------------------------------------------------------------\n",
      "Evaluando 6 preguntas con 4 métricas en batches de 2\n",
      "   🔄 Procesando batch 1/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 1\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17b942307d4f474886063d9858ac0916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20008a6b98d04250b3fb0a5ba4ecd150",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2335b71c1a624050bbe76ec932b476b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44977d7ff766468791b25ebf64571a41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 1 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 2/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 2\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b51ba5af0415418cb0b5798fb3b3980b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34dc1b58a9534bd7a359b823450c8be8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e45d07e1c5564c6fae2c545503b4d3cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f3942fd460544e4aa60f5c08f732cd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 2 completado con 4 métricas\n",
      "Esperando 120s antes del siguiente batch...\n",
      "   🔄 Procesando batch 3/3 (2 preguntas)\n",
      "      Intento 1/3 para batch 3\n",
      "         Evaluando context_precision...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58b44e595d7146a89c3754fabf32106e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py:140: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextPrecisionWithReference instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision completado\n",
      "         Evaluando context_recall...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42be9723305149d58b5f8dd45e2210fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\base.py:535: DeprecationWarning: The function _single_turn_ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  self._single_turn_ascore(sample=sample, callbacks=group_cm),\n",
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py:171: DeprecationWarning: The function _ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use LLMContextRecall instead.\n",
      "  return await self._ascore(row, callbacks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_recall completado\n",
      "         Evaluando faithfulness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "969edb4545914b129b9451afff54b090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness completado\n",
      "         Evaluando answer_correctness...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b20a25f2d73e4e68913e4113732325f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\rag\\Lib\\site-packages\\ragas\\metrics\\_answer_correctness.py:260: DeprecationWarning: The function ascore was deprecated in 0.2, and will be removed in the 0.3 release. Use single_turn_ascore instead.\n",
      "  similarity_score = await self.answer_similarity.ascore(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_correctness completado\n",
      "Batch 3 completado con 4 métricas\n",
      "Evaluación completada: 6 preguntas con 4 métricas\n",
      "\n",
      "COMBINACIÓN: prompt_few_shot + gte-multilingual-base\n",
      "   context_precision: 0.248\n",
      "   context_recall: 0.300\n",
      "   faithfulness: 0.782\n",
      "   answer_correctness: 0.233\n",
      "\"EVALUACIÓN COMPLETA\n",
      "\n",
      "TABLA DE RESULTADOS:\n",
      "====================================================================================================\n",
      "\n",
      "PROMPT: prompt_zero_shot\n",
      "all-MiniLM-L6-v2:\n",
      "      context_precision: 0.317\n",
      "      context_recall: 0.157\n",
      "      faithfulness: 0.566\n",
      "      answer_correctness: 0.223\n",
      "e5-large-instruct:\n",
      "      context_precision: 0.365\n",
      "      context_recall: 0.217\n",
      "      faithfulness: 0.626\n",
      "      answer_correctness: 0.350\n",
      "gte-multilingual-base:\n",
      "      context_precision: 0.390\n",
      "      context_recall: 0.129\n",
      "      faithfulness: 0.598\n",
      "      answer_correctness: 0.379\n",
      "\n",
      "PROMPT: prompt_one_shot\n",
      "all-MiniLM-L6-v2:\n",
      "      context_precision: 0.478\n",
      "      context_recall: 0.273\n",
      "      faithfulness: 0.754\n",
      "      answer_correctness: 0.218\n",
      "e5-large-instruct:\n",
      "      context_precision: 0.450\n",
      "      context_recall: 0.323\n",
      "      faithfulness: 0.733\n",
      "      answer_correctness: 0.353\n",
      "gte-multilingual-base:\n",
      "      context_precision: 0.479\n",
      "      context_recall: 0.105\n",
      "      faithfulness: 0.746\n",
      "      answer_correctness: 0.246\n",
      "\n",
      "PROMPT: prompt_few_shot\n",
      "all-MiniLM-L6-v2:\n",
      "      context_precision: 0.427\n",
      "      context_recall: 0.254\n",
      "      faithfulness: 0.763\n",
      "      answer_correctness: 0.322\n",
      "e5-large-instruct:\n",
      "      context_precision: 0.420\n",
      "      context_recall: 0.187\n",
      "      faithfulness: 0.745\n",
      "      answer_correctness: 0.472\n",
      "gte-multilingual-base:\n",
      "      context_precision: 0.248\n",
      "      context_recall: 0.300\n",
      "      faithfulness: 0.782\n",
      "      answer_correctness: 0.233\n"
     ]
    }
   ],
   "source": [
    "# Evaluar TODAS las combinaciones: 3 prompts × 3 embeddings = 9 combinaciones\n",
    "resultados_completos = {}\n",
    "\n",
    "prompts_list = ['prompt_zero_shot', 'prompt_one_shot', 'prompt_few_shot']\n",
    "\n",
    "for prompt_name in prompts_list:\n",
    "    print(f\"\\nEVALUANDO CON PROMPT: {prompt_name}\")\n",
    "    print(\"=\"*80)\n",
    "    # CAMBIAR EL TEMPLATE GLOBAL (esto es lo clave)\n",
    "    selected_template = PROMPTS[prompt_name]\n",
    "    prompt_template = ChatPromptTemplate.from_template(selected_template)\n",
    "\n",
    "    # Generar respuestas con este prompt específico\n",
    "    results_list_prompt = []\n",
    "\n",
    "    # Necesitas generar las respuestas con tu grafo de LangGraph primero\n",
    "    print(\"Generando respuestas con LangGraph...\")\n",
    "\n",
    "    for i, (question, ground_truth) in enumerate(zip(questions, ground_truths)):\n",
    "        print(f\"Procesando pregunta {i+1}/{len(questions)} con {prompt_name}\")\n",
    "\n",
    "        # Aquí usas tu grafo de LangGraph para generar la respuesta\n",
    "        state = {\n",
    "            'question': question,\n",
    "            'llm_name': 'Llama-3.2-3B-instruct',  # Tu LLM de generación\n",
    "            'embedding_name': 'all-MiniLM-L6-v2',  # Se cambiará en el bucle    \n",
    "            'prompt_name': prompt_name,\n",
    "            'context': [],\n",
    "            'answer': '',\n",
    "            'metadata': {}\n",
    "        }\n",
    "        try:\n",
    "            # INVOCAR TU GRAFO (ajusta según tu código)\n",
    "            final_state = graph.invoke(state)\n",
    "            answer = final_state.get('answer', '')\n",
    "            contexts = final_state.get('context', [])\n",
    "\n",
    "            if answer and answer.strip():  # Verificar que hay respuesta\n",
    "                  results_list_prompt.append({\n",
    "                      'question': question,\n",
    "                      'answer': answer,\n",
    "                      'contexts': [doc.page_content for doc in contexts] if contexts else ['Sin contexto'],\n",
    "                      'ground_truth': ground_truth\n",
    "                  })\n",
    "            else:\n",
    "                  print(f\"Pregunta {i+1} sin respuesta válida\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error en pregunta {i+1}: {e}\")\n",
    "\n",
    "    print(f\"Respuestas válidas generadas con {prompt_name}: {len(results_list_prompt)}\")\n",
    "\n",
    "      # Solo evaluar si tenemos respuestas válidas\n",
    "    if len(results_list_prompt) >= 2:\n",
    "          # EVALUAR CON LOS 3 EMBEDDINGS\n",
    "        resultados_por_embedding = {}\n",
    "\n",
    "        for embedding_name, current_embedding_model in EMBEDDING_MODELS.items():\n",
    "            print(f\"\\nEVALUANDO: {prompt_name} + {embedding_name}\")\n",
    "            print(\"-\"*60)\n",
    "\n",
    "            resultado = evaluate_with_mistral_four_metrics(\n",
    "                results_list=results_list_prompt,\n",
    "                  embedding_model=current_embedding_model,\n",
    "                  max_batch_size=2,\n",
    "                  delay_between_batches=120\n",
    "            )\n",
    "\n",
    "            resultados_por_embedding[embedding_name] = resultado\n",
    "\n",
    "              # Mostrar métricas promedio\n",
    "            print(f\"\\nCOMBINACIÓN: {prompt_name} + {embedding_name}\")\n",
    "            for metric in ['context_precision', 'context_recall', 'faithfulness', 'answer_correctness']:\n",
    "                if metric in resultado.columns:\n",
    "                    valores = resultado[metric].dropna()\n",
    "                    if len(valores) > 0:\n",
    "                        print(f\"   {metric}: {valores.mean():.3f}\")\n",
    "                    else:\n",
    "                        print(f\"   {metric}: Sin valores válidos\")\n",
    "\n",
    "            time.sleep(90)  # Pausa entre embeddings\n",
    "\n",
    "          # Guardar resultados de este prompt\n",
    "        resultados_completos[prompt_name] = resultados_por_embedding\n",
    "\n",
    "    else:\n",
    "        print(f\"No hay suficientes respuestas válidas para {prompt_name}, saltando evaluación\")\n",
    "\n",
    "    if prompt_name != prompts_list[-1]:\n",
    "        print(f\"\\nPAUSA ENTRE PROMPTS: 300 segundos...\")\n",
    "        time.sleep(300)\n",
    "\n",
    "print(\"\\\"EVALUACIÓN COMPLETA\")\n",
    "\n",
    "  # Mostrar tabla final\n",
    "print(\"\\nTABLA DE RESULTADOS:\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "for prompt_name, embeddings_results in resultados_completos.items():\n",
    "    print(f\"\\nPROMPT: {prompt_name}\")\n",
    "    for embedding_name, resultado in embeddings_results.items():\n",
    "        print(f\"{embedding_name}:\")\n",
    "        for metric in ['context_precision', 'context_recall', 'faithfulness', 'answer_correctness']:\n",
    "            if metric in resultado.columns:\n",
    "                valores = resultado[metric].dropna()\n",
    "                if len(valores) > 0:\n",
    "                    print(f\"      {metric}: {valores.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EVALUACIÓN COM LLAMA QUE NO FUNCIONA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFIGURACIÓN DE EVALUACIÓN:\n",
      "LLM Evaluador (RAGAS): hf.co/bartowski/Llama-3.2-3B-Instruct-GGUF:Q8_0\n",
      "LLMs Generadores: Qwen3-4B-instruct-2507, Phi-3.5-mini-instruct\n",
      "Métricas: context_precision, context_recall, faithfulness, answer_correctness\n",
      "Embeddings específicos para answer_correctness por combinación\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "  # Importar RAGAS y métricas\n",
    "from ragas import evaluate  \n",
    "from ragas.metrics import (\n",
    "    context_precision,\n",
    "    context_recall,\n",
    "    faithfulness,\n",
    "    answer_correctness\n",
    "    \n",
    "    \n",
    "    )\n",
    "\n",
    "  # CONFIGURAR LLAMA COMO EVALUADOR PARA RAGAS\n",
    "from langchain_ollama import ChatOllama\n",
    "llama_evaluator = ChatOllama(\n",
    "    model=\"hf.co/bartowski/Llama-3.2-3B-Instruct-GGUF:Q8_0\", \n",
    "    temperature=0.1,\n",
    "    num_predict=200,\n",
    "    timeout=1200,  # 15 minutos para Llama 3B\n",
    "    num_ctx=4096,\n",
    "    num_thread=8\n",
    ")\n",
    "\n",
    "print(\"CONFIGURACIÓN DE EVALUACIÓN:\")\n",
    "print(f\"LLM Evaluador (RAGAS): {llama_evaluator.model}\")\n",
    "print(\"LLMs Generadores: Qwen3-4B-instruct-2507, Phi-3.5-mini-instruct\")\n",
    "print(\"Métricas: context_precision, context_recall, faithfulness, answer_correctness\")\n",
    "print(\"Embeddings específicos para answer_correctness por combinación\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "  # Variables comunes\n",
    "embeddings = list(EMBEDDING_MODELS.keys())\n",
    "prompts = list(PROMPTS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUACIÓN CON GENERADOR QWEN\n",
      "Generador: Qwen3-4B-instruct-2507\n",
      "Evaluador: hf.co/bartowski/Llama-3.2-3B-Instruct-GGUF:Q8_0\n",
      "============================================================\n",
      "Evaluando 9 combinaciones para Qwen:\n",
      "   • Qwen3-4B-instruct-2507 + all-MiniLM-L6-v2 + prompt_zero_shot\n",
      "   • Qwen3-4B-instruct-2507 + all-MiniLM-L6-v2 + prompt_one_shot\n",
      "   • Qwen3-4B-instruct-2507 + all-MiniLM-L6-v2 + prompt_few_shot\n",
      "   • Qwen3-4B-instruct-2507 + e5-large-instruct + prompt_zero_shot\n",
      "   • Qwen3-4B-instruct-2507 + e5-large-instruct + prompt_one_shot\n",
      "   • Qwen3-4B-instruct-2507 + e5-large-instruct + prompt_few_shot\n",
      "   • Qwen3-4B-instruct-2507 + gte-multilingual-base + prompt_zero_shot\n",
      "   • Qwen3-4B-instruct-2507 + gte-multilingual-base + prompt_one_shot\n",
      "   • Qwen3-4B-instruct-2507 + gte-multilingual-base + prompt_few_shot\n",
      "\n",
      "QWEN COMBINACIÓN 1/9\n",
      "   Generador: Qwen3-4B-instruct-2507\n",
      "   Embedding: all-MiniLM-L6-v2 -> IdearqAllMiniLM\n",
      "   Prompt: prompt_zero_shot\n",
      "Generando respuestas con Qwen...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Published by Elsevier Inc. All rights reserved. doi:10.1016/j.yqres.2011.12.003 Contents lists available at SciVerse ScienceDirect Quaternary Research journal homepage: www.elsevier.com/locate/yqres https://doi.org/10.1016/j.yqres.2011.12.003 Published online by Cambridge University Press Introduc...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  12%|█▎        | 1/8 [04:20<30:22, 260.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. A data obtida, é claramente mais recuada que os con­ textos mais antigos reportados em território hoje portu­ guês, nomeadamente Gruta da Nascente do Rio Almonda (OxA­‑9287 – 5480­‑5320 cal BC a 2 sigmas) e da Gruta do Caldeirão (OxA­‑1036 – 5480 – 5070 cal BC a 2 sigmas). Entre nós, apenas se rep...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  25%|██▌       | 2/8 [05:24<14:29, 144.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 2. ENCUADRE CRONO-CULTURAL DEL HA- LLAZGO: COGOTAS I Entre las entidades arqueológicas de la Edad del Bronce peninsular, Cogotas I sobresale por su extensa cobertura geográfica, que desborda la Meseta por el Valle del Ebro y Extremadura, y por su dilatada crono- logía —c. 1800-1150 cal BC, cubrien...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  38%|███▊      | 3/8 [06:24<08:51, 106.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. y NEIRA, A. (1999): “Prehistoria”, en M.A. Rabanal Alonso (coord.): La His­ toria de León, tomo I, Universidad de León y Diario de León. CELIS SÁNCHEZ, J. (1993a): “La secuencia del poblado de la Primera Edad del Hierro de los «Cuestos de la Estación», Benavente, Zamora”, en F. Romero, C. Sanz y Z...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  50%|█████     | 4/8 [07:42<06:19, 94.98s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Con el desarrollo de las excavaciones arqueológicas en diversos asentamientos, el aumento del número de dataciones y la realización de diversos estudios en los últimos años, las perspectivas de investigación sobre el Bronce final en el Levante comienza a variar sustancialmente, estando ya en condi...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  62%|██████▎   | 5/8 [13:44<09:33, 191.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. En la actualidad, El Argar sigue siendo el grupo arqueo­ lógico de la Edad del Bronce mejor conocido de la península ibérica, con un desarrollo temporal entre el 2200 y el 1550 cal BC. También se puede afirmar que fue una de las sociedades con mayor capacidad productiva y desarrollo social de la E...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  75%|███████▌  | 6/8 [16:00<05:44, 172.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Prehist., 74, N.º 2, julio-diciembre 2017, pp. 296-318, ISSN: 0082-5638 doi: 10.3989/tp.2017.12196 Torres Ortiz, M. 1996: “La cronología de los túmulos A y B de Setefilla. El origen del rito de la crema- ción en la cultura tartésica”. Complutum 7: 147-162. Torres Ortiz, M. 1998: “La cronología abs...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  88%|████████▊ | 7/8 [17:32<02:26, 146.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Ruiz Alonso, M. Guenaga, A., López Quintana, J. C. y Zapata Peña, L. (2010). Antracología y yacimientos dolménicos: el caso de Mendigana. En Actas del Congreso Internacional sobre Megalitismo y otras manifestaciones funerarias con- temporáneas en su contexto social, económico y cultural (pp. 566-5...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas: 100%|██████████| 8/8 [19:15<00:00, 144.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "8/8 preguntas exitosas\n",
      "Evaluando respuestas de Qwen con Llama...\n",
      "Procesando 8 preguntas en lotes de 4...\n",
      "   Evaluando lote 1/2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a656c7e5c0f45198c3cbe3d0c521ac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[1]: TimeoutError()\n",
      "Exception raised in Job[7]: TimeoutError()\n",
      "Exception raised in Job[2]: TimeoutError()\n",
      "Exception raised in Job[4]: TimeoutError()\n",
      "Exception raised in Job[3]: TimeoutError()\n",
      "Exception raised in Job[6]: TimeoutError()\n",
      "Exception raised in Job[5]: TimeoutError()\n",
      "Exception raised in Job[9]: TimeoutError()\n",
      "Exception raised in Job[10]: TimeoutError()\n",
      "Exception raised in Job[8]: TimeoutError()\n",
      "Exception raised in Job[11]: TimeoutError()\n",
      "Exception raised in Job[14]: TimeoutError()\n",
      "Exception raised in Job[13]: TimeoutError()\n",
      "Exception raised in Job[12]: TimeoutError()\n",
      "Exception raised in Job[15]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Evaluando lote 2/2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5488aa3a17e34d6898c5b8554301c273",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[2]: TimeoutError()\n",
      "Exception raised in Job[4]: TimeoutError()\n",
      "Exception raised in Job[3]: TimeoutError()\n",
      "Exception raised in Job[6]: TimeoutError()\n",
      "Exception raised in Job[5]: TimeoutError()\n",
      "Exception raised in Job[7]: TimeoutError()\n",
      "Exception raised in Job[9]: TimeoutError()\n",
      "Exception raised in Job[8]: TimeoutError()\n",
      "Exception raised in Job[14]: TimeoutError()\n",
      "Exception raised in Job[11]: TimeoutError()\n",
      "Exception raised in Job[10]: TimeoutError()\n",
      "Exception raised in Job[12]: TimeoutError()\n",
      "Exception raised in Job[13]: TimeoutError()\n",
      "Exception raised in Job[15]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✅ Evaluación Llama → Qwen completada:\n",
      "      Context_Recall: 1.000\n",
      "QWEN COMBINACIÓN 2/9\n",
      "   Generador: Qwen3-4B-instruct-2507\n",
      "   Embedding: all-MiniLM-L6-v2 -> IdearqAllMiniLM\n",
      "   Prompt: prompt_one_shot\n",
      "Generando respuestas con Qwen...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Published by Elsevier Inc. All rights reserved. doi:10.1016/j.yqres.2011.12.003 Contents lists available at SciVerse ScienceDirect Quaternary Research journal homepage: www.elsevier.com/locate/yqres https://doi.org/10.1016/j.yqres.2011.12.003 Published online by Cambridge University Press Introduc...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  12%|█▎        | 1/8 [03:42<25:55, 222.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. A data obtida, é claramente mais recuada que os con­ textos mais antigos reportados em território hoje portu­ guês, nomeadamente Gruta da Nascente do Rio Almonda (OxA­‑9287 – 5480­‑5320 cal BC a 2 sigmas) e da Gruta do Caldeirão (OxA­‑1036 – 5480 – 5070 cal BC a 2 sigmas). Entre nós, apenas se rep...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  25%|██▌       | 2/8 [04:52<13:18, 133.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 2. ENCUADRE CRONO-CULTURAL DEL HA- LLAZGO: COGOTAS I Entre las entidades arqueológicas de la Edad del Bronce peninsular, Cogotas I sobresale por su extensa cobertura geográfica, que desborda la Meseta por el Valle del Ebro y Extremadura, y por su dilatada crono- logía —c. 1800-1150 cal BC, cubrien...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  38%|███▊      | 3/8 [06:16<09:12, 110.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. y NEIRA, A. (1999): “Prehistoria”, en M.A. Rabanal Alonso (coord.): La His­ toria de León, tomo I, Universidad de León y Diario de León. CELIS SÁNCHEZ, J. (1993a): “La secuencia del poblado de la Primera Edad del Hierro de los «Cuestos de la Estación», Benavente, Zamora”, en F. Romero, C. Sanz y Z...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  50%|█████     | 4/8 [07:25<06:16, 94.20s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Con el desarrollo de las excavaciones arqueológicas en diversos asentamientos, el aumento del número de dataciones y la realización de diversos estudios en los últimos años, las perspectivas de investigación sobre el Bronce final en el Levante comienza a variar sustancialmente, estando ya en condi...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  62%|██████▎   | 5/8 [13:09<09:12, 184.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. En la actualidad, El Argar sigue siendo el grupo arqueo­ lógico de la Edad del Bronce mejor conocido de la península ibérica, con un desarrollo temporal entre el 2200 y el 1550 cal BC. También se puede afirmar que fue una de las sociedades con mayor capacidad productiva y desarrollo social de la E...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  75%|███████▌  | 6/8 [15:13<05:27, 163.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Prehist., 74, N.º 2, julio-diciembre 2017, pp. 296-318, ISSN: 0082-5638 doi: 10.3989/tp.2017.12196 Torres Ortiz, M. 1996: “La cronología de los túmulos A y B de Setefilla. El origen del rito de la crema- ción en la cultura tartésica”. Complutum 7: 147-162. Torres Ortiz, M. 1998: “La cronología abs...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  88%|████████▊ | 7/8 [16:22<02:12, 132.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Ruiz Alonso, M. Guenaga, A., López Quintana, J. C. y Zapata Peña, L. (2010). Antracología y yacimientos dolménicos: el caso de Mendigana. En Actas del Congreso Internacional sobre Megalitismo y otras manifestaciones funerarias con- temporáneas en su contexto social, económico y cultural (pp. 566-5...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas: 100%|██████████| 8/8 [17:49<00:00, 133.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "8/8 preguntas exitosas\n",
      "Evaluando respuestas de Qwen con Llama...\n",
      "Procesando 8 preguntas en lotes de 4...\n",
      "   Evaluando lote 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6f5a9dad2dc4720ad057920de96f5b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[1]: TimeoutError()\n",
      "Exception raised in Job[2]: TimeoutError()\n",
      "Exception raised in Job[4]: TimeoutError()\n",
      "Exception raised in Job[3]: TimeoutError()\n",
      "Exception raised in Job[6]: TimeoutError()\n",
      "Exception raised in Job[5]: TimeoutError()\n",
      "Exception raised in Job[7]: TimeoutError()\n",
      "Exception raised in Job[9]: TimeoutError()\n",
      "Exception raised in Job[10]: TimeoutError()\n",
      "Exception raised in Job[11]: TimeoutError()\n",
      "Exception raised in Job[8]: TimeoutError()\n",
      "Exception raised in Job[13]: TimeoutError()\n",
      "Exception raised in Job[14]: TimeoutError()\n",
      "Exception raised in Job[12]: TimeoutError()\n",
      "Exception raised in Job[15]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Evaluando lote 2/2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5351a2a3417d4f6199cade67362ee1e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[2]: TimeoutError()\n",
      "Exception raised in Job[5]: TimeoutError()\n",
      "Exception raised in Job[6]: TimeoutError()\n",
      "Exception raised in Job[4]: TimeoutError()\n",
      "Exception raised in Job[1]: TimeoutError()\n",
      "Exception raised in Job[3]: TimeoutError()\n",
      "Exception raised in Job[12]: TimeoutError()\n",
      "Exception raised in Job[9]: TimeoutError()\n",
      "Exception raised in Job[11]: TimeoutError()\n",
      "Exception raised in Job[10]: TimeoutError()\n",
      "Exception raised in Job[7]: TimeoutError()\n",
      "Exception raised in Job[8]: TimeoutError()\n",
      "Exception raised in Job[13]: TimeoutError()\n",
      "Exception raised in Job[14]: TimeoutError()\n",
      "Exception raised in Job[15]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✅ Evaluación Llama → Qwen completada:\n",
      "QWEN COMBINACIÓN 3/9\n",
      "   Generador: Qwen3-4B-instruct-2507\n",
      "   Embedding: all-MiniLM-L6-v2 -> IdearqAllMiniLM\n",
      "   Prompt: prompt_few_shot\n",
      "Generando respuestas con Qwen...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Published by Elsevier Inc. All rights reserved. doi:10.1016/j.yqres.2011.12.003 Contents lists available at SciVerse ScienceDirect Quaternary Research journal homepage: www.elsevier.com/locate/yqres https://doi.org/10.1016/j.yqres.2011.12.003 Published online by Cambridge University Press Introduc...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  12%|█▎        | 1/8 [03:43<26:04, 223.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. A data obtida, é claramente mais recuada que os con­ textos mais antigos reportados em território hoje portu­ guês, nomeadamente Gruta da Nascente do Rio Almonda (OxA­‑9287 – 5480­‑5320 cal BC a 2 sigmas) e da Gruta do Caldeirão (OxA­‑1036 – 5480 – 5070 cal BC a 2 sigmas). Entre nós, apenas se rep...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  25%|██▌       | 2/8 [04:38<12:27, 124.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 2. ENCUADRE CRONO-CULTURAL DEL HA- LLAZGO: COGOTAS I Entre las entidades arqueológicas de la Edad del Bronce peninsular, Cogotas I sobresale por su extensa cobertura geográfica, que desborda la Meseta por el Valle del Ebro y Extremadura, y por su dilatada crono- logía —c. 1800-1150 cal BC, cubrien...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  38%|███▊      | 3/8 [04:56<06:18, 75.66s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. y NEIRA, A. (1999): “Prehistoria”, en M.A. Rabanal Alonso (coord.): La His­ toria de León, tomo I, Universidad de León y Diario de León. CELIS SÁNCHEZ, J. (1993a): “La secuencia del poblado de la Primera Edad del Hierro de los «Cuestos de la Estación», Benavente, Zamora”, en F. Romero, C. Sanz y Z...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  50%|█████     | 4/8 [06:14<05:07, 76.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Con el desarrollo de las excavaciones arqueológicas en diversos asentamientos, el aumento del número de dataciones y la realización de diversos estudios en los últimos años, las perspectivas de investigación sobre el Bronce final en el Levante comienza a variar sustancialmente, estando ya en condi...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  62%|██████▎   | 5/8 [11:55<08:35, 171.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. En la actualidad, El Argar sigue siendo el grupo arqueo­ lógico de la Edad del Bronce mejor conocido de la península ibérica, con un desarrollo temporal entre el 2200 y el 1550 cal BC. También se puede afirmar que fue una de las sociedades con mayor capacidad productiva y desarrollo social de la E...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  75%|███████▌  | 6/8 [14:49<05:45, 172.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Prehist., 74, N.º 2, julio-diciembre 2017, pp. 296-318, ISSN: 0082-5638 doi: 10.3989/tp.2017.12196 Torres Ortiz, M. 1996: “La cronología de los túmulos A y B de Setefilla. El origen del rito de la crema- ción en la cultura tartésica”. Complutum 7: 147-162. Torres Ortiz, M. 1998: “La cronología abs...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  88%|████████▊ | 7/8 [15:49<02:15, 135.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Ruiz Alonso, M. Guenaga, A., López Quintana, J. C. y Zapata Peña, L. (2010). Antracología y yacimientos dolménicos: el caso de Mendigana. En Actas del Congreso Internacional sobre Megalitismo y otras manifestaciones funerarias con- temporáneas en su contexto social, económico y cultural (pp. 566-5...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas: 100%|██████████| 8/8 [17:21<00:00, 130.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "8/8 preguntas exitosas\n",
      "Evaluando respuestas de Qwen con Llama...\n",
      "Procesando 8 preguntas en lotes de 4...\n",
      "   Evaluando lote 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98adeb6c97f940ba97aed5a3f8a291d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[2]: TimeoutError()\n",
      "Exception raised in Job[1]: TimeoutError()\n",
      "Exception raised in Job[5]: TimeoutError()\n",
      "Exception raised in Job[4]: TimeoutError()\n",
      "Exception raised in Job[3]: TimeoutError()\n",
      "Exception raised in Job[6]: TimeoutError()\n",
      "Exception raised in Job[8]: TimeoutError()\n",
      "Exception raised in Job[7]: TimeoutError()\n",
      "Exception raised in Job[11]: TimeoutError()\n",
      "Exception raised in Job[9]: TimeoutError()\n",
      "Exception raised in Job[10]: TimeoutError()\n",
      "Exception raised in Job[13]: TimeoutError()\n",
      "Exception raised in Job[14]: TimeoutError()\n",
      "Exception raised in Job[12]: TimeoutError()\n",
      "Exception raised in Job[15]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Evaluando lote 2/2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25b1fe6d45da423294d58af8c993bc4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[2]: TimeoutError()\n",
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[1]: TimeoutError()\n",
      "Exception raised in Job[6]: TimeoutError()\n",
      "Exception raised in Job[4]: TimeoutError()\n",
      "Exception raised in Job[5]: TimeoutError()\n",
      "Exception raised in Job[7]: TimeoutError()\n",
      "Exception raised in Job[3]: TimeoutError()\n",
      "Exception raised in Job[10]: TimeoutError()\n",
      "Exception raised in Job[9]: TimeoutError()\n",
      "Exception raised in Job[8]: TimeoutError()\n",
      "Exception raised in Job[11]: TimeoutError()\n",
      "Exception raised in Job[14]: TimeoutError()\n",
      "Exception raised in Job[13]: TimeoutError()\n",
      "Exception raised in Job[12]: TimeoutError()\n",
      "Exception raised in Job[15]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✅ Evaluación Llama → Qwen completada:\n",
      "QWEN COMBINACIÓN 4/9\n",
      "   Generador: Qwen3-4B-instruct-2507\n",
      "   Embedding: e5-large-instruct -> IdearqE5\n",
      "   Prompt: prompt_zero_shot\n",
      "Generando respuestas con Qwen...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. This article must therefore be hereby marked “advertisement” in accordance with 18 U.S.C. §1734 solely to indicate this fact. 14180–14185 PNAS November 20, 2001 vol. 98 no. 24 www.pnas.org cgi doi 10.1073 pnas.241522898 Downloaded from https://www.pnas.org by 2.138.20.97 on August 12, 2025 from IP...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  12%|█▎        | 1/8 [05:13<36:32, 313.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'5.º CONGRESSO DO NEOLÍTICO PENINSULAR 405 1. Introducción La minería del sílex en la Europa prehistórica tiene lugar en un marco cronológico bien conocido. Hay esca‑ sas y ocasionalmente ambiguas evidencias de explota‑ ciones del Pleistoceno (p.e. Baena et al., 2011), alguna dispersa para el Mesolít...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  25%|██▌       | 2/8 [07:08<19:39, 196.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. La cronología radiocarbónica de las primeras manifestaciones megalíticas en el sureste de la Península Ibérica… 273 Trab. Prehist., 74, N.º 2, julio-diciembre 2017, pp. 257-277, ISSN: 0082-5638 doi: 10.3989/tp.2017.12194 de probabilidad), posiblemente entre el 2395-2270 cal BC (68% de probabilidad...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  38%|███▊      | 3/8 [11:40<19:16, 231.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 1984: “La Muela de Alarilla. Un yacimiento de la Edad del Bronce en el valle medio del río Henares”. Revista de Arqueología 37: 6-16. Misiego, J. C.; Sanz, F. J.; Marcos, G. J. y Martín, M. A. 1999: “Excavaciones Arqueológicas en el castro de Sacaojos (Santiago de la Valduerna, León)”. Nu­ mantia ...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  50%|█████     | 4/8 [13:26<12:06, 181.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'81 ISSN: 1131-6993 El Bronce Final en el Levante de la península Ibérica: bases arqueológicas y periodización Late Bronze Age in Eastern Iberian Peninsula: Archaeological Bases and Periodization Francisco Javier Jover Maestre*, Alberto Lorrio Alvarado**\\n\\n---\\n\\n. Con el desarrollo de las excavacio...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  62%|██████▎   | 5/8 [18:23<11:09, 223.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Introducción Los objetos de adorno realizados con marfil de pro­ boscídeo son una constante en el registro material de los yacimientos de la península ibérica, sobre todo a partir de la primera mitad del II milenio cal BC, si bien en el sur están presentes desde inicios del III milenio cal BC. La ...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  75%|███████▌  | 6/8 [22:28<07:41, 230.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Demografía y poblamiento en la Meseta Sur entre el 5500 y el 1200 cal BC. Una perspectiva desde el Radiocarbono 84 La base de datos de dataciones de 14C de la Meseta Sur peninsular se caracteriza por la estructuración de la información cronológica en campos que permitan la situación geográfica de ...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  88%|████████▊ | 7/8 [27:36<04:16, 256.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. La cronología radiocarbónica de las primeras manifestaciones megalíticas en el sureste de la Península Ibérica… 273 Trab. Prehist., 74, N.º 2, julio-diciembre 2017, pp. 257-277, ISSN: 0082-5638 doi: 10.3989/tp.2017.12194 de probabilidad), posiblemente entre el 2395-2270 cal BC (68% de probabilidad...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas: 100%|██████████| 8/8 [30:19<00:00, 227.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "8/8 preguntas exitosas\n",
      "Evaluando respuestas de Qwen con Llama...\n",
      "Procesando 8 preguntas en lotes de 4...\n",
      "   Evaluando lote 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90908f2d6d564f40944bc23cdf3d3b1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[2]: TimeoutError()\n",
      "Exception raised in Job[1]: TimeoutError()\n",
      "Exception raised in Job[4]: TimeoutError()\n",
      "Exception raised in Job[3]: TimeoutError()\n",
      "Exception raised in Job[6]: TimeoutError()\n",
      "Exception raised in Job[5]: TimeoutError()\n",
      "Exception raised in Job[7]: TimeoutError()\n",
      "Exception raised in Job[10]: TimeoutError()\n",
      "Exception raised in Job[9]: TimeoutError()\n",
      "Exception raised in Job[8]: TimeoutError()\n",
      "Exception raised in Job[14]: TimeoutError()\n",
      "Exception raised in Job[11]: TimeoutError()\n",
      "Exception raised in Job[12]: TimeoutError()\n",
      "Exception raised in Job[13]: TimeoutError()\n",
      "Exception raised in Job[15]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Evaluando lote 2/2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1aab8b090224ee9a545aa46f5fc0581",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[2]: TimeoutError()\n",
      "Exception raised in Job[4]: TimeoutError()\n",
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[1]: TimeoutError()\n",
      "Exception raised in Job[3]: TimeoutError()\n",
      "Exception raised in Job[6]: TimeoutError()\n",
      "Exception raised in Job[7]: TimeoutError()\n",
      "Exception raised in Job[5]: TimeoutError()\n",
      "Exception raised in Job[9]: TimeoutError()\n",
      "Exception raised in Job[8]: TimeoutError()\n",
      "Exception raised in Job[11]: TimeoutError()\n",
      "Exception raised in Job[10]: TimeoutError()\n",
      "Exception raised in Job[12]: TimeoutError()\n",
      "Exception raised in Job[14]: TimeoutError()\n",
      "Exception raised in Job[13]: TimeoutError()\n",
      "Exception raised in Job[15]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✅ Evaluación Llama → Qwen completada:\n",
      "QWEN COMBINACIÓN 5/9\n",
      "   Generador: Qwen3-4B-instruct-2507\n",
      "   Embedding: e5-large-instruct -> IdearqE5\n",
      "   Prompt: prompt_one_shot\n",
      "Generando respuestas con Qwen...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. This article must therefore be hereby marked “advertisement” in accordance with 18 U.S.C. §1734 solely to indicate this fact. 14180–14185 PNAS November 20, 2001 vol. 98 no. 24 www.pnas.org cgi doi 10.1073 pnas.241522898 Downloaded from https://www.pnas.org by 2.138.20.97 on August 12, 2025 from IP...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  12%|█▎        | 1/8 [04:58<34:50, 298.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'5.º CONGRESSO DO NEOLÍTICO PENINSULAR 405 1. Introducción La minería del sílex en la Europa prehistórica tiene lugar en un marco cronológico bien conocido. Hay esca‑ sas y ocasionalmente ambiguas evidencias de explota‑ ciones del Pleistoceno (p.e. Baena et al., 2011), alguna dispersa para el Mesolít...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  25%|██▌       | 2/8 [06:27<17:31, 175.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. La cronología radiocarbónica de las primeras manifestaciones megalíticas en el sureste de la Península Ibérica… 273 Trab. Prehist., 74, N.º 2, julio-diciembre 2017, pp. 257-277, ISSN: 0082-5638 doi: 10.3989/tp.2017.12194 de probabilidad), posiblemente entre el 2395-2270 cal BC (68% de probabilidad...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  38%|███▊      | 3/8 [11:04<18:29, 221.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 1984: “La Muela de Alarilla. Un yacimiento de la Edad del Bronce en el valle medio del río Henares”. Revista de Arqueología 37: 6-16. Misiego, J. C.; Sanz, F. J.; Marcos, G. J. y Martín, M. A. 1999: “Excavaciones Arqueológicas en el castro de Sacaojos (Santiago de la Valduerna, León)”. Nu­ mantia ...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  50%|█████     | 4/8 [12:29<11:10, 167.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'81 ISSN: 1131-6993 El Bronce Final en el Levante de la península Ibérica: bases arqueológicas y periodización Late Bronze Age in Eastern Iberian Peninsula: Archaeological Bases and Periodization Francisco Javier Jover Maestre*, Alberto Lorrio Alvarado**\\n\\n---\\n\\n. Con el desarrollo de las excavacio...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  62%|██████▎   | 5/8 [17:19<10:35, 211.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Introducción Los objetos de adorno realizados con marfil de pro­ boscídeo son una constante en el registro material de los yacimientos de la península ibérica, sobre todo a partir de la primera mitad del II milenio cal BC, si bien en el sur están presentes desde inicios del III milenio cal BC. La ...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  75%|███████▌  | 6/8 [20:10<06:36, 198.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Demografía y poblamiento en la Meseta Sur entre el 5500 y el 1200 cal BC. Una perspectiva desde el Radiocarbono 84 La base de datos de dataciones de 14C de la Meseta Sur peninsular se caracteriza por la estructuración de la información cronológica en campos que permitan la situación geográfica de ...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  88%|████████▊ | 7/8 [25:39<04:00, 240.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. La cronología radiocarbónica de las primeras manifestaciones megalíticas en el sureste de la Península Ibérica… 273 Trab. Prehist., 74, N.º 2, julio-diciembre 2017, pp. 257-277, ISSN: 0082-5638 doi: 10.3989/tp.2017.12194 de probabilidad), posiblemente entre el 2395-2270 cal BC (68% de probabilidad...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas: 100%|██████████| 8/8 [28:55<00:00, 216.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "8/8 preguntas exitosas\n",
      "Evaluando respuestas de Qwen con Llama...\n",
      "Procesando 8 preguntas en lotes de 4...\n",
      "   Evaluando lote 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b70ee78f9cff47a18a5a5fbcef088fed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[2]: TimeoutError()\n",
      "Exception raised in Job[1]: TimeoutError()\n",
      "Exception raised in Job[3]: TimeoutError()\n",
      "Exception raised in Job[6]: TimeoutError()\n",
      "Exception raised in Job[5]: TimeoutError()\n",
      "Exception raised in Job[4]: TimeoutError()\n",
      "Exception raised in Job[7]: TimeoutError()\n",
      "Exception raised in Job[11]: TimeoutError()\n",
      "Exception raised in Job[10]: TimeoutError()\n",
      "Exception raised in Job[9]: TimeoutError()\n",
      "Exception raised in Job[8]: TimeoutError()\n",
      "Exception raised in Job[14]: TimeoutError()\n",
      "Exception raised in Job[12]: TimeoutError()\n",
      "Exception raised in Job[15]: TimeoutError()\n",
      "Exception raised in Job[13]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Evaluando lote 2/2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9259637802884924bc19cf989a28624f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[2]: TimeoutError()\n",
      "Exception raised in Job[5]: TimeoutError()\n",
      "Exception raised in Job[6]: TimeoutError()\n",
      "Exception raised in Job[3]: TimeoutError()\n",
      "Exception raised in Job[4]: TimeoutError()\n",
      "Exception raised in Job[1]: TimeoutError()\n",
      "Exception raised in Job[11]: TimeoutError()\n",
      "Exception raised in Job[12]: TimeoutError()\n",
      "Exception raised in Job[9]: TimeoutError()\n",
      "Exception raised in Job[7]: TimeoutError()\n",
      "Exception raised in Job[10]: TimeoutError()\n",
      "Exception raised in Job[8]: TimeoutError()\n",
      "Exception raised in Job[13]: TimeoutError()\n",
      "Exception raised in Job[14]: TimeoutError()\n",
      "Exception raised in Job[15]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✅ Evaluación Llama → Qwen completada:\n",
      "QWEN COMBINACIÓN 6/9\n",
      "   Generador: Qwen3-4B-instruct-2507\n",
      "   Embedding: e5-large-instruct -> IdearqE5\n",
      "   Prompt: prompt_few_shot\n",
      "Generando respuestas con Qwen...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. This article must therefore be hereby marked “advertisement” in accordance with 18 U.S.C. §1734 solely to indicate this fact. 14180–14185 PNAS November 20, 2001 vol. 98 no. 24 www.pnas.org cgi doi 10.1073 pnas.241522898 Downloaded from https://www.pnas.org by 2.138.20.97 on August 12, 2025 from IP...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  12%|█▎        | 1/8 [04:23<30:44, 263.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'5.º CONGRESSO DO NEOLÍTICO PENINSULAR 405 1. Introducción La minería del sílex en la Europa prehistórica tiene lugar en un marco cronológico bien conocido. Hay esca‑ sas y ocasionalmente ambiguas evidencias de explota‑ ciones del Pleistoceno (p.e. Baena et al., 2011), alguna dispersa para el Mesolít...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  25%|██▌       | 2/8 [05:54<16:11, 161.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. La cronología radiocarbónica de las primeras manifestaciones megalíticas en el sureste de la Península Ibérica… 273 Trab. Prehist., 74, N.º 2, julio-diciembre 2017, pp. 257-277, ISSN: 0082-5638 doi: 10.3989/tp.2017.12194 de probabilidad), posiblemente entre el 2395-2270 cal BC (68% de probabilidad...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  38%|███▊      | 3/8 [09:11<14:49, 178.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 1984: “La Muela de Alarilla. Un yacimiento de la Edad del Bronce en el valle medio del río Henares”. Revista de Arqueología 37: 6-16. Misiego, J. C.; Sanz, F. J.; Marcos, G. J. y Martín, M. A. 1999: “Excavaciones Arqueológicas en el castro de Sacaojos (Santiago de la Valduerna, León)”. Nu­ mantia ...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  50%|█████     | 4/8 [10:55<09:55, 148.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'81 ISSN: 1131-6993 El Bronce Final en el Levante de la península Ibérica: bases arqueológicas y periodización Late Bronze Age in Eastern Iberian Peninsula: Archaeological Bases and Periodization Francisco Javier Jover Maestre*, Alberto Lorrio Alvarado**\\n\\n---\\n\\n. Con el desarrollo de las excavacio...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  62%|██████▎   | 5/8 [15:52<10:06, 202.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Introducción Los objetos de adorno realizados con marfil de pro­ boscídeo son una constante en el registro material de los yacimientos de la península ibérica, sobre todo a partir de la primera mitad del II milenio cal BC, si bien en el sur están presentes desde inicios del III milenio cal BC. La ...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  75%|███████▌  | 6/8 [19:46<07:06, 213.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Demografía y poblamiento en la Meseta Sur entre el 5500 y el 1200 cal BC. Una perspectiva desde el Radiocarbono 84 La base de datos de dataciones de 14C de la Meseta Sur peninsular se caracteriza por la estructuración de la información cronológica en campos que permitan la situación geográfica de ...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  88%|████████▊ | 7/8 [25:00<04:06, 246.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. La cronología radiocarbónica de las primeras manifestaciones megalíticas en el sureste de la Península Ibérica… 273 Trab. Prehist., 74, N.º 2, julio-diciembre 2017, pp. 257-277, ISSN: 0082-5638 doi: 10.3989/tp.2017.12194 de probabilidad), posiblemente entre el 2395-2270 cal BC (68% de probabilidad...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas: 100%|██████████| 8/8 [27:29<00:00, 206.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "8/8 preguntas exitosas\n",
      "Evaluando respuestas de Qwen con Llama...\n",
      "Procesando 8 preguntas en lotes de 4...\n",
      "   Evaluando lote 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86187debbb8e45a0949f8e53bcc36015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[3]: TimeoutError()\n",
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[1]: TimeoutError()\n",
      "Exception raised in Job[6]: TimeoutError()\n",
      "Exception raised in Job[2]: TimeoutError()\n",
      "Exception raised in Job[5]: TimeoutError()\n",
      "Exception raised in Job[4]: TimeoutError()\n",
      "Exception raised in Job[10]: TimeoutError()\n",
      "Exception raised in Job[9]: TimeoutError()\n",
      "Exception raised in Job[8]: TimeoutError()\n",
      "Exception raised in Job[7]: TimeoutError()\n",
      "Exception raised in Job[14]: TimeoutError()\n",
      "Exception raised in Job[12]: TimeoutError()\n",
      "Exception raised in Job[13]: TimeoutError()\n",
      "Exception raised in Job[15]: TimeoutError()\n",
      "Exception raised in Job[11]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Evaluando lote 2/2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a85de74ce72e48729f2ee83cab8952d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[2]: TimeoutError()\n",
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[1]: TimeoutError()\n",
      "Exception raised in Job[6]: TimeoutError()\n",
      "Exception raised in Job[4]: TimeoutError()\n",
      "Exception raised in Job[5]: TimeoutError()\n",
      "Exception raised in Job[3]: TimeoutError()\n",
      "Exception raised in Job[9]: TimeoutError()\n",
      "Exception raised in Job[7]: TimeoutError()\n",
      "Exception raised in Job[10]: TimeoutError()\n",
      "Exception raised in Job[8]: TimeoutError()\n",
      "Exception raised in Job[11]: TimeoutError()\n",
      "Exception raised in Job[12]: TimeoutError()\n",
      "Exception raised in Job[13]: TimeoutError()\n",
      "Exception raised in Job[15]: TimeoutError()\n",
      "Exception raised in Job[14]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✅ Evaluación Llama → Qwen completada:\n",
      "QWEN COMBINACIÓN 7/9\n",
      "   Generador: Qwen3-4B-instruct-2507\n",
      "   Embedding: gte-multilingual-base -> IdearqGTE\n",
      "   Prompt: prompt_zero_shot\n",
      "Generando respuestas con Qwen...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Published by Elsevier Inc. All rights reserved. doi:10.1016/j.yqres.2011.12.003 Contents lists available at SciVerse ScienceDirect Quaternary Research journal homepage: www.elsevier.com/locate/yqres https://doi.org/10.1016/j.yqres.2011.12.003 Published online by Cambridge University Press Introduc...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  12%|█▎        | 1/8 [04:53<34:13, 293.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'5.º CONGRESSO DO NEOLÍTICO PENINSULAR 405 1. Introducción La minería del sílex en la Europa prehistórica tiene lugar en un marco cronológico bien conocido. Hay esca‑ sas y ocasionalmente ambiguas evidencias de explota‑ ciones del Pleistoceno (p.e. Baena et al., 2011), alguna dispersa para el Mesolít...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  25%|██▌       | 2/8 [07:25<21:02, 210.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Págs. 253-273 ISBN: 978-84-8317-921-5 · ISBN: 978-84-940141-2-3 Resumen La región cantábrica ha proporcionado una de las principales concentraciones de testimonios funerarios mesolíticos del continente europeo, con un registro prácticamente continuo desde el Aziliense hasta el final del período, e...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  38%|███▊      | 3/8 [12:18<20:40, 248.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 141 Complutum 32(1) 2021: 141-165 Complutum ISSN: 1131-6993 https://dx.doi.org//cmpl.76452 ARTÍCULOS La panoplia de finales de la IIª Edad del Hierro de la sima de La Cerrosa-Lagaña (Suarías, Peñamellera Baja, Asturias). ¿Un conjunto asociado a las Guerras Cántabras?1 Susana de Luis Mariño2; Maria...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  50%|█████     | 4/8 [13:40<12:09, 182.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Con el desarrollo de las excavaciones arqueológicas en diversos asentamientos, el aumento del número de dataciones y la realización de diversos estudios en los últimos años, las perspectivas de investigación sobre el Bronce final en el Levante comienza a variar sustancialmente, estando ya en condi...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  62%|██████▎   | 5/8 [19:14<11:51, 237.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Jover Maestre, F.J., López, J.A. y García, G. (2021): De las primeras comunidades neolíticas a la confi­ guración de los grupos iberos en el Levante de la pe­ nínsula ibérica. Alicante Kristiansen, K. y Larsson, T.B. (2006): La emergen­ cia de la sociedad del Bronce. Viajes, transmisiones y transf...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  75%|███████▌  | 6/8 [22:56<07:43, 231.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Causas internas más o menos imbricadas con la evolución paleoambiental y las respuestas sociales a estos cambios, o bien, de origen externo ligadas a la presión ejer- cida por los primeros grupos neolíticos han sido descritas (García Puchol et al., 2006). - De este modo, la pionera implantación ne...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  88%|████████▊ | 7/8 [27:57<04:14, 254.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. MESTRES, J.S. y NICOLÁS, J.C. de, 1999, Contribución de la datación por radiocarbono al establecimiento de la cronología absoluta de la prehistoria de Menorca, Caesaraugusta, 73, Zaragoza, p.327-341. El megalitismo mallorquín en el contexto del... MOLIST, M. y CLOP, X., 2000, La investigación sobr...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas: 100%|██████████| 8/8 [31:23<00:00, 235.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "8/8 preguntas exitosas\n",
      "Evaluando respuestas de Qwen con Llama...\n",
      "Procesando 8 preguntas en lotes de 4...\n",
      "   Evaluando lote 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41c395ee539445ea94fb03d6c389fbfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[1]: TimeoutError()\n",
      "Exception raised in Job[2]: TimeoutError()\n",
      "Exception raised in Job[4]: TimeoutError()\n",
      "Exception raised in Job[3]: TimeoutError()\n",
      "Exception raised in Job[5]: TimeoutError()\n",
      "Exception raised in Job[6]: TimeoutError()\n",
      "Exception raised in Job[7]: TimeoutError()\n",
      "Exception raised in Job[9]: TimeoutError()\n",
      "Exception raised in Job[8]: TimeoutError()\n",
      "Exception raised in Job[14]: TimeoutError()\n",
      "Exception raised in Job[12]: TimeoutError()\n",
      "Exception raised in Job[13]: TimeoutError()\n",
      "Exception raised in Job[11]: TimeoutError()\n",
      "Exception raised in Job[10]: TimeoutError()\n",
      "Exception raised in Job[15]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Evaluando lote 2/2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "229db13dc95f42f3bec8a5b55b277e7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[1]: TimeoutError()\n",
      "Exception raised in Job[5]: TimeoutError()\n",
      "Exception raised in Job[2]: TimeoutError()\n",
      "Exception raised in Job[4]: TimeoutError()\n",
      "Exception raised in Job[3]: TimeoutError()\n",
      "Exception raised in Job[6]: TimeoutError()\n",
      "Exception raised in Job[8]: TimeoutError()\n",
      "Exception raised in Job[7]: TimeoutError()\n",
      "Exception raised in Job[10]: TimeoutError()\n",
      "Exception raised in Job[11]: TimeoutError()\n",
      "Exception raised in Job[9]: TimeoutError()\n",
      "Exception raised in Job[13]: TimeoutError()\n",
      "Exception raised in Job[14]: TimeoutError()\n",
      "Exception raised in Job[15]: TimeoutError()\n",
      "Exception raised in Job[12]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✅ Evaluación Llama → Qwen completada:\n",
      "QWEN COMBINACIÓN 8/9\n",
      "   Generador: Qwen3-4B-instruct-2507\n",
      "   Embedding: gte-multilingual-base -> IdearqGTE\n",
      "   Prompt: prompt_one_shot\n",
      "Generando respuestas con Qwen...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Published by Elsevier Inc. All rights reserved. doi:10.1016/j.yqres.2011.12.003 Contents lists available at SciVerse ScienceDirect Quaternary Research journal homepage: www.elsevier.com/locate/yqres https://doi.org/10.1016/j.yqres.2011.12.003 Published online by Cambridge University Press Introduc...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  12%|█▎        | 1/8 [05:35<39:06, 335.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'5.º CONGRESSO DO NEOLÍTICO PENINSULAR 405 1. Introducción La minería del sílex en la Europa prehistórica tiene lugar en un marco cronológico bien conocido. Hay esca‑ sas y ocasionalmente ambiguas evidencias de explota‑ ciones del Pleistoceno (p.e. Baena et al., 2011), alguna dispersa para el Mesolít...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  25%|██▌       | 2/8 [07:49<21:40, 216.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Págs. 253-273 ISBN: 978-84-8317-921-5 · ISBN: 978-84-940141-2-3 Resumen La región cantábrica ha proporcionado una de las principales concentraciones de testimonios funerarios mesolíticos del continente europeo, con un registro prácticamente continuo desde el Aziliense hasta el final del período, e...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  38%|███▊      | 3/8 [12:37<20:47, 249.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 141 Complutum 32(1) 2021: 141-165 Complutum ISSN: 1131-6993 https://dx.doi.org//cmpl.76452 ARTÍCULOS La panoplia de finales de la IIª Edad del Hierro de la sima de La Cerrosa-Lagaña (Suarías, Peñamellera Baja, Asturias). ¿Un conjunto asociado a las Guerras Cántabras?1 Susana de Luis Mariño2; Maria...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  50%|█████     | 4/8 [14:06<12:24, 186.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Con el desarrollo de las excavaciones arqueológicas en diversos asentamientos, el aumento del número de dataciones y la realización de diversos estudios en los últimos años, las perspectivas de investigación sobre el Bronce final en el Levante comienza a variar sustancialmente, estando ya en condi...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  62%|██████▎   | 5/8 [18:20<10:31, 210.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Jover Maestre, F.J., López, J.A. y García, G. (2021): De las primeras comunidades neolíticas a la confi­ guración de los grupos iberos en el Levante de la pe­ nínsula ibérica. Alicante Kristiansen, K. y Larsson, T.B. (2006): La emergen­ cia de la sociedad del Bronce. Viajes, transmisiones y transf...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  75%|███████▌  | 6/8 [22:13<07:16, 218.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Causas internas más o menos imbricadas con la evolución paleoambiental y las respuestas sociales a estos cambios, o bien, de origen externo ligadas a la presión ejer- cida por los primeros grupos neolíticos han sido descritas (García Puchol et al., 2006). - De este modo, la pionera implantación ne...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  88%|████████▊ | 7/8 [27:52<04:17, 257.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. MESTRES, J.S. y NICOLÁS, J.C. de, 1999, Contribución de la datación por radiocarbono al establecimiento de la cronología absoluta de la prehistoria de Menorca, Caesaraugusta, 73, Zaragoza, p.327-341. El megalitismo mallorquín en el contexto del... MOLIST, M. y CLOP, X., 2000, La investigación sobr...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas: 100%|██████████| 8/8 [30:48<00:00, 231.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "8/8 preguntas exitosas\n",
      "Evaluando respuestas de Qwen con Llama...\n",
      "Procesando 8 preguntas en lotes de 4...\n",
      "   Evaluando lote 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c61fba15ef1c48fb9b2eb156427f4cd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[1]: TimeoutError()\n",
      "Exception raised in Job[2]: TimeoutError()\n",
      "Exception raised in Job[4]: TimeoutError()\n",
      "Exception raised in Job[3]: TimeoutError()\n",
      "Exception raised in Job[5]: TimeoutError()\n",
      "Exception raised in Job[6]: TimeoutError()\n",
      "Exception raised in Job[8]: TimeoutError()\n",
      "Exception raised in Job[7]: TimeoutError()\n",
      "Exception raised in Job[10]: TimeoutError()\n",
      "Exception raised in Job[11]: TimeoutError()\n",
      "Exception raised in Job[9]: TimeoutError()\n",
      "Exception raised in Job[12]: TimeoutError()\n",
      "Exception raised in Job[13]: TimeoutError()\n",
      "Exception raised in Job[14]: TimeoutError()\n",
      "Exception raised in Job[15]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Evaluando lote 2/2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d76f8f391454e69afffd3768627d67e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[1]: TimeoutError()\n",
      "Exception raised in Job[2]: TimeoutError()\n",
      "Exception raised in Job[5]: TimeoutError()\n",
      "Exception raised in Job[4]: TimeoutError()\n",
      "Exception raised in Job[3]: TimeoutError()\n",
      "Exception raised in Job[6]: TimeoutError()\n",
      "Exception raised in Job[10]: TimeoutError()\n",
      "Exception raised in Job[9]: TimeoutError()\n",
      "Exception raised in Job[8]: TimeoutError()\n",
      "Exception raised in Job[7]: TimeoutError()\n",
      "Exception raised in Job[13]: TimeoutError()\n",
      "Exception raised in Job[12]: TimeoutError()\n",
      "Exception raised in Job[15]: TimeoutError()\n",
      "Exception raised in Job[11]: TimeoutError()\n",
      "Exception raised in Job[14]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✅ Evaluación Llama → Qwen completada:\n",
      "QWEN COMBINACIÓN 9/9\n",
      "   Generador: Qwen3-4B-instruct-2507\n",
      "   Embedding: gte-multilingual-base -> IdearqGTE\n",
      "   Prompt: prompt_few_shot\n",
      "Generando respuestas con Qwen...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Published by Elsevier Inc. All rights reserved. doi:10.1016/j.yqres.2011.12.003 Contents lists available at SciVerse ScienceDirect Quaternary Research journal homepage: www.elsevier.com/locate/yqres https://doi.org/10.1016/j.yqres.2011.12.003 Published online by Cambridge University Press Introduc...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  12%|█▎        | 1/8 [05:51<40:57, 351.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'5.º CONGRESSO DO NEOLÍTICO PENINSULAR 405 1. Introducción La minería del sílex en la Europa prehistórica tiene lugar en un marco cronológico bien conocido. Hay esca‑ sas y ocasionalmente ambiguas evidencias de explota‑ ciones del Pleistoceno (p.e. Baena et al., 2011), alguna dispersa para el Mesolít...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  25%|██▌       | 2/8 [08:33<23:59, 240.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Págs. 253-273 ISBN: 978-84-8317-921-5 · ISBN: 978-84-940141-2-3 Resumen La región cantábrica ha proporcionado una de las principales concentraciones de testimonios funerarios mesolíticos del continente europeo, con un registro prácticamente continuo desde el Aziliense hasta el final del período, e...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  38%|███▊      | 3/8 [12:22<19:36, 235.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 141 Complutum 32(1) 2021: 141-165 Complutum ISSN: 1131-6993 https://dx.doi.org//cmpl.76452 ARTÍCULOS La panoplia de finales de la IIª Edad del Hierro de la sima de La Cerrosa-Lagaña (Suarías, Peñamellera Baja, Asturias). ¿Un conjunto asociado a las Guerras Cántabras?1 Susana de Luis Mariño2; Maria...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  50%|█████     | 4/8 [13:44<11:38, 174.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Con el desarrollo de las excavaciones arqueológicas en diversos asentamientos, el aumento del número de dataciones y la realización de diversos estudios en los últimos años, las perspectivas de investigación sobre el Bronce final en el Levante comienza a variar sustancialmente, estando ya en condi...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  62%|██████▎   | 5/8 [20:37<13:01, 260.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Jover Maestre, F.J., López, J.A. y García, G. (2021): De las primeras comunidades neolíticas a la confi­ guración de los grupos iberos en el Levante de la pe­ nínsula ibérica. Alicante Kristiansen, K. y Larsson, T.B. (2006): La emergen­ cia de la sociedad del Bronce. Viajes, transmisiones y transf...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  75%|███████▌  | 6/8 [24:20<08:15, 247.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Causas internas más o menos imbricadas con la evolución paleoambiental y las respuestas sociales a estos cambios, o bien, de origen externo ligadas a la presión ejer- cida por los primeros grupos neolíticos han sido descritas (García Puchol et al., 2006). - De este modo, la pionera implantación ne...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  88%|████████▊ | 7/8 [29:53<04:35, 275.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. MESTRES, J.S. y NICOLÁS, J.C. de, 1999, Contribución de la datación por radiocarbono al establecimiento de la cronología absoluta de la prehistoria de Menorca, Caesaraugusta, 73, Zaragoza, p.327-341. El megalitismo mallorquín en el contexto del... MOLIST, M. y CLOP, X., 2000, La investigación sobr...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas: 100%|██████████| 8/8 [32:10<00:00, 241.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "8/8 preguntas exitosas\n",
      "Evaluando respuestas de Qwen con Llama...\n",
      "Procesando 8 preguntas en lotes de 4...\n",
      "   Evaluando lote 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da9b3178bdb54c3fa1fff0781ab737bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[2]: TimeoutError()\n",
      "Exception raised in Job[1]: TimeoutError()\n",
      "Exception raised in Job[3]: TimeoutError()\n",
      "Exception raised in Job[6]: TimeoutError()\n",
      "Exception raised in Job[5]: TimeoutError()\n",
      "Exception raised in Job[4]: TimeoutError()\n",
      "Exception raised in Job[9]: TimeoutError()\n",
      "Exception raised in Job[10]: TimeoutError()\n",
      "Exception raised in Job[8]: TimeoutError()\n",
      "Exception raised in Job[7]: TimeoutError()\n",
      "Exception raised in Job[11]: TimeoutError()\n",
      "Exception raised in Job[14]: TimeoutError()\n",
      "Exception raised in Job[13]: TimeoutError()\n",
      "Exception raised in Job[12]: TimeoutError()\n",
      "Exception raised in Job[15]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Evaluando lote 2/2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef59d3a4a40244b48989a563e2ab8ba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/16 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[2]: TimeoutError()\n",
      "Exception raised in Job[1]: TimeoutError()\n",
      "Exception raised in Job[3]: TimeoutError()\n",
      "Exception raised in Job[5]: TimeoutError()\n",
      "Exception raised in Job[4]: TimeoutError()\n",
      "Exception raised in Job[9]: TimeoutError()\n",
      "Exception raised in Job[6]: TimeoutError()\n",
      "Exception raised in Job[8]: TimeoutError()\n",
      "Exception raised in Job[7]: TimeoutError()\n",
      "Exception raised in Job[11]: TimeoutError()\n",
      "Exception raised in Job[13]: TimeoutError()\n",
      "Exception raised in Job[10]: TimeoutError()\n",
      "Exception raised in Job[12]: TimeoutError()\n",
      "Exception raised in Job[15]: TimeoutError()\n",
      "Exception raised in Job[14]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✅ Evaluación Llama → Qwen completada:\n",
      "\n",
      "================================================================================\n",
      "EVALUACIÓN QWEN COMPLETADA\n",
      "================================================================================\n",
      "✅ Resultados detallados Qwen: (72, 13)\n",
      "✅ Métricas resumen Qwen: (9, 17)\n",
      "Resultados Qwen guardados:\n",
      "   Detallado: qwen_evaluation_detailed_20250916_022939.csv\n",
      "   Métricas: qwen_evaluation_metrics_20250916_022939.csv\n",
      "\n",
      "RESUMEN QWEN:\n",
      "   Combinaciones totales: 9\n",
      "   Evaluaciones exitosas: 9\n",
      "   Tasa de éxito: 100.0%\n",
      "\n",
      "MEJORES COMBINACIONES QWEN:\n",
      "\n",
      "CONTEXT RECALL MEAN:\n",
      " embedding_model      prompt_type  context_recall_mean\n",
      "all-MiniLM-L6-v2 prompt_zero_shot                  1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"EVALUACIÓN CON GENERADOR QWEN\")\n",
    "print(\"Generador: Qwen3-4B-instruct-2507\")\n",
    "print(f\"Evaluador: {llama_evaluator.model}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Configuración específica para Qwen como GENERADOR\n",
    "test_llm = 'Qwen3-4B-instruct-2507'  # GENERADOR de respuestas RAG\n",
    "\n",
    "# Listas para almacenar resultados de Qwen\n",
    "qwen_detailed_results = []\n",
    "qwen_metrics_results = []\n",
    "\n",
    "# Generar combinaciones solo para Qwen\n",
    "qwen_combinations = list(product([test_llm], embeddings, prompts))\n",
    "total_qwen_combinations = len(qwen_combinations)\n",
    "\n",
    "print(f\"Evaluando {total_qwen_combinations} combinaciones para Qwen:\")\n",
    "for emb in embeddings:\n",
    "    for prompt in prompts:\n",
    "         print(f\"   • {test_llm} + {emb} + {prompt}\")\n",
    "print()\n",
    "\n",
    "# Evaluar cada combinación de Qwen\n",
    "for combo_idx, (llm_name, test_embedding, test_prompt) in enumerate(qwen_combinations):\n",
    "\n",
    "    print(f\"QWEN COMBINACIÓN {combo_idx+1}/{total_qwen_combinations}\")\n",
    "    print(f\"   Generador: {llm_name}\")\n",
    "    print(f\"   Embedding: {test_embedding} -> {WEAVIATE_CLASSES[test_embedding]}\")\n",
    "    print(f\"   Prompt: {test_prompt}\")\n",
    "\n",
    "    combination_start_time = time.time()\n",
    "    results_list = []\n",
    "    successful_questions = 0\n",
    "\n",
    "    # Generar respuestas para todas las preguntas\n",
    "    print(\"Generando respuestas con Qwen...\")\n",
    "    for q_idx, question in enumerate(tqdm(questions, desc=\"   Preguntas\")):\n",
    "        try:\n",
    "            state = {\n",
    "                'question': question,\n",
    "                'llm_name': llm_name,  # Qwen genera la respuesta\n",
    "                'embedding_name': test_embedding,\n",
    "                'prompt_name': test_prompt,\n",
    "                'context': [], 'answer': '', 'metadata': {}\n",
    "            }\n",
    "\n",
    "            final_state = graph.invoke(state)  # Qwen genera respuesta RAG\n",
    "            answer = final_state.get('answer', '')\n",
    "            contexts = final_state.get('context', [])\n",
    "\n",
    "            if answer and 'ERROR:' not in answer and len(contexts) > 0:\n",
    "                # Almacenar para dataset RAGAS\n",
    "                results_list.append({\n",
    "                    'question': question,\n",
    "                    'answer': answer,  # Respuesta generada por Qwen\n",
    "                    'contexts': [doc.page_content for doc in contexts],\n",
    "                    'ground_truth': ground_truths[q_idx] if q_idx < len(ground_truths) else ''\n",
    "                 })\n",
    "                successful_questions += 1\n",
    "\n",
    "            # Almacenar detalles individuales\n",
    "            qwen_detailed_results.append({\n",
    "                'combination_id': combo_idx,\n",
    "                'generator_llm': llm_name,  # Qwen generador\n",
    "                'evaluator_llm': llama_evaluator.model,  # Llama evaluador\n",
    "                'embedding_model': test_embedding,\n",
    "                'weaviate_collection': WEAVIATE_CLASSES[test_embedding],\n",
    "                'prompt_type': test_prompt,\n",
    "                'question_id': q_idx,\n",
    "                'question': question,\n",
    "                'answer': answer,\n",
    "                'contexts': [doc.page_content for doc in contexts],\n",
    "                'num_contexts': len(contexts),\n",
    "                'ground_truth': ground_truths[q_idx] if q_idx < len(ground_truths) else '',\n",
    "                'status': 'success' if answer and 'ERROR:' not in answer else 'error'\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error en pregunta {q_idx+1}: {e}\")\n",
    "            qwen_detailed_results.append({\n",
    "                'combination_id': combo_idx,\n",
    "                'generator_llm': llm_name,\n",
    "                'evaluator_llm': llama_evaluator.model,\n",
    "                'embedding_model': test_embedding,\n",
    "                'weaviate_collection': WEAVIATE_CLASSES[test_embedding],\n",
    "                'prompt_type': test_prompt,\n",
    "                'question_id': q_idx,\n",
    "                'question': question,\n",
    "                'answer': f'ERROR: {str(e)}',\n",
    "                'contexts': [],\n",
    "                'num_contexts': 0,\n",
    "                'ground_truth': ground_truths[q_idx] if q_idx < len(ground_truths) else '',\n",
    "                'status': 'error'\n",
    "             })\n",
    "\n",
    "    print(f\"{successful_questions}/{len(questions)} preguntas exitosas\")\n",
    "\n",
    "    # Evaluar con RAGAS usando Llama como evaluador\n",
    "    if successful_questions >= 2:\n",
    "        print(\"Evaluando respuestas de Qwen con Llama...\" )\n",
    "\n",
    "        try:\n",
    "            dataset = Dataset.from_list(results_list)\n",
    "              # USAR EL EMBEDDING ESPECÍFICO DE ESTA COMBINACIÓN\n",
    "            current_embedding_model = EMBEDDING_MODELS[test_embedding]\n",
    "\n",
    "            # CONFIGURACIÓN PARA EVITAR TIMEOUTS\n",
    "            import asyncio\n",
    "            asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())\n",
    "\n",
    "            # Procesar en lotes pequeños si hay muchas preguntas\n",
    "            if len(results_list) > 4:\n",
    "                print(f\"Procesando {len(results_list)} preguntas en lotes de 4...\")\n",
    "\n",
    "                # Dividir en lotes de 4\n",
    "                batch_results = []\n",
    "                for i in range(0, len(results_list), 4):\n",
    "                    batch = results_list[i:i+4]\n",
    "                    batch_dataset = Dataset.from_list(batch)\n",
    "\n",
    "                    print(f\"   Evaluando lote {i//4 + 1}/{(len(results_list) + 3)//4}\")\n",
    "\n",
    "                    batch_eval = evaluate(\n",
    "                        batch_dataset,\n",
    "                        llm=llama_evaluator,\n",
    "                        embeddings=current_embedding_model,\n",
    "                        metrics=[context_precision, context_recall, faithfulness, answer_correctness],\n",
    "                        raise_exceptions=False\n",
    "                    )\n",
    "                    batch_results.append(batch_eval.to_pandas())\n",
    "\n",
    "                    # Pausa entre lotes\n",
    "                    time.sleep(30)\n",
    "\n",
    "                # Combinar resultados\n",
    "                metrics_df = pd.concat(batch_results, ignore_index=True)\n",
    "\n",
    "            else:\n",
    "                # Evaluación normal para pocos elementos\n",
    "                evaluation_results = evaluate(\n",
    "                    dataset,\n",
    "                    llm=llama_evaluator,\n",
    "                    embeddings=current_embedding_model,\n",
    "                    metrics=[context_precision, context_recall, faithfulness, answer_correctness],\n",
    "                    raise_exceptions=False\n",
    "                )\n",
    "                metrics_df = evaluation_results.to_pandas()\n",
    "\n",
    "            # Función para calcular métricas seguras\n",
    "            def safe_mean_std(series):\n",
    "                clean_series = series.dropna()\n",
    "                if len(clean_series) > 0:\n",
    "                    return clean_series.mean(), clean_series.std()\n",
    "                return None, None\n",
    "\n",
    "            avg_metrics = {}\n",
    "            for metric in ['context_precision', 'context_recall', 'faithfulness', 'answer_correctness']:\n",
    "                if metric in metrics_df.columns:\n",
    "                    mean_val, std_val = safe_mean_std(metrics_df[metric])\n",
    "                    avg_metrics[f'{metric}_mean'] = mean_val\n",
    "                    avg_metrics[f'{metric}_std'] = std_val\n",
    "\n",
    "            # Guardar métricas de la combinación\n",
    "            combination_metrics = {\n",
    "                'combination_id': combo_idx,\n",
    "                'generator_llm': llm_name,\n",
    "                'evaluator_llm': llama_evaluator.model,\n",
    "                'embedding_model': test_embedding,\n",
    "                'weaviate_collection': WEAVIATE_CLASSES[test_embedding],\n",
    "                'prompt_type': test_prompt,\n",
    "                'total_questions': len(questions),\n",
    "                'successful_questions': successful_questions,\n",
    "                'evaluation_time_seconds': time.time() - combination_start_time,\n",
    "                **avg_metrics\n",
    "            }\n",
    "            qwen_metrics_results.append(combination_metrics)\n",
    "\n",
    "            print(f\"   ✅ Evaluación Llama → Qwen completada:\")\n",
    "            for metric in ['context_precision_mean', 'context_recall_mean', 'faithfulness_mean', 'answer_correctness_mean']:\n",
    "                if metric in avg_metrics and avg_metrics[metric] is not None:\n",
    "                    print(f\"      {metric.replace('_mean', '').title()}: {avg_metrics[metric]:.3f}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Error en evaluación RAGAS: {e}\")\n",
    "            qwen_metrics_results.append({\n",
    "                'combination_id': combo_idx,\n",
    "                'generator_llm': llm_name,\n",
    "                'evaluator_llm': llama_evaluator.model,\n",
    "                'embedding_model': test_embedding,\n",
    "                'weaviate_collection': WEAVIATE_CLASSES[test_embedding],\n",
    "                'prompt_type': test_prompt,\n",
    "                'total_questions': len(questions),\n",
    "                'successful_questions': successful_questions,\n",
    "                'evaluation_time_seconds': time.time() - combination_start_time,\n",
    "                'context_precision_mean': None,\n",
    "                'context_recall_mean': None,\n",
    "                'faithfulness_mean': None,\n",
    "                'answer_correctness_mean': None,\n",
    "                'context_precision_std': None,\n",
    "                'context_recall_std': None,\n",
    "                'faithfulness_std': None,\n",
    "                'answer_correctness_std': None,\n",
    "                'error': str(e)\n",
    "            })\n",
    "    else:\n",
    "        print(f\"   ⚠️  Solo {successful_questions} preguntas exitosas, saltando RAGAS\")\n",
    "        qwen_metrics_results.append({\n",
    "            'combination_id': combo_idx,\n",
    "            'generator_llm': llm_name,\n",
    "            'evaluator_llm': llama_evaluator.model,\n",
    "            'embedding_model': test_embedding,\n",
    "            'weaviate_collection': WEAVIATE_CLASSES[test_embedding],\n",
    "            'prompt_type': test_prompt,\n",
    "            'total_questions': len(questions),\n",
    "            'successful_questions': successful_questions,\n",
    "            'evaluation_time_seconds': time.time() - combination_start_time,\n",
    "             'error': 'Insufficient successful questions'\n",
    "     })\n",
    "\n",
    "  # Crear DataFrames de resultados de Qwen\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EVALUACIÓN QWEN COMPLETADA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "qwen_detailed_df = pd.DataFrame(qwen_detailed_results)\n",
    "qwen_metrics_df = pd.DataFrame(qwen_metrics_results)\n",
    "\n",
    "print(f\"✅ Resultados detallados Qwen: {qwen_detailed_df.shape}\")\n",
    "print(f\"✅ Métricas resumen Qwen: {qwen_metrics_df.shape}\")\n",
    "\n",
    "  # Guardar resultados de Qwen\n",
    "timestamp = pd.Timestamp.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "qwen_detailed_csv = f'qwen_evaluation_detailed_{timestamp}.csv'\n",
    "qwen_metrics_csv = f'qwen_evaluation_metrics_{timestamp}.csv'\n",
    "\n",
    "qwen_detailed_df.to_csv(qwen_detailed_csv, index=False, encoding='utf-8')\n",
    "qwen_metrics_df.to_csv(qwen_metrics_csv, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"Resultados Qwen guardados:\")\n",
    "print(f\"   Detallado: {qwen_detailed_csv}\")\n",
    "print(f\"   Métricas: {qwen_metrics_csv}\")\n",
    "\n",
    "  # Mostrar mejores combinaciones de Qwen\n",
    "if not qwen_metrics_df.empty:\n",
    "    successful_qwen = len([c for c in qwen_metrics_results if 'error' not in c or not c.get('error')])\n",
    "    print(f\"\\nRESUMEN QWEN:\")\n",
    "    print(f\"   Combinaciones totales: {total_qwen_combinations}\")\n",
    "    print(f\"   Evaluaciones exitosas: {successful_qwen}\")\n",
    "    print(f\"   Tasa de éxito: {successful_qwen/total_qwen_combinations*100:.1f}%\")\n",
    "\n",
    "    print(f\"\\nMEJORES COMBINACIONES QWEN:\")\n",
    "\n",
    "    for metric in ['context_precision_mean', 'context_recall_mean', 'faithfulness_mean', 'answer_correctness_mean']:\n",
    "        if metric in qwen_metrics_df.columns:\n",
    "            valid_data = qwen_metrics_df[qwen_metrics_df[metric].notna()]\n",
    "            if not valid_data.empty:\n",
    "                print(f\"\\n{metric.upper().replace('_', ' ')}:\")\n",
    "                top_qwen = valid_data.nlargest(3, metric)[['embedding_model', 'prompt_type', metric]]\n",
    "                print(top_qwen.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROBQAR EWSTYO\n",
    "Los modelos más rápidos para evitar timeouts:\n",
    "\n",
    "  1. llama3.2:1b - El más rápido (20-30 segundos por evaluación)        \n",
    "  2. qwen2.5:1.5b - Muy rápido (30-40 segundos)\n",
    "  3. phi3.5:3.8b - Rápido (60-90 segundos)\n",
    "\n",
    "  🎯 Opción 2: Volver a Mistral API (recomendado)\n",
    "\n",
    "  Mucho más rápido que cualquier modelo local (~2-5 segundos vs minutos)\n",
    "\n",
    "  📋 CÓDIGO: Solo Qwen con Mistral API como evaluador\n",
    "\n",
    "  from itertools import product\n",
    "  from datasets import Dataset\n",
    "  import pandas as pd\n",
    "  import time\n",
    "  from tqdm import tqdm\n",
    "  import warnings\n",
    "  import random\n",
    "  warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "  # Importar RAGAS y métricas\n",
    "  from ragas import evaluate\n",
    "  from ragas.metrics import (\n",
    "      context_precision,\n",
    "      context_recall,\n",
    "      faithfulness,\n",
    "      answer_correctness\n",
    "  )\n",
    "\n",
    "  # 🎯 VOLVER A MISTRAL API COMO EVALUADOR (MÁS RÁPIDO)\n",
    "  from langchain_mistralai import ChatMistralAI\n",
    "\n",
    "  mistral_evaluator = ChatMistralAI(\n",
    "      api_key=\"dv0RMPhxjgwM6pePID1FXvloyU2iltVu\",\n",
    "      model=\"mistral-small-latest\",\n",
    "      temperature=0.1,\n",
    "      max_retries=5\n",
    "  )\n",
    "\n",
    "  # Función para manejar rate limits automáticamente\n",
    "  def evaluate_with_rate_limit_handling(dataset, llm, embeddings_model, max_attempts=3):\n",
    "      base_delay = 60\n",
    "\n",
    "      for attempt in range(max_attempts):\n",
    "          try:\n",
    "              print(f\"      🔄 Evaluación intento {attempt + 1}/{max_attempts}\")\n",
    "\n",
    "              result = evaluate(\n",
    "                  dataset,\n",
    "                  llm=llm,\n",
    "                  embeddings=embeddings_model,\n",
    "                  metrics=[context_precision, context_recall, faithfulness, answer_correctness],\n",
    "                  raise_exceptions=False\n",
    "              )\n",
    "\n",
    "              print(f\"      ✅ Evaluación exitosa en intento {attempt + 1}\")\n",
    "              return result, None\n",
    "\n",
    "          except Exception as e:\n",
    "              error_msg = str(e).lower()\n",
    "\n",
    "              if \"rate limit\" in error_msg or \"429\" in str(e):\n",
    "                  delay = base_delay * (2 ** attempt) + random.uniform(0, 30)\n",
    "                  print(f\"      ⏰ Rate limit. Esperando {delay:.0f} segundos...\")\n",
    "                  time.sleep(delay)\n",
    "              else:\n",
    "                  print(f\"      ❌ Error: {e}\")\n",
    "                  if attempt == max_attempts - 1:\n",
    "                      return None, str(e)\n",
    "                  time.sleep(30)\n",
    "\n",
    "      return None, \"Máximo de intentos alcanzado\"\n",
    "\n",
    "  print(\"🚀 EVALUACIÓN SOLO QWEN CON MISTRAL API\")\n",
    "  print(\"🤖 Generador: Qwen3-4B-instruct-2507\")\n",
    "  print(f\"🧠 Evaluador: Mistral API ({mistral_evaluator.model})\")\n",
    "  print(\"📊 Métricas: context_precision, context_recall, faithfulness, answer_correctness\")\n",
    "  print(\"=\"*80)\n",
    "\n",
    "  # Configuración específica para solo Qwen\n",
    "  test_llm = 'Qwen3-4B-instruct-2507'  # Solo Qwen como generador\n",
    "  embeddings = list(EMBEDDING_MODELS.keys())  # 3 embeddings\n",
    "  prompts = list(PROMPTS.keys())  # 3 prompts\n",
    "\n",
    "  # Listas para almacenar resultados\n",
    "  qwen_detailed_results = []\n",
    "  qwen_metrics_results = []\n",
    "\n",
    "  # Generar combinaciones solo para Qwen\n",
    "  qwen_combinations = list(product([test_llm], embeddings, prompts))\n",
    "  total_combinations = len(qwen_combinations)\n",
    "\n",
    "  print(f\"📋 Evaluando {total_combinations} combinaciones para Qwen:\")\n",
    "  for emb in embeddings:\n",
    "      for prompt in prompts:\n",
    "          print(f\"   • {test_llm} + {emb} + {prompt}\")\n",
    "  print()\n",
    "\n",
    "  # Evaluar cada combinación\n",
    "  for combo_idx, (llm_name, test_embedding, test_prompt) in enumerate(qwen_combinations):\n",
    "\n",
    "      print(f\"🔄 QWEN COMBINACIÓN {combo_idx+1}/{total_combinations}\")\n",
    "      print(f\"   Generador: {llm_name}\")\n",
    "      print(f\"   Embedding: {test_embedding} -> {WEAVIATE_CLASSES[test_embedding]}\")\n",
    "      print(f\"   Prompt: {test_prompt}\")\n",
    "\n",
    "      combination_start_time = time.time()\n",
    "      results_list = []\n",
    "      successful_questions = 0\n",
    "\n",
    "      # Generar respuestas con Qwen\n",
    "      print(\"   📝 Generando respuestas con Qwen...\")\n",
    "      for q_idx, question in enumerate(tqdm(questions, desc=\"   Preguntas\")):\n",
    "          try:\n",
    "              state = {\n",
    "                  'question': question,\n",
    "                  'llm_name': llm_name,  # Qwen genera\n",
    "                  'embedding_name': test_embedding,\n",
    "                  'prompt_name': test_prompt,\n",
    "                  'context': [], 'answer': '', 'metadata': {}\n",
    "              }\n",
    "\n",
    "              final_state = graph.invoke(state)\n",
    "              answer = final_state.get('answer', '')\n",
    "              contexts = final_state.get('context', [])\n",
    "\n",
    "              if answer and 'ERROR:' not in answer and len(contexts) > 0:\n",
    "                  results_list.append({\n",
    "                      'question': question,\n",
    "                      'answer': answer,\n",
    "                      'contexts': [doc.page_content for doc in contexts],\n",
    "                      'ground_truth': ground_truths[q_idx] if q_idx < len(ground_truths) else ''\n",
    "                  })\n",
    "                  successful_questions += 1\n",
    "\n",
    "              # Almacenar detalles\n",
    "              qwen_detailed_results.append({\n",
    "                  'combination_id': combo_idx,\n",
    "                  'generator_llm': llm_name,\n",
    "                  'evaluator_llm': 'mistral-small-latest',\n",
    "                  'embedding_model': test_embedding,\n",
    "                  'weaviate_collection': WEAVIATE_CLASSES[test_embedding],\n",
    "                  'prompt_type': test_prompt,\n",
    "                  'question_id': q_idx,\n",
    "                  'question': question,\n",
    "                  'answer': answer,\n",
    "                  'contexts': [doc.page_content for doc in contexts],\n",
    "                  'num_contexts': len(contexts),\n",
    "                  'ground_truth': ground_truths[q_idx] if q_idx < len(ground_truths) else '',\n",
    "                  'status': 'success' if answer and 'ERROR:' not in answer else 'error'\n",
    "              })\n",
    "\n",
    "          except Exception as e:\n",
    "              print(f\"      ❌ Error en pregunta {q_idx+1}: {e}\")\n",
    "              qwen_detailed_results.append({\n",
    "                  'combination_id': combo_idx,\n",
    "                  'generator_llm': llm_name,\n",
    "                  'evaluator_llm': 'mistral-small-latest',\n",
    "                  'embedding_model': test_embedding,\n",
    "                  'weaviate_collection': WEAVIATE_CLASSES[test_embedding],\n",
    "                  'prompt_type': test_prompt,\n",
    "                  'question_id': q_idx,\n",
    "                  'question': question,\n",
    "                  'answer': f'ERROR: {str(e)}',\n",
    "                  'contexts': [],\n",
    "                  'num_contexts': 0,\n",
    "                  'ground_truth': ground_truths[q_idx] if q_idx < len(ground_truths) else '',\n",
    "                  'status': 'error'\n",
    "              })\n",
    "\n",
    "      print(f\"   ✅ {successful_questions}/{len(questions)} preguntas exitosas\")\n",
    "\n",
    "      # Evaluar con RAGAS usando Mistral\n",
    "      if successful_questions >= 2:\n",
    "          print(\"   🧮 Evaluando respuestas de Qwen con Mistral API...\" )\n",
    "\n",
    "          dataset = Dataset.from_list(results_list)\n",
    "          current_embedding_model = EMBEDDING_MODELS[test_embedding]\n",
    "\n",
    "          # 🎯 USAR FUNCIÓN CON MANEJO DE RATE LIMIT\n",
    "          evaluation_results, error = evaluate_with_rate_limit_handling(\n",
    "              dataset,\n",
    "              mistral_evaluator,\n",
    "              current_embedding_model\n",
    "          )\n",
    "\n",
    "          if evaluation_results is not None:\n",
    "              # Procesar métricas\n",
    "              metrics_df = evaluation_results.to_pandas()\n",
    "\n",
    "              def safe_mean_std(series):\n",
    "                  clean_series = series.dropna()\n",
    "                  if len(clean_series) > 0:\n",
    "                      return clean_series.mean(), clean_series.std()\n",
    "                  return None, None\n",
    "\n",
    "              avg_metrics = {}\n",
    "              for metric in ['context_precision', 'context_recall', 'faithfulness', 'answer_correctness']:\n",
    "                  if metric in metrics_df.columns:\n",
    "                      mean_val, std_val = safe_mean_std(metrics_df[metric])\n",
    "                      avg_metrics[f'{metric}_mean'] = mean_val\n",
    "                      avg_metrics[f'{metric}_std'] = std_val\n",
    "\n",
    "              combination_metrics = {\n",
    "                  'combination_id': combo_idx,\n",
    "                  'generator_llm': llm_name,\n",
    "                  'evaluator_llm': 'mistral-small-latest',\n",
    "                  'embedding_model': test_embedding,\n",
    "                  'weaviate_collection': WEAVIATE_CLASSES[test_embedding],\n",
    "                  'prompt_type': test_prompt,\n",
    "                  'total_questions': len(questions),\n",
    "                  'successful_questions': successful_questions,\n",
    "                  'evaluation_time_seconds': time.time() - combination_start_time,\n",
    "                  **avg_metrics\n",
    "              }\n",
    "              qwen_metrics_results.append(combination_metrics)\n",
    "\n",
    "              print(f\"   ✅ Evaluación Mistral → Qwen completada:\")\n",
    "              for metric in ['context_precision_mean', 'context_recall_mean', 'faithfulness_mean', 'answer_correctness_mean']:\n",
    "                  if metric in avg_metrics and avg_metrics[metric] is not None:\n",
    "                      print(f\"      {metric.replace('_mean', '').title()}: {avg_metrics[metric]:.3f}\")\n",
    "\n",
    "          else:\n",
    "              print(f\"   ❌ Evaluación falló: {error}\")\n",
    "              qwen_metrics_results.append({\n",
    "                  'combination_id': combo_idx,\n",
    "                  'generator_llm': llm_name,\n",
    "                  'evaluator_llm': 'mistral-small-latest',\n",
    "                  'embedding_model': test_embedding,\n",
    "                  'weaviate_collection': WEAVIATE_CLASSES[test_embedding],\n",
    "                  'prompt_type': test_prompt,\n",
    "                  'total_questions': len(questions),\n",
    "                  'successful_questions': successful_questions,\n",
    "                  'evaluation_time_seconds': time.time() - combination_start_time,\n",
    "                  'error': error\n",
    "              })\n",
    "\n",
    "      # Delay inteligente entre combinaciones\n",
    "      if combo_idx < len(qwen_combinations) - 1:\n",
    "          base_delay = 90 + random.uniform(0, 30)  # 1.5-2 minutos\n",
    "          print(f\"   ⏸️  Esperando {base_delay:.0f} segundos antes de siguiente combinación...\")\n",
    "          time.sleep(base_delay)\n",
    "\n",
    "  # Crear DataFrames finales\n",
    "  print(\"\\n\" + \"=\"*80)\n",
    "  print(\"🎉 EVALUACIÓN QWEN CON MISTRAL COMPLETADA\")\n",
    "  print(\"=\"*80)\n",
    "\n",
    "  qwen_detailed_df = pd.DataFrame(qwen_detailed_results)\n",
    "  qwen_metrics_df = pd.DataFrame(qwen_metrics_results)\n",
    "\n",
    "  print(f\"✅ Resultados detallados: {qwen_detailed_df.shape}\")\n",
    "  print(f\"✅ Métricas resumen: {qwen_metrics_df.shape}\")\n",
    "\n",
    "  # Guardar resultados\n",
    "  timestamp = pd.Timestamp.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "  detailed_csv = f'qwen_mistral_evaluation_detailed_{timestamp}.csv'\n",
    "  metrics_csv = f'qwen_mistral_evaluation_metrics_{timestamp}.csv'\n",
    "\n",
    "  qwen_detailed_df.to_csv(detailed_csv, index=False, encoding='utf-8')\n",
    "  qwen_metrics_df.to_csv(metrics_csv, index=False, encoding='utf-8')\n",
    "\n",
    "  print(f\"💾 Resultados guardados:\")\n",
    "  print(f\"   Detallado: {detailed_csv}\")\n",
    "  print(f\"   Métricas: {metrics_csv}\")\n",
    "\n",
    "  # Mostrar mejores combinaciones\n",
    "  if not qwen_metrics_df.empty:\n",
    "      successful_evaluations = len([c for c in qwen_metrics_results if 'error' not in c or not c.get('error')])\n",
    "      print(f\"\\n📊 RESUMEN:\")\n",
    "      print(f\"   Combinaciones totales: {total_combinations}\")\n",
    "      print(f\"   Evaluaciones exitosas: {successful_evaluations}\")\n",
    "      print(f\"   Tasa de éxito: {successful_evaluations/total_combinations*100:.1f}%\")\n",
    "\n",
    "      print(f\"\\n🏆 MEJORES COMBINACIONES QWEN:\")\n",
    "\n",
    "      for metric in ['context_precision_mean', 'context_recall_mean', 'faithfulness_mean', 'answer_correctness_mean']:\n",
    "          if metric in qwen_metrics_df.columns:\n",
    "              valid_data = qwen_metrics_df[qwen_metrics_df[metric].notna()]\n",
    "              if not valid_data.empty:\n",
    "                  print(f\"\\n📊 {metric.upper().replace('_', ' ')}:\")\n",
    "                  top_3 = valid_data.nlargest(3, metric)[['embedding_model', 'prompt_type', metric]]\n",
    "                  print(top_3.to_string(index=False))\n",
    "\n",
    "  ⚡ Ventajas de esta aproximación:\n",
    "\n",
    "  1. Mucho más rápido: ~30 minutos vs ~6 horas\n",
    "  2. Menos complejo: Solo 9 combinaciones vs 18\n",
    "  3. Gestión automática de rate limits\n",
    "  4. Resultados comparables: Mistral da evaluaciones de buena calidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.metrics import (\n",
    "    context_precision,    \n",
    "    context_recall,       \n",
    "    faithfulness,         \n",
    "    answer_correctness    \n",
    "  )\n",
    "import asyncio\n",
    "# Configurar Mistral para evaluación RAGAS\n",
    "from langchain_mistralai import ChatMistralAI\n",
    "mistral_llm = ChatMistralAI(\n",
    "    api_key=\"dv0RMPhxjgwM6pePID1FXvloyU2iltVu\",\n",
    "    model=\"mistral-small-latest\",\n",
    "    temperature=0.1,\n",
    "    timeout=120,  # 2 minutos por llamada\n",
    "    max_retries=3\n",
    "  )\n",
    "\n",
    "# Embeddings para evaluación\n",
    "#eval_embeddings = EMBEDDING_MODELS[\"all-MiniLM-L6-v2\"]\n",
    "# Configuración de modelos, embeddings y prompts\n",
    "llm_models = list(LLM.keys())  # Usa los LLMs definidos en tu notebook\n",
    "embeddings = list(EMBEDDING_MODELS.keys())  # Usa los embeddings definidos\n",
    "prompts = list(PROMPTS.keys())  # Usa los prompts definidos\n",
    "\n",
    "# DataFrame para todos los resultados\n",
    "df_results_list = []\n",
    "combination_metrics_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "from langchain_ollama import ChatOllama\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "# Importar RAGAS y métricas\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    context_precision,\n",
    "    context_recall,\n",
    "    faithfulness,\n",
    "    answer_correctness\n",
    ")\n",
    "\n",
    "# Configurar Mistral para evaluación RAGAS\n",
    "from langchain_mistralai import ChatMistralAI\n",
    "evaluation_llm = ChatOllama(\n",
    "      model=\"hf.co/bartowski/Llama-3.2-3B-Instruct-GGUF:Q8_0\",  # Tu modelo exacto\n",
    "      temperature=0.1,\n",
    "      num_predict=1000,\n",
    "      timeout=300\n",
    ")\n",
    "\n",
    "  # PERSONALIZAR EL PROMPT DE CONTEXT_PRECISION EN ESPAÑOL\n",
    "context_precision.context_precision_prompt.instruction = \"\"\"\n",
    "  Dada una pregunta sobre arqueología y un conjunto de contextos que pueden estar en varios idiomas (español, inglés, francés, catalán, portugués), identifica qué contextos son útiles para responder la pregunta.\n",
    "  Los contextos pueden contener información técnica, fechas, yacimientos arqueológicos, cronologías, dataciones, etc. Un contexto es útil si contiene información relevante que ayude a responder la pregunta, aunque sea parcialmente, independientemente      \n",
    "  del idioma en que esté escrito.\n",
    "\n",
    "  Pregunta: {question}\n",
    "  Contextos: {contexts}\n",
    "\n",
    "  Contextos útiles (devuelve solo los índices de contextos útiles, ej: [0, 2]):\n",
    "  \"\"\"\n",
    "\n",
    "# Configuración según tu notebook\n",
    "llm_models = list(LLM.keys())\n",
    "embeddings = list(EMBEDDING_MODELS.keys())\n",
    "prompts = list(PROMPTS.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuando desde combinación 2\n",
      "EVALUACIÓN RAGAS CON 27 COMBINACIONES\n",
      "Métricas: context_precision, context_recall, faithfulness, answer_correctness\n",
      "Evaluador: Mistral API (mistral-small-latest)\n",
      "Prompt personalizado en español para arqueología\n",
      "================================================================================\n",
      "\n",
      "COMBINACIÓN 1/27\n",
      "   LLM: Qwen3-4B-instruct-2507\n",
      "   Embedding: all-MiniLM-L6-v2 -> IdearqAllMiniLM\n",
      "   Prompt: prompt_zero_shot\n",
      "Generando respuestas...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Published by Elsevier Inc. All rights reserved. doi:10.1016/j.yqres.2011.12.003 Contents lists available at SciVerse ScienceDirect Quaternary Research journal homepage: www.elsevier.com/locate/yqres https://doi.org/10.1016/j.yqres.2011.12.003 Published online by Cambridge University Press Introduc...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  12%|█▎        | 1/8 [04:31<31:39, 271.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. A data obtida, é claramente mais recuada que os con­ textos mais antigos reportados em território hoje portu­ guês, nomeadamente Gruta da Nascente do Rio Almonda (OxA­‑9287 – 5480­‑5320 cal BC a 2 sigmas) e da Gruta do Caldeirão (OxA­‑1036 – 5480 – 5070 cal BC a 2 sigmas). Entre nós, apenas se rep...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  25%|██▌       | 2/8 [05:50<15:50, 158.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 2. ENCUADRE CRONO-CULTURAL DEL HA- LLAZGO: COGOTAS I Entre las entidades arqueológicas de la Edad del Bronce peninsular, Cogotas I sobresale por su extensa cobertura geográfica, que desborda la Meseta por el Valle del Ebro y Extremadura, y por su dilatada crono- logía —c. 1800-1150 cal BC, cubrien...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  38%|███▊      | 3/8 [06:54<09:35, 115.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. y NEIRA, A. (1999): “Prehistoria”, en M.A. Rabanal Alonso (coord.): La His­ toria de León, tomo I, Universidad de León y Diario de León. CELIS SÁNCHEZ, J. (1993a): “La secuencia del poblado de la Primera Edad del Hierro de los «Cuestos de la Estación», Benavente, Zamora”, en F. Romero, C. Sanz y Z...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  50%|█████     | 4/8 [08:14<06:45, 101.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Con el desarrollo de las excavaciones arqueológicas en diversos asentamientos, el aumento del número de dataciones y la realización de diversos estudios en los últimos años, las perspectivas de investigación sobre el Bronce final en el Levante comienza a variar sustancialmente, estando ya en condi...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  62%|██████▎   | 5/8 [13:28<08:53, 177.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. En la actualidad, El Argar sigue siendo el grupo arqueo­ lógico de la Edad del Bronce mejor conocido de la península ibérica, con un desarrollo temporal entre el 2200 y el 1550 cal BC. También se puede afirmar que fue una de las sociedades con mayor capacidad productiva y desarrollo social de la E...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  75%|███████▌  | 6/8 [15:35<05:21, 160.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Prehist., 74, N.º 2, julio-diciembre 2017, pp. 296-318, ISSN: 0082-5638 doi: 10.3989/tp.2017.12196 Torres Ortiz, M. 1996: “La cronología de los túmulos A y B de Setefilla. El origen del rito de la crema- ción en la cultura tartésica”. Complutum 7: 147-162. Torres Ortiz, M. 1998: “La cronología abs...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  88%|████████▊ | 7/8 [16:58<02:15, 135.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Ruiz Alonso, M. Guenaga, A., López Quintana, J. C. y Zapata Peña, L. (2010). Antracología y yacimientos dolménicos: el caso de Mendigana. En Actas del Congreso Internacional sobre Megalitismo y otras manifestaciones funerarias con- temporáneas en su contexto social, económico y cultural (pp. 566-5...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas: 100%|██████████| 8/8 [18:17<00:00, 137.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "16/8 preguntas exitosas\n",
      "Evaluando con RAGAS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ca140168fef4584b75c9faa8af90bf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[1]: TimeoutError()\n",
      "Exception raised in Job[2]: TimeoutError()\n",
      "Exception raised in Job[3]: TimeoutError()\n",
      "Exception raised in Job[4]: TimeoutError()\n",
      "Exception raised in Job[5]: TimeoutError()\n",
      "Exception raised in Job[6]: TimeoutError()\n",
      "Exception raised in Job[7]: TimeoutError()\n",
      "Exception raised in Job[9]: TimeoutError()\n",
      "Exception raised in Job[8]: TimeoutError()\n",
      "Exception raised in Job[10]: TimeoutError()\n",
      "Exception raised in Job[11]: TimeoutError()\n",
      "Exception raised in Job[13]: TimeoutError()\n",
      "Exception raised in Job[12]: TimeoutError()\n",
      "Exception raised in Job[14]: TimeoutError()\n",
      "Exception raised in Job[15]: TimeoutError()\n",
      "Exception raised in Job[16]: TimeoutError()\n",
      "Exception raised in Job[18]: TimeoutError()\n",
      "Exception raised in Job[19]: TimeoutError()\n",
      "Exception raised in Job[22]: TimeoutError()\n",
      "Exception raised in Job[20]: TimeoutError()\n",
      "Exception raised in Job[23]: TimeoutError()\n",
      "Exception raised in Job[25]: TimeoutError()\n",
      "Exception raised in Job[24]: TimeoutError()\n",
      "Exception raised in Job[26]: TimeoutError()\n",
      "Exception raised in Job[27]: TimeoutError()\n",
      "Exception raised in Job[29]: TimeoutError()\n",
      "Exception raised in Job[28]: TimeoutError()\n",
      "Exception raised in Job[31]: TimeoutError()\n",
      "Exception raised in Job[30]: TimeoutError()\n",
      "Exception raised in Job[32]: TimeoutError()\n",
      "Exception raised in Job[33]: TimeoutError()\n",
      "Exception raised in Job[34]: TimeoutError()\n",
      "Exception raised in Job[35]: TimeoutError()\n",
      "Exception raised in Job[36]: TimeoutError()\n",
      "Exception raised in Job[37]: TimeoutError()\n",
      "Exception raised in Job[38]: TimeoutError()\n",
      "Exception raised in Job[39]: TimeoutError()\n",
      "Exception raised in Job[40]: TimeoutError()\n",
      "Exception raised in Job[41]: TimeoutError()\n",
      "Exception raised in Job[42]: TimeoutError()\n",
      "Exception raised in Job[43]: TimeoutError()\n",
      "Exception raised in Job[44]: TimeoutError()\n",
      "Exception raised in Job[45]: TimeoutError()\n",
      "Exception raised in Job[46]: TimeoutError()\n",
      "Exception raised in Job[47]: TimeoutError()\n",
      "Exception raised in Job[48]: TimeoutError()\n",
      "Exception raised in Job[50]: TimeoutError()\n",
      "Exception raised in Job[51]: TimeoutError()\n",
      "Exception raised in Job[52]: TimeoutError()\n",
      "Exception raised in Job[53]: TimeoutError()\n",
      "Exception raised in Job[54]: TimeoutError()\n",
      "Exception raised in Job[55]: TimeoutError()\n",
      "Exception raised in Job[56]: TimeoutError()\n",
      "Exception raised in Job[57]: TimeoutError()\n",
      "Exception raised in Job[59]: TimeoutError()\n",
      "Exception raised in Job[58]: TimeoutError()\n",
      "Exception raised in Job[60]: TimeoutError()\n",
      "Exception raised in Job[63]: TimeoutError()\n",
      "Exception raised in Job[61]: TimeoutError()\n",
      "Exception raised in Job[62]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      📊 Columnas disponibles: ['user_input', 'retrieved_contexts', 'response', 'reference', 'context_precision', 'context_recall', 'faithfulness', 'answer_correctness']\n",
      "      📊 Filas en dataset: 16\n",
      "      context_precision: ❌ Sin valores válidos\n",
      "      context_recall: 0.667 (calculado en 3/16 preguntas)\n",
      "      faithfulness: ❌ Sin valores válidos\n",
      "      answer_correctness: ❌ Sin valores válidos\n",
      "RAGAS completado:\n",
      "      Context_Recall: 0.667\n",
      "   ⏸️  Esperando 60 segundos para evitar rate limit...\n",
      "\n",
      "COMBINACIÓN 2/27\n",
      "   LLM: Qwen3-4B-instruct-2507\n",
      "   Embedding: all-MiniLM-L6-v2 -> IdearqAllMiniLM\n",
      "   Prompt: prompt_one_shot\n",
      "Generando respuestas...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Published by Elsevier Inc. All rights reserved. doi:10.1016/j.yqres.2011.12.003 Contents lists available at SciVerse ScienceDirect Quaternary Research journal homepage: www.elsevier.com/locate/yqres https://doi.org/10.1016/j.yqres.2011.12.003 Published online by Cambridge University Press Introduc...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  12%|█▎        | 1/8 [04:19<30:17, 259.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. A data obtida, é claramente mais recuada que os con­ textos mais antigos reportados em território hoje portu­ guês, nomeadamente Gruta da Nascente do Rio Almonda (OxA­‑9287 – 5480­‑5320 cal BC a 2 sigmas) e da Gruta do Caldeirão (OxA­‑1036 – 5480 – 5070 cal BC a 2 sigmas). Entre nós, apenas se rep...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  25%|██▌       | 2/8 [05:35<15:08, 151.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 2. ENCUADRE CRONO-CULTURAL DEL HA- LLAZGO: COGOTAS I Entre las entidades arqueológicas de la Edad del Bronce peninsular, Cogotas I sobresale por su extensa cobertura geográfica, que desborda la Meseta por el Valle del Ebro y Extremadura, y por su dilatada crono- logía —c. 1800-1150 cal BC, cubrien...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  38%|███▊      | 3/8 [05:49<07:22, 88.54s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. y NEIRA, A. (1999): “Prehistoria”, en M.A. Rabanal Alonso (coord.): La His­ toria de León, tomo I, Universidad de León y Diario de León. CELIS SÁNCHEZ, J. (1993a): “La secuencia del poblado de la Primera Edad del Hierro de los «Cuestos de la Estación», Benavente, Zamora”, en F. Romero, C. Sanz y Z...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  50%|█████     | 4/8 [07:13<05:47, 86.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Con el desarrollo de las excavaciones arqueológicas en diversos asentamientos, el aumento del número de dataciones y la realización de diversos estudios en los últimos años, las perspectivas de investigación sobre el Bronce final en el Levante comienza a variar sustancialmente, estando ya en condi...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  62%|██████▎   | 5/8 [13:35<09:40, 193.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. En la actualidad, El Argar sigue siendo el grupo arqueo­ lógico de la Edad del Bronce mejor conocido de la península ibérica, con un desarrollo temporal entre el 2200 y el 1550 cal BC. También se puede afirmar que fue una de las sociedades con mayor capacidad productiva y desarrollo social de la E...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  75%|███████▌  | 6/8 [15:39<05:39, 169.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Prehist., 74, N.º 2, julio-diciembre 2017, pp. 296-318, ISSN: 0082-5638 doi: 10.3989/tp.2017.12196 Torres Ortiz, M. 1996: “La cronología de los túmulos A y B de Setefilla. El origen del rito de la crema- ción en la cultura tartésica”. Complutum 7: 147-162. Torres Ortiz, M. 1998: “La cronología abs...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  88%|████████▊ | 7/8 [16:44<02:15, 135.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas: 100%|██████████| 8/8 [17:14<00:00, 129.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error en pregunta 8: [WinError 10054] Se ha forzado la interrupción de una conexión existente por el host remoto\n",
      "14/8 preguntas exitosas\n",
      "Evaluando con RAGAS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "815ea19d0acc4ff29537b4c799a61bfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[1]: TimeoutError()\n",
      "Exception raised in Job[2]: TimeoutError()\n",
      "Exception raised in Job[5]: TimeoutError()\n",
      "Exception raised in Job[4]: TimeoutError()\n",
      "Exception raised in Job[3]: TimeoutError()\n",
      "Exception raised in Job[6]: TimeoutError()\n",
      "Exception raised in Job[10]: TimeoutError()\n",
      "Exception raised in Job[9]: TimeoutError()\n",
      "Exception raised in Job[8]: TimeoutError()\n",
      "Exception raised in Job[7]: TimeoutError()\n",
      "Exception raised in Job[13]: TimeoutError()\n",
      "Exception raised in Job[12]: TimeoutError()\n",
      "Exception raised in Job[15]: TimeoutError()\n",
      "Exception raised in Job[11]: TimeoutError()\n",
      "Exception raised in Job[14]: TimeoutError()\n",
      "Exception raised in Job[16]: TimeoutError()\n",
      "Exception raised in Job[18]: TimeoutError()\n",
      "Exception raised in Job[19]: TimeoutError()\n",
      "Exception raised in Job[21]: TimeoutError()\n",
      "Exception raised in Job[20]: TimeoutError()\n",
      "Exception raised in Job[22]: TimeoutError()\n",
      "Exception raised in Job[24]: TimeoutError()\n",
      "Exception raised in Job[23]: TimeoutError()\n",
      "Exception raised in Job[27]: TimeoutError()\n",
      "Exception raised in Job[26]: TimeoutError()\n",
      "Exception raised in Job[25]: TimeoutError()\n",
      "Exception raised in Job[29]: TimeoutError()\n",
      "Exception raised in Job[28]: TimeoutError()\n",
      "Exception raised in Job[30]: TimeoutError()\n",
      "Exception raised in Job[31]: TimeoutError()\n",
      "Exception raised in Job[32]: TimeoutError()\n",
      "Exception raised in Job[33]: TimeoutError()\n",
      "Exception raised in Job[35]: TimeoutError()\n",
      "Exception raised in Job[34]: TimeoutError()\n",
      "Exception raised in Job[37]: TimeoutError()\n",
      "Exception raised in Job[36]: TimeoutError()\n",
      "Exception raised in Job[38]: TimeoutError()\n",
      "Exception raised in Job[39]: TimeoutError()\n",
      "Exception raised in Job[40]: TimeoutError()\n",
      "Exception raised in Job[42]: TimeoutError()\n",
      "Exception raised in Job[41]: TimeoutError()\n",
      "Exception raised in Job[44]: TimeoutError()\n",
      "Exception raised in Job[43]: TimeoutError()\n",
      "Exception raised in Job[46]: TimeoutError()\n",
      "Exception raised in Job[45]: TimeoutError()\n",
      "Exception raised in Job[47]: TimeoutError()\n",
      "Exception raised in Job[48]: TimeoutError()\n",
      "Exception raised in Job[50]: TimeoutError()\n",
      "Exception raised in Job[51]: TimeoutError()\n",
      "Exception raised in Job[52]: TimeoutError()\n",
      "Exception raised in Job[53]: TimeoutError()\n",
      "Exception raised in Job[54]: TimeoutError()\n",
      "Exception raised in Job[55]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      📊 Columnas disponibles: ['user_input', 'retrieved_contexts', 'response', 'reference', 'context_precision', 'context_recall', 'faithfulness', 'answer_correctness']\n",
      "      📊 Filas en dataset: 14\n",
      "      context_precision: ❌ Sin valores válidos\n",
      "      context_recall: 0.500 (calculado en 2/14 preguntas)\n",
      "      faithfulness: ❌ Sin valores válidos\n",
      "      answer_correctness: ❌ Sin valores válidos\n",
      "RAGAS completado:\n",
      "      Context_Recall: 0.500\n",
      "   ⏸️  Esperando 60 segundos para evitar rate limit...\n",
      "\n",
      "COMBINACIÓN 3/27\n",
      "   LLM: Qwen3-4B-instruct-2507\n",
      "   Embedding: all-MiniLM-L6-v2 -> IdearqAllMiniLM\n",
      "   Prompt: prompt_few_shot\n",
      "Generando respuestas...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Published by Elsevier Inc. All rights reserved. doi:10.1016/j.yqres.2011.12.003 Contents lists available at SciVerse ScienceDirect Quaternary Research journal homepage: www.elsevier.com/locate/yqres https://doi.org/10.1016/j.yqres.2011.12.003 Published online by Cambridge University Press Introduc...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  12%|█▎        | 1/8 [04:23<30:47, 263.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. A data obtida, é claramente mais recuada que os con­ textos mais antigos reportados em território hoje portu­ guês, nomeadamente Gruta da Nascente do Rio Almonda (OxA­‑9287 – 5480­‑5320 cal BC a 2 sigmas) e da Gruta do Caldeirão (OxA­‑1036 – 5480 – 5070 cal BC a 2 sigmas). Entre nós, apenas se rep...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  25%|██▌       | 2/8 [05:18<14:03, 140.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 2. ENCUADRE CRONO-CULTURAL DEL HA- LLAZGO: COGOTAS I Entre las entidades arqueológicas de la Edad del Bronce peninsular, Cogotas I sobresale por su extensa cobertura geográfica, que desborda la Meseta por el Valle del Ebro y Extremadura, y por su dilatada crono- logía —c. 1800-1150 cal BC, cubrien...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  38%|███▊      | 3/8 [05:32<06:53, 82.78s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. y NEIRA, A. (1999): “Prehistoria”, en M.A. Rabanal Alonso (coord.): La His­ toria de León, tomo I, Universidad de León y Diario de León. CELIS SÁNCHEZ, J. (1993a): “La secuencia del poblado de la Primera Edad del Hierro de los «Cuestos de la Estación», Benavente, Zamora”, en F. Romero, C. Sanz y Z...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  50%|█████     | 4/8 [06:40<05:08, 77.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Con el desarrollo de las excavaciones arqueológicas en diversos asentamientos, el aumento del número de dataciones y la realización de diversos estudios en los últimos años, las perspectivas de investigación sobre el Bronce final en el Levante comienza a variar sustancialmente, estando ya en condi...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  62%|██████▎   | 5/8 [11:38<07:50, 156.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. En la actualidad, El Argar sigue siendo el grupo arqueo­ lógico de la Edad del Bronce mejor conocido de la península ibérica, con un desarrollo temporal entre el 2200 y el 1550 cal BC. También se puede afirmar que fue una de las sociedades con mayor capacidad productiva y desarrollo social de la E...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  75%|███████▌  | 6/8 [13:56<05:00, 150.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Prehist., 74, N.º 2, julio-diciembre 2017, pp. 296-318, ISSN: 0082-5638 doi: 10.3989/tp.2017.12196 Torres Ortiz, M. 1996: “La cronología de los túmulos A y B de Setefilla. El origen del rito de la crema- ción en la cultura tartésica”. Complutum 7: 147-162. Torres Ortiz, M. 1998: “La cronología abs...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  88%|████████▊ | 7/8 [15:16<02:07, 127.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Ruiz Alonso, M. Guenaga, A., López Quintana, J. C. y Zapata Peña, L. (2010). Antracología y yacimientos dolménicos: el caso de Mendigana. En Actas del Congreso Internacional sobre Megalitismo y otras manifestaciones funerarias con- temporáneas en su contexto social, económico y cultural (pp. 566-5...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas: 100%|██████████| 8/8 [16:34<00:00, 124.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "16/8 preguntas exitosas\n",
      "Evaluando con RAGAS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "509fd548d0bf448d9fa224da5c124fe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[1]: TimeoutError()\n",
      "Exception raised in Job[2]: TimeoutError()\n",
      "Exception raised in Job[5]: TimeoutError()\n",
      "Exception raised in Job[4]: TimeoutError()\n",
      "Exception raised in Job[3]: TimeoutError()\n",
      "Exception raised in Job[6]: TimeoutError()\n",
      "Exception raised in Job[8]: TimeoutError()\n",
      "Exception raised in Job[7]: TimeoutError()\n",
      "Exception raised in Job[10]: TimeoutError()\n",
      "Exception raised in Job[9]: TimeoutError()\n",
      "Exception raised in Job[12]: TimeoutError()\n",
      "Exception raised in Job[13]: TimeoutError()\n",
      "Exception raised in Job[11]: TimeoutError()\n",
      "Exception raised in Job[14]: TimeoutError()\n",
      "Exception raised in Job[15]: TimeoutError()\n",
      "Exception raised in Job[16]: TimeoutError()\n",
      "Exception raised in Job[18]: TimeoutError()\n",
      "Exception raised in Job[20]: TimeoutError()\n",
      "Exception raised in Job[19]: TimeoutError()\n",
      "Exception raised in Job[21]: TimeoutError()\n",
      "Exception raised in Job[24]: TimeoutError()\n",
      "Exception raised in Job[23]: TimeoutError()\n",
      "Exception raised in Job[22]: TimeoutError()\n",
      "Exception raised in Job[25]: TimeoutError()\n",
      "Exception raised in Job[26]: TimeoutError()\n",
      "Exception raised in Job[28]: TimeoutError()\n",
      "Exception raised in Job[27]: TimeoutError()\n",
      "Exception raised in Job[29]: TimeoutError()\n",
      "Exception raised in Job[30]: TimeoutError()\n",
      "Exception raised in Job[31]: TimeoutError()\n",
      "Exception raised in Job[32]: TimeoutError()\n",
      "Exception raised in Job[33]: TimeoutError()\n",
      "Exception raised in Job[34]: TimeoutError()\n",
      "Exception raised in Job[36]: TimeoutError()\n",
      "Exception raised in Job[35]: TimeoutError()\n",
      "Exception raised in Job[37]: TimeoutError()\n",
      "Exception raised in Job[38]: TimeoutError()\n",
      "Exception raised in Job[39]: TimeoutError()\n",
      "Exception raised in Job[40]: TimeoutError()\n",
      "Exception raised in Job[41]: TimeoutError()\n",
      "Exception raised in Job[42]: TimeoutError()\n",
      "Exception raised in Job[44]: TimeoutError()\n",
      "Exception raised in Job[43]: TimeoutError()\n",
      "Exception raised in Job[45]: TimeoutError()\n",
      "Exception raised in Job[46]: TimeoutError()\n",
      "Exception raised in Job[47]: TimeoutError()\n",
      "Exception raised in Job[48]: TimeoutError()\n",
      "Exception raised in Job[51]: TimeoutError()\n",
      "Exception raised in Job[50]: TimeoutError()\n",
      "Exception raised in Job[52]: TimeoutError()\n",
      "Exception raised in Job[55]: TimeoutError()\n",
      "Exception raised in Job[53]: TimeoutError()\n",
      "Exception raised in Job[54]: TimeoutError()\n",
      "Exception raised in Job[56]: TimeoutError()\n",
      "Exception raised in Job[57]: TimeoutError()\n",
      "Exception raised in Job[59]: TimeoutError()\n",
      "Exception raised in Job[58]: TimeoutError()\n",
      "Exception raised in Job[60]: TimeoutError()\n",
      "Exception raised in Job[61]: TimeoutError()\n",
      "Exception raised in Job[62]: TimeoutError()\n",
      "Exception raised in Job[63]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      📊 Columnas disponibles: ['user_input', 'retrieved_contexts', 'response', 'reference', 'context_precision', 'context_recall', 'faithfulness', 'answer_correctness']\n",
      "      📊 Filas en dataset: 16\n",
      "      context_precision: ❌ Sin valores válidos\n",
      "      context_recall: 0.500 (calculado en 2/16 preguntas)\n",
      "      faithfulness: ❌ Sin valores válidos\n",
      "      answer_correctness: ❌ Sin valores válidos\n",
      "RAGAS completado:\n",
      "      Context_Recall: 0.500\n",
      "   ⏸️  Esperando 60 segundos para evitar rate limit...\n",
      "\n",
      "COMBINACIÓN 4/27\n",
      "   LLM: Qwen3-4B-instruct-2507\n",
      "   Embedding: e5-large-instruct -> IdearqE5\n",
      "   Prompt: prompt_zero_shot\n",
      "Generando respuestas...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. This article must therefore be hereby marked “advertisement” in accordance with 18 U.S.C. §1734 solely to indicate this fact. 14180–14185 PNAS November 20, 2001 vol. 98 no. 24 www.pnas.org cgi doi 10.1073 pnas.241522898 Downloaded from https://www.pnas.org by 2.138.20.97 on August 12, 2025 from IP...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  12%|█▎        | 1/8 [04:43<33:02, 283.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'5.º CONGRESSO DO NEOLÍTICO PENINSULAR 405 1. Introducción La minería del sílex en la Europa prehistórica tiene lugar en un marco cronológico bien conocido. Hay esca‑ sas y ocasionalmente ambiguas evidencias de explota‑ ciones del Pleistoceno (p.e. Baena et al., 2011), alguna dispersa para el Mesolít...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  25%|██▌       | 2/8 [06:16<17:07, 171.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. La cronología radiocarbónica de las primeras manifestaciones megalíticas en el sureste de la Península Ibérica… 273 Trab. Prehist., 74, N.º 2, julio-diciembre 2017, pp. 257-277, ISSN: 0082-5638 doi: 10.3989/tp.2017.12194 de probabilidad), posiblemente entre el 2395-2270 cal BC (68% de probabilidad...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  38%|███▊      | 3/8 [10:48<18:07, 217.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 1984: “La Muela de Alarilla. Un yacimiento de la Edad del Bronce en el valle medio del río Henares”. Revista de Arqueología 37: 6-16. Misiego, J. C.; Sanz, F. J.; Marcos, G. J. y Martín, M. A. 1999: “Excavaciones Arqueológicas en el castro de Sacaojos (Santiago de la Valduerna, León)”. Nu­ mantia ...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  50%|█████     | 4/8 [12:32<11:30, 172.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'81 ISSN: 1131-6993 El Bronce Final en el Levante de la península Ibérica: bases arqueológicas y periodización Late Bronze Age in Eastern Iberian Peninsula: Archaeological Bases and Periodization Francisco Javier Jover Maestre*, Alberto Lorrio Alvarado**\\n\\n---\\n\\n. Con el desarrollo de las excavacio...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  62%|██████▎   | 5/8 [17:07<10:28, 209.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Introducción Los objetos de adorno realizados con marfil de pro­ boscídeo son una constante en el registro material de los yacimientos de la península ibérica, sobre todo a partir de la primera mitad del II milenio cal BC, si bien en el sur están presentes desde inicios del III milenio cal BC. La ...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  75%|███████▌  | 6/8 [21:14<07:24, 222.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Demografía y poblamiento en la Meseta Sur entre el 5500 y el 1200 cal BC. Una perspectiva desde el Radiocarbono 84 La base de datos de dataciones de 14C de la Meseta Sur peninsular se caracteriza por la estructuración de la información cronológica en campos que permitan la situación geográfica de ...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  88%|████████▊ | 7/8 [27:16<04:27, 267.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. La cronología radiocarbónica de las primeras manifestaciones megalíticas en el sureste de la Península Ibérica… 273 Trab. Prehist., 74, N.º 2, julio-diciembre 2017, pp. 257-277, ISSN: 0082-5638 doi: 10.3989/tp.2017.12194 de probabilidad), posiblemente entre el 2395-2270 cal BC (68% de probabilidad...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas: 100%|██████████| 8/8 [29:53<00:00, 224.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "16/8 preguntas exitosas\n",
      "Evaluando con RAGAS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6a10a058644457f9efd3d1afbdf39a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[1]: TimeoutError()\n",
      "Exception raised in Job[2]: TimeoutError()\n",
      "Exception raised in Job[4]: TimeoutError()\n",
      "Exception raised in Job[3]: TimeoutError()\n",
      "Exception raised in Job[6]: TimeoutError()\n",
      "Exception raised in Job[5]: TimeoutError()\n",
      "Exception raised in Job[7]: TimeoutError()\n",
      "Exception raised in Job[8]: TimeoutError()\n",
      "Exception raised in Job[11]: TimeoutError()\n",
      "Exception raised in Job[10]: TimeoutError()\n",
      "Exception raised in Job[9]: TimeoutError()\n",
      "Exception raised in Job[12]: TimeoutError()\n",
      "Exception raised in Job[13]: TimeoutError()\n",
      "Exception raised in Job[14]: TimeoutError()\n",
      "Exception raised in Job[15]: TimeoutError()\n",
      "Exception raised in Job[16]: TimeoutError()\n",
      "Exception raised in Job[18]: TimeoutError()\n",
      "Exception raised in Job[19]: TimeoutError()\n",
      "Exception raised in Job[20]: TimeoutError()\n",
      "Exception raised in Job[23]: TimeoutError()\n",
      "Exception raised in Job[21]: TimeoutError()\n",
      "Exception raised in Job[22]: TimeoutError()\n",
      "Exception raised in Job[24]: TimeoutError()\n",
      "Exception raised in Job[25]: TimeoutError()\n",
      "Exception raised in Job[27]: TimeoutError()\n",
      "Exception raised in Job[26]: TimeoutError()\n",
      "Exception raised in Job[28]: TimeoutError()\n",
      "Exception raised in Job[29]: TimeoutError()\n",
      "Exception raised in Job[30]: TimeoutError()\n",
      "Exception raised in Job[31]: TimeoutError()\n",
      "Exception raised in Job[32]: TimeoutError()\n",
      "Exception raised in Job[34]: TimeoutError()\n",
      "Exception raised in Job[35]: TimeoutError()\n",
      "Exception raised in Job[36]: TimeoutError()\n",
      "Exception raised in Job[38]: TimeoutError()\n",
      "Exception raised in Job[37]: TimeoutError()\n",
      "Exception raised in Job[39]: TimeoutError()\n",
      "Exception raised in Job[40]: TimeoutError()\n",
      "Exception raised in Job[42]: TimeoutError()\n",
      "Exception raised in Job[41]: TimeoutError()\n",
      "Exception raised in Job[43]: TimeoutError()\n",
      "Exception raised in Job[44]: TimeoutError()\n",
      "Exception raised in Job[46]: TimeoutError()\n",
      "Exception raised in Job[45]: TimeoutError()\n",
      "Exception raised in Job[47]: TimeoutError()\n",
      "Exception raised in Job[48]: TimeoutError()\n",
      "Exception raised in Job[51]: TimeoutError()\n",
      "Exception raised in Job[50]: TimeoutError()\n",
      "Exception raised in Job[52]: TimeoutError()\n",
      "Exception raised in Job[53]: TimeoutError()\n",
      "Exception raised in Job[54]: TimeoutError()\n",
      "Exception raised in Job[55]: TimeoutError()\n",
      "Exception raised in Job[56]: TimeoutError()\n",
      "Exception raised in Job[57]: TimeoutError()\n",
      "Exception raised in Job[58]: TimeoutError()\n",
      "Exception raised in Job[59]: TimeoutError()\n",
      "Exception raised in Job[61]: TimeoutError()\n",
      "Exception raised in Job[60]: TimeoutError()\n",
      "Exception raised in Job[62]: TimeoutError()\n",
      "Exception raised in Job[63]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      📊 Columnas disponibles: ['user_input', 'retrieved_contexts', 'response', 'reference', 'context_precision', 'context_recall', 'faithfulness', 'answer_correctness']\n",
      "      📊 Filas en dataset: 16\n",
      "      context_precision: ❌ Sin valores válidos\n",
      "      context_recall: 0.867 (calculado en 3/16 preguntas)\n",
      "      faithfulness: ❌ Sin valores válidos\n",
      "      answer_correctness: ❌ Sin valores válidos\n",
      "RAGAS completado:\n",
      "      Context_Recall: 0.867\n",
      "   ⏸️  Esperando 60 segundos para evitar rate limit...\n",
      "\n",
      "COMBINACIÓN 5/27\n",
      "   LLM: Qwen3-4B-instruct-2507\n",
      "   Embedding: e5-large-instruct -> IdearqE5\n",
      "   Prompt: prompt_one_shot\n",
      "Generando respuestas...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. This article must therefore be hereby marked “advertisement” in accordance with 18 U.S.C. §1734 solely to indicate this fact. 14180–14185 PNAS November 20, 2001 vol. 98 no. 24 www.pnas.org cgi doi 10.1073 pnas.241522898 Downloaded from https://www.pnas.org by 2.138.20.97 on August 12, 2025 from IP...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  12%|█▎        | 1/8 [05:56<41:35, 356.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'5.º CONGRESSO DO NEOLÍTICO PENINSULAR 405 1. Introducción La minería del sílex en la Europa prehistórica tiene lugar en un marco cronológico bien conocido. Hay esca‑ sas y ocasionalmente ambiguas evidencias de explota‑ ciones del Pleistoceno (p.e. Baena et al., 2011), alguna dispersa para el Mesolít...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  25%|██▌       | 2/8 [07:33<20:23, 203.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. La cronología radiocarbónica de las primeras manifestaciones megalíticas en el sureste de la Península Ibérica… 273 Trab. Prehist., 74, N.º 2, julio-diciembre 2017, pp. 257-277, ISSN: 0082-5638 doi: 10.3989/tp.2017.12194 de probabilidad), posiblemente entre el 2395-2270 cal BC (68% de probabilidad...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  38%|███▊      | 3/8 [13:02<21:44, 260.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 1984: “La Muela de Alarilla. Un yacimiento de la Edad del Bronce en el valle medio del río Henares”. Revista de Arqueología 37: 6-16. Misiego, J. C.; Sanz, F. J.; Marcos, G. J. y Martín, M. A. 1999: “Excavaciones Arqueológicas en el castro de Sacaojos (Santiago de la Valduerna, León)”. Nu­ mantia ...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  50%|█████     | 4/8 [15:45<14:48, 222.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'81 ISSN: 1131-6993 El Bronce Final en el Levante de la península Ibérica: bases arqueológicas y periodización Late Bronze Age in Eastern Iberian Peninsula: Archaeological Bases and Periodization Francisco Javier Jover Maestre*, Alberto Lorrio Alvarado**\\n\\n---\\n\\n. Con el desarrollo de las excavacio...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  62%|██████▎   | 5/8 [21:15<13:03, 261.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Introducción Los objetos de adorno realizados con marfil de pro­ boscídeo son una constante en el registro material de los yacimientos de la península ibérica, sobre todo a partir de la primera mitad del II milenio cal BC, si bien en el sur están presentes desde inicios del III milenio cal BC. La ...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  75%|███████▌  | 6/8 [25:23<08:33, 256.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Demografía y poblamiento en la Meseta Sur entre el 5500 y el 1200 cal BC. Una perspectiva desde el Radiocarbono 84 La base de datos de dataciones de 14C de la Meseta Sur peninsular se caracteriza por la estructuración de la información cronológica en campos que permitan la situación geográfica de ...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  88%|████████▊ | 7/8 [30:35<04:34, 274.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. La cronología radiocarbónica de las primeras manifestaciones megalíticas en el sureste de la Península Ibérica… 273 Trab. Prehist., 74, N.º 2, julio-diciembre 2017, pp. 257-277, ISSN: 0082-5638 doi: 10.3989/tp.2017.12194 de probabilidad), posiblemente entre el 2395-2270 cal BC (68% de probabilidad...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas: 100%|██████████| 8/8 [33:52<00:00, 254.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "16/8 preguntas exitosas\n",
      "Evaluando con RAGAS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e6a8b692c5f46b3aad95d3a83b16aea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[8]: TimeoutError()\n",
      "Exception raised in Job[2]: TimeoutError()\n",
      "Exception raised in Job[1]: TimeoutError()\n",
      "Exception raised in Job[5]: TimeoutError()\n",
      "Exception raised in Job[4]: TimeoutError()\n",
      "Exception raised in Job[3]: TimeoutError()\n",
      "Exception raised in Job[6]: TimeoutError()\n",
      "Exception raised in Job[7]: TimeoutError()\n",
      "Exception raised in Job[10]: TimeoutError()\n",
      "Exception raised in Job[9]: TimeoutError()\n",
      "Exception raised in Job[11]: TimeoutError()\n",
      "Exception raised in Job[13]: TimeoutError()\n",
      "Exception raised in Job[12]: TimeoutError()\n",
      "Exception raised in Job[15]: TimeoutError()\n",
      "Exception raised in Job[14]: TimeoutError()\n",
      "Exception raised in Job[16]: TimeoutError()\n",
      "Exception raised in Job[18]: TimeoutError()\n",
      "Exception raised in Job[21]: TimeoutError()\n",
      "Exception raised in Job[19]: TimeoutError()\n",
      "Exception raised in Job[20]: TimeoutError()\n",
      "Exception raised in Job[22]: TimeoutError()\n",
      "Exception raised in Job[24]: TimeoutError()\n",
      "Exception raised in Job[23]: TimeoutError()\n",
      "Exception raised in Job[26]: TimeoutError()\n",
      "Exception raised in Job[25]: TimeoutError()\n",
      "Exception raised in Job[29]: TimeoutError()\n",
      "Exception raised in Job[28]: TimeoutError()\n",
      "Exception raised in Job[27]: TimeoutError()\n",
      "Exception raised in Job[31]: TimeoutError()\n",
      "Exception raised in Job[30]: TimeoutError()\n",
      "Exception raised in Job[32]: TimeoutError()\n",
      "Exception raised in Job[35]: TimeoutError()\n",
      "Exception raised in Job[34]: TimeoutError()\n",
      "Exception raised in Job[36]: TimeoutError()\n",
      "Exception raised in Job[38]: TimeoutError()\n",
      "Exception raised in Job[39]: TimeoutError()\n",
      "Exception raised in Job[40]: TimeoutError()\n",
      "Exception raised in Job[41]: TimeoutError()\n",
      "Exception raised in Job[42]: TimeoutError()\n",
      "Exception raised in Job[43]: TimeoutError()\n",
      "Exception raised in Job[46]: TimeoutError()\n",
      "Exception raised in Job[44]: TimeoutError()\n",
      "Exception raised in Job[45]: TimeoutError()\n",
      "Exception raised in Job[47]: TimeoutError()\n",
      "Exception raised in Job[48]: TimeoutError()\n",
      "Exception raised in Job[49]: TimeoutError()\n",
      "Exception raised in Job[50]: TimeoutError()\n",
      "Exception raised in Job[51]: TimeoutError()\n",
      "Exception raised in Job[52]: TimeoutError()\n",
      "Exception raised in Job[53]: TimeoutError()\n",
      "Exception raised in Job[54]: TimeoutError()\n",
      "Exception raised in Job[55]: TimeoutError()\n",
      "Exception raised in Job[56]: TimeoutError()\n",
      "Exception raised in Job[57]: TimeoutError()\n",
      "Exception raised in Job[58]: TimeoutError()\n",
      "Exception raised in Job[59]: TimeoutError()\n",
      "Exception raised in Job[60]: TimeoutError()\n",
      "Exception raised in Job[62]: TimeoutError()\n",
      "Exception raised in Job[61]: TimeoutError()\n",
      "Exception raised in Job[63]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      📊 Columnas disponibles: ['user_input', 'retrieved_contexts', 'response', 'reference', 'context_precision', 'context_recall', 'faithfulness', 'answer_correctness']\n",
      "      📊 Filas en dataset: 16\n",
      "      context_precision: ❌ Sin valores válidos\n",
      "      context_recall: 0.800 (calculado en 3/16 preguntas)\n",
      "      faithfulness: ❌ Sin valores válidos\n",
      "      answer_correctness: ❌ Sin valores válidos\n",
      "RAGAS completado:\n",
      "      Context_Recall: 0.800\n",
      "   ⏸️  Esperando 60 segundos para evitar rate limit...\n",
      "\n",
      "COMBINACIÓN 6/27\n",
      "   LLM: Qwen3-4B-instruct-2507\n",
      "   Embedding: e5-large-instruct -> IdearqE5\n",
      "   Prompt: prompt_few_shot\n",
      "Generando respuestas...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. This article must therefore be hereby marked “advertisement” in accordance with 18 U.S.C. §1734 solely to indicate this fact. 14180–14185 PNAS November 20, 2001 vol. 98 no. 24 www.pnas.org cgi doi 10.1073 pnas.241522898 Downloaded from https://www.pnas.org by 2.138.20.97 on August 12, 2025 from IP...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  12%|█▎        | 1/8 [04:39<32:33, 279.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'5.º CONGRESSO DO NEOLÍTICO PENINSULAR 405 1. Introducción La minería del sílex en la Europa prehistórica tiene lugar en un marco cronológico bien conocido. Hay esca‑ sas y ocasionalmente ambiguas evidencias de explota‑ ciones del Pleistoceno (p.e. Baena et al., 2011), alguna dispersa para el Mesolít...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  25%|██▌       | 2/8 [06:37<18:28, 184.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. La cronología radiocarbónica de las primeras manifestaciones megalíticas en el sureste de la Península Ibérica… 273 Trab. Prehist., 74, N.º 2, julio-diciembre 2017, pp. 257-277, ISSN: 0082-5638 doi: 10.3989/tp.2017.12194 de probabilidad), posiblemente entre el 2395-2270 cal BC (68% de probabilidad...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  38%|███▊      | 3/8 [10:17<16:43, 200.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 1984: “La Muela de Alarilla. Un yacimiento de la Edad del Bronce en el valle medio del río Henares”. Revista de Arqueología 37: 6-16. Misiego, J. C.; Sanz, F. J.; Marcos, G. J. y Martín, M. A. 1999: “Excavaciones Arqueológicas en el castro de Sacaojos (Santiago de la Valduerna, León)”. Nu­ mantia ...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  50%|█████     | 4/8 [12:11<11:05, 166.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'81 ISSN: 1131-6993 El Bronce Final en el Levante de la península Ibérica: bases arqueológicas y periodización Late Bronze Age in Eastern Iberian Peninsula: Archaeological Bases and Periodization Francisco Javier Jover Maestre*, Alberto Lorrio Alvarado**\\n\\n---\\n\\n. Con el desarrollo de las excavacio...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  62%|██████▎   | 5/8 [17:20<10:53, 217.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Introducción Los objetos de adorno realizados con marfil de pro­ boscídeo son una constante en el registro material de los yacimientos de la península ibérica, sobre todo a partir de la primera mitad del II milenio cal BC, si bien en el sur están presentes desde inicios del III milenio cal BC. La ...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  75%|███████▌  | 6/8 [20:28<06:55, 207.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Demografía y poblamiento en la Meseta Sur entre el 5500 y el 1200 cal BC. Una perspectiva desde el Radiocarbono 84 La base de datos de dataciones de 14C de la Meseta Sur peninsular se caracteriza por la estructuración de la información cronológica en campos que permitan la situación geográfica de ...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  88%|████████▊ | 7/8 [24:42<03:42, 222.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_few_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. La cronología radiocarbónica de las primeras manifestaciones megalíticas en el sureste de la Península Ibérica… 273 Trab. Prehist., 74, N.º 2, julio-diciembre 2017, pp. 257-277, ISSN: 0082-5638 doi: 10.3989/tp.2017.12194 de probabilidad), posiblemente entre el 2395-2270 cal BC (68% de probabilidad...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas: 100%|██████████| 8/8 [27:04<00:00, 203.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "16/8 preguntas exitosas\n",
      "Evaluando con RAGAS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49d5155e76a24269a02ad19f9f756534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[1]: TimeoutError()\n",
      "Exception raised in Job[5]: TimeoutError()\n",
      "Exception raised in Job[2]: TimeoutError()\n",
      "Exception raised in Job[4]: TimeoutError()\n",
      "Exception raised in Job[3]: TimeoutError()\n",
      "Exception raised in Job[6]: TimeoutError()\n",
      "Exception raised in Job[8]: TimeoutError()\n",
      "Exception raised in Job[7]: TimeoutError()\n",
      "Exception raised in Job[11]: TimeoutError()\n",
      "Exception raised in Job[10]: TimeoutError()\n",
      "Exception raised in Job[9]: TimeoutError()\n",
      "Exception raised in Job[15]: TimeoutError()\n",
      "Exception raised in Job[14]: TimeoutError()\n",
      "Exception raised in Job[13]: TimeoutError()\n",
      "Exception raised in Job[12]: TimeoutError()\n",
      "Exception raised in Job[16]: TimeoutError()\n",
      "Exception raised in Job[18]: TimeoutError()\n",
      "Exception raised in Job[22]: TimeoutError()\n",
      "Exception raised in Job[21]: TimeoutError()\n",
      "Exception raised in Job[20]: TimeoutError()\n",
      "Exception raised in Job[19]: TimeoutError()\n",
      "Exception raised in Job[23]: TimeoutError()\n",
      "Exception raised in Job[24]: TimeoutError()\n",
      "Exception raised in Job[25]: TimeoutError()\n",
      "Exception raised in Job[26]: TimeoutError()\n",
      "Exception raised in Job[28]: TimeoutError()\n",
      "Exception raised in Job[27]: TimeoutError()\n",
      "Exception raised in Job[30]: TimeoutError()\n",
      "Exception raised in Job[31]: TimeoutError()\n",
      "Exception raised in Job[29]: TimeoutError()\n",
      "Exception raised in Job[32]: TimeoutError()\n",
      "Exception raised in Job[35]: TimeoutError()\n",
      "Exception raised in Job[34]: TimeoutError()\n",
      "Exception raised in Job[36]: TimeoutError()\n",
      "Exception raised in Job[37]: TimeoutError()\n",
      "Exception raised in Job[38]: TimeoutError()\n",
      "Exception raised in Job[39]: TimeoutError()\n",
      "Exception raised in Job[41]: TimeoutError()\n",
      "Exception raised in Job[40]: TimeoutError()\n",
      "Exception raised in Job[42]: TimeoutError()\n",
      "Exception raised in Job[45]: TimeoutError()\n",
      "Exception raised in Job[44]: TimeoutError()\n",
      "Exception raised in Job[43]: TimeoutError()\n",
      "Exception raised in Job[46]: TimeoutError()\n",
      "Exception raised in Job[47]: TimeoutError()\n",
      "Exception raised in Job[48]: TimeoutError()\n",
      "Exception raised in Job[49]: TimeoutError()\n",
      "Exception raised in Job[50]: TimeoutError()\n",
      "Exception raised in Job[51]: TimeoutError()\n",
      "Exception raised in Job[53]: TimeoutError()\n",
      "Exception raised in Job[52]: TimeoutError()\n",
      "Exception raised in Job[54]: TimeoutError()\n",
      "Exception raised in Job[55]: TimeoutError()\n",
      "Exception raised in Job[56]: TimeoutError()\n",
      "Exception raised in Job[57]: TimeoutError()\n",
      "Exception raised in Job[58]: TimeoutError()\n",
      "Exception raised in Job[59]: TimeoutError()\n",
      "Exception raised in Job[60]: TimeoutError()\n",
      "Exception raised in Job[61]: TimeoutError()\n",
      "Exception raised in Job[62]: TimeoutError()\n",
      "Exception raised in Job[63]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      📊 Columnas disponibles: ['user_input', 'retrieved_contexts', 'response', 'reference', 'context_precision', 'context_recall', 'faithfulness', 'answer_correctness']\n",
      "      📊 Filas en dataset: 16\n",
      "      context_precision: ❌ Sin valores válidos\n",
      "      context_recall: 0.800 (calculado en 2/16 preguntas)\n",
      "      faithfulness: ❌ Sin valores válidos\n",
      "      answer_correctness: ❌ Sin valores válidos\n",
      "RAGAS completado:\n",
      "      Context_Recall: 0.800\n",
      "   ⏸️  Esperando 60 segundos para evitar rate limit...\n",
      "\n",
      "COMBINACIÓN 7/27\n",
      "   LLM: Qwen3-4B-instruct-2507\n",
      "   Embedding: gte-multilingual-base -> IdearqGTE\n",
      "   Prompt: prompt_zero_shot\n",
      "Generando respuestas...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Published by Elsevier Inc. All rights reserved. doi:10.1016/j.yqres.2011.12.003 Contents lists available at SciVerse ScienceDirect Quaternary Research journal homepage: www.elsevier.com/locate/yqres https://doi.org/10.1016/j.yqres.2011.12.003 Published online by Cambridge University Press Introduc...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  12%|█▎        | 1/8 [04:51<33:59, 291.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'5.º CONGRESSO DO NEOLÍTICO PENINSULAR 405 1. Introducción La minería del sílex en la Europa prehistórica tiene lugar en un marco cronológico bien conocido. Hay esca‑ sas y ocasionalmente ambiguas evidencias de explota‑ ciones del Pleistoceno (p.e. Baena et al., 2011), alguna dispersa para el Mesolít...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  25%|██▌       | 2/8 [07:31<21:25, 214.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Págs. 253-273 ISBN: 978-84-8317-921-5 · ISBN: 978-84-940141-2-3 Resumen La región cantábrica ha proporcionado una de las principales concentraciones de testimonios funerarios mesolíticos del continente europeo, con un registro prácticamente continuo desde el Aziliense hasta el final del período, e...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  38%|███▊      | 3/8 [11:58<19:51, 238.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 141 Complutum 32(1) 2021: 141-165 Complutum ISSN: 1131-6993 https://dx.doi.org//cmpl.76452 ARTÍCULOS La panoplia de finales de la IIª Edad del Hierro de la sima de La Cerrosa-Lagaña (Suarías, Peñamellera Baja, Asturias). ¿Un conjunto asociado a las Guerras Cántabras?1 Susana de Luis Mariño2; Maria...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  50%|█████     | 4/8 [13:54<12:39, 189.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Con el desarrollo de las excavaciones arqueológicas en diversos asentamientos, el aumento del número de dataciones y la realización de diversos estudios en los últimos años, las perspectivas de investigación sobre el Bronce final en el Levante comienza a variar sustancialmente, estando ya en condi...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  62%|██████▎   | 5/8 [19:24<12:01, 240.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Jover Maestre, F.J., López, J.A. y García, G. (2021): De las primeras comunidades neolíticas a la confi­ guración de los grupos iberos en el Levante de la pe­ nínsula ibérica. Alicante Kristiansen, K. y Larsson, T.B. (2006): La emergen­ cia de la sociedad del Bronce. Viajes, transmisiones y transf...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  75%|███████▌  | 6/8 [23:00<07:44, 232.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Causas internas más o menos imbricadas con la evolución paleoambiental y las respuestas sociales a estos cambios, o bien, de origen externo ligadas a la presión ejer- cida por los primeros grupos neolíticos han sido descritas (García Puchol et al., 2006). - De este modo, la pionera implantación ne...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  88%|████████▊ | 7/8 [27:08<03:57, 237.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_zero_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. MESTRES, J.S. y NICOLÁS, J.C. de, 1999, Contribución de la datación por radiocarbono al establecimiento de la cronología absoluta de la prehistoria de Menorca, Caesaraugusta, 73, Zaragoza, p.327-341. El megalitismo mallorquín en el contexto del... MOLIST, M. y CLOP, X., 2000, La investigación sobr...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas: 100%|██████████| 8/8 [29:43<00:00, 222.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "16/8 preguntas exitosas\n",
      "Evaluando con RAGAS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c88442355da244f3bbff24939af6861c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[2]: TimeoutError()\n",
      "Exception raised in Job[4]: TimeoutError()\n",
      "Exception raised in Job[3]: TimeoutError()\n",
      "Exception raised in Job[6]: TimeoutError()\n",
      "Exception raised in Job[5]: TimeoutError()\n",
      "Exception raised in Job[8]: TimeoutError()\n",
      "Exception raised in Job[7]: TimeoutError()\n",
      "Exception raised in Job[11]: TimeoutError()\n",
      "Exception raised in Job[10]: TimeoutError()\n",
      "Exception raised in Job[9]: TimeoutError()\n",
      "Exception raised in Job[12]: TimeoutError()\n",
      "Exception raised in Job[15]: TimeoutError()\n",
      "Exception raised in Job[14]: TimeoutError()\n",
      "Exception raised in Job[13]: TimeoutError()\n",
      "Exception raised in Job[16]: TimeoutError()\n",
      "Exception raised in Job[18]: TimeoutError()\n",
      "Exception raised in Job[19]: TimeoutError()\n",
      "Exception raised in Job[20]: TimeoutError()\n",
      "Exception raised in Job[21]: TimeoutError()\n",
      "Exception raised in Job[22]: TimeoutError()\n",
      "Exception raised in Job[24]: TimeoutError()\n",
      "Exception raised in Job[23]: TimeoutError()\n",
      "Exception raised in Job[26]: TimeoutError()\n",
      "Exception raised in Job[25]: TimeoutError()\n",
      "Exception raised in Job[29]: TimeoutError()\n",
      "Exception raised in Job[28]: TimeoutError()\n",
      "Exception raised in Job[27]: TimeoutError()\n",
      "Exception raised in Job[31]: TimeoutError()\n",
      "Exception raised in Job[30]: TimeoutError()\n",
      "Exception raised in Job[32]: TimeoutError()\n",
      "Exception raised in Job[35]: TimeoutError()\n",
      "Exception raised in Job[34]: TimeoutError()\n",
      "Exception raised in Job[36]: TimeoutError()\n",
      "Exception raised in Job[37]: TimeoutError()\n",
      "Exception raised in Job[40]: TimeoutError()\n",
      "Exception raised in Job[39]: TimeoutError()\n",
      "Exception raised in Job[38]: TimeoutError()\n",
      "Exception raised in Job[41]: TimeoutError()\n",
      "Exception raised in Job[42]: TimeoutError()\n",
      "Exception raised in Job[43]: TimeoutError()\n",
      "Exception raised in Job[46]: TimeoutError()\n",
      "Exception raised in Job[45]: TimeoutError()\n",
      "Exception raised in Job[44]: TimeoutError()\n",
      "Exception raised in Job[47]: TimeoutError()\n",
      "Exception raised in Job[48]: TimeoutError()\n",
      "Exception raised in Job[50]: TimeoutError()\n",
      "Exception raised in Job[51]: TimeoutError()\n",
      "Exception raised in Job[52]: TimeoutError()\n",
      "Exception raised in Job[53]: TimeoutError()\n",
      "Exception raised in Job[54]: TimeoutError()\n",
      "Exception raised in Job[56]: TimeoutError()\n",
      "Exception raised in Job[55]: TimeoutError()\n",
      "Exception raised in Job[58]: TimeoutError()\n",
      "Exception raised in Job[57]: TimeoutError()\n",
      "Exception raised in Job[59]: TimeoutError()\n",
      "Exception raised in Job[60]: TimeoutError()\n",
      "Exception raised in Job[61]: TimeoutError()\n",
      "Exception raised in Job[62]: TimeoutError()\n",
      "Exception raised in Job[63]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      📊 Columnas disponibles: ['user_input', 'retrieved_contexts', 'response', 'reference', 'context_precision', 'context_recall', 'faithfulness', 'answer_correctness']\n",
      "      📊 Filas en dataset: 16\n",
      "      context_precision: ❌ Sin valores válidos\n",
      "      context_recall: 0.938 (calculado en 4/16 preguntas)\n",
      "      faithfulness: ❌ Sin valores válidos\n",
      "      answer_correctness: ❌ Sin valores válidos\n",
      "RAGAS completado:\n",
      "      Context_Recall: 0.938\n",
      "   ⏸️  Esperando 60 segundos para evitar rate limit...\n",
      "\n",
      "COMBINACIÓN 8/27\n",
      "   LLM: Qwen3-4B-instruct-2507\n",
      "   Embedding: gte-multilingual-base -> IdearqGTE\n",
      "   Prompt: prompt_one_shot\n",
      "Generando respuestas...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Published by Elsevier Inc. All rights reserved. doi:10.1016/j.yqres.2011.12.003 Contents lists available at SciVerse ScienceDirect Quaternary Research journal homepage: www.elsevier.com/locate/yqres https://doi.org/10.1016/j.yqres.2011.12.003 Published online by Cambridge University Press Introduc...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  12%|█▎        | 1/8 [06:00<42:00, 360.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'5.º CONGRESSO DO NEOLÍTICO PENINSULAR 405 1. Introducción La minería del sílex en la Europa prehistórica tiene lugar en un marco cronológico bien conocido. Hay esca‑ sas y ocasionalmente ambiguas evidencias de explota‑ ciones del Pleistoceno (p.e. Baena et al., 2011), alguna dispersa para el Mesolít...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  25%|██▌       | 2/8 [08:19<23:00, 230.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Págs. 253-273 ISBN: 978-84-8317-921-5 · ISBN: 978-84-940141-2-3 Resumen La región cantábrica ha proporcionado una de las principales concentraciones de testimonios funerarios mesolíticos del continente europeo, con un registro prácticamente continuo desde el Aziliense hasta el final del período, e...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  38%|███▊      | 3/8 [12:28<19:55, 239.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. 141 Complutum 32(1) 2021: 141-165 Complutum ISSN: 1131-6993 https://dx.doi.org//cmpl.76452 ARTÍCULOS La panoplia de finales de la IIª Edad del Hierro de la sima de La Cerrosa-Lagaña (Suarías, Peñamellera Baja, Asturias). ¿Un conjunto asociado a las Guerras Cántabras?1 Susana de Luis Mariño2; Maria...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  50%|█████     | 4/8 [13:43<11:37, 174.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Con el desarrollo de las excavaciones arqueológicas en diversos asentamientos, el aumento del número de dataciones y la realización de diversos estudios en los últimos años, las perspectivas de investigación sobre el Bronce final en el Levante comienza a variar sustancialmente, estando ya en condi...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  62%|██████▎   | 5/8 [18:37<10:51, 217.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Jover Maestre, F.J., López, J.A. y García, G. (2021): De las primeras comunidades neolíticas a la confi­ guración de los grupos iberos en el Levante de la pe­ nínsula ibérica. Alicante Kristiansen, K. y Larsson, T.B. (2006): La emergen­ cia de la sociedad del Bronce. Viajes, transmisiones y transf...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  75%|███████▌  | 6/8 [23:38<08:11, 245.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. Causas internas más o menos imbricadas con la evolución paleoambiental y las respuestas sociales a estos cambios, o bien, de origen externo ligadas a la presión ejer- cida por los primeros grupos neolíticos han sido descritas (García Puchol et al., 2006). - De este modo, la pionera implantación ne...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas:  88%|████████▊ | 7/8 [28:41<04:24, 264.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "    -> Entrando en el nodo 'generate'...\n",
      "       - LLM a usar: Qwen3-4B-instruct-2507\n",
      "       - Prompt a usar: prompt_one_shot\n",
      "       - Contexto para el prompt (primeros 300 chars):\\n'. MESTRES, J.S. y NICOLÁS, J.C. de, 1999, Contribución de la datación por radiocarbono al establecimiento de la cronología absoluta de la prehistoria de Menorca, Caesaraugusta, 73, Zaragoza, p.327-341. El megalitismo mallorquín en el contexto del... MOLIST, M. y CLOP, X., 2000, La investigación sobr...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Preguntas: 100%|██████████| 8/8 [31:29<00:00, 236.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> El LLM ha devuelto una respuesta.\n",
      "16/8 preguntas exitosas\n",
      "Evaluando con RAGAS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dc8acbb9f9946ab823d854ea4179e24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[2]: TimeoutError()\n",
      "Exception raised in Job[1]: TimeoutError()\n",
      "Exception raised in Job[5]: TimeoutError()\n",
      "Exception raised in Job[6]: TimeoutError()\n",
      "Exception raised in Job[4]: TimeoutError()\n",
      "Exception raised in Job[3]: TimeoutError()\n",
      "Exception raised in Job[9]: TimeoutError()\n",
      "Exception raised in Job[8]: TimeoutError()\n",
      "Exception raised in Job[7]: TimeoutError()\n",
      "Exception raised in Job[12]: TimeoutError()\n",
      "Exception raised in Job[11]: TimeoutError()\n",
      "Exception raised in Job[10]: TimeoutError()\n",
      "Exception raised in Job[13]: TimeoutError()\n",
      "Exception raised in Job[14]: TimeoutError()\n",
      "Exception raised in Job[15]: TimeoutError()\n",
      "Exception raised in Job[16]: TimeoutError()\n",
      "Exception raised in Job[18]: TimeoutError()\n",
      "Exception raised in Job[19]: TimeoutError()\n",
      "Exception raised in Job[21]: TimeoutError()\n",
      "Exception raised in Job[20]: TimeoutError()\n",
      "Exception raised in Job[22]: TimeoutError()\n",
      "Exception raised in Job[24]: TimeoutError()\n",
      "Exception raised in Job[23]: TimeoutError()\n",
      "Exception raised in Job[25]: TimeoutError()\n",
      "Exception raised in Job[27]: TimeoutError()\n",
      "Exception raised in Job[26]: TimeoutError()\n",
      "Exception raised in Job[28]: TimeoutError()\n",
      "Exception raised in Job[29]: TimeoutError()\n",
      "Exception raised in Job[30]: TimeoutError()\n",
      "Exception raised in Job[31]: TimeoutError()\n"
     ]
    }
   ],
   "source": [
    "# Listas para almacenar resultados\n",
    "df_results_list = []\n",
    "combination_metrics_list = []\n",
    "\n",
    "# Generar todas las combinaciones\n",
    "combinations = list(product(llm_models, embeddings, prompts))\n",
    "total_combinations = len(combinations)\n",
    "\n",
    "# VERIFICAR RESULTADOS PARCIALES\n",
    "existing_combinations = []\n",
    "try:\n",
    "    existing_df = pd.read_csv('rag_evaluation_metrics_20250906_024221.csv')  # Cambiar por tu archivo\n",
    "    existing_combinations = existing_df['combination_id'].tolist()\n",
    "    print(f\"Continuando desde combinación {len(existing_combinations)+1}\")\n",
    "except:\n",
    "    print(\"Empezando evaluación desde el inicio\")\n",
    "\n",
    "print(f\"EVALUACIÓN RAGAS CON {total_combinations} COMBINACIONES\")\n",
    "print(f\"Métricas: context_precision, context_recall, faithfulness, answer_correctness\")\n",
    "print(f\"Evaluador: Mistral API ({mistral_llm.model})\")\n",
    "print(f\"Prompt personalizado en español para arqueología\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Evaluar cada combinación\n",
    "for combo_idx, (test_llm, test_embedding, test_prompt) in enumerate(combinations):\n",
    "\n",
    "    # SALTAR SI YA SE EVALUÓ\n",
    "    if combo_idx in existing_combinations:\n",
    "        print(f\"Saltando combinación {combo_idx+1} (ya evaluada)\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\nCOMBINACIÓN {combo_idx+1}/{total_combinations}\")\n",
    "    print(f\"   LLM: {test_llm}\")\n",
    "    print(f\"   Embedding: {test_embedding} -> {WEAVIATE_CLASSES[test_embedding]}\")\n",
    "    print(f\"   Prompt: {test_prompt}\")\n",
    "\n",
    "    combination_start_time = time.time()\n",
    "    results_list = []\n",
    "    successful_questions = 0\n",
    "\n",
    "    # Generar respuestas para todas las preguntas\n",
    "    print(\"Generando respuestas...\")\n",
    "    for q_idx, question in enumerate(tqdm(questions, desc=\"   Preguntas\")):\n",
    "        try:\n",
    "            state = {\n",
    "                'question': question,\n",
    "                'llm_name': test_llm,\n",
    "                'embedding_name': test_embedding,\n",
    "                'prompt_name': test_prompt,\n",
    "                'context': [], 'answer': '', 'metadata': {}\n",
    "            }\n",
    "\n",
    "            final_state = graph.invoke(state)\n",
    "            answer = final_state.get('answer', '')\n",
    "            contexts = final_state.get('context', [])\n",
    "\n",
    "            if answer and 'ERROR:' not in answer and len(contexts) > 0:\n",
    "                # Almacenar para dataset RAGAS\n",
    "                results_list.append({\n",
    "                    'question': question,\n",
    "                    'answer': answer,\n",
    "                    'contexts': [str(doc.page_content) for doc in contexts],  # Forzar string\n",
    "                    'ground_truth': ground_truths[q_idx] if q_idx < len(ground_truths) else ''\n",
    "                })\n",
    "                successful_questions += 1\n",
    "\n",
    "            # Almacenar para dataset RAGAS\n",
    "            if answer and 'ERROR:' not in answer and len(contexts) > 0:\n",
    "                results_list.append({\n",
    "                    'question': question,\n",
    "                    'answer': final_state.get('answer', ''),\n",
    "                    'contexts': [doc.page_content for doc in final_state.get('context', [])],\n",
    "                    'ground_truth': ground_truths[q_idx] if q_idx < len(ground_truths) else ''\n",
    "                })\n",
    "                successful_questions += 1\n",
    "\n",
    "            # Almacenar detalles individuales\n",
    "            df_results_list.append({\n",
    "                'combination_id': combo_idx,\n",
    "                'llm_model': test_llm,\n",
    "                'embedding_model': test_embedding,\n",
    "                'weaviate_collection': WEAVIATE_CLASSES[test_embedding],\n",
    "                'prompt_type': test_prompt,\n",
    "                'question_id': q_idx,\n",
    "                'question': question,\n",
    "                'answer': answer,\n",
    "                'contexts': [doc.page_content for doc in final_state.get('context', [])],\n",
    "                'num_contexts': len(final_state.get('context', [])),\n",
    "                'ground_truth': ground_truths[q_idx] if q_idx < len(ground_truths) else '',\n",
    "                'status': 'success' if answer and 'ERROR:' not in answer else 'error'\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error en pregunta {q_idx+1}: {e}\")\n",
    "            df_results_list.append({\n",
    "                'combination_id': combo_idx,\n",
    "                'llm_model': test_llm,\n",
    "                'embedding_model': test_embedding,\n",
    "                'weaviate_collection': WEAVIATE_CLASSES[test_embedding],\n",
    "                'prompt_type': test_prompt,\n",
    "                'question_id': q_idx,\n",
    "                'question': question,\n",
    "                'answer': f'ERROR: {str(e)}',\n",
    "                'contexts': [],\n",
    "                'num_contexts': 0,\n",
    "                'ground_truth': ground_truths[q_idx] if q_idx < len(ground_truths) else '',\n",
    "                'status': 'error'\n",
    "            })\n",
    "    print(f\"{successful_questions}/{len(questions)} preguntas exitosas\")\n",
    "\n",
    "    # Evaluar con RAGAS si hay resultados válidos\n",
    "    if successful_questions >= 2:\n",
    "        print(\"Evaluando con RAGAS...\" )\n",
    "\n",
    "        try:\n",
    "            dataset = Dataset.from_list(results_list)\n",
    "            current_embedding_model = EMBEDDING_MODELS[test_embedding]\n",
    "\n",
    "            evaluation_results = evaluate(\n",
    "                dataset,\n",
    "                llm=evaluation_llm,\n",
    "                embeddings=current_embedding_model,\n",
    "                metrics=[\n",
    "                    context_precision,\n",
    "                    context_recall,\n",
    "                    faithfulness,\n",
    "                    answer_correctness\n",
    "                ],\n",
    "                raise_exceptions=False # Continuar si una métrica falla\n",
    "            )\n",
    "\n",
    "            # Extraer métricas promedio\n",
    "            metrics_df = evaluation_results.to_pandas()\n",
    "\n",
    "            if evaluation_results is not None:\n",
    "                # Procesar métricas normalmente\n",
    "                metrics_df = evaluation_results.to_pandas()\n",
    "\n",
    "                # 🔍 DEBUG: Ver qué métricas se calcularon\n",
    "                print(f\"      📊 Columnas disponibles: {list(metrics_df.columns)}\")\n",
    "                print(f\"      📊 Filas en dataset: {len(metrics_df)}\")\n",
    "\n",
    "                # Mostrar valores de cada métrica\n",
    "                for metric in ['context_precision', 'context_recall', 'faithfulness', 'answer_correctness']:\n",
    "                    if metric in metrics_df.columns:\n",
    "                        values = metrics_df[metric].dropna()\n",
    "                        if len(values) > 0:\n",
    "                            print(f\"      {metric}: {values.mean():.3f} (calculado en {len(values)}/{len(metrics_df)} preguntas)\")\n",
    "                        else:\n",
    "                            print(f\"      {metric}: ❌ Sin valores válidos\")\n",
    "                    else:\n",
    "                        print(f\"      {metric}: ❌ Columna no encontrada\")\n",
    "\n",
    "            # Función para calcular métricas seguras\n",
    "            def safe_mean_std(series):\n",
    "                clean_series = series.dropna()\n",
    "                if len(clean_series) > 0:\n",
    "                    return clean_series.mean(), clean_series.std()\n",
    "                return None, None\n",
    "\n",
    "            avg_metrics = {}\n",
    "            for metric in ['context_precision', 'context_recall', 'faithfulness', 'answer_correctness']:\n",
    "                if metric in metrics_df.columns:\n",
    "                    mean_val, std_val = safe_mean_std(metrics_df[metric])\n",
    "                    avg_metrics[f'{metric}_mean'] = mean_val\n",
    "                    avg_metrics[f'{metric}_std'] = std_val\n",
    "\n",
    "            # Guardar métricas de la combinación\n",
    "            combination_metrics = {\n",
    "                'combination_id': combo_idx,\n",
    "                'llm_model': test_llm,\n",
    "                'embedding_model': test_embedding,\n",
    "                'weaviate_collection': WEAVIATE_CLASSES[test_embedding],\n",
    "                'prompt_type': test_prompt,\n",
    "                'total_questions': len(questions),\n",
    "                'successful_questions': successful_questions,\n",
    "                'evaluation_time_seconds': time.time() - combination_start_time,\n",
    "                **avg_metrics\n",
    "            }\n",
    "            combination_metrics_list.append(combination_metrics)\n",
    "\n",
    "            print(f\"RAGAS completado:\")\n",
    "            for metric in ['context_precision_mean', 'context_recall_mean', 'faithfulness_mean', 'answer_correctness_mean']:\n",
    "                if metric in avg_metrics and avg_metrics[metric] is not None:\n",
    "                    print(f\"      {metric.replace('_mean', '').title()}: {avg_metrics[metric]:.3f}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error en evaluación RAGAS: {e}\")\n",
    "            combination_metrics_list.append({\n",
    "                'combination_id': combo_idx,\n",
    "                'llm_model': test_llm,\n",
    "                'embedding_model': test_embedding,\n",
    "                'weaviate_collection': WEAVIATE_CLASSES[test_embedding],\n",
    "                'prompt_type': test_prompt,\n",
    "                'total_questions': len(questions),\n",
    "                'successful_questions': successful_questions,\n",
    "                'evaluation_time_seconds': time.time() - combination_start_time,\n",
    "                'context_precision_mean': None,\n",
    "                'context_recall_mean': None,\n",
    "                'faithfulness_mean': None,\n",
    "                'answer_correctness_mean': None,\n",
    "                'context_precision_std': None,\n",
    "                'context_recall_std': None,\n",
    "                'faithfulness_std': None,\n",
    "                'answer_correctness_std': None,\n",
    "                'error': str(e)\n",
    "                })\n",
    "    else:\n",
    "        print(f\"Solo {successful_questions} preguntas exitosas, saltando RAGAS\")\n",
    "        combination_metrics_list.append({\n",
    "            'combination_id': combo_idx,\n",
    "            'llm_model': test_llm,\n",
    "            'embedding_model': test_embedding,\n",
    "            'weaviate_collection': WEAVIATE_CLASSES[test_embedding],\n",
    "            'prompt_type': test_prompt,\n",
    "            'total_questions': len(questions),\n",
    "            'successful_questions': successful_questions,\n",
    "            'evaluation_time_seconds': time.time() - combination_start_time,\n",
    "            'error': 'Insufficient successful questions'\n",
    "        })\n",
    "\n",
    "    # DELAY ENTRE COMBINACIONES\n",
    "    if combo_idx < len(combinations) - 1:\n",
    "        print(f\"   ⏸️  Esperando 60 segundos para evitar rate limit...\")\n",
    "        time.sleep(60)\n",
    "\n",
    "  # Crear DataFrames finales\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EVALUACIÓN COMPLETADA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "detailed_results_df = pd.DataFrame(df_results_list)\n",
    "metrics_summary_df = pd.DataFrame(combination_metrics_list)\n",
    "\n",
    "print(f\"Evaluaciones detalladas: {detailed_results_df.shape}\")\n",
    "print(f\"Resumen de métricas: {metrics_summary_df.shape}\")\n",
    "\n",
    "# Guardar resultados\n",
    "timestamp = pd.Timestamp.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "detailed_csv = f'rag_evaluation_detailed_{timestamp}.csv'\n",
    "metrics_csv = f'rag_evaluation_metrics_{timestamp}.csv'\n",
    "\n",
    "detailed_results_df.to_csv(detailed_csv, index=False, encoding='utf-8')\n",
    "metrics_summary_df.to_csv(metrics_csv, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"Resultados guardados:\")\n",
    "print(f\"   Detallado: {detailed_csv}\")\n",
    "print(f\"   Métricas: {metrics_csv}\")\n",
    "\n",
    "# Mostrar ranking de mejores combinaciones\n",
    "if not metrics_summary_df.empty:\n",
    "    successful_evaluations = len([c for c in combination_metrics_list if 'error' not in c or not c.get('error')])\n",
    "    print(f\"\\nRESUMEN:\")\n",
    "    print(f\"   Combinaciones totales: {total_combinations}\")\n",
    "    print(f\"   Evaluaciones exitosas: {successful_evaluations}\")\n",
    "    print(f\"   Tasa de éxito: {successful_evaluations/total_combinations*100:.1f}%\")\n",
    "\n",
    "    print(f\"\\nTOP 5 COMBINACIONES POR MÉTRICA:\")\n",
    "\n",
    "    for metric in ['context_precision_mean', 'context_recall_mean', 'faithfulness_mean', 'answer_correctness_mean']:\n",
    "        if metric in metrics_summary_df.columns:\n",
    "            valid_data = metrics_summary_df[metrics_summary_df[metric].notna()]\n",
    "            if not valid_data.empty:\n",
    "                print(f\"\\n{metric.upper().replace('_', ' ')}:\")\n",
    "                top_5 = valid_data.nlargest(5, metric)[['llm_model', 'embedding_model', 'prompt_type', metric]]\n",
    "                print(top_5.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar todas las combinaciones\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "combinations = list(product(llm_models, embeddings, prompts))\n",
    "total_combinations = len(combinations)\n",
    "\n",
    "print(f\"EVALUACIÓN RAGAS CON {total_combinations} COMBINACIONES\")\n",
    "print(f\"Métricas: context_precision, context_recall, faithfulness, answer_correctness\")me s\n",
    "print(f\"Evaluador: Mistral API ({mistral_llm.model})\")\n",
    "print(f\"Embeddings para evaluación: {eval_embeddings}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Evaluar cada combinación\n",
    "for combo_idx, (test_llm, test_embedding, test_prompt) in enumerate(combinations):\n",
    "    print(f\"\\nCOMBINACIÓN {combo_idx+1}/{total_combinations}\")\n",
    "    print(f\"   LLM: {test_llm}\")\n",
    "    print(f\"   Embedding: {test_embedding} -> {WEAVIATE_CLASSES[test_embedding]}\")\n",
    "    print(f\"   Prompt: {test_prompt}\")\n",
    "\n",
    "    combination_start_time = time.time()\n",
    "    results_list = []\n",
    "\n",
    "    # Generar respuestas para todas las preguntas\n",
    "    print(\"Generando respuestas...\")\n",
    "    for q_idx, question in enumerate(tqdm(questions, desc=\"   Preguntas\")):\n",
    "        try:\n",
    "            state = {\n",
    "                'question': question,\n",
    "                'llm_name': test_llm,\n",
    "                'embedding_name': test_embedding,\n",
    "                'prompt_name': test_prompt,\n",
    "                'context': [], 'answer': '', 'metadata': {}\n",
    "            }\n",
    "\n",
    "            final_state = graph.invoke(state)\n",
    "\n",
    "            # Almacenar para dataset RAGAS\n",
    "            results_list.append({\n",
    "                'question': question,\n",
    "                'answer': final_state.get('answer', ''),\n",
    "                'contexts': [doc.page_content for doc in final_state.get('context', [])],\n",
    "                'ground_truth': ground_truths[q_idx] if q_idx < len(ground_truths) else ''\n",
    "            })\n",
    "\n",
    "            # Almacenar detalles individuales\n",
    "            df_results_list.append({\n",
    "                'combination_id': combo_idx,\n",
    "                'llm_model': test_llm,\n",
    "                'embedding_model': test_embedding,\n",
    "                'weaviate_collection': WEAVIATE_CLASSES[test_embedding],\n",
    "                'prompt_type': test_prompt,\n",
    "                'question_id': q_idx,\n",
    "                'question': question,\n",
    "                'answer': final_state.get('answer', ''),\n",
    "                'contexts': [doc.page_content for doc in final_state.get('context', [])],\n",
    "                'num_contexts': len(final_state.get('context', [])),\n",
    "                'ground_truth': ground_truths[q_idx] if q_idx < len(ground_truths) else '',\n",
    "                'status': 'success'\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error en pregunta {q_idx+1}: {e}\")\n",
    "            df_results_list.append({\n",
    "                'combination_id': combo_idx,\n",
    "                'llm_model': test_llm,\n",
    "                'embedding_model': test_embedding,\n",
    "                'weaviate_collection': WEAVIATE_CLASSES[test_embedding],\n",
    "                'prompt_type': test_prompt,\n",
    "                'question_id': q_idx,\n",
    "                'question': question,\n",
    "                'answer': f'ERROR: {str(e)}',\n",
    "                'contexts': [],\n",
    "                'num_contexts': 0,\n",
    "                'ground_truth': ground_truths[q_idx] if q_idx < len(ground_truths) else '',\n",
    "                'status': 'error'\n",
    "            })\n",
    "\n",
    "      # Evaluar con RAGAS si hay resultados válidos\n",
    "    if results_list and len([r for r in results_list if r['answer'] and 'ERROR:' not in r['answer']]) > 0:\n",
    "        print(\"Evaluando con RAGAS...\" )\n",
    "        try:\n",
    "            \n",
    "            # Crear dataset\n",
    "            dataset = Dataset.from_list(results_list)\n",
    "\n",
    "            # Evaluar con RAGAS\n",
    "            current_embedding_model = EMBEDDING_MODELS[test_embedding]\n",
    "            evaluation_results = evaluate(\n",
    "                dataset,\n",
    "                llm=mistral_llm,\n",
    "                embeddings=current_embedding_model,\n",
    "                #embeddings=eval_embeddings,\n",
    "                metrics=[\n",
    "                    context_precision,\n",
    "                    context_recall,\n",
    "                    faithfulness,\n",
    "                    answer_correctness\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            # Extraer métricas promedio\n",
    "            metrics_df = evaluation_results.to_pandas()\n",
    "            avg_metrics = {\n",
    "                'context_precision_mean': metrics_df['context_precision'].mean(),\n",
    "                'context_recall_mean': metrics_df['context_recall'].mean(),\n",
    "                'faithfulness_mean': metrics_df['faithfulness'].mean(),\n",
    "                'answer_correctness_mean': metrics_df['answer_correctness'].mean(),\n",
    "                'context_precision_std': metrics_df['context_precision'].std(),\n",
    "                'context_recall_std': metrics_df['context_recall'].std(),\n",
    "                'faithfulness_std': metrics_df['faithfulness'].std(),\n",
    "                'answer_correctness_std': metrics_df['answer_correctness'].std()\n",
    "            }\n",
    "\n",
    "            # Guardar métricas de la combinación\n",
    "            combination_metrics = {\n",
    "                'combination_id': combo_idx,\n",
    "                'llm_model': test_llm,\n",
    "                'embedding_model': test_embedding,\n",
    "                'weaviate_collection': WEAVIATE_CLASSES[test_embedding],\n",
    "                'prompt_type': test_prompt,\n",
    "                'total_questions': len(questions),\n",
    "                'successful_questions': len([r for r in results_list if r['answer'] and 'ERROR:' not in r['answer']]),\n",
    "                'evaluation_time_seconds': time.time() - combination_start_time,\n",
    "                **avg_metrics\n",
    "            }\n",
    "\n",
    "            combination_metrics_list.append(combination_metrics)\n",
    "\n",
    "            print(f\"RAGAS completado:\")\n",
    "            print(f\"      Context Precision: {avg_metrics['context_precision_mean']:.3f}\")\n",
    "            print(f\"      Context Recall: {avg_metrics['context_recall_mean']:.3f}\")\n",
    "            print(f\"      Faithfulness: {avg_metrics['faithfulness_mean']:.3f}\")\n",
    "            print(f\"      Answer Correctness: {avg_metrics['answer_correctness_mean']:.3f}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error en evaluación RAGAS: {e}\")\n",
    "            # Guardar combinación con error\n",
    "            combination_metrics_list.append({\n",
    "                'combination_id': combo_idx,\n",
    "                'llm_model': test_llm,\n",
    "                'embedding_model': test_embedding,\n",
    "                'weaviate_collection': WEAVIATE_CLASSES[test_embedding],\n",
    "                'prompt_type': test_prompt,\n",
    "                'total_questions': len(questions),\n",
    "                'successful_questions': 0,\n",
    "                'evaluation_time_seconds': time.time() - combination_start_time,\n",
    "                'context_precision_mean': None,\n",
    "                'context_recall_mean': None,\n",
    "                'faithfulness_mean': None,\n",
    "                'answer_correctness_mean': None,\n",
    "                'context_precision_std': None,\n",
    "                'context_recall_std': None,\n",
    "                'faithfulness_std': None,\n",
    "                'answer_correctness_std': None,\n",
    "                'error': str(e)\n",
    "            })\n",
    "    else:\n",
    "        print(\"No hay resultados válidos para evaluar con RAGAS\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EVALUACIÓN COMPLETADA\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear DataFrames finales\n",
    "detailed_results_df = pd.DataFrame(all_results_list)\n",
    "metrics_summary_df = pd.DataFrame(combination_metrics_list)\n",
    "\n",
    "print(f\"Evaluaciones detalladas: {detailed_results_df.shape}\")pero\n",
    "print(f\"Resumen de métricas: {metrics_summary_df.shape}\")\n",
    "\n",
    "# Guardar resultados\n",
    "timestamp = pd.Timestamp.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "detailed_csv = f'rag_evaluation_detailed_{timestamp}.csv'\n",
    "metrics_csv = f'rag_evaluation_metrics_{timestamp}.csv'\n",
    "\n",
    "detailed_results_df.to_csv(detailed_csv, index=False, encoding='utf-8')\n",
    "metrics_summary_df.to_csv(metrics_csv, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"Resultados detallados: {detailed_csv}\")\n",
    "print(f\"Métricas resumen: {metrics_csv}\")\n",
    "\n",
    "# Mostrar ranking de mejores combinaciones\n",
    "if not metrics_summary_df.empty:\n",
    "    print(f\"\\nTOP 5 COMBINACIONES POR MÉTRICA:\")\n",
    "\n",
    "    for metric in ['context_precision_mean', 'context_recall_mean', 'faithfulness_mean', 'answer_correctness_mean']:\n",
    "        if metric in metrics_summary_df.columns:\n",
    "            print(f\"\\n{metric.upper()}:\")\n",
    "            top_5 = metrics_summary_df.nlargest(5, metric)[['llm_model', 'embedding_model', 'prompt_type', metric]]\n",
    "            print(top_5.to_string(index=False))\n",
    "\n",
    "print(f\"\\nEstadísticas generales:\")\n",
    "print(f\"   Total combinaciones: {len(combination_metrics_list)}\")\n",
    "print(f\"   Evaluaciones exitosas: {len([c for c in combination_metrics_list if 'error' not in c])}\")\n",
    "print(f\"   Tasa de éxito: {len([c for c in combination_metrics_list if 'error' not in c])/len(combination_metrics_list)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prueba con una combinación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_llm = 'Phi-3.5-mini-instruct'\n",
    "test_embedding = 'gte-multilingual-base'\n",
    "test_prompt = 'prompt_zero_shot'\n",
    "\n",
    "results_list = []\n",
    "\n",
    "# 3. El bucle que ejecuta el grafo para cada pregunta\n",
    "print(f\"--- Ejecutando bucle con la combinación: {test_llm} | {test_embedding} | {test_prompt} ---\")\n",
    "for q_idx, question in enumerate(questions):\n",
    "    print(f\"Procesando pregunta #{q_idx}...\")\n",
    "    try:\n",
    "        state = {\n",
    "            'question': question,\n",
    "            'llm_name': test_llm,\n",
    "            'embedding_name': test_embedding,\n",
    "            'prompt_name': test_prompt,\n",
    "            'context': [], 'answer': '', 'metadata': {}\n",
    "        }\n",
    "        \n",
    "        final_state = graph.invoke(state)\n",
    "        \n",
    "        results_list.append({\n",
    "            'question': question,\n",
    "            'answer': final_state.get('answer', ''),\n",
    "            'contexts': [doc.page_content for doc in final_state.get('context', [])],\n",
    "            'ground_truth': ground_truths[q_idx] if q_idx < len(ground_truths) else ''\n",
    "        })\n",
    "        print(f\"  -> Pregunta #{q_idx} procesada.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  -> ERROR con la pregunta #{q_idx}: {e}\")\n",
    "\n",
    "# 4. Creamos la variable 'dataset'\n",
    "print(\"\\n--- Bucle terminado. Creando el objeto Dataset... ---\")\n",
    "dataset = Dataset.from_list(results_list)\n",
    "\n",
    "print(\"\\n¡LISTO! La variable 'dataset' ha sido creada.\")\n",
    "print(\"Ahora ya puedes ejecutar la celda de 'evaluate'.\")\n",
    "print(\"\\nContenido del dataset que se ha creado:\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para api mistral\n",
    "from langchain_mistralai import ChatMistralAI\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    context_precision, # Corresponds to your LLMContextPrecision\n",
    "    context_recall,    # Corresponds to your LLMContextRecall\n",
    "    faithfulness,      # Corresponds to your Faithfulness\n",
    "    answer_correctness # Corresponds to your FactualCorrectness\n",
    ")\n",
    "\n",
    "#evaluator_llm = LangchainLLMWrapper(mistral_llm)\n",
    "\n",
    "\n",
    "mistral_llm = ChatMistralAI(api_key=\"dv0RMPhxjgwM6pePID1FXvloyU2iltVu\", model=\"mistral-small-latest\")\n",
    "\n",
    "eval_embeddings = EMBEDDING_MODELS[\"all-MiniLM-L6-v2\"]\n",
    "# La evaluación se ejecuta una vez sobre todo el dataset\n",
    "evaluation_results = evaluate(\n",
    "    dataset=dataset,  \n",
    "    llm=mistral_llm, \n",
    "    embeddings=eval_embeddings, \n",
    "    metrics=[\n",
    "        context_precision,\n",
    "        context_recall,\n",
    "        faithfulness,\n",
    "        answer_correctness,\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 'evaluation_results' ahora contiene los scores.\n",
    "# Puedes convertirlo a un DataFrame de pandas para verlo mejor\n",
    "df_results = evaluation_results.to_pandas()\n",
    "print(df_results.head())\n",
    "\n",
    "# time.sleep(2) probablemente ya no es necesario sin un bucle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG pipeline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
